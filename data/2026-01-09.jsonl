{"id": "2601.04429", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04429", "abs": "https://arxiv.org/abs/2601.04429", "authors": ["Ming Zhou", "Klaus Neymeyr"], "title": "Toward genuine efficiency and cluster robustness of preconditioned CG-like eigensolvers", "comment": "25 pages, 8 figures", "summary": "The performance of eigenvalue problem solvers (eigensolvers) depends on various factors such as preconditioning and eigenvalue distribution. Developing stable and rapidly converging vectorwise eigensolvers is a crucial step in improving the overall efficiency of their blockwise implementations. The present paper is concerned with the locally optimal block preconditioned conjugate gradient (LOBPCG) method for Hermitian eigenvalue problems, and motivated by two recently proposed alternatives for its single-vector version LOPCG. A common basis of these eigensolvers is the well-known CG method for linear systems. However, the optimality of CG search directions cannot perfectly be transferred to CG-like eigensolvers. In particular, while computing clustered eigenvalues, LOPCG and its alternatives suffer from frequent delays, leading to a staircase-shaped convergence behavior which cannot be explained by the existing estimates. Keeping this in mind, we construct a class of cluster robust vector iterations where LOPCG is replaced by asymptotically equivalent two-term recurrences and the search directions are timely corrected by selecting a far previous iterate as augmentation. The new approach significantly reduces the number of required steps and the total computational time."}
{"id": "2601.04479", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04479", "abs": "https://arxiv.org/abs/2601.04479", "authors": ["Ren-Cang Li"], "title": "Approximations of Extremal Eigenspace and Orthonormal Polar Factor", "comment": null, "summary": "This paper is concerned with two extremal problems from matrix analysis. One is about approximating the top eigenspaces of a Hermitian matrix and the other one about approximating the orthonormal polar factor of a general matrix. Tight error bounds on the quality of the approximations are obtained."}
{"id": "2601.04482", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04482", "abs": "https://arxiv.org/abs/2601.04482", "authors": ["Haojun Qin", "Zhiwei Gao", "Jinye Shen", "George Karniadakis"], "title": "Nonlinear parametrization solver for fractional Burgers equations", "comment": null, "summary": "Fractional Burgers equations pose substantial challenges for classical numerical methods due to the combined effects of nonlocality and shock-forming nonlinear dynamics. In particular, linear approximation frameworks-such as spectral, finite-difference, or discontinuous Galerkin methods-often suffer from Gibbs-type oscillations or require carefully tuned stabilization mechanisms, whose effectiveness degrades in transport-dominated and long-time integration regimes. In this work, we introduce a sequential-in-time nonlinear parametrization (STNP) for solving fractional Burgers equations, including models with a fractional Laplacian or with nonlocal nonlinear fluxes. The solution is represented by a nonlinear parametric ansatz, and the parameter evolution is obtained by projecting the governing dynamics onto the tangent space of the parameter manifold through a regularized least-squares formulation at each time step. This yields a well-posed and stable time-marching scheme that preserves causality and avoids global-in-time optimization. We provide a theoretical analysis of the resulting projected dynamics, including a stability estimate and an a posteriori error bound that explicitly decomposes the total error into contributions from initial condition fitting, projection residuals, and discretization of fractional operators. Our analysis clarifies the stabilizing role of regularization and quantifies its interaction with the nonlocal discretization error. Numerical experiments for both fractional Burgers models demonstrate that STNP achieves oscillation-free shock resolution and accurately captures long-time dynamics. The method consistently outperforms high-order spectral schemes augmented with spectral vanishing viscosity, while requiring significantly fewer degrees of freedom and avoiding ad hoc stabilization."}
{"id": "2601.04496", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04496", "abs": "https://arxiv.org/abs/2601.04496", "authors": ["Jie Jiang", "Yuesheng Xu"], "title": "Adaptive Multi-Grade Deep Learning for Highly Oscillatory Fredholm Integral Equations of the Second Kind", "comment": null, "summary": "This paper studies the use of Multi-Grade Deep Learning (MGDL) for solving highly oscillatory Fredholm integral equations of the second kind. We provide rigorous error analyses of continuous and discrete MGDL models, showing that the discrete model retains the convergence and stability of its continuous counterpart under sufficiently small quadrature error. We identify the DNN training error as the primary source of approximation error, motivating a novel adaptive MGDL algorithm that selects the network grade based on training performance. Numerical experiments with highly oscillatory (including wavenumber 500) and singular solutions confirm the accuracy, effectiveness and robustness of the proposed approach."}
{"id": "2601.04371", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04371", "abs": "https://arxiv.org/abs/2601.04371", "authors": ["Alexander Gnedin"], "title": "Optimal Stopping for the Uniform Distribution", "comment": "19 pages, 2 figures", "summary": "Many discrete-time optimal stopping problems are known to have more tractable limit forms based on a planar Poisson process. Using this tool we find a solution to the optimal stopping problem for i.i.d. sequence of $n$ discrete uniform random variables, in the asymptotic regime where $n$ and the range of distribution are of the same order. The optimal stopping rule in the Poisson problem is identified, by means of a time change, with known asymptotic solution to Lindley's problem of minimising the expected rank."}
{"id": "2601.04473", "categories": ["math.ST", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04473", "abs": "https://arxiv.org/abs/2601.04473", "authors": ["Jiaheng Chen", "Daniel Sanz-Alonso"], "title": "Convergence Rates for Learning Pseudo-Differential Operators", "comment": "72 pages, 1 figure", "summary": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing."}
{"id": "2601.04652", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.04652", "abs": "https://arxiv.org/abs/2601.04652", "authors": ["Na Xiang", "Jingtao Shi"], "title": "Stochastic Linear-Quadratic Optimal Control Problems with Markovian Regime Switching and $H_\\infty$ Constraint under Partial Information", "comment": "46 pages, 10 figures", "summary": "This paper is concerned with a stochastic linear-quadratic optimal control problem of Markovian regime switching system with model uncertainty and partial information, where the information available to the control is based on a sub-$σ$-algebra of the filtration generated by the underlying Brownian motion and the Markov chain. Based on $H_\\infty$ control theory, we turn to deal with a soft-constrained zero-sum linear-quadratic stochastic differential game with Markov chain and partial information. By virtue of the filtering technique, the Riccati equation approach, the method of orthogonal decomposition, and the completion-of-squares method, we obtain the closed-loop saddle point of the zero-sum game via the optimal feedback control-strategy pair. Subsequently, we prove that the corresponding outcome of the closed-loop saddle point satisfies the $H_\\infty$ performance criterion. Finally, the obtained theoretical results are applied to a stock market investment problem to further illustrate the practical significance and effectiveness."}
{"id": "2601.04557", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04557", "abs": "https://arxiv.org/abs/2601.04557", "authors": ["Conor Rowan"], "title": "The explicit constraint force method for optimal experimental design", "comment": null, "summary": "The explicit constraint force method (ECFM) was recently introduced as a novel formulation of the physics-informed solution reconstruction problem, and was subsequently extended to inverse problems. In both solution reconstruction and inverse problems, model parameters are estimated with the help of measurement data. In practice, experimentalists seek to design experiments such that the acquired data leads to the most robust recovery of the missing parameters in a subsequent inverse problem. While there are well-established techniques for designing experiments with standard approaches to the inverse problem, optimal experimental design (OED) has yet to be explored with the ECFM formulation. In this work, we investigate OED with a constraint force objective. First, we review traditional approaches to OED based on the Fisher information matrix, and propose an analogous formulation based on constraint forces. Next, we reflect on the different interpretations of the objective from standard and constraint force-based inverse problems. We then test our method on several example problems. These examples suggest that an experiment which is optimal in the sense of constraint forces tends to position measurements in the stiffest regions of the system. Because the responses -- and thus the measurements -- are small in these regions, this strategy is impractical in the presence of measurement noise and/or finite measurement precision. As such, our provisional conclusion is that ECFM is not a viable approach to OED."}
{"id": "2601.04384", "categories": ["math.PR", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.04384", "abs": "https://arxiv.org/abs/2601.04384", "authors": ["Aaron Berger", "Ross Berkowitz", "Pat Devlin", "Van Vu"], "title": "Anti-concentration with respect to random permutations", "comment": null, "summary": "Classical anti-concentration results focus on the random sum $S := \\sum _{i=1}^n ξ_i v_i$, where $ξ_i$ are independent random variables and $v_i$ are real numbers. In this paper, we prove new concentration results concerning the random sum $S := \\sum_{i=1}^n w_{π_i } v_i $, where $w_i , v_i$ are real numbers and $π$ is a random permutation."}
{"id": "2601.04906", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.04906", "abs": "https://arxiv.org/abs/2601.04906", "authors": ["Mohammed Es-Salih Benjrada", "Cecile Durot", "Tommaso Lando"], "title": "Inference for concave distribution functions under measurement error", "comment": null, "summary": "We propose an estimator of a concave cumulative distribution function under the measurement error model, where the non-negative variables of interest are perturbed by additive independent random noise. The estimator is defined as the least concave majorant on the positive half-line of the deconvolution estimator of the distribution function. We show its uniform consistency and its square root convergence in law in $\\ell_\\infty(\\mathbb R)$. To assess the validity of the concavity assumption, we construct a test for the nonparametric null hypothesis that the distribution function is concave on the positive half-line, against the alternative that it is not. We calibrate the test using bootstrap methods. The theoretical justification for calibration led us to establish a bootstrap version of Theorem 1 in Söhl and Trabs (2012), a Donsker-type result from which we obtain, as a special case, the limiting behavior of the deconvolution estimator of the distribution function in a bootstrap setting with measurement error. Combining this Donsker-type theorem with the functional delta method, we show that the test statistic and its bootstrap version have the same limiting distribution under the null hypothesis, whereas under the alternative, the bootstrap statistic is stochastically smaller. Consequently, the power of the test tends to one, for any fixed alternative, as the sample size tends to infinity. In addition to the theoretical results for the estimator and the test, we investigate their finite-sample performance in simulation studies."}
{"id": "2601.04965", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.04965", "abs": "https://arxiv.org/abs/2601.04965", "authors": ["Liqun Qi", "Chunfeng Cui", "Yi Yu"], "title": "Sum of Squares Decompositions and Rank Bounds for Biquadratic Forms", "comment": null, "summary": "We study positive semi-definite (PSD) biquadratic forms and their sum-of-squares (SOS) representations. For the class of partially symmetric biquadratic forms, we establish necessary and sufficient conditions for positive semi-definiteness and prove that every PSD partially symmetric biquadratic form is a sum of squares of bilinear forms. This extends the known result for fully symmetric biquadratic forms. We describe an efficient computational procedure for constructing SOS decompositions, exploiting the Kronecker-product structure of the associated matrix representation. We present a $2 \\times 2$ PSD biquadratic form, and show that it can be expressed as the sum of three squares, but cannot be expressed as the sum of two squares. Furthermore, we present a $3 \\times 2$ PSD biquadratic form, and show that it can be expressed as the sum of four squares, but cannot be expressed as the sum of three squares. These show that previously proved results that a $2 \\times 2$ PSD biquadratic form can be expressed as the sum of three squares, and a $3 \\times 2$ PSD biquadratic form can be expressed as the sum of four squares, are tight."}
{"id": "2601.04628", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04628", "abs": "https://arxiv.org/abs/2601.04628", "authors": ["S. M. Mallikarjunaiah"], "title": "An HHT-$α$-based finite element framework for wave propagation in constitutively nonlinear elastic materials", "comment": null, "summary": "This paper presents a computational framework for modeling wave propagation in geometrically linear elastic materials characterized by algebraically nonlinear constitutive relations. We derive a specific form of the nonlinear wave equation in which the nonlinearity explicitly appears in the time-derivative terms that govern the evolution of the mechanical fields. The numerical solution is established using a fully discrete formulation that combines the standard finite element method for spatial discretization with the implicit Hilber-Hughes-Taylor (HHT)-$α$ scheme for time integration. To address the nonlinear nature of the discrete system, we employ Newton's method to iteratively solve the linearized equations at each time step. The accuracy and robustness of the proposed framework are rigorously verified through convergence analyses, which demonstrate optimal convergence rates in both space and time. Furthermore, a detailed parametric study is conducted to elucidate the influence of the model's constitutive parameters. The results reveal that the magnitude parameter of the stress-dependent variation in wave speed leads to wavefront steepening and the formation of shock discontinuities. Conversely, the exponent parameter acts as a nonlinearity filter; high values suppress nonlinear effects in small-strain regimes, whereas low values allow significant dispersive behavior. This work provides a validated tool for analyzing shock formation in advanced nonlinear materials."}
{"id": "2601.04490", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04490", "abs": "https://arxiv.org/abs/2601.04490", "authors": ["Armen Petrosyan"], "title": "Restoring Convergence in Heavy-Tailed Risk Models: A Weighted Kolmogorov Approach for Robust Backtesting", "comment": null, "summary": "Standard risk metrics used in model validation, such as the Kolmogorov-Smirnov distance, fail to converge at practical rates when applied to high-frequency financial data characterized by heavy tails (infinite skewness). This creates a \"noise barrier\" where valid risk models are rejected due to tail events irrelevant to central tendency accuracy. In this paper, we introduce a Weighted Kolmogorov Metric tailored for financial time series with sub-cubic moments ($\\mathbb{E}|X|^{2+δ}<\\infty$). By incorporating an exhaustion function $h(x)$ that mechanically downweights extreme tail noise, we prove that we can restore the optimal Gaussian convergence rate of $O(n^{-1/2})$ even for Pareto and Student-t distributions common in Crypto and FX markets. We provide a complete proof using a core/tail truncation scheme and establish the optimal tuning of the weight parameter $q$."}
{"id": "2601.05217", "categories": ["math.ST", "cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05217", "abs": "https://arxiv.org/abs/2601.05217", "authors": ["Martin Larsson", "Johannes Ruf", "Aaditya Ramdas"], "title": "A complete characterization of testable hypotheses", "comment": "28 pages", "summary": "We revisit a fundamental question in hypothesis testing: given two sets of probability measures $\\mathcal{P}$ and $\\mathcal{Q}$, when does a nontrivial (i.e.\\ strictly unbiased) test for $\\mathcal{P}$ against $\\mathcal{Q}$ exist? Le~Cam showed that, when $\\mathcal{P}$ and $\\mathcal{Q}$ have a common dominating measure, a test that has power exceeding its level by more than $\\varepsilon$ exists if and only if the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ are separated in total variation distance by more than $\\varepsilon$. The requirement of a dominating measure is frequently violated in nonparametric statistics. In a passing remark, Le~Cam described an approach to address more general scenarios, but he stopped short of stating a formal theorem. This work completes Le~Cam's program, by presenting a matching necessary and sufficient condition for testability: for the aforementioned theorem to hold without assumptions, one must take the closures of the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ in the space of bounded finitely additive measures. We provide simple elucidating examples, and elaborate on various subtle measure theoretic and topological points regarding compactness and achievability."}
{"id": "2601.05029", "categories": ["math.OC", "math.FA", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05029", "abs": "https://arxiv.org/abs/2601.05029", "authors": ["Evie Nielen", "Oliver Tse"], "title": "Stochastic convergence of a class of greedy-type algorithms for Configuration Optimization Problems", "comment": "32 pages, 9 figures", "summary": "Greedy Sampling Methods (GSMs) are widely used to construct approximate solutions of Configuration Optimization Problems (COPs), where a loss functional is minimized over finite configurations of points in a compact domain. While effective in practice, deterministic convergence analyses of greedy-type algorithms are often restrictive and difficult to verify. We propose a stochastic framework in which greedy-type methods are formulated as continuous-time Markov processes on the space of configurations. This viewpoint enables convergence analysis in expectation and in probability under mild structural assumptions on the error functional and the transition kernel. For global error functionals, we derive explicit convergence rates, including logarithmic, polynomial, and exponential decay, depending on an abstract improvement condition. As a pedagogical example, we study stochastic greedy sampling for one-dimensional piecewise linear interpolation and prove exponential convergence of the $L^1$-interpolation error for $C^2$-functions. Motivated by this analysis, we introduce the Randomized Polytope Division Method (R-PDM), a randomized variant of the classical Polytope Division Method, and demonstrate its effectiveness and variance reduction in numerical experiments"}
{"id": "2601.04708", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04708", "abs": "https://arxiv.org/abs/2601.04708", "authors": ["Congpei An", "Alvise Sommariva", "Marco Vianello"], "title": "On the role of weak Marcinkiewicz-Zygmund constants in polynomial approximation by orthogonal bases", "comment": null, "summary": "We compute numerically the $L^2$ Marcinkiewicz-Zygmund constants of cubature rules, with a special attention to their role in polynomial approximation by orthogonal bases. We test some relevant rules on domains such as the interval, the square, the disk, the triangle, the cube and the sphere. The approximation power of the corresponding least squares (LS) projection is compared with standard hyperinterpolation and its recently proposed ``exactness-relaxed'' version. The Matlab codes used for these tests are available in open-source form."}
{"id": "2601.04546", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04546", "abs": "https://arxiv.org/abs/2601.04546", "authors": ["Evgeni Dimitrov", "Christian Serio", "Zongrui Yang"], "title": "The pinned half-space Airy line ensemble", "comment": "58 pages, 1 figure", "summary": "Half-space models in the Kardar-Parisi-Zhang (KPZ) universality class exhibit rich boundary phenomena that alter the asymptotic behavior familiar from their full-space counterparts. A distinguishing feature of these systems is the presence of a boundary parameter that governs a transition between subcritical, critical, and supercritical regimes, characterized by different scaling exponents and fluctuation statistics.\n  In this paper we construct the pinned half-space Airy line ensemble $\\mathcal{A}^{\\mathrm{hs}; \\infty}$ on $[0,\\infty)$ -- a natural half-space analogue of the Airy line ensemble -- expected to arise as the universal scaling limit of supercritical half-space KPZ models. The ensemble $\\mathcal{A}^{\\mathrm{hs}; \\infty}$ is obtained as the weak limit of the critical half-space Airy line ensembles $\\mathcal{A}^{\\mathrm{hs}; \\varpi}$ introduced in arXiv:2505.01798 as the boundary parameter $\\varpi$ tends to infinity.\n  We show that $\\mathcal{A}^{\\mathrm{hs}; \\infty}$ has a Pfaffian point process structure with an explicit correlation kernel and that, after a parabolic shift, it satisfies a one-sided Brownian Gibbs property described by pairwise pinned Brownian motions. Far from the origin, $\\mathcal{A}^{\\mathrm{hs}; \\infty}$ converges to the standard Airy line ensemble, while at the origin its distribution coincides with that of the ordered eigenvalues (with doubled multiplicity) of the stochastic Airy operator with $β= 4$."}
{"id": "2601.04584", "categories": ["math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.04584", "abs": "https://arxiv.org/abs/2601.04584", "authors": ["Behzad Aalipur", "Mohammad S. M. Moakhar"], "title": "Distributional Limits for Eigenvalues of Graphon Kernel Matrices", "comment": null, "summary": "We study fluctuations of individual eigenvalues of kernel matrices arising from dense graphon-based random graphs. Under minimal integrability and boundedness assumptions on the graphon, we establish distributional limits for simple, well-separated eigenvalues of the associated integral operator. We show that a sharp dichotomy governs the asymptotic behavior. In the non-degenerate regime, the properly normalized empirical eigenvalue satisfies a central limit theorem with an explicit variance, whereas in the degenerate regime, the leading fluctuations vanish and the centered eigenvalue converges to an explicit weighted chi-square limit determined by the operator spectrum. Our analysis requires no smoothness or Lipschitz-type assumptions on the graphon. While earlier work under comparable integrability conditions established operator convergence and eigenspace consistency, the present results characterize the full fluctuation behavior of individual eigenvalues, thereby extending eigenvalue fluctuation theory beyond regimes accessible through operator convergence alone."}
{"id": "2601.05056", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05056", "abs": "https://arxiv.org/abs/2601.05056", "authors": ["Silan Zhang", "Yujie Tang"], "title": "ZIVR: An Incremental Variance Reduction Technique For Zeroth-Order Composite Problems", "comment": null, "summary": "This paper investigates zeroth-order (ZO) finite-sum composite optimization. Recently, variance reduction techniques have been applied to ZO methods to mitigate the non-vanishing variance of 2-point estimators in constrained/composite optimization, yielding improved convergence rates. However, existing ZO variance reduction methods typically involve batch sampling of size at least $Θ(n)$ or $Θ(d)$, which can be computationally prohibitive for large-scale problems. In this work, we propose a general variance reduction framework, Zeroth-Order Incremental Variance Reduction (ZIVR), which supports flexible implementations$\\unicode{x2014}$including a pure 2-point zeroth-order algorithm that eliminates the need for large batch sampling. Furthermore, we establish comprehensive convergence guarantees for ZIVR across strongly-convex, convex, and non-convex settings that match their first-order counterparts. Numerical experiments validate the effectiveness of our proposed algorithm."}
{"id": "2601.04839", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04839", "abs": "https://arxiv.org/abs/2601.04839", "authors": ["Abdolreza Amiri", "Gabriel R. Barrenechea", "Tristan Pryer"], "title": "A finite element method preserving the eigenvalue range of symmetric tensor fields", "comment": "29 pages, 8 figures", "summary": "This paper presents a finite element method that preserves (at the degrees of freedom) the eigenvalue range of the solution of tensor-valued time-dependent convection--diffusion equations. Starting from a high-order spatial baseline discretisation (in this case, the CIP stabilised finite element method), our approach formulates the fully discrete problem as a variational inequality posed on a closed convex set of tensor-valued functions that respect the same eigenvalue bounds at their degrees of freedom. The numerical realisation of the scheme relies on the definition of a projection that, at each node, performs the diagonalisation of the tensor and then truncates the eigenvalues to lie within the prescribed bounds. The temporal discretisation is carried out using the implicit Euler method, and unconditional stability and optimal-order error estimates are proven for this choice. Numerical experiments confirm the theoretical findings and illustrate the method's ability to maintain eigenvalue constraints while accurately approximating solutions in the convection-dominated regime."}
{"id": "2601.04584", "categories": ["math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.04584", "abs": "https://arxiv.org/abs/2601.04584", "authors": ["Behzad Aalipur", "Mohammad S. M. Moakhar"], "title": "Distributional Limits for Eigenvalues of Graphon Kernel Matrices", "comment": null, "summary": "We study fluctuations of individual eigenvalues of kernel matrices arising from dense graphon-based random graphs. Under minimal integrability and boundedness assumptions on the graphon, we establish distributional limits for simple, well-separated eigenvalues of the associated integral operator. We show that a sharp dichotomy governs the asymptotic behavior. In the non-degenerate regime, the properly normalized empirical eigenvalue satisfies a central limit theorem with an explicit variance, whereas in the degenerate regime, the leading fluctuations vanish and the centered eigenvalue converges to an explicit weighted chi-square limit determined by the operator spectrum. Our analysis requires no smoothness or Lipschitz-type assumptions on the graphon. While earlier work under comparable integrability conditions established operator convergence and eigenspace consistency, the present results characterize the full fluctuation behavior of individual eigenvalues, thereby extending eigenvalue fluctuation theory beyond regimes accessible through operator convergence alone."}
{"id": "2601.05207", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.05207", "abs": "https://arxiv.org/abs/2601.05207", "authors": ["Sebastián Álvarez", "Julio Deride", "Cristopher Hermosilla"], "title": "On the Value Function of Convex Bolza Problems Governed by Stochastic Difference Equations", "comment": null, "summary": "In this paper we study the value function of Bolza problems governed by stochastic difference equations, with particular emphasis on the convex non-anticipative case. Our goal is to provide some insights on the structure of the subdiferential of the value function. In particular, we establish a connection between the evolution of the subgradients of the value function and a stochastic difference equation of Hamiltonian type. This result can be seen as a transposition of the method of characteristics, introduced by Rockafellar and Wolenski in the 2000s, to the stochastic discrete-time setting. Similarly as done in the literature for the deterministic case, the analysis is based on a duality approach. For this reason we study first a dual representation for the value function in terms of the value function of a dual problem, which is a pseudo Bolza problem. The main difference with the deterministic case is that (due to the non-anticipativity) the symmetry between the Bolza problem and its dual is no longer valid. This in turn implies that ensuring the existence of minimizers for the Bolza problem (which is a key point for establishing the method of characteristics) is not as simple as in the deterministic case, and it should be addressed differently. To complete the exposition, we study the existence of minimizers for a particular class of Bolza problems governed by linear stochastic difference equations, the so-called linear-convex optimal control problems."}
{"id": "2601.04866", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04866", "abs": "https://arxiv.org/abs/2601.04866", "authors": ["Paola F. Antonietti", "Lourenço Beirão da Veiga", "Michele Botti", "André Harnist", "Giuseppe Vacca", "Marco Verani"], "title": "Virtual Element methods for non-Newtonian shear-thickening fluid flow problems", "comment": null, "summary": "In this work, we present a comprehensive theoretical analysis for Virtual Element discretizations of incompressible non-Newtonian flows governed by the Carreau-Yasuda constitutive law, in the shear-thickening regime (r > 2) including both degenerate (delta = 0) and non-degenerate (delta > 0) cases. The proposed Virtual Element method features two distinguishing advantages: the construction of an exactly divergence-free discrete velocity field and compatibility with general polygonal meshes. The analysis presented in this work extends a previous work, where only shear-thinning behavior (1 < r < 2) was considered. Indeed, the theoretical analysis of the shear-thickening setting requires several novel analytical tools, including: an inf-sup stability analysis of the discrete velocity-pressure coupling in non-Hilbertian norms, a stabilization term specifically designed to address the nonlinear structure as the exponent r > 2; and the introduction of a suitable discrete norm tailored to the underlying nonlinear constitutive relation. Numerical results demonstrate the practical performance of the proposed formulation."}
{"id": "2601.04677", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04677", "abs": "https://arxiv.org/abs/2601.04677", "authors": ["Simmaco Di Lillo", "Claudio Macci", "Barbara Pacchiarotti"], "title": "Large deviation principles and functional limit theorems in the deep limit of wide random neural networks", "comment": "22 pages", "summary": "This paper studies large deviation principles and weak convergence,\n  both at the level of finite-dimensional distributions and in functional form,\n  for a class of continuous, isotropic, centered Gaussian random\n  fields defined on the unit sphere. The covariance functions of these\n  fields evolve recursively through a nonlinear map induced by an\n  activation function, reflecting the statistical dynamics of infinitely\n  wide random neural networks as depth increases.\n  We consider two types of centered fields, obtained by subtracting either the value at the\n  North Pole or the spherical average. According to the behavior of the derivative at $t=1$ of the associated covariance function, we identify three regimes: low disorder, sparse, and high disorder.\n  In the low-disorder regime, we establish functional large deviation principles and weak\n  convergence results. In the sparse regime, we obtain large deviation\n  principles and weak convergence for finite-dimensional distributions,\n  while both properties fail at the functional level sense due to the emergence of discontinuities\n  in the covariance recursion."}
{"id": "2601.04999", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04999", "abs": "https://arxiv.org/abs/2601.04999", "authors": ["Alessandro Lanza", "Serena Morigi", "Youwei Wen", "Li Yang"], "title": "Guided Variational Network for Image Decomposition", "comment": null, "summary": "Cartoon-texture image decomposition is a critical preprocessing problem bottlenecked by the numerical intractability of classical variational or optimization models and the tedious manual tuning of global regularization parameters.We propose a Guided Variational Decomposition (GVD) model which introduces spatially adaptive quadratic norms whose pixel-wise weights are learned either through local probabilistic statistics or via a lightweight neural network within a bilevel framework.This leads to a unified, interpretable, and computationally efficient model that bridges classical variational ideas with modern adaptive and data-driven methodologies. Numerical experiments on this framework, which inherently includes automatic parameter selection, delivers GVD as a robust, self-tuning, and superior solution for reliable image decomposition."}
{"id": "2601.04738", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04738", "abs": "https://arxiv.org/abs/2601.04738", "authors": ["Tsukasa Moritoki", "Dai Taguchi"], "title": "Strong rate of convergence for the Euler--Maruyama scheme of SDEs with unbounded Hölder continuous drift coefficient", "comment": "20 pages", "summary": "In this paper, we provide the strong rate of convergence for the Euler--Maruyama scheme for multi-dimensional stochastic differential equations with uniformly locally (unbounded) Hölder continuous drift and multiplicative noise. Our technique is based on Itô--Tanaka trick (Zvonkin transformation) for unbounded drift. Moreover, in order to apply the stochastic sewing lemma, we use the heat kernel estimate for the density function of the Euler--Maruyama scheme."}
{"id": "2601.05146", "categories": ["math.NA", "math.AP", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.05146", "abs": "https://arxiv.org/abs/2601.05146", "authors": ["Jan Bouwe van den Berg", "Maxime Breden"], "title": "A simple rigorous integrator for semilinear parabolic PDEs", "comment": null, "summary": "Simulations of the dynamics generated by partial differential equations (PDEs) provide approximate, numerical solutions to initial value problems. Such simulations are ubiquitous in scientific computing, but the correctness of the results is usually not guaranteed. We propose a new method for the rigorous integration of parabolic PDEs, i.e., the derivation of rigorous and explicit error bounds between the numerically obtained approximate solution and the exact one, which is then proven to exist over the entire time interval considered. These guaranteed error bounds are obtained a posteriori, using a fixed point reformulation based on a piece-wise in time constant approximation of the linearization around the numerical solution. Our setup leads to relatively simple-to-understand estimates, which has several advantages. Most critically, it allows us to optimize various aspects of the proof, and in particular to provide an adaptive time-stepping strategy. In case the solution converges to a stable hyperbolic equilibrium, we are also able to prove this convergence, applying our rigorous integrator with a final, infinitely long timestep. We showcase the ability of our method to rigorously integrate over relatively long time intervals, and to capture non-trivial dynamics, via examples on the Swift--Hohenberg equation, the Ohta--Kawasaki equation and the Kuramoto--Sivashinsky equation. We expect that the simplicity and efficiency of the approach will enable generalization to a wide variety of other parabolic PDEs, as well as applications to boundary value problems."}
{"id": "2601.04840", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04840", "abs": "https://arxiv.org/abs/2601.04840", "authors": ["Antoine Jego", "Titus Lupu"], "title": "Three-dimensional Brownian loop soup clusters", "comment": "38 pages, 2 figures", "summary": "We study Brownian loop soup clusters in $\\mathbb{R}^3$ for an arbitrary intensity $α>0$. We show the existence of a phase transition for the presence of unbounded clusters and study its basic properties. In particular, we show that, when $α$ is sufficiently large, almost surely all the loops are connected into a single cluster. Such a phenomenon is not observed in discrete percolation-type models. In addition, we prove the existence of a one-arm exponent and compare the clusters with the finite-range system obtained by imposing lower and upper bounds on the diameter of the loops.\n  Finally, we provide a toolbox concerning the Brownian loop measure in $\\mathbb{R}^d$, $d \\ge 3$. In particular, we derive decomposition formulas by rerooting the loops in specific ways and show that the loop measure is conformally invariant, generalising results of [Lup18] in dimension 1 and [LW04] in dimension 2."}
{"id": "2601.05224", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.05224", "abs": "https://arxiv.org/abs/2601.05224", "authors": ["Delfina B. Comerso Salzer", "Malena I. Español", "Gabriela Jeronimo"], "title": "Variable Projection Methods for Solving Regularized Separable Inverse Problems with Applications to Semi-Blind Image Deblurring", "comment": "26 pages", "summary": "Separable nonlinear least squares problems appear in many inverse problems, including semi-blind image deblurring. The variable projection (VarPro) method provides an efficient approach for solving such problems by eliminating linear variables and reducing the problem to a smaller, nonlinear one. In this work, we extend VarPro to solve minimization problems containing a differentiable regularization term on the nonlinear parameters, along with a general-form Tikhonov regularization term on the linear variables. Furthermore, we develop a quasi-Newton method for solving the resulting reduced problem, and provide a local convergence analysis under standard smoothness assumptions, establishing conditions for superlinear or quadratic convergence. For large-scale settings, we introduce an inexact LSQR-based variant and prove its local convergence despite inner-solve and Hessian approximations. Numerical experiments on semi-blind deblurring show that parameter regularization prevents degenerate no-blur solutions and that the proposed methods achieve accurate reconstructions, with the inexact variant offering a favorable accuracy-cost tradeoff consistent with the theory."}
{"id": "2601.04850", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04850", "abs": "https://arxiv.org/abs/2601.04850", "authors": ["Andrius Grigutis", "Laurynas Lukoševičius", "Mindaugas Venckevičius"], "title": "Several expressions of the net single premiums under the constant force of mortality", "comment": null, "summary": "In this article, we present several formulas that make it easier to compute the net single premiums when the mortality force over the fractional ages is assumed to be constant (C). More precisely, we compute the moments of the random variables $ν^{T_x}$, $T_x$, $T_xν^{T_x}$, etc., where $T_x$ denotes the future lifetime of a person who is $x\\in\\{0,\\,1,\\,\\ldots\\}$ years old, and $ν$ is the annual discount multiplier. We verify the obtained formulas on the real data from the human mortality table and the Gompertz survival law. The obtained numbers are compared with the corresponding ones when the survival function over fractional ages is interpolated using the uniform distribution of deaths (UDD) and Balducci's (B) assumptions. We also formulate and prove the statement on the comparison of the moments of the mentioned random variables under assumptions (C), (UDD), and (B)."}
{"id": "2601.04473", "categories": ["math.ST", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04473", "abs": "https://arxiv.org/abs/2601.04473", "authors": ["Jiaheng Chen", "Daniel Sanz-Alonso"], "title": "Convergence Rates for Learning Pseudo-Differential Operators", "comment": "72 pages, 1 figure", "summary": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing."}
{"id": "2601.04863", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04863", "abs": "https://arxiv.org/abs/2601.04863", "authors": ["Axel Péneau"], "title": "Convergence to Stable Laws for Products of Random Matrices", "comment": null, "summary": "Under reasonable algebraic assumptions and under an infinite second order moment assumption, we show that the logarithm of the norm (log-norm) of a product of random i.i.d. matrices with entries in $\\mathbb{R}$ or in any other local field satisfies a generalized Central Limit Theorem (GCLT) in the sense of Paul Lévi.\n  The proof is based on a weak law of large number for the difference $Δ_n$ between the log-norm of the product of the first $n$ matrices and the sum of their log-norms. This weak law of large numbers morally says that $Δ_n$ behaves like a sum of i.i.d. random variables that have a finite moment of order $2q$ as long as the log-norm of each matrices has a finite moment of order $q$ for a given $q > 0$.\n  This gain of moment is the central result of the present paper and is based on the construction of pivotal times. Moreover, these results admit a nice higher rank extension when one looks at the full Cartan projection instead of the log-norm."}
{"id": "2601.05029", "categories": ["math.OC", "math.FA", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05029", "abs": "https://arxiv.org/abs/2601.05029", "authors": ["Evie Nielen", "Oliver Tse"], "title": "Stochastic convergence of a class of greedy-type algorithms for Configuration Optimization Problems", "comment": "32 pages, 9 figures", "summary": "Greedy Sampling Methods (GSMs) are widely used to construct approximate solutions of Configuration Optimization Problems (COPs), where a loss functional is minimized over finite configurations of points in a compact domain. While effective in practice, deterministic convergence analyses of greedy-type algorithms are often restrictive and difficult to verify. We propose a stochastic framework in which greedy-type methods are formulated as continuous-time Markov processes on the space of configurations. This viewpoint enables convergence analysis in expectation and in probability under mild structural assumptions on the error functional and the transition kernel. For global error functionals, we derive explicit convergence rates, including logarithmic, polynomial, and exponential decay, depending on an abstract improvement condition. As a pedagogical example, we study stochastic greedy sampling for one-dimensional piecewise linear interpolation and prove exponential convergence of the $L^1$-interpolation error for $C^2$-functions. Motivated by this analysis, we introduce the Randomized Polytope Division Method (R-PDM), a randomized variant of the classical Polytope Division Method, and demonstrate its effectiveness and variance reduction in numerical experiments"}
{"id": "2601.04865", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04865", "abs": "https://arxiv.org/abs/2601.04865", "authors": ["Konstantin A. Rybakov"], "title": "Forming invariant stochastic differential systems with a given first integral", "comment": null, "summary": "This article proposes a method for forming invariant stochastic differential systems, namely dynamic systems with trajectories belonging to a given smooth manifold. The Itô or Stratonovich stochastic differential equations with the Wiener component describe dynamic systems, and the manifold is implicitly defined by a differentiable function. A convenient implementation of the algorithm for forming invariant stochastic differential systems within symbolic computation environments characterizes the proposed method. It is based on determining a basis associated with a tangent hyperplane to the manifold. The article discusses the problem of basis degeneration and examines variants that allow for the simple construction of a basis that does not degenerate. Examples of invariant stochastic differential systems are given, and numerical simulations are performed for them."}
{"id": "2601.04869", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04869", "abs": "https://arxiv.org/abs/2601.04869", "authors": ["Samuel G. G. Johnston"], "title": "Log-concavity and concentration bounds for a single gap between GUE eigenvalues", "comment": "8 pages", "summary": "We observe that the distribution of the eigenvalues of an $N$-by-$N$ GUE random matrix is log-concave on $\\mathbb{R}^N$, and that the same is true for the law of a single gap between two consecutive eigenvalues. We use this observation to prove several concentration bounds for the semicircle-renormalised eigengaps, improving on bounds recently obtained in [Tao (2024). On the distribution of eigenvalues of GUE and its minors at fixed index. [arXiv:2412.10889]."}
{"id": "2601.04974", "categories": ["math.PR", "math-ph", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.04974", "abs": "https://arxiv.org/abs/2601.04974", "authors": ["Manh Hong Duong", "Hung Dang Nguyen", "Wenxuan Tao"], "title": "Ergodicity and asymptotic limits for Langevin interacting systems with singular forces and multiplicative noises", "comment": null, "summary": "In this paper, we study systems of $N$ interacting particles described by the classical and relativistic Langevin dynamics with singular forces and multiplicative noises. For the classical model, we prove the ergodicity, obtaining an exponential rate of convergence to the invariant Boltzmann-Gibbs distribution, and the small-mass limit, recovering the $N$-particle interacting overdamped Langevin dynamics. For the relativistic model, we establish the ergodicity, obtaining an algebraic mixing rate of any order to the Maxwell-Jüttner distribution, and the Newtonian limit (that is when the speed of light tends to infinity), approximating a system of underdamped Langevin dynamics. The proofs rely on the construction of Lyapunov functions that account for irregular potentials and multiplicative noises."}
{"id": "2601.04997", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.04997", "abs": "https://arxiv.org/abs/2601.04997", "authors": ["Patrícia Gonçalves", "Adriana Neumann", "Maria Chiara Ricciuti"], "title": "Fluctuations of the Boundary-Driven Symmetric Zero-Range Process from the NESS", "comment": "54 pages, 3 figures", "summary": "We study the non-equilibrium stationary fluctuations of a symmetric zero-range process on the discrete interval $\\{1, \\ldots, N-1\\}$ coupled to reservoirs at sites $1$ and $N-1$, which inject and remove particles at rates proportional to $N^{-θ}$ for any value of $θ\\in\\mathbb{R}$. We prove that, if the jump rate is bounded and under diffusive scaling, the fluctuations converge to the solution of a generalised Ornstein-Uhlenbeck equation with characteristic operators that depend on the stationary density profile. The limiting equation is supplemented with boundary conditions of Dirichlet, Robin, or Neumann type, depending on the strength of the reservoirs. We also introduce two notions of solutions to the corresponding martingale problems, which differ according to the choice of test functions."}
{"id": "2601.05029", "categories": ["math.OC", "math.FA", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05029", "abs": "https://arxiv.org/abs/2601.05029", "authors": ["Evie Nielen", "Oliver Tse"], "title": "Stochastic convergence of a class of greedy-type algorithms for Configuration Optimization Problems", "comment": "32 pages, 9 figures", "summary": "Greedy Sampling Methods (GSMs) are widely used to construct approximate solutions of Configuration Optimization Problems (COPs), where a loss functional is minimized over finite configurations of points in a compact domain. While effective in practice, deterministic convergence analyses of greedy-type algorithms are often restrictive and difficult to verify. We propose a stochastic framework in which greedy-type methods are formulated as continuous-time Markov processes on the space of configurations. This viewpoint enables convergence analysis in expectation and in probability under mild structural assumptions on the error functional and the transition kernel. For global error functionals, we derive explicit convergence rates, including logarithmic, polynomial, and exponential decay, depending on an abstract improvement condition. As a pedagogical example, we study stochastic greedy sampling for one-dimensional piecewise linear interpolation and prove exponential convergence of the $L^1$-interpolation error for $C^2$-functions. Motivated by this analysis, we introduce the Randomized Polytope Division Method (R-PDM), a randomized variant of the classical Polytope Division Method, and demonstrate its effectiveness and variance reduction in numerical experiments"}
{"id": "2601.05217", "categories": ["math.ST", "cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05217", "abs": "https://arxiv.org/abs/2601.05217", "authors": ["Martin Larsson", "Johannes Ruf", "Aaditya Ramdas"], "title": "A complete characterization of testable hypotheses", "comment": "28 pages", "summary": "We revisit a fundamental question in hypothesis testing: given two sets of probability measures $\\mathcal{P}$ and $\\mathcal{Q}$, when does a nontrivial (i.e.\\ strictly unbiased) test for $\\mathcal{P}$ against $\\mathcal{Q}$ exist? Le~Cam showed that, when $\\mathcal{P}$ and $\\mathcal{Q}$ have a common dominating measure, a test that has power exceeding its level by more than $\\varepsilon$ exists if and only if the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ are separated in total variation distance by more than $\\varepsilon$. The requirement of a dominating measure is frequently violated in nonparametric statistics. In a passing remark, Le~Cam described an approach to address more general scenarios, but he stopped short of stating a formal theorem. This work completes Le~Cam's program, by presenting a matching necessary and sufficient condition for testability: for the aforementioned theorem to hold without assumptions, one must take the closures of the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ in the space of bounded finitely additive measures. We provide simple elucidating examples, and elaborate on various subtle measure theoretic and topological points regarding compactness and achievability."}
