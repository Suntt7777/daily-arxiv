{"id": "2601.11701", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.11701", "abs": "https://arxiv.org/abs/2601.11701", "authors": ["Abhinav Chakraborty", "Yuetian Luo", "Rina Foygel Barber"], "title": "Stability and Accuracy Trade-offs in Statistical Estimation", "comment": "The first two authors contributed equally and are listed in alphabetical order", "summary": "Algorithmic stability is a central concept in statistics and learning theory that measures how sensitive an algorithm's output is to small changes in the training data. Stability plays a crucial role in understanding generalization, robustness, and replicability, and a variety of stability notions have been proposed in different learning settings. However, while stability entails desirable properties, it is typically not sufficient on its own for statistical learning -- and indeed, it may be at odds with accuracy, since an algorithm that always outputs a constant function is perfectly stable but statistically meaningless. Thus, it is essential to understand the potential statistical cost of stability. In this work, we address this question by adopting a statistical decision-theoretic perspective, treating stability as a constraint in estimation. Focusing on two representative notions-worst-case stability and average-case stability-we first establish general lower bounds on the achievable estimation accuracy under each type of stability constraint. We then develop optimal stable estimators for four canonical estimation problems, including several mean estimation and regression settings. Together, these results characterize the optimal trade-offs between stability and accuracy across these tasks. Our findings formalize the intuition that average-case stability imposes a qualitatively weaker restriction than worst-case stability, and they further reveal that the gap between these two can vary substantially across different estimation problems."}
{"id": "2601.11717", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.11717", "abs": "https://arxiv.org/abs/2601.11717", "authors": ["Elchanan Mossel", "Anirudh Sridhar"], "title": "Detecting Mutual Excitations in Non-Stationary Hawkes Processes", "comment": "12 pages", "summary": "We consider the problem of learning the network of mutual excitations (i.e., the dependency graph) in a non-stationary, multivariate Hawkes process. We consider a general setting where baseline rates at each node are time-varying and delay kernels are not shift-invariant. Our main results show that if the dependency graph of an $n$-variate Hawkes process is sparse (i.e., it has a maximum degree that is bounded with respect to $n$), our algorithm accurately reconstructs it from data after observing the Hawkes process for $T = \\mathrm{polylog}(n)$ time, with high probability. Our algorithm is computationally efficient, and provably succeeds in learning dependencies even if only a subset of time series are observed and event times are not precisely known."}
{"id": "2601.12064", "categories": ["math.ST", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.12064", "abs": "https://arxiv.org/abs/2601.12064", "authors": ["Nadezhda Gribkova", "Jianxi Su", "Mengqi Wang"], "title": "Expansion and Bounds for the Bias of Empirical Tail Value-at-Risk", "comment": "38 pages, 7 figures", "summary": "Tail Value-at-Risk (TVaR) is a widely adopted risk measure playing a critically important role in both academic research and industry practice in insurance. In data applications, TVaR is often estimated using the empirical method, owing to its simplicity and nonparametric nature. The empirical TVaR has been explicitly advocated by regulatory authorities as a standard approach for computing TVaR. However, prior literature has pointed out that the empirical TVaR estimator is negatively biased, which can lead to a systemic underestimation of risk in finite-sample applications. This paper aims to deepen the understanding of the bias of the empirical TVaR estimator in two dimensions: its magnitude as well as the key distributional and structural determinants driving the severity of the bias. To this end, we derive a leading-term approximation for the bias based on its asymptotic expansion. The closed-form expression associated with the leading-term approximation enables us to obtain analytical insights into the structural properties governing the bias of the empirical TVaR estimator. To account for the discrepancy between the leading-term approximation and the true bias, we further derive an explicit upper bound for the bias. We validate the proposed bias analysis framework via simulations and demonstrate its practical relevance using real data."}
{"id": "2601.12957", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.12957", "abs": "https://arxiv.org/abs/2601.12957", "authors": ["Hanne Kekkonen", "Andreas Tataris"], "title": "Random tree Besov priors: Data-driven regularisation parameter selection", "comment": null, "summary": "We develop a data-driven algorithm for automatically selecting the regularisation parameter in Bayesian inversion under random tree Besov priors. One of the key challenges in Bayesian inversion is the construction of priors that are both expressive and computationally feasible. Random tree Besov priors, introduced in Kekkonen et al. (2023), provide a flexible framework for capturing local regularity properties and sparsity patterns in a wavelet basis. In this paper, we extend this approach by introducing a hierarchical model that enables data-driven selection of the wavelet density parameter, allowing the regularisation strength to adapt across scales while retaining computational efficiency. We focus on nonparametric regression and also present preliminary plug-and-play results for a deconvolution problem."}
{"id": "2601.11626", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11626", "abs": "https://arxiv.org/abs/2601.11626", "authors": ["Maksym Shamrai"], "title": "Concatenated Matrix SVD: Compression Bounds, Incremental Approximation, and Error-Constrained Clustering", "comment": null, "summary": "Large collections of matrices arise throughout modern machine learning, signal processing, and scientific computing, where they are commonly compressed by concatenation followed by truncated singular value decomposition (SVD). This strategy enables parameter sharing and efficient reconstruction and has been widely adopted across domains ranging from multi-view learning and signal processing to neural network compression. However, it leaves a fundamental question unanswered: which matrices can be safely concatenated and compressed together under explicit reconstruction error constraints? Existing approaches rely on heuristic or architecture-specific grouping and provide no principled guarantees on the resulting SVD approximation error. In the present work, we introduce a theory-driven framework for compression-aware clustering of matrices under SVD compression constraints. Our analysis establishes new spectral bounds for horizontally concatenated matrices, deriving global upper bounds on the optimal rank-$r$ SVD reconstruction error from lower bounds on singular value growth. The first bound follows from Weyl-type monotonicity under blockwise extensions, while the second leverages singular values of incremental residuals to yield tighter, per-block guarantees. We further develop an efficient approximate estimator based on incremental truncated SVD that tracks dominant singular values without forming the full concatenated matrix. Therefore, we propose three clustering algorithms that merge matrices only when their predicted joint SVD compression error remains below a user-specified threshold. The algorithms span a trade-off between speed, provable accuracy, and scalability, enabling compression-aware clustering with explicit error control. Code is available online."}
{"id": "2601.11588", "categories": ["math.PR", "math.AP", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11588", "abs": "https://arxiv.org/abs/2601.11588", "authors": ["Shuhui Liu", "Xintian Liu", "Chenchen Mou", "Defeng Sun"], "title": "The global well-posedness for master equations of mean field games of controls", "comment": "27 pages", "summary": "In this manuscript, we establish the global well-posedness for master equations of mean field games of controls, where the interaction is through the joint law of the state and control. Our results are proved under two different conditions: the Lasry-Lions monotonicity and the displacement $λ$-monotonicity, both considered in their integral forms. We provide a detailed analysis of both the differential and integral versions of these monotonicity conditions for the corresponding nonseparable Hamiltonian and examine their relation. The proof of global well-posedness relies on the propagation of these monotonicity conditions in their integral forms and a priori uniform Lipschitz continuity of the solution with respect to the measure variable."}
{"id": "2601.11548", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11548", "abs": "https://arxiv.org/abs/2601.11548", "authors": ["Tao Hu"], "title": "Robustness of the Frank-Wolfe Method under Inexact Oracles and the Cost of Linear Minimization", "comment": "11 pages", "summary": "We investigate the robustness of the Frank-Wolfe method when gradients are computed inexactly and examine the relative computational cost of the linear minimization oracle (LMO) versus projection. For smooth nonconvex functions, we establish a convergence guarantee of order $\\mathcal{O}(1/\\sqrt{k}+δ)$ for Frank-Wolfe with a $δ$--oracle. Our results strengthen previous analyses for convex objectives and show that the oracle errors do not accumulate asymptotically. We further prove that approximate projections cannot be computationally cheaper than accurate LMOs, thus extending to the case of inexact projections. These findings reinforce the robustness and efficiency of the Frank-Wolfe framework."}
{"id": "2601.13254", "categories": ["math.ST", "math.AP", "math.FA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13254", "abs": "https://arxiv.org/abs/2601.13254", "authors": ["Dimitri Konen"], "title": "Inverting the Fisher information operator in non-linear models", "comment": null, "summary": "We consider non-linear regression models corrupted by generic noise when the regression functions form a non-linear subspace of L^2, relevant in non-linear PDE inverse problems and data assimilation. We show that when the score of the model is injective, the Fisher information operator is automatically invertible between well-identified Hilbert spaces, and we provide an operational characterization of these spaces. This allows us to construct in broad generality the efficient Gaussian involved in the classical minimax and convolution theorems to establish information lower bounds, that are typically achieved by Bayesian algorithms thus showing optimality of these methods. We illustrate our results on time-evolution PDE models for reaction-diffusion and Navier-Stokes equations."}
{"id": "2601.11677", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.11677", "abs": "https://arxiv.org/abs/2601.11677", "authors": ["Muhammad Ammad", "Md Yushalify Misro", "Samia Bibi", "Ahmad Ramli"], "title": "Dirichlet Extremals for Discrete Plateau Problems in GT-Bezier Spaces via PSO", "comment": null, "summary": "We study a discrete analogue of the parametric Plateau problem in a non-polynomial tensor-product surface spaces generated by the generalized trigonometric (GT)--Bézier basis. Boundary interpolation is imposed by prescribing the boundary rows and columns of the control net, while the interior control points are selected by a Dirichlet principle: for each admissible choice of Bézier basis shape parameters, we compute the unique Dirichlet-energy extremal within the corresponding GT--Bézier patch space, which yields a parameter-dependent symmetric linear system for the interior control net under standard nondegeneracy assumptions. The remaining design freedom is thereby reduced to a four-parameter optimization problem, which we solve by particle swarm optimization. Numerical experiments show that the resulting two-level procedure consistently decreases the Dirichlet energy and, in our tests, often reduces the realized surface area relative to classical Bernstein--Bézier Dirichlet patches and representative quasi-harmonic and bending-energy constructions under identical boundary control data. We further adapt the same Dirichlet-extremal methodology to a hybrid tensor-product/bilinear Coons framework, obtaining minimality-biased TB--Coons patches from sparse boundary specifications."}
{"id": "2601.11820", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.11820", "abs": "https://arxiv.org/abs/2601.11820", "authors": ["Davide Gabrielli", "Federica Iacovissi"], "title": "Large deviations and the matrix product ansatz", "comment": "31 pages, 3 figures", "summary": "We consider probability measures on $A^N$, the set of sequences of symbols on a finite alphabet $A$ of length $N$, that give a weight to each sequence in terms of a collection of matrices with non-negative entries and having rows and columns labeled by a finite or countable set $B$. We prove for such kind of measures large deviations principles for several empirical measures. Our approach is based on a simultaneous combination of an enlargement of the state space to sequences on $A\\times B$ and a spectral conjugation that produces a stochastic matrix, as discussed in \\cite{GI1}. As a result we describe the measures as hidden Markov measures and can deduce the large deviations results by contraction from the corresponding ones for the enlarged Markov chain. The measure on the enlarged state space is a Markov bridge. The invariant measures of several non equilibrium models of interacting particle systems can be represented by the so called {\\it Matrix Product Ansatz} that corresponds to measures of the type that we consider and with matrices labeled by $B$ that is typically countable infinite. The large deviations behavior is different in the cases with $B$ finite or countable. In the finite case we give a variational formula for both the algebraic and the spatial empirical measures, that can be solved in special cases. For the infinite case, we illustrate the method through an example that is the invariant measure of the boundary driven TASEP model in a special regime. We recover in this way the celebrated results in \\cite{Der4,Derr7}, and in particular we obtain a variational representation of the rate function similar to that in \\cite{Bryc}. Our approach is general and can in principle be applied to any measure represented by the matrix product ansatz with matrices having positive entries."}
{"id": "2601.11552", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11552", "abs": "https://arxiv.org/abs/2601.11552", "authors": ["Triloki Nath", "Manohar Choudhary"], "title": "Minimal Perimeter Triangle in Nonconvex Quadrilateral:Generalized Fagnano Problem", "comment": "13 pages", "summary": "In 1775, Fagnano introduced the following geometric optimization problem: inscribe a triangle of minimal perimeter in a given acute-angled triangle. A widely accessible solution is provided by the Hungarian mathematician L. Fejer in 1900. This paper presents a specific generalization of the classical Fagnano problem, which states that given a nonconvex quadrilateral (having one reflex angle and others are acute angles), find a triangle of minimal perimeter with exactly one vertex on each of the sides that do not form reflex angle, and the third vertex lies on either of the sides forming the reflex angle. We provide its geometric solution. Additionally, we establish an upper bound for the classic Fagnano problem, demonstrating that the minimal perimeter of the triangle inscribed in a given acute-angled triangle cannot exceed twice the length of any of its sides."}
{"id": "2601.13744", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.13744", "abs": "https://arxiv.org/abs/2601.13744", "authors": ["Gérard Biau", "Claire Boyer"], "title": "A Note on k-NN Gating in RAG", "comment": null, "summary": "We develop a statistical proxy framework for retrieval-augmented generation (RAG), designed to formalize how a language model (LM) should balance its own predictions with retrieved evidence. For each query x, the system combines a frozen base model q0 ($\\times$ x) with a k-nearest neighbor retriever r (k ) ($\\times$ x) through a measurable gate k(x). A retrieval-trust weight wfact (x) quantifies the geometric reliability of the retrieved neighborhood and penalizes retrieval in low-trust regions. We derive the Bayes-optimal per-query gate and analyze its effect on a discordance-based hallucination criterion that captures disagreements between LM predictions and retrieved evidence. We further show that this discordance admits a deterministic asymptotic limit governed solely by the structural agreement (or disagreement) between the Bayes rule and the LM. To account for distribution mismatch between queries and memory, we introduce a hybrid geometric-semantic model combining covariate deformation and label corruption. Overall, this note provides a principled statistical foundation for factuality-oriented RAG systems."}
{"id": "2601.11771", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.11771", "abs": "https://arxiv.org/abs/2601.11771", "authors": ["Tong Mao", "Jinchao Xu", "Xiaofeng Xu"], "title": "Solving High-Dimensional PDEs Using Linearized Neural Networks", "comment": null, "summary": "Linearized shallow neural networks that are constructed by fixing the hidden-layer parameters have recently shown strong performance in solving partial differential equations (PDEs). Such models, widely used in the random feature method (RFM) and extreme learning machines (ELM), transform network training into a linear least-squares problem. In this paper, we conduct a numerical study of the variational (Galerkin) and collocation formulations for these linearized networks. Our numerical results reveal that, in the variational formulation, the associated linear systems are severely ill-conditioned, forming the primary computational bottleneck in scaling the neural network size, even when direct solvers are employed. In contrast, collocation methods combined with robust least-squares solvers exhibit better numerical stability and achieve higher accuracy as we increase neuron numbers. This behavior is consistently observed for both ReLU$^k$ and $\\tanh$ activations, with $\\tanh$ networks exhibiting even worse conditioning. Furthermore, we demonstrate that random sampling of the hidden layer parameters, commonly used in RFM and ELM, is not necessary for achieving high accuracy. For ReLU$^k$ activations, this follows from existing theory and is verified numerically in this paper, while for $\\tanh$ activations, we introduce two deterministic schemes that achieve comparable accuracy."}
{"id": "2601.11973", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.11973", "abs": "https://arxiv.org/abs/2601.11973", "authors": ["Alexander Veretennikov"], "title": "On efficient estimates of the rate of convergence for Markov chains", "comment": "26 pages, 19 references", "summary": "The paper presents efficient approaches for evaluating convergence rate in total variation for finite and general linear Markov chains. The motivation for studying convergence rate in this metric is its usefulness in various limit theorems. For homogeneous Markov chains the goal is to compare several different methods: (1) the second eigenvalue for the transition matrix method (the method no. 1), (2) the method based on Markov -- Dobrushin's ergodic coefficient, and the new spectral method developed in earlier works, as well as modifications of they both by iterations (the ``other methods''). We answer the question whether or not the ``other methods'' may provide the optimal or close to optimal convergence rate in the case of homogeneous Markov chains. The answer turns out to be positive for appropriate modifications of both ``other methods''. The analogues of these ``other methods'' for the non-homogeneous Markov chains are also presented. The work is theoretical. However, the methods of computing efficient bounds of convergence rates may be in demand in various applied areas."}
{"id": "2601.11554", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11554", "abs": "https://arxiv.org/abs/2601.11554", "authors": ["Triloki Nath", "Manohar Choudhary", "Ram K. Pandey"], "title": "A Generalized Waist Problem: Optimality Condition and Algorithm", "comment": null, "summary": "Many years ago John Tyrell a lecturer at King's college London challenged his Ph.D. students with the following puzzle: show that there is a unique triangle of minimal perimeter with exactly one vertex to lie on one of three given lines, pairwise disjoint and not all parallel in the space. The problem in literature is known as the waist problem, and only convexity rescued in this case. Motivated by this we generalize it by replacing lines with a number of convex sets in the Euclidean space and ask to minimize the sum of distances connecting the sets by means of closed polygonal curve. This generalized problem significantly broadens its geometric and practical scope in view of modern convex analysis. We establish the existence of solutions and prove its uniqueness under the condition that at least one of the convex sets is strictly convex and all are in general position: each set can be separated by convex hull of others. A complete set of necessary and sufficient optimality conditions is derived, and their geometric interpretations are explored to link these conditions with classical principles such as the reflection law of light. To address this problem computationally, we develop a projected subgradient descent method and prove its convergence. Our algorithm is supported by detailed numerical experiments, particularly in cases involving discs and spheres. Additionally, we present a real-world analogy of the problem in the form of inter-island connectivity, illustrating its practical relevance. This work not only advances the theory of geometric optimization but also contributes effective methods and insights applicable to facility location, network design, robotics., computational geometry, and spatial planning."}
{"id": "2601.13782", "categories": ["math.ST", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.13782", "abs": "https://arxiv.org/abs/2601.13782", "authors": ["Shir Tapiro-Moshe", "Yariv Aizenbud", "Barak Sober"], "title": "Moving Least Squares without Quasi-Uniformity: A Stochastic Approach", "comment": null, "summary": "Local Polynomial Regression (LPR) and Moving Least Squares (MLS) are closely related nonparametric estimation methods, developed independently in statistics and approximation theory. While statistical LPR analysis focuses on overcoming sampling noise under probabilistic assumptions, the deterministic MLS theory studies smoothness properties and convergence rates with respect to the \\textit{fill-distance} (a resolution parameter). Despite this similarity, the deterministic assumptions underlying MLS fail to hold under random sampling. We begin by quantifying the probabilistic behavior of the fill-distance $h_n$ and \\textit{separation} $δ_n$ of an i.i.d. random sample. That is, for a distribution satisfying a mild regularity condition, $h_n\\propto n^{-1/d}\\log^{1/d} (n)$ and $δ_n \\propto n^{-1/d}$. We then prove that, for MLS of degree $k\\!-\\!1$, the approximation error associated with a differential operator $Q$ of order $|m|\\le k-1$ decays as $h_n^{\\,k-|m|}$ up to logarithmic factors, establishing stochastic analogues of the classical MLS estimates. Additionally, We show that the MLS approximant is smooth with high probability. Finally, we apply the stochastic MLS theory to manifold estimation. Assuming that the sampled Manifold is $k$-times smooth, we show that the Hausdorff distance between the true manifold and its MLS reconstruction decays as $h_n^k$, extending the deterministic Manifold-MLS guarantees to random samples. This work provides the first unified stochastic analysis of MLS, demonstrating that -- despite the failure of deterministic sampling assumptions -- the classical convergence and smoothness properties persist under natural probabilistic models"}
{"id": "2601.11831", "categories": ["math.NA", "nlin.CD", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.11831", "abs": "https://arxiv.org/abs/2601.11831", "authors": ["Rui Fang", "Ali Pakzad"], "title": "Global Recovery from Local Data: Interior Nudging for 2D Navier-Stokes equations in a Physical Domain", "comment": "26 pages, 10 plots", "summary": "In many real-world applications of data assimilation (DA), the strategic placement of observers is crucial for effective and efficient forecasting. Motivated by practical constraints in sensor deployment, we show that global recovery of the flow field can be achieved using observations available only in a subregion of the domain, possibly far from the boundary. We focus on the two-dimensional incompressible Navier-Stokes equations posed in a bounded physical domain with Dirichlet boundary conditions. Building on the continuous data assimilation framework of Azouani, Olson, and Titi (2014), we rigorously prove that the assimilated solution converges globally to the true solution under suitable conditions on the nudging parameter, spatial resolution, and the geometry of the observation region, specifically, when the maximum distance from any point in the domain to the observational subregion is bounded by a constant multiple of \\( ν^{1/2} \\) (in terms of scaling). Our computational results, conducted via finite element methods over complex geometries, support the theoretical findings and reveal even greater robustness in practice. Specifically, synchronization with the true solution is achieved even when the observational subregion lies farther from the rest of the domain than the theoretical threshold permits. Across all three tested scenarios, the local nudging algorithm performs comparably to full-domain assimilation, reaching global accuracy up to machine precision. Interestingly, observational data near the boundary are found to be largely uninformative. This demonstrates that full observability is not necessary: carefully chosen interior observations, even far from the boundary, can suffice."}
{"id": "2601.12172", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.12172", "abs": "https://arxiv.org/abs/2601.12172", "authors": ["Ákos Urbán"], "title": "The Pólya Web", "comment": "The work presented here was carried out in the framework of a Master's thesis under the supervision of Bálint Tóth and Balázs Bárány", "summary": "We introduce the Pólya Web, a system of coalescing random walks based on the classic Pólya urn model. This construction serves as an analogue to the web of coalescing random walks studied by Tóth and Werner (1998), replacing simple symmetric random walks with Pólya walks as primary constituents. First, we study the general web of up-right oriented coalescing random walks. We investigate its geometric properties and prove that certain indicator random variables satisfy negative association. Notably, the proof involves a non-trivial application of the van den Berg-Kesten-Reimer (BKR) inequality. Based on this property, we derive a strong law for the number of connected components generated by walks starting at the same time. Subsequently, we focus on the specific properties of the Pólya Web. It is well-known that the normalized coordinates of a single Pólya Walk converge almost surely to a beta-distributed random variable. We determine the joint distribution of these limiting variables in the coalescing framework. Using these joint densities, we provide exact calculations regarding the almost sure convergence of the number of components. Finally, by applying a local scaling to the Pólya Web at the edges, we introduce the Yule Web, a web of coalescing Yule processes. We demonstrate that the fundamental properties and results derived for the Pólya Web can be extended to this limiting case."}
{"id": "2601.11555", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11555", "abs": "https://arxiv.org/abs/2601.11555", "authors": ["Triloki Nath", "Manohar Choudhary", "Ram K. Pandey"], "title": "A Generalized $(k,m)$ Heron Problem:Optimality Conditions and Algorithm", "comment": null, "summary": "This paper presents a new extension of the classical Heron problem, termed the generalized $(k,m)$-Heron problem, which seeks an optimal configuration among $k$ feasible and $m$ target non-empty closed convex sets in $\\mathbb{R}^n$. The problem is formulated as finding a point in each set that minimizes the pairwise distances from the points in the $k$-feasible sets to the points in the $m$-target sets. This formulation leads to a convex optimization framework that generalizes several well-known geometric distance problems. Using tools from convex analysis, we establish fundamental results on existence, uniqueness, and first-order optimality conditions through subdifferential calculus and normal cone theory. Building on these insights, a Projected Subgradient Algorithm (PSA) is proposed for numerical solution, and its convergence is rigorously proved under a diminishing step-size rule. Numerical experiments in $\\mathbb{R}^2$ and $\\mathbb{R}^3$ illustrate the algorithm's stability, geometric accuracy, and computational efficiency. Overall, this work provides a comprehensive analytical and algorithmic framework for multi-set geometric optimization with promising implications for location science, robotics, and computational geometry."}
{"id": "2601.13930", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.13930", "abs": "https://arxiv.org/abs/2601.13930", "authors": ["Kohei Kawamoto", "Yuichi Goto", "Koji Tsukuda"], "title": "On spectral clustering under non-isotropic Gaussian mixture models", "comment": "8 pages", "summary": "We evaluate the misclustering probability of a spectral clustering algorithm under a Gaussian mixture model with a general covariance structure. The algorithm partitions the data into two groups based on the sign of the first principal component score. As a corollary of the main result, the clustering procedure is shown to be consistent in a high-dimensional regime."}
{"id": "2601.11900", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.11900", "abs": "https://arxiv.org/abs/2601.11900", "authors": ["Shiheng Zhang", "Jingwei Hu"], "title": "A Separable and Asymptotic-Preserving Dynamical Low-Rank Method for the Vlasov--Poisson--Fokker--Planck System", "comment": null, "summary": "We present a dynamical low-rank (DLR) method for the Vlasov--Poisson--Fokker--Planck (VPFP) system. Our main contributions are two-fold: (i) a conservative spatial discretization of the Fokker--Planck operator that factors into velocity-only and space-only components, enabling efficient low-rank projection, and (ii) a time discretization within the DLR framework that properly handles stiff collisions. We propose both first-order and second-order low-rank IMEX schemes. For the first-order scheme, we prove an asymptotic-preserving (AP) property when the field fluctuation is small. Numerical experiments demonstrate accuracy, robustness, and AP property at modest ranks."}
{"id": "2601.12197", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.12197", "abs": "https://arxiv.org/abs/2601.12197", "authors": ["Bihan Chatterjee", "Siva Theja Maguluri", "Debankur Mukherjee"], "title": "Higher-Order Approximations of Sojourn Times in M/G/1 Queues via Stein's Method", "comment": null, "summary": "We study the stationary sojourn time distribution in an M/G/1 queue operating under heavy traffic. It is known that the sojourn time converges to an exponential distribution in the limit. Our focus is on obtaining pre-asymptotic, higher-order approximations that go beyond the classical exponential limit. Using Stein's method, we develop an approach based on higher-order expansions of the generator of the underlying Markov process. The key technical step is to represent higher-order derivatives in terms of lower-order ones and control the resulting error via derivative bounds of the Stein equation. Under suitable moment-matching conditions on the service distribution, we show that the approximation error decays as a high-order power of the slack parameter $\\varepsilon=1-ρ$. Error bounds are established in the Zolotarev metric, which further imply bounds on the Wasserstein distance as well as the moments. Our results demonstrate that the accuracy of the exponential approximation can be systematically improved by matching progressively more moments of the service distribution."}
{"id": "2601.11751", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11751", "abs": "https://arxiv.org/abs/2601.11751", "authors": ["Sadjad Bazarnovi", "Taner Cokyasar", "Omer Verbas", "Abolfazl Kouros Mohammadian"], "title": "Integrated Optimization of Scheduling and Flexible Charging in Mixed Electric-Diesel Urban Transit Bus Systems", "comment": null, "summary": "The transition of transit fleets to alternative powertrains offers a potential pathway to reducing the cost of mobility. However, the limited range and long charging durations of battery electric buses (BEBs) introduce significant operational complexities, necessitating innovative scheduling and charging strategies. This study proposes an integrated mixed-integer linear programming model to optimize vehicle scheduling and charging strategies for mixed fleets of BEBs and diesel buses. Unlike existing models, which often assume a fixed BEB fleet size or restrict charging to a single charger type, our approach simultaneously determines the optimal fleet composition, scheduling, and flexible partial charging strategy incorporating both slow and fast chargers at garages and terminal stations. The model minimizes combined fleet purchase and operational costs. A queuing strategy is introduced, departing from traditional first-come, first-served methods by dynamically allocating waiting and charging times based on operational priorities and resource availability, improving overall scheduling efficiency. To overcome computational complexities arising from numerous variables, a column generation framework is developed, facilitating scalable solutions for large-scale transit networks. Numerical experiments using real-world transit data from the Chicago Transit Authority and the Pace suburban bus systems demonstrate the model's effectiveness. Results indicate that while a full transition to alternative powertrains results in a modest cost increase, optimal mixed-fleet configurations can actually reduce total system costs. Furthermore, sensitivity analyses reveal that restricting charging to garages significantly increases fleet size and operational costs, underscoring the potential of distributed opportunistic charging."}
{"id": "2601.13946", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.13946", "abs": "https://arxiv.org/abs/2601.13946", "authors": ["Philip Boeken", "Eduardo Skapinakis", "Konstantin Genin", "Joris M. Mooij"], "title": "Topological Criteria for Hypothesis Testing with Finite-Precision Measurements", "comment": null, "summary": "We establish topological necessary and sufficient conditions under which a pair of statistical hypotheses can be consistently distinguished when i.i.d. observations are recorded only to finite precision. Requiring the test's decision regions to be open in the sample-space topology to accommodate finite-precision data, we show that a pair of null- and alternative hypotheses $H_0$ and $H_1$ admits a consistent test if and only if they are $F_σ$ in the weak topology on the space of probability measures $W := H_0\\cup H_1$. Additionally, the hypotheses admit uniform error control under $H_0$ and/or $H_1$ if and only if $H_0$ and/or $H_1$ are closed in $W$. Under compactness assumptions, uniform consistency is characterised by $H_0$ and $H_1$ having disjoint closures in the ambient space of probability measures. These criteria imply that - without regularity assumptions - conditional independence is not consistently testable. We introduce a Lipschitz-continuity assumption on the family of conditional distributions under which we recover testability of conditional independence with uniform error control under the null, with testable smoothness constraints."}
{"id": "2601.11922", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.11922", "abs": "https://arxiv.org/abs/2601.11922", "authors": ["Edward L. Yang", "Roy Y. He"], "title": "Phase-IDENT: Identification of Two-phase PDEs with Uncertainty Quantification", "comment": null, "summary": "We propose a novel method, Phase-IDENT, for identifying partial differential equations (PDEs) from noisy observations of dynamical systems that exhibit phase transitions. Such phenomena are prevalent in fluid dynamics and materials science, where they can be modeled mathematically as functions satisfying different PDEs within distinct regions separated by phase boundaries. Our approach simultaneously identifies the underlying PDEs in each regime and accurately reconstructs the phase boundaries. Furthermore, by incorporating change point detection techniques, we provide uncertainty quantification for the detected boundaries, enhancing the interpretability and robustness of our method. We conduct numerical experiments on a variety of two-phase PDE systems under different noise levels, and the results demonstrate the effectiveness of the proposed approach."}
{"id": "2601.12633", "categories": ["math.PR", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12633", "abs": "https://arxiv.org/abs/2601.12633", "authors": ["Pierre Del Moral", "Ajay Jasra"], "title": "New Trends in the Stability of Sinkhorn Semigroups", "comment": null, "summary": "Entropic optimal transport problems play an increasingly important role in machine learning and generative modelling. In contrast with optimal transport maps which often have limited applicability in high dimensions, Schrodinger bridges can be solved using the celebrated Sinkhorn's algorithm, a.k.a. the iterative proportional fitting procedure. The stability properties of Sinkhorn bridges when the number of iterations tends to infinity is a very active research area in applied probability and machine learning. Traditional proofs of convergence are mainly based on nonlinear versions of Perron-Frobenius theory and related Hilbert projective metric techniques, gradient descent, Bregman divergence techniques and Hamilton-Jacobi-Bellman equations, including propagation of convexity profiles based on coupling diffusions by reflection methods. The objective of this review article is to present, in a self-contained manner, recently developed Sinkhorn/Gibbs-type semigroup analysis based upon contraction coefficients and Lyapunov-type operator-theoretic techniques. These powerful, off-the-shelf semigroup methods are based upon transportation cost inequalities (e.g. log-Sobolev, Talagrand quadratic inequality, curvature estimates), $φ$-divergences, Kantorovich-type criteria and Dobrushin contraction-type coefficients on weighted Banach spaces as well as Wasserstein distances. This novel semigroup analysis allows one to unify and simplify many arguments in the stability of Sinkhorn algorithm. It also yields new contraction estimates w.r.t. generalized $φ$-entropies, as well as weighted total variation norms, Kantorovich criteria and Wasserstein distances."}
{"id": "2601.11782", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11782", "abs": "https://arxiv.org/abs/2601.11782", "authors": ["Albert Joon Lee", "David E. Bernal Neira"], "title": "Mixed-Integer Reaggregated Hull Reformulation of Special Structured Generalized Linear Disjunctive Programs", "comment": "20 pages, 5 figures", "summary": "Generalized Disjunctive Programming (GDP) provides a powerful framework for combining algebraic constraints with logical disjunctions. To solve these problems, mixed-integer reformulations are required, but traditional reformulation schemes, such as Big-M and Hull, either yield a weak continuous relaxation or result in a bloated model size. Castro and Grossmann showed that scheduling problems can be formulated as GDP by modeling task orderings as disjunctions with algebraic timing constraints. Moreover, in their work, a particular representation of the single-unit scheduling problem, namely using a time-slot concept, can be reformulated as a tight yet compact mixed-integer linear program with notable computational performance. Based on that observation, and focusing on the case where the constraints in disjunctions are linear and share the same coefficients, we connect the characterization of the convex hull of these disjunctive sets by Jeroslow and Blair with Castro and Grossmann's time-slot reaggregation strategy to derive a unified reformulation methodology. We test this reformulation in two problems, single-unit scheduling and two-dimensional strip-packing. We derive new formulations of the general precedence concept of single-unit scheduling and symmetry-breaking formulations of the strip-packing problem, yielding mixed-integer programs with strong theoretical guarantees, particularly compact formulations in terms of continuous variables, and efficient computational performance when solving them with commercial mixed-integer solvers for these problems."}
{"id": "2601.13955", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.13955", "abs": "https://arxiv.org/abs/2601.13955", "authors": ["Akira Shinkyu"], "title": "Uniform Consistency of Generalized Cross-Validation for Ridge Regression in High-Dimensional Misspecified Linear Models", "comment": null, "summary": "This study examines generalized cross-validation for the tuning parameter selection for ridge regression in high-dimensional misspecified linear models. The set of candidates for the tuning parameter includes not only positive values but also zero and negative values. We demonstrate that if the second moment of the specification error converges to zero, generalized cross-validation is still a uniformly consistent estimator of the out-of-sample prediction risk. This implies that generalized cross-validation selects the tuning parameter for which ridge regression asymptotically achieves the smallest prediction risk among the candidates if the degree of misspecification for the regression function is small. Our simulation studies show that ridge regression tuned by generalized cross-validation exhibits a prediction performance similar to that of optimally tuned ridge regression and outperforms the Lasso under correct and incorrect model specifications."}
{"id": "2601.11963", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.11963", "abs": "https://arxiv.org/abs/2601.11963", "authors": ["Congpei An", "Xiaosheng Zhuang"], "title": "A Survey on Spherical Designs: Existence, Numerical Constructions, and Applications", "comment": null, "summary": "This paper provides a survey of spherical designs and their applications, with a particular emphasis on the perspective of ``numerical analysis''. A set \\(X_N\\) of \\(N\\) points on the unit sphere \\(\\mathbb{S}^d\\) is called a \\textit{spherical \\(t\\)-design} if the average value of any polynomial of degree at most \\(t\\) over \\(X_N\\) equals its average over the entire sphere. Spherical designs represent one of the most significant topics in the study of point distributions on spheres. They are deeply connected to algebraic combinatorics, discrete geometry, differential geometry, approximation theory, optimization, coding theory, quantum physics, and other fields, which have led to the development of profound and elegant mathematical theories. This article reviews fundamental theoretical results, numerical construction methods, and applied outcomes related to spherical designs. Key topics covered include existence proofs, optimization-based construction techniques, fast computational algorithms, and applications in interpolation, numerical integration, hyperinterpolation, signal and image processing, as well as numerical solutions to partial differential and integral equations."}
{"id": "2601.12677", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.12677", "abs": "https://arxiv.org/abs/2601.12677", "authors": ["Christian Hirsch", "Takashi Owada", "Ruiting Tong"], "title": "Stable and Fréchet limit theorem for subgraph functionals in the hyperbolic random geometric graph", "comment": null, "summary": "We study the fluctuations of subgraph counts in hyperbolic random geometric graphs on the $d$-dimensional Poincaré ball in the heterogeneous, heavy-tailed degree regime. In a hyperbolic random geometric graph whose vertices are given by a Poisson point process on a growing hyperbolic ball, we consider two basic families of subgraphs: star shape counts and clique counts, and we analyze their global counts and maxima over the vertex set. Working in the parameter regime where a small number of vertices close to the center of the Poincaré ball carry very large degrees and act as hubs, we establish joint functional limit theorems for suitably normalized star shape and clique count processes together with the associated maxima processes. The limits are given by a two-dimensional dependent process whose components are a stable Lévy process and an extremal Fréchet process, reflecting the fact that a small number of hubs dominates both the total number of local subgraphs and their extremes. As an application, we derive fluctuation results for the global clustering coefficient, showing that its asymptotic behavior is described by the ratio of the components of a bivariate Lévy process with perfectly dependent stable jumps."}
{"id": "2601.11795", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11795", "abs": "https://arxiv.org/abs/2601.11795", "authors": ["Qi Wang", "Christian Piermarini", "Yunlang Zhu", "Frank E. Curtis"], "title": "Projected Stochastic Momentum Methods for Nonlinear Equality-Constrained Optimization for Machine Learning", "comment": null, "summary": "Two algorithms are proposed, analyzed, and tested for solving continuous optimization problems with nonlinear equality constraints. Each is an extension of a stochastic momentum-based method from the unconstrained setting to the setting of a stochastic Newton-SQP-type algorithm for solving equality-constrained problems. One is an extension of the heavy-ball method and the other is an extension of the Adam optimization method. Convergence guarantees for the algorithms for the constrained setting are provided that are on par with state-of-the-art guarantees for their unconstrained counterparts. A critical feature of each extension is that the momentum terms are implemented with projected gradient estimates, rather than with the gradient estimates themselves. The significant practical effect of this choice is seen in an extensive set of numerical experiments on solving informed supervised machine learning problems. These experiments also show benefits of employing a constrained approach to supervised machine learning rather than a typical regularization-based approach."}
{"id": "2601.13966", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.13966", "abs": "https://arxiv.org/abs/2601.13966", "authors": ["Dong Huang", "Pengkun Yang"], "title": "Information-Theoretic and Computational Limits of Correlation Detection under Graph Sampling", "comment": "61 pages, 7 figures", "summary": "Correlation analysis is a fundamental problem in statistics. In this paper, we consider the correlation detection problem between a pair of Erdos-Renyi graphs. Specifically, the problem is formulated as a hypothesis testing problem: under the null hypothesis, the two graphs are independent; under the alternative hypothesis, the two graphs are edge-correlated through a latent permutation. We focus on the scenario where only two induced subgraphs are sampled, and characterize the sample size threshold for detection. At the information-theoretic level, we establish the sample complexity rates that are optimal up to constant factors over most parameter regimes, and the remaining gap is bounded by a subpolynomial factor. On the algorithmic side, we propose polynomial-time tests based on counting trees and bounded degree motifs, and identify the regimes where they succeed. Moreover, leveraging the low-degree conjecture, we provide evidence of computational hardness that matches our achievable guarantees, showing that the proposed polynomial-time tests are rate-optimal. Together, these results reveal a statistical--computational gap in the sample size required for correlation detection. Finally, we validate the proposed algorithms on synthetic data and a real coauthor network, demonstrating strong empirical performance."}
{"id": "2601.11975", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.11975", "abs": "https://arxiv.org/abs/2601.11975", "authors": ["Carlos Castro", "Fabricio Macià", "Cristóbal Meroño", "Daniel Sánchez-Mendoza"], "title": "The linearization approach to the Calderón problem revisited: reconstruction via the Born approximation", "comment": "38 pages, 9 figures", "summary": "Linearization techniques are widely used in the analysis and numerical solution of the Calderón inverse problem, even if their theoretical basis is not fully understood. In this article, we study the effectiveness of linearization for reconstructing a conductivity from its Dirichlet-to-Neumann (DtN) map, combining rigorous analysis with numerical experiments. In particular, we prove that any DtN map arising from a radial conductivity in the unit ball of $\\mathbb{R}^d$ admits an exact representation as a linearized DtN map for a uniquely determined integrable function, the Born approximation. We linearize on a family of background conductivities that includes the constant case, giving a rigorous foundation for linearization-based methods in this framework. We also characterize the Born approximation as a solution of a generalized moment problem. Since this moment problem is formally well-defined even for non-radial conductivities, we use it to develop a numerical algorithm to reconstruct the Born approximation of a general conductivity on the unit disk. We provide numerical experiments to test the resolution and robustness of the Born approximation in different situations. Finally, we show how it can be used as the starting point of an algorithm for reconstructing a conductivity from its DtN map."}
{"id": "2601.12997", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.12997", "abs": "https://arxiv.org/abs/2601.12997", "authors": ["Robert E. Gaunt", "Heather L. Sutcliffe"], "title": "The distribution of the ratio of products of independent zero mean normal random variables", "comment": "11 pages", "summary": "Let $X_1,\\ldots,X_M$ and $Y_1,\\ldots,Y_N$ be independent zero mean normal random variables with variances $σ_{X_i}^2$, $i=1,\\ldots,M$, and $σ_{Y_j}^2$, $j=1,\\ldots,N$, respectively, and let $X=X_1\\cdots X_M$ and $Y=Y_1\\cdots Y_N$. In this paper, we derive the exact probability density function of the ratio $X/Y$. We apply this formula to derive exact formulas for the cumulative distribution function and the characteristic function. We also obtain further distributional properties, including asymptotic approximations for the probability density function, tail probabilities and the quantile function."}
{"id": "2601.11826", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11826", "abs": "https://arxiv.org/abs/2601.11826", "authors": ["Young-Ju Lee", "Jongho Park"], "title": "A high-order augmented Lagrangian method with arbitrarily fast convergence", "comment": "22 pages, 7 figures", "summary": "We propose a high-order version of the augmented Lagrangian method for solving convex optimization problems with linear constraints, which achieves arbitrarily fast -- and even superlinear -- convergence rates. First, we analyze the convergence rates of the high-order proximal point method under certain uniform convexity assumptions on the energy functional. We then introduce the high-order augmented Lagrangian method and analyze its convergence by leveraging the convergence results of the high-order proximal point method. Finally, we present applications of the high-order augmented Lagrangian method to various problems arising in the sciences, including data fitting, flow in porous media, and scientific machine learning."}
{"id": "2601.14013", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.14013", "abs": "https://arxiv.org/abs/2601.14013", "authors": ["Anders Bredahl Kock", "David Preinerstorfer"], "title": "Robustness for free: asymptotic size and power of max-tests in high dimensions", "comment": null, "summary": "Consider testing a zero restriction on the mean of a $d$-dimensional random vector based on an i.i.d. sample of size $n$. Suppose further that the coordinates are only assumed to possess $m>2$ moments. Then, max-tests based on arithmetic means and critical values derived from Gaussian approximations are not guaranteed to be asymptotically valid unless $d$ is relatively small compared to $n$, because said approximation faces a polynomial growth barrier of $d=o(n^{m/2-1})$.\n  We propose a max-test based on winsorized means, and show that it holds the desired asymptotic size even when $d$ grows at an exponential rate in $n$ and the data are adversarially contaminated. Our characterization of its asymptotic power function shows that these benefits do not come at the cost of reduced asymptotic power: the robustified max-test has identical asymptotic power to that based on arithmetic means whenever the stronger assumptions underlying the latter are satisfied.\n  We also investigate when -- and when not -- data-driven (bootstrap) critical values can strictly increase asymptotic power of the robustified max-test."}
{"id": "2601.12000", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12000", "abs": "https://arxiv.org/abs/2601.12000", "authors": ["Yu Yang", "Qiaolin He"], "title": "A Multi-Level Deep Framework for Deep Solvers of Partial Differential Equations", "comment": null, "summary": "In this paper, inspired by the multigrid method, we propose a multi-level deep framework for deep solvers. Overall, it divides the entire training process into different levels of training. At each level of training, an adaptive sampling method proposed in this paper is first employed to obtain new training points, so that these points become increasingly concentrated in computational regions corresponding to high-frequency components. Then, the generalization ability of deep neural networks are utilized to update the PDEs for the next level of training based on the results from all previous levels. Rigorous mathematical proofs and detailed numerical experiments are employed to demonstrate the effectiveness of the proposed method."}
{"id": "2601.13086", "categories": ["math.PR", "math.GT", "math.SP"], "pdf": "https://arxiv.org/pdf/2601.13086", "abs": "https://arxiv.org/abs/2601.13086", "authors": ["Roman Lemonde", "Jian Wang"], "title": "Brownian Loops and the Selberg Zeta Function", "comment": "19 pages, 1 figure", "summary": "We study the Brownian loop measure on hyperbolic surfaces for Brownian motion with a constant killing rate. We compute the mass of Brownian loops with killing in a free homotopy class and then relate the total mass of loops in all essential homotopy classes to the Selberg zeta function when the surface is geometrically finite. As an application, we provide a probabilistic interpretation of different notions of regularized determinants of Laplacian, in both the compact and infinite-area cases."}
{"id": "2601.11948", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11948", "abs": "https://arxiv.org/abs/2601.11948", "authors": ["Kai Liu", "Hua-Cheng Zhou", "Zhong-Jie Han", "Xiangyang Peng"], "title": "Observer design and boundary output feedback stabilization for semilinear parabolic system over general multidimensional domain", "comment": null, "summary": "This paper investigates the output feedback stabilization of parabolic equation with Lipschitz nonlinearity over general multidimensional domain using spectral geometry theories. First, a novel nonlinear observer is designed, and the error system is shown to achieve any prescribed decay rate by leveraging the Berezin-Li-Yau inequality from spectral geometry, which also provides effective guidance for sensor placement. Subsequently, a finite-dimensional state feedback controller is proposed, which ensures the quantitative rapid stabilization of the linear part. By integrating this control law with the observer, an efficient boundary output feedback control strategy is developed. The feasibility of the proposed control design is rigorously verified for arbitrary Lipschitz constants, thereby resolving a persistent theoretical challenge. Finally, a numerical case study confirms the effectiveness of the approach."}
{"id": "2601.14223", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.14223", "abs": "https://arxiv.org/abs/2601.14223", "authors": ["Annika Betken", "Giorgio Micali", "Manuel Ruiz Marín"], "title": "Symmetry Testing in Time Series using Ordinal Patterns: A U-Statistic Approach", "comment": null, "summary": "We introduce a general framework for testing temporal symmetries in time series based on the distribution of ordinal patterns. While previous approaches have focused on specific forms of asymmetry, such as time reversal, our method provides a unified framework applicable to arbitrary symmetry tests. We establish asymptotic results for the resulting test statistics under a broad class of stationary processes. Comprehensive experiments on both synthetic and real data demonstrate that the proposed test achieves high sensitivity to structural asymmetries while remaining fully data-driven and computationally efficient."}
{"id": "2601.12161", "categories": ["math.NA", "cs.LG", "math.DS", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.12161", "abs": "https://arxiv.org/abs/2601.12161", "authors": ["Tomoki Koike", "Prakash Mohan", "Marc T. Henry de Frahan", "Julie Bessac", "Elizabeth Qian"], "title": "Streaming Operator Inference for Model Reduction of Large-Scale Dynamical Systems", "comment": null, "summary": "Projection-based model reduction enables efficient simulation of complex dynamical systems by constructing low-dimensional surrogate models from high-dimensional data. The Operator Inference (OpInf) approach learns such reduced surrogate models through a two-step process: constructing a low-dimensional basis via Singular Value Decomposition (SVD) to compress the data, then solving a linear least-squares (LS) problem to infer reduced operators that govern the dynamics in this compressed space, all without access to the underlying code or full model operators, i.e., non-intrusively. Traditional OpInf operates as a batch learning method, where both the SVD and LS steps process all data simultaneously. This poses a barrier to deployment of the approach on large-scale applications where dataset sizes prevent the loading of all data into memory at once. Additionally, the traditional batch approach does not naturally allow model updates using new data acquired during online computation. To address these limitations, we propose Streaming OpInf, which learns reduced models from sequentially arriving data streams. Our approach employs incremental SVD for adaptive basis construction and recursive LS for streaming operator updates, eliminating the need to store complete data sets while enabling online model adaptation. The approach can flexibly combine different choices of streaming algorithms for numerical linear algebra: we systematically explore the impact of these choices both analytically and numerically to identify effective combinations for accurate reduced model learning. Numerical experiments on benchmark problems and a large-scale turbulent channel flow demonstrate that Streaming OpInf achieves accuracy comparable to batch OpInf while reducing memory requirements by over 99% and enabling dimension reductions exceeding 31,000x, resulting in orders-of-magnitude faster predictions."}
{"id": "2601.13158", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.13158", "abs": "https://arxiv.org/abs/2601.13158", "authors": ["Robert E. Gaunt"], "title": "On the characteristic function of the asymmetric Student's $t$-distribution and an integral involving the sine function", "comment": "6 pages", "summary": "We obtain a new closed-form formula for the characteristic function of the asymmetric Student's $t$-distribution. As part of our analysis, we derive a new closed-form formula for the integral $\\int_0^\\infty \\sin(ax)/(b^2+x^2)^n\\,\\mathrm{d}x$, for $a,b>0$, $n\\in\\mathbb{Z}^+$, expressed in terms of the exponential integral function. As a consequence of our integral formula, we deduce a closed-form formula for the limit $\\lim_{ν\\rightarrow n} \\{I_{ν-1/2}(x)-\\mathbf{L}_{1/2-ν}(x)\\}/\\sin(πν)$, for $n\\in\\mathbb{Z}^+$, $x>0$."}
{"id": "2601.12117", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12117", "abs": "https://arxiv.org/abs/2601.12117", "authors": ["Jingren Liu", "Hanzhang Qin", "Junyi Liu", "Mabel C. Chou", "Jong-Shi Pang"], "title": "Offline Policy Learning with Weight Clipping and Heaviside Composite Optimization", "comment": null, "summary": "Offline policy learning aims to use historical data to learn an optimal personalized decision rule. In the standard estimate-then-optimize framework, reweighting-based methods (e.g., inverse propensity weighting or doubly robust estimators) are widely used to produce unbiased estimates of policy values. However, when the propensity scores of some treatments are small, these reweighting-based methods suffer from high variance in policy value estimation, which may mislead the downstream policy optimization and yield a learned policy with inferior value. In this paper, we systematically develop an offline policy learning algorithm based on a weight-clipping estimator that truncates small propensity scores via a clipping threshold chosen to minimize the mean squared error (MSE) in policy value estimation. Focusing on linear policies, we address the bilevel and discontinuous objective induced by weight-clipping-based policy optimization by reformulating the problem as a Heaviside composite optimization problem, which provides a rigorous computational framework. The reformulated policy optimization problem is then solved efficiently using the progressive integer programming method, making practical policy learning tractable. We establish an upper bound for the suboptimality of the proposed algorithm, which reveals how the reduction in MSE of policy value estimation, enabled by our proposed weight-clipping estimator, leads to improved policy learning performance."}
{"id": "2601.13259", "categories": ["math.PR", "math.FA", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13259", "abs": "https://arxiv.org/abs/2601.13259", "authors": ["Francesco Pedrotti"], "title": "Entropy-Wasserstein regularization, defective local concentration and a cutoff criterion beyond non-negative curvature", "comment": "21 pages", "summary": "Notions of positive curvature have been shown to imply many remarkable properties for Markov processes, in terms, e.g., of regularization effects, functional inequalities, mixing time bounds and, more recently, the cutoff phenomenon. In this work, we are interested in a relaxed variant of Ollivier's coarse Ricci curvature, where a Markov kernel $P$ satisfies only a weaker Wasserstein bound $W_p(μP, νP) \\leq K W_p(μ,ν)+M$ for constants $M\\ge 0, K\\in [0,1], p \\ge 1$. Under appropriate additional assumptions on the one-step transition measures $δ_x P$, we establish (i) a form of local concentration, given by a defective Talagrand inequality, and (ii) an entropy-transport regularization effect. We consider as illustrative examples the Langevin dynamics and the Proximal Sampler when the target measure is a log-Lipschitz perturbation of a log-concave measure. As an application of the above results, we derive criteria for the occurrence of the cutoff phenomenon in some negatively curved settings."}
{"id": "2601.12246", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12246", "abs": "https://arxiv.org/abs/2601.12246", "authors": ["Zhirui Shen", "Bin Wang"], "title": "Explicit symmetric low-regularity integrators for the semilinear Klein-Gordon equation", "comment": null, "summary": "This paper is concerned with the design and analysis of symmetric low-regularity integrators for the semilinear Klein-Gordon equation. We first propose a general symmetrization procedure that allows for the systematic construction of symmetric schemes from existing explicit (non-symmetric) integrators. Applying this procedure, we derive two novel schemes. Error analyses show that both integrators achieve their optimal convergence orders in the energy space under significantly relaxed regularity assumptions. Furthermore, the symmetry property ensures that the convergence order of a first-order symmetric scheme improves as the regularity of the exact solution increases. A numerical experiment demonstrates that the proposed second-order symmetric scheme nearly preserves the system energy over extended periods."}
{"id": "2601.13259", "categories": ["math.PR", "math.FA", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13259", "abs": "https://arxiv.org/abs/2601.13259", "authors": ["Francesco Pedrotti"], "title": "Entropy-Wasserstein regularization, defective local concentration and a cutoff criterion beyond non-negative curvature", "comment": "21 pages", "summary": "Notions of positive curvature have been shown to imply many remarkable properties for Markov processes, in terms, e.g., of regularization effects, functional inequalities, mixing time bounds and, more recently, the cutoff phenomenon. In this work, we are interested in a relaxed variant of Ollivier's coarse Ricci curvature, where a Markov kernel $P$ satisfies only a weaker Wasserstein bound $W_p(μP, νP) \\leq K W_p(μ,ν)+M$ for constants $M\\ge 0, K\\in [0,1], p \\ge 1$. Under appropriate additional assumptions on the one-step transition measures $δ_x P$, we establish (i) a form of local concentration, given by a defective Talagrand inequality, and (ii) an entropy-transport regularization effect. We consider as illustrative examples the Langevin dynamics and the Proximal Sampler when the target measure is a log-Lipschitz perturbation of a log-concave measure. As an application of the above results, we derive criteria for the occurrence of the cutoff phenomenon in some negatively curved settings."}
{"id": "2601.12166", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12166", "abs": "https://arxiv.org/abs/2601.12166", "authors": ["Chengwenjian Wang", "Alexander S. Estes", "Jean-Philippe P. Richard"], "title": "Balancing adaptability and predictability: K-revision multistage stochastic programming", "comment": "41 pages, 10 figures, 5 tables", "summary": "A standard assumption in multistage stochastic programming is that decisions are made after observing the uncertainty from the prior stage. The resulting solutions can be difficult to implement in practice, as they leave practitioners ill-prepared for future stages. To provide better foresight, we introduce the K-revision approach. This new framework requires plans to be specified in advance. To maintain flexibility, we allow plans to be revised a maximum of K times as new information becomes available. We analyze the complexity of K-revision problems, showing NP-hardness even in a simple setting. We examine, both theoretically and computationally, the impact of the K-revision approach on the objective compared with classical multistage stochastic programming models and the partially adaptive approach introduced in [1, 2]. We develop two MIP formulations, one directly from our definition and the other based on a combinatorial characterization. We analyze the tightness of these formulations and propose several methods to strengthen them. Computational experiments on synthetic problems and practical applications demonstrate that our approach is both computationally tractable and effective in reaching near-optimal performance while increasing the predictability of the solutions produced."}
{"id": "2601.13347", "categories": ["math.NA", "math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13347", "abs": "https://arxiv.org/abs/2601.13347", "authors": ["Aryeh Keating", "Mirjeta Pasha"], "title": "A Scalable Sequential Framework for Dynamic Inverse Problems via Model Parameter Estimation", "comment": "27 Pages, 8 Figures", "summary": "Large-scale dynamic inverse problems are often ill-posed due to model complexity and the high dimensionality of the unknown parameters. Regularization is commonly employed to mitigate ill-posedness by incorporating prior information and structural constraints. However, classical regularization formulations are frequently infeasible in this setting due to prohibitive memory requirements, necessitating sequential methods that process data and state information online, eliminating the need to form the full space-time problem. In this work, we propose a memory-efficient framework for reconstructing dynamic sequences of undersampled images from computerized tomography data that requires minimal hyperparameter tuning. The approach is based on a prior-informed, dimension-reduced Kalman filter with smoothing. While well suited for dynamic image reconstruction, practical deployment is challenging when the state transition model and covariance parameters must be initialized without prior knowledge and estimated in a single pass. To address these limitations, we integrate regularized motion models with expectation-maximization strategies for the estimation of state transition dynamics and error covariances within the Kalman filtering framework. We demonstrate the effectiveness of the proposed method through numerical experiments on limited-angle and single-shot computerized tomography problems, highlighting improvements in reconstruction accuracy, memory efficiency, and computational cost."}
{"id": "2601.12675", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12675", "abs": "https://arxiv.org/abs/2601.12675", "authors": ["Yongsheng Chen", "Suddhasattwa Das", "Wei Guo", "Xinghui Zhong"], "title": "Physics-informed machine learning for reconstruction of dynamical systems with invariant measure score matching", "comment": null, "summary": "In this paper, we develop a novel mesh-free framework, termed physics-informed neural networks with invariant measure score matching (PINN-IMSM), for reconstructing dynamical systems from unlabeled point-cloud data that capture the system's invariant measure. The invariant density satisfies the steady-state Fokker-Planck (FP) equation. We reformulate this equation in terms of its score function (the gradient of the log-density), which is estimated directly from data via denoising score matching, thereby bypassing explicit density estimation. This learned score is then embedded into a physics-informed neural network (PINN) to reconstruct the drift velocity field under the resulting score-based FP equation. The mesh-free nature of PINNs allows the framework to scale to higher dimensions, avoiding the curse of dimensionality inherent in mesh-based methods. To address the ill-posedness of high-dimensional inverse problems, we recast the problem as a PDE-constrained optimization that seeks the minimal-energy velocity field. Under suitable conditions, we prove that this problem admits a unique solution that depends continuously on the score function. The constrained formulation is solved using a stochastic augmented Lagrangian method. Numerical experiments on representative dynamical systems, including the Van der Pol oscillator, an active swimmer in an anharmonic trap, and the chaotic Lorenz-63 and Lorenz-96 systems, demonstrate that PINN-IMSM accurately recovers invariant measures and reconstructs faithful dynamical behavior for problems in up to five dimensions."}
{"id": "2601.13332", "categories": ["math.PR", "math-ph", "math.CV"], "pdf": "https://arxiv.org/pdf/2601.13332", "abs": "https://arxiv.org/abs/2601.13332", "authors": ["Dmitry Chelkak", "Zachary Deiman"], "title": "Domino tilings of black-and-white Temperleyan cylinders", "comment": "26 pages, 3 figures", "summary": "We consider the dimer model in cylindrical domains $Ω_δ$ on square grids of mesh size $δ$ with two Temperleyan boundary components of different colors. Assuming that the $Ω_δ$ approximate a cylindrical domain $Ω$ as $δ\\to 0$, we prove the convergence of height fluctuations to the Gaussian Free Field in $Ω$ plus an independent discrete Gaussian multiple of the harmonic measure of one of the boundary components. The limit of the dimer coupling functions on $Ω_δ$ is holomorphic in $Ω$ but not conformally covariant. Given this, we determine the limiting structure of height fluctuations from general principles rather than from explicit computations. In particular, our analysis justifies the inevitable appearance of the discrete Gaussian distribution in the doubly connected setup."}
{"id": "2601.12190", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12190", "abs": "https://arxiv.org/abs/2601.12190", "authors": ["Luis Briceño-Arias", "Fernando Roldán"], "title": "Optimal Leveraging of Smoothness and Strong Convexity for Peaceman--Rachford Splitting", "comment": null, "summary": "In this paper, we introduce a simple methodology to leverage strong convexity and smoothness in order to obtain an optimal linear convergence rate for the Peaceman--Rachford splitting (PRS) scheme applied to optimization problems involving two smooth strongly convex functions. The approach consists of adding and subtracting suitable quadratic terms from one function to the other so as to redistribute strong convexity in the primal formulation and smoothness in the dual formulation. This yields an equivalent modified optimization problem in which each term has adjustable levels of strong convexity and smoothness. In this setting, the Peaceman--Rachford splitting method converges linearly to the solution of the modified problem with a convergence rate that can be optimized with respect to the introduced parameters. Upon returning to the original formulation, this procedure gives rise to a modified variant of PRS. The optimal linear rate established in this work is strictly better than the best rates previously available in the general setting. The practical performance of the method is illustrated through an academic example and applications in image processing."}
{"id": "2601.14170", "categories": ["math.PR", "cond-mat.stat-mech", "cs.DM", "math.CO", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.14170", "abs": "https://arxiv.org/abs/2601.14170", "authors": ["Vilas Winstein"], "title": "Wasserstein distances between ERGMs and Erdős-Rényi models", "comment": "33 pages", "summary": "Ferromagnetic exponential random graph models (ERGMs) are random graph models under which the presence of certain small structures (such as triangles) is encouraged; they can be constructed by tilting an Erdős--Rényi model by the exponential of a particular nonlinear Hamiltonian. These models are mixtures of metastable wells which each behave macroscopically like an Erdős--Rényi model, exhibiting the same laws of large numbers for subgraph counts [CD13]. However, on the microscopic scale these metastable wells are very different from Erdős--Rényi models, with the total variation distance between the two measures tending to 1 [MX23]. In this article we clarify this situation by providing a sharp (up to constants) bound on the Hamming-Wasserstein distance between the two models, which is the average number of edges at which they differ, under the coupling which minimizes this average. In particular, we show that this distance is $Θ(n^{3/2})$, quantifying exactly how these models differ. \n  An upper bound of this form has appeared in the past [RR19], but this was restricted to the subcritical (high-temperature) regime of parameters. We extend this bound, using a new proof technique, to the supercritical (low-temperature) regime, and prove a matching lower bound which has only previously appeared in the subcritical regime of special cases of ERGMs satisfying a \"triangle-free\" condition [DF25]. To prove the lower bound in the presence of triangles, we introduce an approximation of the discrete derivative of the Hamiltonian, which controls the dynamical properties of the ERGM, in terms of local counts of triangles and wedges (two-stars) near an edge. This approximation is the main technical and conceptual contribution of the article, and we expect it will be useful in a variety of other contexts as well. Along the way, we also prove a bound on the marginal edge probability under the ERGM via a new bootstrapping argument. Such a bound has already appeared [FLSW25], but again only in the subcritical regime and using a different proof strategy."}
{"id": "2601.12734", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.12734", "abs": "https://arxiv.org/abs/2601.12734", "authors": ["Zetao Ma", "Rui Du", "Lei Zhang"], "title": "Optimal Error Estimates of a Linearized Backward Euler Localized Orthogonal Decomposition for the Landau-Lifshitz Equation", "comment": null, "summary": "We introduce a novel spatial discretization technique for the reliable and efficient simulation of magnetization dynamics governed by the Landau-Lifshitz (LL) equation. The overall discretization error is systematically decomposed into temporal and spatial components. The spatial error analysis is conducted by formulating the LL equation within the framework of the Localized Orthogonal Decomposition (LOD) method. Numerical examples are presented to validate the accuracy and approximation properties of the proposed scheme."}
{"id": "2601.13354", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.13354", "abs": "https://arxiv.org/abs/2601.13354", "authors": ["Jean-Gabriel Attali"], "title": "Existence and uniqueness of invariant measures for non-Feller Markov semigroups", "comment": "15 pages", "summary": "We study existence and uniqueness of invariant probability measures for continuous-time Markov processes on general state spaces. Existence is obtained from tightness of time averages under a weak regularity assumption inspired by quasi-Feller semigroups, allowing for discontinuous and non-Feller dynamics.\n  Our main contribution concerns uniqueness. Under a natural $ψ$-irreducibility assumption, we show that the normalized resolvent kernel satisfies a domination property with respect to a reference measure. As a consequence, every invariant probability measure charges this reference measure. Since distinct ergodic invariant measures are mutually singular on standard Borel spaces, this domination property implies uniqueness whenever an invariant probability measure exists.\n  The argument is purely measure-theoretic and does not rely on Harris recurrence, return-time estimates, or Foster--Lyapunov conditions, and applies in particular to jump processes and hybrid models with discontinuous dynamics."}
{"id": "2601.12217", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12217", "abs": "https://arxiv.org/abs/2601.12217", "authors": ["Li Ye", "Yisheng Song"], "title": "Interval B-Tensors and Interval Double B-Tensors", "comment": null, "summary": "This paper systematically investigates the properties and characterization of interval B-tensors and interval double B-tensors. We propose verifiable necessary and sufficient conditions that allow for determining whether an entire interval tensor family belongs to these classes based solely on its extreme point tensors. The study elucidates profound connections between these interval tensors and other structured ones such as interval Z-tensors and P-tensors, while also providing simplified criteria for special cases like circulant structures. Furthermore, under the condition of even order and symmetry, we prove that interval B-tensors (double B-tensors) ensure the property of being an interval P-tensor. This work extends interval matrix theory to tensors, offering new analytical tools for fields such as polynomial optimization and complementarity problems involving uncertainty."}
{"id": "2601.12776", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12776", "abs": "https://arxiv.org/abs/2601.12776", "authors": ["Yonghui Bo", "Yushun Wang"], "title": "High-order Lagrange multiplier schemes for general Hamiltonian PDEs", "comment": null, "summary": "In this paper, we introduce a Lagrange multiplier approach to construct linearly implicit energy-preserving schemes of arbitrary order for general Hamiltonian PDEs. Unlike the widely used auxiliary variable methods, this novel approach does not require the nonlinear part of the energy to be bounded from below, thereby offering broader applicability. Moreover, this approach preserves the original energy exactly at both the continuous and discrete levels, as opposed to a modified energy preserved by the auxiliary variable methods. Rigorous proofs are provided for the energy conservation and numerical accuracy of all derived schemes. The trade-off for these advantages is the need to solve a nonlinear algebraic equation to determine the Lagrange multiplier. Nevertheless, numerical experiments show that the associated computational cost is generally not dominant, indicating that the new schemes retain computational efficiency comparable to the auxiliary variable-based schemes. Numerical results demonstrate the efficiency, accuracy, and structure-preserving properties of the proposed schemes."}
{"id": "2601.13426", "categories": ["math.PR", "cs.DS", "econ.GN", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.13426", "abs": "https://arxiv.org/abs/2601.13426", "authors": ["Taha Ameen", "Flore Sentenac", "Sophie H. Yu"], "title": "A uniformity principle for spatial matching", "comment": null, "summary": "Platforms matching spatially distributed supply to demand face a fundamental design choice: given a fixed total budget of service range, how should it be allocated across supply nodes ex ante, i.e. before supply and demand locations are realized, to maximize fulfilled demand? We model this problem using bipartite random geometric graphs where $n$ supply and $m$ demand nodes are uniformly distributed on $[0,1]^k$ ($k \\ge 1$), and edges form when demand falls within a supply node's service region, the volume of which is determined by its service range. Since each supply node serves at most one demand, platform performance is determined by the expected size of a maximum matching. We establish a uniformity principle: whenever one service range allocation is more uniform than the other, the more uniform allocation yields a larger expected matching. This principle emerges from diminishing marginal returns to range expanding service range, and limited interference between supply nodes due to bounded ranges naturally fragmenting the graph. For $k=1$, we further characterize the expected matching size through a Markov chain embedding and derive closed-form expressions for special cases. Our results provide theoretical guidance for optimizing service range allocation and designing incentive structures in ride-hailing, on-demand labor markets, and drone delivery networks."}
{"id": "2601.12226", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12226", "abs": "https://arxiv.org/abs/2601.12226", "authors": ["Zongxia Liang", "Zhou Zhou", "Yaqi Zhuang", "Bin Zou"], "title": "Mean-Field Games Under Model Uncertainty", "comment": null, "summary": "We study discrete-time, finite-state mean-field games (MFGs) under model uncertainty, where agents face ambiguity about the state transition probabilities. Each agent maximizes its expected payoff against the worst-case transitions within an uncertainty set. Unlike in classical MFGs, model uncertainty renders the population distribution flow stochastic. This leads us to consider strategies that depend on both individual states and the realized distribution of the population. Our main results establish the asymptotic relationship between $N$-agent games and MFGs: every MFG equilibrium constitutes an $\\varepsilon$-Nash equilibrium for sufficiently large populations, and conversely, limits of $N$-agent equilibria are MFG equilibria. We also prove the existence of equilibria for finite-agent games and construct a solvable mean-field example with closed-form solutions."}
{"id": "2601.12792", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12792", "abs": "https://arxiv.org/abs/2601.12792", "authors": ["Harshit Bajpai", "Ankik Kumar Giri"], "title": "Graph Laplacian assisted regularization method under noise level free heuristic and statistical stopping rule", "comment": null, "summary": "In this work, we address the solution of both linear and nonlinear ill-posed inverse problems by developing a novel graph-based regularization framework, where the regularization term is formulated through an iteratively updated graph Laplacian. The proposed approach operates without prior knowledge of the noise level and employs two distinct stopping criteria namely, the heuristic rule and the statistical discrepancy principle. To facilitate the latter, we utilize averaged measurements derived from multiple repeated observations. We provide a detailed convergence analysis of the method in statistical prospective, establishing its stability and regularization properties under both stopping strategies. The algorithm begins with the computation of an initial reconstruction using any suitable techniques like Tikhonov regularization (Tik), filtered back projection (FBP) or total variation (TV), which is used as the foundation for generating the initial graph Laplacian. The reconstruction is made better step by step using an iterative process, during which the graph Laplacian is dynamically re-calibrated to reflect how the solution's structure is changing. Finally, we present numerical experiments on X-ray Computed Tomography (CT) and phase retrieval CT, demonstrating the effectiveness and robustness of the proposed method and comparing its reconstruction performance under both stopping rules."}
{"id": "2601.13738", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.13738", "abs": "https://arxiv.org/abs/2601.13738", "authors": ["Maximilian Fels", "Oren Louidor", "Tianqi Wu"], "title": "Second Order Asymptotics for the Hard Wall Probability of the 2D Harmonic Crystal", "comment": "27 pages", "summary": "We estimate the probability that the discrete Gaussian free field on a planar domain with Dirichlet boundary conditions stays positive in the bulk. Improving upon the result by Bolthausen, Deuschel and Giacomin from 2001, we derive the order of the subleading term of this probability when a sequence of discretized scale-ups of given domain and compactly included smooth bulk are considered. A main ingredient in the proof is the double exponential decay of the right tail of the centered minimum of the field in the bulk, conditioned on a certain weighted average of its values to be zero."}
{"id": "2601.12383", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12383", "abs": "https://arxiv.org/abs/2601.12383", "authors": ["Ahmad Mousavi", "Morteza Kimiaei", "Saman Babaie-Kafaki", "Vyacheslav Kungurtsev"], "title": "An efficient penalty decomposition algorithm for minimization over sparse symmetric sets", "comment": null, "summary": "This paper proposes an improved quasi-Newton penalty decomposition algorithm for the minimization of continuously differentiable functions, possibly nonconvex, over sparse symmetric sets. The method solves a sequence of penalty subproblems approximately via a two-block decomposition scheme: the first subproblem admits a closed-form solution without sparsity constraints, while the second subproblem is handled through an efficient sparse projection over the symmetric feasible set. Under a new assumption on the gradient of the objective function, weaker than global Lipschitz continuity from the origin, we establish that accumulation points of the outer iterates are basic feasible and cardinality-constrained Mordukhovich stationarity points. To ensure robustness and efficiency in finite-precision arithmetic, the algorithm incorporates several practical enhancements, including an enhanced line search strategy based on either backtracking or extrapolation, and four inexpensive diagonal Hessian approximations derived from differences of previous iterates and gradients or from eigenvalue-distribution information. Numerical experiments on a diverse benchmark of $30$ synthetic and data-driven test problems, including machine-learning datasets from the UCI repository and sparse symmetric instances with dimensions ranging from $10$ to $500$, demonstrate that the proposed algorithm is competitive with several state-of-the-art methods in terms of efficiency, robustness, and strong stationarity."}
{"id": "2601.12793", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12793", "abs": "https://arxiv.org/abs/2601.12793", "authors": ["Archana Arya", "Kaushik Kalyanaraman"], "title": "Two Frameworks and their Fourth Order Implicit Schemes for Time Discretization of Maxwell's Equations", "comment": null, "summary": "Our work is about energy conserving fourth-order time discretizations of a three-field formulation of Maxwell's equations in conjunction with a spatial discretization using higher-order and compatible de Rham finite element spaces. Toward this end, we delineate two broad classes of strategies for general higher-order time discretizations which we term spatial and temporal strategies. We provide a description of these two strategies and develop fourth-order time accurate schemes in the context of our Maxwell's system. However, our description can be used to prescribe similar fourth- or even higher-order time-integration methods for any linear (or quasi-linear) system of time-dependent partial differential equations. Our organizing principle in our proposed two strategies is to Taylor expand the unknown solution in time by assuming sufficient regularity. Then, in the spatial strategy, we use Maxwell's equations themselves to replace the fourth-order time derivatives in an appropriately truncated Taylor expansion with corresponding higher-order spatial derivatives. On the other hand, in the temporal strategy, we simply use higher-order finite difference schemes for the various higher-order time derivative terms in the truncated Taylor approximation. In both cases, we then defer to a standard finite element exterior calculus manner of compatible discretization for the spatial component of the Maxwell's solution. For our proposed schemes corresponding to the two strategies, we show that they are both stable and convergent and provide some validating numerical examples in $\\mathbb{R}^2$. Our main contributions are in the development of the fourth-order time discretization methods that are energy conserving using our two outlined strategies and proofs of their convergence for semi- and full-discretizations of our three-field system of Maxwell's equations."}
{"id": "2601.14074", "categories": ["math.PR", "math.CA"], "pdf": "https://arxiv.org/pdf/2601.14074", "abs": "https://arxiv.org/abs/2601.14074", "authors": ["José Arcia-Manoleskos", "Manuel Domínguez de la Iglesia"], "title": "LU-type factorizations for birth--death processes and their Darboux transformations", "comment": "38 pages", "summary": "We study LU-type factorizations of the infinitesimal generator of a birth--death process on $\\mathbb{N}_0$. Our goal is to characterize those factorizations whose Darboux transformations (that is, inverting the order of the factors) yield new infinitesimal generators of birth--death processes. Two types are considered: lower--upper (LU), which is unique and upper--lower (UL), which involves a free parameter. For both cases, we determine the conditions under which such factorizations can occur, derive explicit formulas for their coefficients, and provide a probabilistic interpretation of the factors. The spectral properties and associated orthogonal polynomials of the Darboux transformations are also analyzed. Finally, the general results are applied to classical examples such as the $M/M/1$ and $M/M/\\infty$ queues and to different cases of linear birth--death processes."}
{"id": "2601.12398", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12398", "abs": "https://arxiv.org/abs/2601.12398", "authors": ["Haijuan Liu", "Xuyang Wu"], "title": "Anderson Acceleration for Distributed Constrained Optimization over Time-varying Networks", "comment": null, "summary": "This paper applies the Anderson Acceleration (AA) technique to accelerate the Fenchel dual gradient method (FDGM) to solve constrained optimization problems over time-varying networks. AA is originally designed for accelerating fixed-point iterations, and its direct application to FDGM faces two challenges: 1) FDGM in time-varying networks cannot be formulated as a standard fixed-point update; 2) even if the network is fixed so that FDGM can be expressed as a fixed-point iteration, the direct application of AA is not distributively implementable. To overcome these challenges, we first rewrite each update of FDGM as inexactly solving several \\emph{local} problems where each local problem involves two neighboring nodes only, and then incorporate AA to solve each local problem with higher accuracy, resulting in the Fenchel Dual Gradient Method with Anderson Acceleration (FDGM-AA). To guarantee global convergence of FDGM-AA, we equip it with a newly designed safe-guard scheme. Under mild conditions, our algorithm converges at a rate of \\(O(1/\\sqrt{k})\\) for the primal sequence and \\(O(1/k)\\) for the dual sequence. The competitive performance of our algorithm is validated through numerical experiments."}
{"id": "2601.12831", "categories": ["math.NA", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12831", "abs": "https://arxiv.org/abs/2601.12831", "authors": ["Markus Haltmeier", "Gyeongha Hwang"], "title": "Data-Consistent Learning of Inverse Problems", "comment": null, "summary": "Inverse problems are inherently ill-posed, suffering from non-uniqueness and instability. Classical regularization methods provide mathematically well-founded solutions, ensuring stability and convergence, but often at the cost of reduced flexibility or visual quality. Learned reconstruction methods, such as convolutional neural networks, can produce visually compelling results, yet they typically lack rigorous theoretical guarantees. DC (DC) networks address this gap by enforcing the measurement model within the network architecture. In particular, null-space networks combined with a classical regularization method as an initial reconstruction define a convergent regularization method. This approach preserves the theoretical reliability of classical schemes while leveraging the expressive power of data-driven learning, yielding reconstructions that are both accurate and visually appealing."}
{"id": "2601.14166", "categories": ["math.PR", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.14166", "abs": "https://arxiv.org/abs/2601.14166", "authors": ["Benedikt Stufler"], "title": "Poisson-Dirichlet graphons and permutons", "comment": null, "summary": "We introduce classes of supergraphs and superpermutations with novel universal graphon and permuton limiting objects whose construction involves the two-parameter Poisson-Dirichlet process introduced by Pitman and Yor (1997). We demonstrate the universality of these limiting objects through general invariance principles in a heavy-tailed regime and establish a comprehensive phase diagram for the asymptotic shape of superstructures."}
{"id": "2601.12400", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12400", "abs": "https://arxiv.org/abs/2601.12400", "authors": ["Laurent Condat", "Artavazd Maranjyan", "Peter Richtárik"], "title": "BiCoLoR: Communication-Efficient Optimization with Bidirectional Compression and Local Training", "comment": null, "summary": "Slow and costly communication is often the main bottleneck in distributed optimization, especially in federated learning where it occurs over wireless networks. We introduce BiCoLoR, a communication-efficient optimization algorithm that combines two widely used and effective strategies: local training, which increases computation between communication rounds, and compression, which encodes high-dimensional vectors into short bitstreams. While these mechanisms have been combined before, compression has typically been applied only to uplink (client-to-server) communication, leaving the downlink (server-to-client) side unaddressed. In practice, however, both directions are costly. We propose BiCoLoR, the first algorithm to combine local training with bidirectional compression using arbitrary unbiased compressors. This joint design achieves accelerated complexity guarantees in both convex and strongly convex heterogeneous settings. Empirically, BiCoLoR outperforms existing algorithms and establishes a new standard in communication efficiency."}
{"id": "2601.12878", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12878", "abs": "https://arxiv.org/abs/2601.12878", "authors": ["Kevin Schäfers", "Michael Günther"], "title": "A hierarchical splitting approach for N-split differential equations", "comment": "21 pages, 9 figures", "summary": "We propose a hierarchical splitting approach to differential equations that provides a design principle for constructing splitting methods for $N$-split systems by iteratively applying splitting methods for two-split systems. We analyze the convergence order, derive explicit formulas for the leading-order error terms, and investigate self-adjointness. Moreover, we discuss compositions of hierarchical splitting methods in detail. We further augment the hierarchical splitting approach with multiple time-stepping techniques, turning the class into a promising framework at the intersection of geometric numerical integration and multirate integration. In this context, we characterize the computational order of a multirate integrator and establish conditions on the multirate factors that guarantee an increased convergence rate in practical computations up to a certain step size. Finally, we design several hierarchical splitting methods and perform numerical simulations for rigid body equations and a separable Hamiltonian system with multirate potential, confirming the theoretical findings and showcasing the computational efficiency of hierarchical splitting methods."}
{"id": "2601.14169", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.14169", "abs": "https://arxiv.org/abs/2601.14169", "authors": ["Giacomo Borghi"], "title": "Chaos propagation in genetic algorithms: An optimal transport approach", "comment": null, "summary": "Genetic algorithms are high-level heuristic optimization methods which enjoy great popularity thanks to their intuitive description, flexibility, and, of course, effectiveness. The optimization procedure is based on the evolution of possible solutions following three mechanisms: selection, mutation, and crossover. In this paper, we look at the algorithm as an interacting particle system and show that it is described by a Boltzmann-type equation in the many particles limit. Specifically, we prove a propagation of chaos result with a novel technique that leverages the optimal transport formulation of the Kantorovich-Rubinstein norm and naturally incorporates the crossover mechanism into the analysis. The convergence rate is sharp with respect to the number of particles."}
{"id": "2601.12411", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12411", "abs": "https://arxiv.org/abs/2601.12411", "authors": ["Saeed Sadeghi Arjmand"], "title": "Dynamic resource allocation in eukaryotic Resource Balance Analysis", "comment": null, "summary": "Resource Balance Analysis (RBA) is a framework for predicting steady-state cellular growth under resource constraints. However, classical RBA formulations are static and do not capture the dynamic regulation of biosynthetic resources or macromolecular turnover, which is particularly important in eukaryotic cells. In this work, we propose a dynamic extension of eukaryotic RBA based on an optimal control formulation. Cellular growth is modeled as the result of a time-dependent allocation of translational capacity between metabolic enzymes and macromolecular machinery, aimed at maximizing biomass accumulation over a finite time horizon. Using Pontryagin's Maximum Principle, we characterize optimal allocation strategies and show that steady-state RBA solutions arise as limiting regimes of the dynamic problem."}
{"id": "2601.12907", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.12907", "abs": "https://arxiv.org/abs/2601.12907", "authors": ["Maxime Bouchereau"], "title": "Machine Learning for highly oscillatory differential equations", "comment": null, "summary": "Highly oscillatory differential equations, commonly encountered in multi-scale problems, are often too complex to solve analytically. However, several numerical methods have been developed to approximate their solutions. Although these methods have shown their efficiency, the first part of the strategy often involves heavy pre-computations from averaging theory. In this paper, we leverage neural networks (machine learning) to approximate the vector fields required by the pre-computations in the first part, and combine this with micro-macro techniques to efficiently solve the oscillatory problem. We illustrate our work by numerical simulations."}
{"id": "2601.14170", "categories": ["math.PR", "cond-mat.stat-mech", "cs.DM", "math.CO", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.14170", "abs": "https://arxiv.org/abs/2601.14170", "authors": ["Vilas Winstein"], "title": "Wasserstein distances between ERGMs and Erdős-Rényi models", "comment": "33 pages", "summary": "Ferromagnetic exponential random graph models (ERGMs) are random graph models under which the presence of certain small structures (such as triangles) is encouraged; they can be constructed by tilting an Erdős--Rényi model by the exponential of a particular nonlinear Hamiltonian. These models are mixtures of metastable wells which each behave macroscopically like an Erdős--Rényi model, exhibiting the same laws of large numbers for subgraph counts [CD13]. However, on the microscopic scale these metastable wells are very different from Erdős--Rényi models, with the total variation distance between the two measures tending to 1 [MX23]. In this article we clarify this situation by providing a sharp (up to constants) bound on the Hamming-Wasserstein distance between the two models, which is the average number of edges at which they differ, under the coupling which minimizes this average. In particular, we show that this distance is $Θ(n^{3/2})$, quantifying exactly how these models differ. \n  An upper bound of this form has appeared in the past [RR19], but this was restricted to the subcritical (high-temperature) regime of parameters. We extend this bound, using a new proof technique, to the supercritical (low-temperature) regime, and prove a matching lower bound which has only previously appeared in the subcritical regime of special cases of ERGMs satisfying a \"triangle-free\" condition [DF25]. To prove the lower bound in the presence of triangles, we introduce an approximation of the discrete derivative of the Hamiltonian, which controls the dynamical properties of the ERGM, in terms of local counts of triangles and wedges (two-stars) near an edge. This approximation is the main technical and conceptual contribution of the article, and we expect it will be useful in a variety of other contexts as well. Along the way, we also prove a bound on the marginal edge probability under the ERGM via a new bootstrapping argument. Such a bound has already appeared [FLSW25], but again only in the subcritical regime and using a different proof strategy."}
{"id": "2601.12738", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12738", "abs": "https://arxiv.org/abs/2601.12738", "authors": ["Ba Khiet Le", "Zakaria Mazgouri", "Michel Théra"], "title": "Monotonicity of Pairs of Operators and Generalized Inertial Proximal Method", "comment": null, "summary": "Monotonicity of pairs of operators is an extension of monotonicity of operators, which plays an important role in solving non-monotone inclusions. One of challenging problems in this new tool is how to design the associated mappings to obtain the monotone pairs. In this paper, we solve this problem and propose a Generalized Inertial Proximal Point Algorithm (GIPPA) using warped resolvents under the monotonicity of pairs. The weak, strong and linear convergence of the algorithm under some mild assumptions are established. We also provide numerical examples illustrating the implementability and effectiveness of the proposed method."}
{"id": "2601.13004", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.13004", "abs": "https://arxiv.org/abs/2601.13004", "authors": ["Charles M. Elliott", "Thomas Sales"], "title": "An iterative approach to a fluid-rigid body interaction problem", "comment": "53 pages, 5 figures, 4 tables", "summary": "We study a novel approach for the existence of solutions to an incompressible fluid-rigid body interaction problem in three dimensions. Our approach introduces an iteration based on a sequence of related problems posed on domains with prescribed evolution. In particular we prove the short-time existence of strong solutions to a system coupling the incompressible Navier--Stokes equations to the ordinary differential equations governing the motion of a rigid body, with no slip boundary conditions on the boundary of the rigid body, provided that the relative density $\\fracρ{ρ_B}$, is sufficiently small. We also discuss the use of our iterative approach in numerical methods for the moving boundary problem, and complement this with some numerical experiments in two dimensions which demonstrate the necessity of the smallness assumption on $\\fracρ{ρ_B}$."}
{"id": "2601.11717", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.11717", "abs": "https://arxiv.org/abs/2601.11717", "authors": ["Elchanan Mossel", "Anirudh Sridhar"], "title": "Detecting Mutual Excitations in Non-Stationary Hawkes Processes", "comment": "12 pages", "summary": "We consider the problem of learning the network of mutual excitations (i.e., the dependency graph) in a non-stationary, multivariate Hawkes process. We consider a general setting where baseline rates at each node are time-varying and delay kernels are not shift-invariant. Our main results show that if the dependency graph of an $n$-variate Hawkes process is sparse (i.e., it has a maximum degree that is bounded with respect to $n$), our algorithm accurately reconstructs it from data after observing the Hawkes process for $T = \\mathrm{polylog}(n)$ time, with high probability. Our algorithm is computationally efficient, and provably succeeds in learning dependencies even if only a subset of time series are observed and event times are not precisely known."}
{"id": "2601.12810", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.12810", "abs": "https://arxiv.org/abs/2601.12810", "authors": ["Hoai-Minh Nguyen"], "title": "Optimal bounds for the boundary control cost of one-dimensional fractional Schrödinger and heat equations", "comment": null, "summary": "We derive sharp bounds for the boundary control cost of the one-dimensional fractional Schrödinger and heat equations. The analysis of the lower bound is based on the study of the control cost of a related singular boundary control problem in finite time, using tools from complex analysis. The analysis of the upper bound relies on the moment method, involving estimates of the Fourier transform of a class of compactly supported functions."}
{"id": "2601.13039", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13039", "abs": "https://arxiv.org/abs/2601.13039", "authors": ["Mattia Manucci", "Benjamin Unger"], "title": "Solving Generalized Lyapunov Equations with guarantees: application to the Model Reduction of Switched Linear Systems", "comment": null, "summary": "We present an efficient strategy to approximate the solutions of large-scale generalized Lyapunov equations (GLEs) with rigorous, computable error guarantees. This work is motivated by applications in model order reduction (MOR) of switched linear systems (SLS) in control form, where GLEs play a central role. We analyze how inaccuracies in the numerical solution of GLEs propagate through the MOR procedure and affect the accuracy and reliability of the reduced order model. Furthermore, the classical balanced-truncation error estimate for SLS is neither theoretically nor practically viable, as they rely on restrictive assumptions requiring several requiring several linear matrix inequalities (LMI) to be satisfied exactly by numerically computed solutions of the GLEs. To overcome these limitation, we propose a new MOR framework for SLS, called piecewise balanced reduction (PBR). The method is based on solving multiple GLEs and the construction of projection matrices that are piecewise constant in time to appropriately balance and subsequently reduce the SLS. We extend the standard balanced-truncation error bounds and demonstrate that the PBR formulation allows us to control the error arising from the inexact LMI. In addition, our new error bound accounts for the influence of the piecewise constant time-varying projection matrices. Altogether, this renders the PBR approach for SLS applicable to a broad and flexible class of SLS. Numerical experiments are provided to corroborate our theoretical results."}
{"id": "2601.12957", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.12957", "abs": "https://arxiv.org/abs/2601.12957", "authors": ["Hanne Kekkonen", "Andreas Tataris"], "title": "Random tree Besov priors: Data-driven regularisation parameter selection", "comment": null, "summary": "We develop a data-driven algorithm for automatically selecting the regularisation parameter in Bayesian inversion under random tree Besov priors. One of the key challenges in Bayesian inversion is the construction of priors that are both expressive and computationally feasible. Random tree Besov priors, introduced in Kekkonen et al. (2023), provide a flexible framework for capturing local regularity properties and sparsity patterns in a wavelet basis. In this paper, we extend this approach by introducing a hierarchical model that enables data-driven selection of the wavelet density parameter, allowing the regularisation strength to adapt across scales while retaining computational efficiency. We focus on nonparametric regression and also present preliminary plug-and-play results for a deconvolution problem."}
{"id": "2601.13026", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13026", "abs": "https://arxiv.org/abs/2601.13026", "authors": ["José Niño-Mora"], "title": "Multi-gear bandits, partial conservation laws, and indexability", "comment": "33 pages", "summary": "This paper considers what we propose to call multi-gear bandits, which are Markov decision processes modeling a generic dynamic and stochastic project fueled by a single resource and which admit multiple actions representing gears of operation naturally ordered by their increasing resource consumption. The optimal operation of a multi-gear bandit aims to strike a balance between project performance costs or rewards and resource usage costs, which depend on the resource price. A computationally convenient and intuitive optimal solution is available when such a model is indexable, meaning that its optimal policies are characterized by a dynamic allocation index (DAI), a function of state--action pairs representing critical resource prices. Motivated by the lack of general indexability conditions and efficient index-computing schemes, and focusing on the infinite-horizon finite-state and -action discounted case, we present a verification theorem ensuring that, if a model satisfies two proposed PCL-indexability conditions with respect to a postulated family of structured policies, then it is indexable and such policies are optimal, with its DAI being given by a marginal productivity index computed by a downshift adaptive-greedy algorithm in $A N$ steps, with $A+1$ actions and $N$ states. The DAI is further used as the basis of a new index policy for the multi-armed multi-gear bandit problem."}
{"id": "2601.13110", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13110", "abs": "https://arxiv.org/abs/2601.13110", "authors": ["Bangti Jin", "Zeljko Kereta", "Yuxin Xia"], "title": "Stochastic Gradient Descent for Nonlinear Inverse Problems in Banach Spaces", "comment": "24 pages, to appear at SIAM Journal on Imaging Sciences", "summary": "Stochastic gradient descent (SGD) and its variants are widely used and highly effective optimization methods in machine learning, especially for neural network training. By using a single datum or a small subset of the data, selected randomly at each iteration, SGD scales well to problem size and has been shown to be effective for solving large-scale inverse problems. In this work, we investigate SGD for solving nonlinear inverse problems in Banach spaces through the lens of iterative regularization. Under general assumptions, we prove almost sure convergence of the iterates to the minimum distance solution and show the regularizing property in expectation under an a priori stopping rule. Further, we establish convergence rates under the conditional stability assumptions for both exact and noisy data. Numerical experiments on Schlieren tomography and electrical impedance tomography are presented to show distinct features of the method."}
{"id": "2601.13136", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13136", "abs": "https://arxiv.org/abs/2601.13136", "authors": ["Marcin Pitera", "Łukasz Stettner"], "title": "Blackwell optimality in risk-sensitive stochastic control", "comment": "Pre-submission version. Accepted and published in IEEE conference proceedings", "summary": "In this paper, we consider a discrete-time Markov Decision Process (MDP) on a finite state-action space with a long-run risk-sensitive criterion used as the objective function. We discuss the concept of Blackwell optimality and comment on intricacies which arise when the risk-neutral expectation is replaced by the risk-sensitive entropy. Also, we show the relation between the Blackwell optimality and ultimate stationarity and provide an illustrative example that helps to better understand the structural difference between these two concepts."}
{"id": "2601.13027", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13027", "abs": "https://arxiv.org/abs/2601.13027", "authors": ["Zixin Deng", "Zheng-Hai Huang", "Yun-Bin Zhao"], "title": "Optimality Conditions for Sparse Bilinear Least Squares Problems", "comment": null, "summary": "The first-order optimality conditions of sparse bilinear least squares problems are studied. The so-called T-type and N-type stationary points for this problem are characterized in terms of tangent cone and normal cone in Bouligand and Clarke senses, and another stationarity concept called the coordinate-wise minima is introduced and discussed. Moreover, the L-like stationary point for this problem is introduced and analyzed through the newly introduced concept of like-projection, and the M-stationary point is also investigated via a complementarity-type reformulation of the problem. The relationship between these stationary points is discussed as well. It turns out that all stationary points discussed in this work satisfy the necessary optimality conditions for the sparse bilinear least squares problem."}
{"id": "2601.13230", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13230", "abs": "https://arxiv.org/abs/2601.13230", "authors": ["Michał Wichrowski"], "title": "Towards Matrix-Free Patch Smoothers for the Stokes Problem: Evaluating Local p-Multigrid Solvers", "comment": null, "summary": "Vertex-patch smoothers offer an effective strategy for achieving robust geometric multigrid convergence for the Stokes equations, particularly in the context of high-order finite elements. However, their practical efficiency is often limited by the computational cost of solving the local saddle-point problems, especially when explicit matrix factorizations are not feasible. We explore a fully iterative, matrix-free-compatible approach to the local patch solve using $p$-multigrid techniques. We evaluate different local solver configurations: Braess-Sarazin and block-triangular preconditioners. Our numerical experiments suggest that the Braess-Sarazin approach is particularly resilient. We find that a single iteration of the local solver yields global convergence rates comparable to those obtained with exact local solvers, even on distorted meshes and in the presence of large viscosity jumps."}
{"id": "2601.13254", "categories": ["math.ST", "math.AP", "math.FA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13254", "abs": "https://arxiv.org/abs/2601.13254", "authors": ["Dimitri Konen"], "title": "Inverting the Fisher information operator in non-linear models", "comment": null, "summary": "We consider non-linear regression models corrupted by generic noise when the regression functions form a non-linear subspace of L^2, relevant in non-linear PDE inverse problems and data assimilation. We show that when the score of the model is injective, the Fisher information operator is automatically invertible between well-identified Hilbert spaces, and we provide an operational characterization of these spaces. This allows us to construct in broad generality the efficient Gaussian involved in the classical minimax and convolution theorems to establish information lower bounds, that are typically achieved by Bayesian algorithms thus showing optimality of these methods. We illustrate our results on time-evolution PDE models for reaction-diffusion and Navier-Stokes equations."}
{"id": "2601.13045", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13045", "abs": "https://arxiv.org/abs/2601.13045", "authors": ["José Niño-Mora"], "title": "Markovian restless bandits and index policies: A review", "comment": "33 pages", "summary": "The restless multi-armed bandit problem is a paradigmatic modeling framework for optimal dynamic priority allocation in stochastic models of wide-ranging applications that has been widely investigated and applied since its inception in a seminal paper by Whittle in the late 1980s. The problem has generated a vast and fast-growing literature from which a significant sample is thematically organized and reviewed in this paper. While the main focus is on priority-index policies due to their intuitive appeal, tractability, asymptotic optimality properties, and often strong empirical performance, other lines of work are also reviewed. Theoretical and algorithmic developments are discussed, along with diverse applications. The main goals are to highlight the remarkable breadth of work that has been carried out on the topic and to stimulate further research in the field."}
{"id": "2601.13256", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13256", "abs": "https://arxiv.org/abs/2601.13256", "authors": ["Wenzhong Zhang", "Zhenyuan Hu", "Wei Cai", "George EM Karniadakis"], "title": "Deep Neural networks for solving high-dimensional parabolic partial differential equations", "comment": null, "summary": "The numerical solution of high dimensional partial differential equations (PDEs) is severely constrained by the curse of dimensionality (CoD), rendering classical grid--based methods impractical beyond a few dimensions. In recent years, deep neural networks have emerged as a promising mesh free alternative, enabling the approximation of PDE solutions in tens to thousands of dimensions. This review provides a tutorial--oriented introduction to neural--network--based methods for solving high dimensional parabolic PDEs, emphasizing conceptual clarity and methodological connections. We organize the literature around three unifying paradigms: (i) PDE residual--based approaches, including physicsinformed neural networks and their high dimensional variants; (ii) stochastic methods derived from Feynman--Kac and backward stochastic differential equation formulations; and (iii) hybrid derivative--free random difference approaches designed to alleviate the computational cost of derivatives in high dimensions. For each paradigm, we outline the underlying mathematical formulation, algorithmic implementation, and practical strengths and limitations. Representative benchmark problems--including Hamilton--Jacobi--Bellman and Black--Scholes equations in up to 1000 dimensions --illustrate the scalability, effectiveness, and accuracy of the methods. The paper concludes with a discussion of open challenges and future directions for reliable and scalable solvers of high dimensional PDEs."}
{"id": "2601.13493", "categories": ["math.OC", "math.FA", "math.PR", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.13493", "abs": "https://arxiv.org/abs/2601.13493", "authors": ["Hanchao Liu", "Dena Firoozi"], "title": "LQ Mean Field Games with Common Noise in Hilbert Spaces: Small and Arbitrary Finite Time Horizons", "comment": "27 pages", "summary": "We extend the results of (Liu and Firoozi, 2025), which develops the theory of linear-quadratic (LQ) mean field games in Hilbert spaces, by incorporating a common noise. This common noise is an infinite-dimensional Wiener process affecting the dynamics of all agents. In the presence of common noise, the mean-field consistency condition is characterized by a system of coupled forward-backward stochastic evolution equations (FBSEEs) in Hilbert spaces, whereas in its absence, it is represented by forward-backward deterministic evolution equations. We establish the existence and uniqueness of solutions to the coupled linear FBSEEs associated with the LQ MFG setting for small time horizons and prove the $ε$-Nash property of the resulting equilibrium strategy. Furthermore, for the first time in the literature, we develop an analysis that establishes the well-posedness of these coupled linear FBSEEs in Hilbert spaces, for which only mild solutions exist, over arbitrary finite time horizons."}
{"id": "2601.13124", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13124", "abs": "https://arxiv.org/abs/2601.13124", "authors": ["Donglei Du", "Qizhi Fang", "Bin Liu", "Tianhang Lu", "Chenchen Wu"], "title": "Full characterization of core for nonlinear optimization games", "comment": null, "summary": "We fully characterize the core of a broad class of nonlinear games by identifying a suitable relaxation for inherent nonlinearity, directly generalizing the linear frameworks in the literature. This characterization significantly expands the scope of cooperative games that can be analyzed and contributes to the literature on games induced from optimization models. We apply these insights to not only establish connections with and provide new insights on classical models but also solve new games untamed in the existing literature, including combinatorial quadratic and ratio games such as portfolio, maximum cut, matching, and assortment games. These results are further extended to more general models and also the approximate core."}
{"id": "2601.13347", "categories": ["math.NA", "math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13347", "abs": "https://arxiv.org/abs/2601.13347", "authors": ["Aryeh Keating", "Mirjeta Pasha"], "title": "A Scalable Sequential Framework for Dynamic Inverse Problems via Model Parameter Estimation", "comment": "27 Pages, 8 Figures", "summary": "Large-scale dynamic inverse problems are often ill-posed due to model complexity and the high dimensionality of the unknown parameters. Regularization is commonly employed to mitigate ill-posedness by incorporating prior information and structural constraints. However, classical regularization formulations are frequently infeasible in this setting due to prohibitive memory requirements, necessitating sequential methods that process data and state information online, eliminating the need to form the full space-time problem. In this work, we propose a memory-efficient framework for reconstructing dynamic sequences of undersampled images from computerized tomography data that requires minimal hyperparameter tuning. The approach is based on a prior-informed, dimension-reduced Kalman filter with smoothing. While well suited for dynamic image reconstruction, practical deployment is challenging when the state transition model and covariance parameters must be initialized without prior knowledge and estimated in a single pass. To address these limitations, we integrate regularized motion models with expectation-maximization strategies for the estimation of state transition dynamics and error covariances within the Kalman filtering framework. We demonstrate the effectiveness of the proposed method through numerical experiments on limited-angle and single-shot computerized tomography problems, highlighting improvements in reconstruction accuracy, memory efficiency, and computational cost."}
{"id": "2601.13576", "categories": ["math.OC", "eess.SY", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13576", "abs": "https://arxiv.org/abs/2601.13576", "authors": ["Shuwen Lu", "Jamol Pender", "Mark E. Lewis"], "title": "Control policies for a two-stage queueing system with parallel and single server options", "comment": null, "summary": "We study a two-stage tandem service queue attended by two servers. Each job-server pair must complete both service phases together, with the server unable to begin a new job until the current one is fully processed after two stages. Immediately after the first phase of service, the server decides whether to send the job/customer to a downstream station that allows parallel processing or to a single-service facility that offers faster or higher-quality service but handles only one job at a time. This choice determines whether the second phase commences immediately or (potentially) after waiting in a queue for the single-service facility to become available.\n  The decision-making scenario is modeled via a Markov decision process formulation, of a clearing system with holding costs at each station. We fully characterize the structural properties of an optimal control policy based on the relationship between the service rates at the downstream stations. A numerical study highlights the significance of optimal control by comparing its performance against several natural heuristic policies."}
{"id": "2601.13130", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13130", "abs": "https://arxiv.org/abs/2601.13130", "authors": ["José Niño-Mora"], "title": "Age of information cost minimization with no buffers, random arrivals and unreliable channels: A PCL-indexability analysis", "comment": "30 pages", "summary": "Over the last decade, the Age of Information has emerged as a key concept and metric for applications where the freshness of sensor-provided data is critical. Limited transmission capacity has motivated research on the design of tractable policies for scheduling information updates to minimize Age of Information cost based on Markov decision models, in particular on the restless multi-armed bandit problem (RMABP). This allows the use of Whittle's popular index policy, which is often nearly optimal, provided indexability (index existence) is proven, which has been recently accomplished in some models. We aim to extend the application scope of Whittle's index policy in a broader AoI scheduling model. We address a model with no buffers incorporating random packet arrivals, unreliable channels, and nondecreasing AoI costs. We use sufficient indexability conditions based on partial conservation laws previously introduced by the author to establish the model's indexability and evaluate its Whittle index in closed form under discounted and average cost criteria. We further use the index formulae to draw insights on how scheduling priority depends on model parameters."}
{"id": "2601.13536", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13536", "abs": "https://arxiv.org/abs/2601.13536", "authors": ["Mohammed Alanazi", "Majid Bani-Yaghoub"], "title": "Sparse Identification of Nonlinear Distributed-Delay Dynamics via the Linear Chain Trick", "comment": "25 pages", "summary": "The Sparse Identification of Nonlinear Dynamics (SINDy) framework has been frequently used to discover parsimonious differential equations governing natural and physical systems. This includes recent extensions to SINDy that enable the recovery of discrete delay differential equations, where delay terms are represented explicitly in the candidate library. However, such formulations cannot capture the distributed delays that naturally arise in biological, physical, and engineering systems. In the present work, we extend SINDy to identify distributed-delay differential equations by incorporating the Linear Chain Trick (LCT), which provides a finite-dimensional ordinary differential equation representing the distributed memory effects. Hence, SINDy can operate in an augmented state space using conventional sparse regression while preserving a clear interpretation of delayed influences via the chain trick. From time-series data, the proposed method jointly infers the governing equations, the mean delay, and the dispersion of the underlying delay distribution. We numerically verify the method on several models with distributed delay, including the logistic growth model and a Hes1--mRNA gene regulatory network model. We show that the proposed method accurately reconstructs distributed delay dynamics, remains robust under noise and sparse sampling, and provides a transparent, data-driven approach for discovering nonlinear systems with distributed-delay."}
{"id": "2601.13586", "categories": ["math.OC", "eess.SY", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13586", "abs": "https://arxiv.org/abs/2601.13586", "authors": ["Shuwen Lu", "Mark E. Lewis", "Jamol Pender"], "title": "Balancing Independent and Collaborative Service", "comment": null, "summary": "We study a two-type server queueing system where flexible Type-I servers, upon their initial interaction with jobs, decide in real time whether to process them independently or in collaboration with dedicated Type-II servers. Independent processing begins immediately, as does collaborative service if a Type-II server is available. Otherwise, the job and its paired Type-I server wait in queue for collaboration. Type-I servers are non-preemptive and cannot engage with new jobs until their current job is completed.\n  We provide a complete characterization of the structural properties of the optimal policy for the clearing system. In particular, an optimal control is shown to follow a threshold structure based on the number of jobs in the queue before a Type-I first interaction and on the number of jobs in either independent or collaborative service.\n  We propose simple threshold heuristics, based on linear approximations, for real-time decision-making. In much of the parameter and state spaces, we establish theoretical bounds that compare the thresholds proposed by our heuristics to those of optimal policies and identify parameter configurations where these bounds are attained. Outside of these regions, the optimal thresholds are infinite. Numerical experiments further demonstrate the accuracy and robustness of our heuristics, particularly when the initial queue length is high. Our proposed heuristics achieve costs within 0.5% of the optimal policy on average and significantly outperform benchmark policies that exhibit extreme sensitivity to system parameters, sometimes incurring costs exceeding 100% of the optimal."}
{"id": "2601.13136", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13136", "abs": "https://arxiv.org/abs/2601.13136", "authors": ["Marcin Pitera", "Łukasz Stettner"], "title": "Blackwell optimality in risk-sensitive stochastic control", "comment": "Pre-submission version. Accepted and published in IEEE conference proceedings", "summary": "In this paper, we consider a discrete-time Markov Decision Process (MDP) on a finite state-action space with a long-run risk-sensitive criterion used as the objective function. We discuss the concept of Blackwell optimality and comment on intricacies which arise when the risk-neutral expectation is replaced by the risk-sensitive entropy. Also, we show the relation between the Blackwell optimality and ultimate stationarity and provide an illustrative example that helps to better understand the structural difference between these two concepts."}
{"id": "2601.13541", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13541", "abs": "https://arxiv.org/abs/2601.13541", "authors": ["Yuanhong Wu", "Shuzhi Liu", "Qinglong Zhang"], "title": "A hybrid numerical method for a microscopic and macroscopic traffic flow model", "comment": null, "summary": "In this paper, we introduce a traffic flow model based on a microscopic follow-the-leader model, while enforcing maximal constraints on the density and velocity of the flow. The related macroscopic model can be represented in conservative formulation. By introducing an advected variable up with the flow, where p is the velocity offset, and u is the relative velocity, we reformulate the classical Aw-Rascle-Zhang (ARZ) model and the modified Aw-Rascle model to describe a realistic fundamental diagrams. The elementary waves are derived, and the Riemann problem is solved to validate the model's theoretical consistency. We further extend to a two-dimensional model. Numerical simulations are given for both one-and two-dimensional case by using the hybrid Godunov-Glimm scheme to verify the model's performance."}
{"id": "2601.13149", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13149", "abs": "https://arxiv.org/abs/2601.13149", "authors": ["Matko Grbac", "Ivan Ivec", "Marko Vrdoljak"], "title": "Classical Optimal Designs for Stationary Diffusion with Multiple Phases", "comment": "25 pages, 4 figures", "summary": "We study optimal design problems for stationary diffusion involving one or more state equations and mixtures of an arbitrary number of anisotropic materials. Since such problems typically do not admit classical solutions, we adopt a homogenization-based relaxation framework.\n  The objective considered is the maximization of a weighted sum of the energies associated with each state equation, with particular emphasis on identifying cases in which the optimal design is classical, that is, of bang-bang type, composed solely of the original pure materials. Such cases provide valuable benchmarks for numerical methods in optimal design.\n  A simplified optimization problem expressed in terms of local material proportions is analyzed through a dual formulation in terms of fluxes. Using a saddle-point characterization, we establish a complete description of its optimal solutions. The proposed approach is applied in detail to spherically symmetric problems. In the case of a ball, the method yields explicit classical solutions of the homogenization-based relaxation problem."}
{"id": "2601.13584", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13584", "abs": "https://arxiv.org/abs/2601.13584", "authors": ["Niels Goedegebure", "Kateryna Marynets"], "title": "Nonlinear fractional-periodic boundary value problems with Hilfer fractional derivative: existence and numerical approximations of solutions", "comment": null, "summary": "We prove conditions for existence of analytical solutions for boundary value problems with the Hilfer fractional derivative, generalizing the commonly used Riemann-Liouville and Caputo operators. The boundary values, referred to in this paper as fractional-periodic, are fractional integral conditions generalizing recurrent solution values for the non-Caputo case of the Hilfer fractional derivative. Analytical solutions to the studied problem are obtained using a perturbation of the corresponding initial value problem with enforced boundary conditions. In general, solutions to the boundary value problem are singular for $t\\downarrow 0$. To overcome this singularity, we construct a sequence of converging solutions in a weighted continuous function space. We present a Bernstein splines-based implementation to numerically approximate solutions. We prove convergence of the numerical method, providing convergence criteria and asymptotic convergence rates. Numerical examples show empirical convergence results corresponding with the theoretical bounds. Moreover, the method is able to approximate the singular behavior of solutions and is demonstrated to converge for nonlinear problems. Finally, we apply a grid search to obtain correspondence to the original, non-perturbed system."}
{"id": "2601.13293", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.13293", "abs": "https://arxiv.org/abs/2601.13293", "authors": ["Michael Hinze", "Christian Kahle", "John Sebastian H. Simon"], "title": "Long-time behavior of solutions to fluid dynamic shape optimization problems via phase-field method", "comment": null, "summary": "We investigate the long time behavior of solutions to a shape and topology optimization problem with respect to the time-dependent Navier--Stokes equations. The sought topology is represented by a stationary phase-field that represents a smooth indicator function. The fluid equations are approximated by a porous media approach and are time-dependent. In the latter aspect, the considered problem formulation extends earlier work.\n  We prove that if the time horizon tends to infinity, minima of the time-dependent problem converge towards minima of the corresponding stationary problem. To do so, a convergence rate with respect to the time horizon, of the values of the objective functional, is analytically derived. This allowed us to prove that the solution to the time-dependent problem converges to a phase-field, as the time horizon goes to infinity, which is proven to be a minimizer for the stationary problem. We validate our results by numerical investigation."}
{"id": "2601.13604", "categories": ["math.NA", "cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.13604", "abs": "https://arxiv.org/abs/2601.13604", "authors": ["Mudassir Shams", "Andrei Velichko", "Bruno Carpentieri"], "title": "Optimizing Parallel Schemes with Lyapunov Exponents and kNN-LLE Estimation", "comment": "25 pages, 9 figures, 10 tables", "summary": "Inverse parallel schemes remain indispensable tools for computing the roots of nonlinear systems, yet their dynamical behavior can be unexpectedly rich, ranging from strong contraction to oscillatory or chaotic transients depending on the choice of algorithmic parameters and initial states. A unified analytical-data-driven methodology for identifying, measuring, and reducing such instabilities in a family of uni-parametric inverse parallel solvers is presented in this study. On the theoretical side, we derive stability and bifurcation characterizations of the underlying iterative maps, identifying parameter regions associated with periodic or chaotic behavior. On the computational side, we introduce a micro-series pipeline based on kNN-driven estimation of the local largest Lyapunov exponent (LLE), applied to scalar time series derived from solver trajectories. The resulting sliding-window Lyapunov profiles provide fine-grained, real-time diagnostics of contractive or unstable phases and reveal transient behaviors not captured by coarse linearized analysis. Leveraging this correspondence, we introduce a Lyapunov-informed parameter selection strategy that identifies solver settings associated with stable behavior, particularly when the estimated LLE indicates persistent instability. Comprehensive experiments on ensembles of perturbed initial guesses demonstrate close agreement between the theoretical stability diagrams and empirical Lyapunov profiles, and show that the proposed adaptive mechanism significantly improves robustness. The study establishes micro-series Lyapunov analysis as a practical, interpretable tool for constructing self-stabilizing root-finding schemes and opens avenues for extending such diagnostics to higher-dimensional or noise-contaminated problems."}
{"id": "2601.13394", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13394", "abs": "https://arxiv.org/abs/2601.13394", "authors": ["Munkaila Dasumani", "Suzanne Lenhart", "Gladys K. Onyambu", "Stephen E. Moore"], "title": "Discrete-Time Optimal Control of Species Augmentation for Predator-Prey Model", "comment": "40 figures, 25pages", "summary": "Species augmentation is one of the methods used to promote biodiversity and prevent endangered species loss and extinction. The current work applies discrete-time optimal control theory to two models of species augmentation for predator-prey relationships. In discrete-time models, the order in which events occur can give different qualitative results. Two models representing different orders of events of optimal augmentation timing are considered. In one model, the population grows and predator-prey action occurs before the translocation of reserve species for augmentation. In the second model, the augmentation happens first and is followed by growth and then predator-prey action.\n  The reserve and target populations are subjected to strong Allee effects. The optimal augmentation models employed in this work aim to maximize the prey (target population) and reserve population at the final time and minimize the associated cost at each time step. Numerical simulations in the two models are conducted using the discrete version of the forward-backward sweep method and the sequential quadratic programming iterative method, respectively. The simulation results show different population levels in the two models under varying parameter scenarios. Objective functional values showing percentage increases with optimal controls are calculated for each simulation. Different optimal augmentation strategies for the two orders of events are discussed. This work represents the first optimal augmentation results for models incorporating the predator-prey relationship with discrete events."}
{"id": "2601.13637", "categories": ["math.NA", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.13637", "abs": "https://arxiv.org/abs/2601.13637", "authors": ["Mudassir Shams", "Andrei Velichko", "Bruno Carpentieri"], "title": "Direct Finite-Time Contraction (Step-Log) Profiling--Driven Optimization of Parallel Schemes for Nonlinear Problems on Multicore Architectures", "comment": "30 pages, 16 figures, 9 tables", "summary": "Efficient computation of all distinct solutions of nonlinear problems is essential in many scientific and engineering applications. Although high-order parallel iterative schemes offer fast convergence, their practical performance is often limited by sensitivity to internal parameters and the lack of reproducible tuning procedures. Classical parameter selection tools based on analytical conditions and dynamical-system diagnostics can be problem-dependent and computationally demanding, which motivates lightweight data-driven alternatives.\n  In this study, we propose a parameterized single-step bi-parametric parallel Weierstrass-type scheme with third-order convergence together with a training-free tuning framework based on Direct finite-time contraction (step-log) profiling. The approach extracts Lyapunov-like finite-time contraction information directly from solver trajectories via step norms and step-log ratios, aggregates the resulting profiles over micro-launch ensembles, and ranks parameter candidates using two compact scores: the stability minimum S_min and the stability moment S_mom. Numerical results demonstrate consistent improvements in convergence rate, stability, and robustness across diverse nonlinear test problems, establishing the proposed profiling-based strategy as an efficient and reproducible alternative to classical parameter tuning methods."}
{"id": "2601.13395", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13395", "abs": "https://arxiv.org/abs/2601.13395", "authors": ["Andrew Zheng", "Adam R. Stinchcombe"], "title": "Generalized Adjoint Method", "comment": "25 pages, 5 figures", "summary": "The adjoint method is an efficient way to numerically compute gradients in optimization problems with constraints, but is only formulated to differentiable cost and constraint functions on real variables. With the introduction of complex variables, which occur often in many inverse problems in electromagnetism and signal processing problems, both the cost and constraint can become non-holomorphic and hence non-differentiable in the standard definitions. Using the notion of CR-calculus, a generalized adjoint method is introduced that can compute the direction of steepest ascent for the cost function while enforcing the constraint even if both are non-holomorphic."}
{"id": "2601.13712", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13712", "abs": "https://arxiv.org/abs/2601.13712", "authors": ["Joubine Aghili", "Hassan Ballout", "Yvon Maday", "Christophe Prud'homme"], "title": "Nonlinear compressive reduced basis approximation : when Taylor meets Kolmogorov", "comment": null, "summary": "This paper investigates model reduction methods for efficiently approximating the solution of parameter-dependent PDEs with a multi-parameter vector $\\vecμ \\in \\mathbb{R}^p$. In cases where the Kolmogorov $N$-width decays fast enough, it is effective to approximate the solution as a sum of $N$ separable terms, each being the product of a parameter-dependent coefficient and a space-dependent function. This leads to reduced-order models with $N$ degrees of freedom and complexity of order ${\\mathcal O}(N^3)$.\n  However, when the $N$-width decays slowly, $N$ must be large to achieve acceptable accuracy, making cubic complexity prohibitive. The linear complexity measure in terms of Kolmogorov width must be replaced by the Gelfand width, with its associated sensing number. Recent nonlinear approaches based on this notion decompose the $N$ coordinates into two groups: $n$ free variables and $\\overline{n}$ dependent variables, where the latter are nonlinear functions of the former ($N= n+\\overline n$). Several works have focused on cases where these $\\overline{n}$ functions are homogeneous quadratic forms of the $n$ variables, with optimization strategies for choosing $n$ given a target accuracy.\n  A rigorous analysis of the local sensing number is carried out, showing that $n = p$ is optimal and appropriate, at least locally, around a reference point. In practical scenarios involving wide parameter ranges, the condition $p\\le n \\le p + k$ (with $k$ small) is valid and more robust from continuity arguments. Additionally, the assumption of a quadratic mapping, while justified in a local sense, becomes insufficient. More expressive nonlinear mappings-including those using machine learning-become necessary. This work contributes a theoretical foundation for such strategies and highlights the need for further investigations to push back the Kolmogorov Barrier."}
{"id": "2601.13486", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13486", "abs": "https://arxiv.org/abs/2601.13486", "authors": ["Anderson Anrrango", "André Quisaguano", "Gonzalo E. Constante-Flores", "Can Li"], "title": "Self-Supervised Learning of Parametric Approximation for Security-Constrained DC-OPF", "comment": "7 pages, 4 figures, 5 tables", "summary": "This paper introduces a self-supervised learning framework for approximating the Security-Constrained DC Optimal Power Flow (SC-DCOPF) problem using a parametric linear model. The approach preserves the physical structure of the DC-OPF while incorporating demand-dependent tunable parameters that scale transmission line limits. These parameters are predicted via a Graph Neural Network and optimized through differentiable layers, enabling direct training from contingency costs without requiring labeled data. The framework integrates pre- and post-contingency optimization layers into an implicit loss function. Numerical experiments on benchmark systems demonstrate that the proposed method achieves high dispatch accuracy, low cost approximation error, and strong data efficiency, outperforming semi-supervised and end-to-end baselines. This scalable and interpretable approach offers a promising solution for real-time secure power system operations."}
{"id": "2601.13800", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.13800", "abs": "https://arxiv.org/abs/2601.13800", "authors": ["Mukul Dwivedi", "Ruben Gutendorf", "Andreas Rupp"], "title": "A Hybridizable Discontinuous Galerkin Method for the non--local Camassa--Holm--Kadomtsev--Petviashvili equation", "comment": null, "summary": "This paper develops a hybridizable discontinuous Galerkin method for the two-dimensional Camassa--Holm--Kadomtsev--Petviashvili equation. The method employs Cartesian meshes with tensor-product polynomial spaces, enabling separate treatment of \\(x\\) and \\(y\\) derivatives. The non-local operator \\(\\partial_{x}^{-1}u_{y}\\) is localized through an auxiliary variable \\(v\\) satisfying \\(v_x = u_y\\), allowing efficient element-by-element computations. We prove energy stability of the semi-discrete scheme and derive \\(\\mathcal{O}(h^{k+1/2})\\) convergence in space. Numerical experiments validate the theoretical results and demonstrate the method's capability to accurately resolve smooth solutions and peaked solitary waves (peakons)."}
{"id": "2601.13493", "categories": ["math.OC", "math.FA", "math.PR", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.13493", "abs": "https://arxiv.org/abs/2601.13493", "authors": ["Hanchao Liu", "Dena Firoozi"], "title": "LQ Mean Field Games with Common Noise in Hilbert Spaces: Small and Arbitrary Finite Time Horizons", "comment": "27 pages", "summary": "We extend the results of (Liu and Firoozi, 2025), which develops the theory of linear-quadratic (LQ) mean field games in Hilbert spaces, by incorporating a common noise. This common noise is an infinite-dimensional Wiener process affecting the dynamics of all agents. In the presence of common noise, the mean-field consistency condition is characterized by a system of coupled forward-backward stochastic evolution equations (FBSEEs) in Hilbert spaces, whereas in its absence, it is represented by forward-backward deterministic evolution equations. We establish the existence and uniqueness of solutions to the coupled linear FBSEEs associated with the LQ MFG setting for small time horizons and prove the $ε$-Nash property of the resulting equilibrium strategy. Furthermore, for the first time in the literature, we develop an analysis that establishes the well-posedness of these coupled linear FBSEEs in Hilbert spaces, for which only mild solutions exist, over arbitrary finite time horizons."}
{"id": "2601.13823", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.13823", "abs": "https://arxiv.org/abs/2601.13823", "authors": ["Van Chien Le", "Kristof Cools"], "title": "Multi-Trace Müller Boundary Integral Equation for Electromagnetic Scattering by Composite Objects", "comment": null, "summary": "This paper introduces a boundary integral equation for time-harmonic electromagnetic scattering by composite dielectric objects. The formulation extends the classical Müller equation to composite structures through the global multi-trace method. The key ingredient enabling this extension is the use of the Stratton-Chu representation in complementary region, also known as the extinction property, which augments the off-diagonal blocks of the interior representation operator. The resulting block system is composed entirely of second-kind operators. A Petrov-Galerkin (mixed) discretization using Rao-Wilton-Glisson trial functions and Buffa-Christiansen test functions is employed, yielding linear systems that remain well conditioned on dense meshes and at low frequencies without the need for additional stabilization. This reduces computational costs associated with matrix-vector multiplications and iterative solving. Numerical experiments demonstrate the accuracy of the method in computing field traces and derived quantities."}
{"id": "2601.13511", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13511", "abs": "https://arxiv.org/abs/2601.13511", "authors": ["Nguyen Quang Huy", "Nguyen Huy Hung", "Tran Van Nghi", "Hoang Ngoc Tuan", "Nguyen Van Tuyen"], "title": "Hidden convexity of quadratic systems and its application to quadratic programming", "comment": "20 pages", "summary": "In this paper, we present sufficient conditions ensuring that the sum of the image of quadratic functions and the nonnegative orthant is convex. The hidden convexity of the trust-region problem with linear inequality constraints is established under a newly proposed assumption, which is compared with the previous one in [{\\it Math. Program. 147, 171--206, 2014}]. We also provide a complete proof of the hidden convexity of a system of two quadratic functions in [{\\it J. Glob. Optim. 56, 1045--1072, 2013}]. Furthermore, necessary and sufficient conditions for the S-lemma concerning systems of quadratic inequalities are investigated. Finally, we derive necessary and sufficient global optimality conditions and strong duality results for quadratic programming."}
{"id": "2601.13908", "categories": ["math.NA", "math.FA", "physics.app-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.13908", "abs": "https://arxiv.org/abs/2601.13908", "authors": ["I. S. Popov"], "title": "Improving the local solution of the DG predictor of the ADER-DG method for solving systems of ordinary differential equations and its applicability to systems of differential-algebraic equations", "comment": "38 pages, 7 figures, 5 tables", "summary": "Improved local numerical solution for the ADER-DG numerical method with a local DG predictor for solving the initial value problem for a first-order ODE system is proposed. The improved local numerical solution demonstrates convergence orders of one higher than the convergence order of the local numerical solution of the original ADER-DG numerical method and has the property of continuity at grid nodes. Rigorous proofs of the approximation orders of the local numerical solution and the improved local numerical solution are presented. Obtaining the proposed improved local numerical solution does not require significant changes to the structure of the ADER-DG numerical method. Therefore, all conclusions regarding the convergence orders of the numerical solution at grid nodes, the resulting superconvergence, and the high stability of the ADER-DG numerical method remain unchanged. A wide range of applications of the ADER-DG numerical method is presented for solving specific initial value problems for ODE systems for a wide range of polynomial degrees. The obtained results provide strong confirmation for the developed rigorous theory. The improved local numerical solution is shown to exhibit both higher accuracy and improved smoothness and point-wise comparability. Empirical convergence orders of all individual numerical solutions were calculated for a wide range of error norms, which well agree with the expected convergence orders. The rigorous proof, based on the $ε$-embedding method, of the applicability of the ADER-DG numerical method with a local DG predictor to solving DAE systems is presents."}
{"id": "2601.13576", "categories": ["math.OC", "eess.SY", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13576", "abs": "https://arxiv.org/abs/2601.13576", "authors": ["Shuwen Lu", "Jamol Pender", "Mark E. Lewis"], "title": "Control policies for a two-stage queueing system with parallel and single server options", "comment": null, "summary": "We study a two-stage tandem service queue attended by two servers. Each job-server pair must complete both service phases together, with the server unable to begin a new job until the current one is fully processed after two stages. Immediately after the first phase of service, the server decides whether to send the job/customer to a downstream station that allows parallel processing or to a single-service facility that offers faster or higher-quality service but handles only one job at a time. This choice determines whether the second phase commences immediately or (potentially) after waiting in a queue for the single-service facility to become available.\n  The decision-making scenario is modeled via a Markov decision process formulation, of a clearing system with holding costs at each station. We fully characterize the structural properties of an optimal control policy based on the relationship between the service rates at the downstream stations. A numerical study highlights the significance of optimal control by comparing its performance against several natural heuristic policies."}
{"id": "2601.14011", "categories": ["math.NA", "cond-mat.soft", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.14011", "abs": "https://arxiv.org/abs/2601.14011", "authors": ["Robert T. Zaks", "Sergey A. Matveev", "Margarita A. Nikishina", "Dmitri V. Alexandrov"], "title": "Numerical solution of Smoluchowski coagulation equation combined with Ostwald ripening", "comment": "23 pages, 6 figures", "summary": "The processes of simultaneous coagulation and Ostwald ripening of particles in the concluding stage of phase transformation are considered. We solve the integro-differential system of Smoluchowski-type kinetic and mass balance equations using a computationally efficient numerical algorithm based on low-rank matrices. We compare our numerical solutions for different initial particle-volume distributions with the universal distribution function for combined coagulation and Ostwald ripening. Our calculations confirm the tendency of a particulate ensemble to the universal particle-volume distribution to be approached asymptotically after a sufficiently long time, no matter what the initial particle-volume distribution might be."}
{"id": "2601.13586", "categories": ["math.OC", "eess.SY", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13586", "abs": "https://arxiv.org/abs/2601.13586", "authors": ["Shuwen Lu", "Mark E. Lewis", "Jamol Pender"], "title": "Balancing Independent and Collaborative Service", "comment": null, "summary": "We study a two-type server queueing system where flexible Type-I servers, upon their initial interaction with jobs, decide in real time whether to process them independently or in collaboration with dedicated Type-II servers. Independent processing begins immediately, as does collaborative service if a Type-II server is available. Otherwise, the job and its paired Type-I server wait in queue for collaboration. Type-I servers are non-preemptive and cannot engage with new jobs until their current job is completed.\n  We provide a complete characterization of the structural properties of the optimal policy for the clearing system. In particular, an optimal control is shown to follow a threshold structure based on the number of jobs in the queue before a Type-I first interaction and on the number of jobs in either independent or collaborative service.\n  We propose simple threshold heuristics, based on linear approximations, for real-time decision-making. In much of the parameter and state spaces, we establish theoretical bounds that compare the thresholds proposed by our heuristics to those of optimal policies and identify parameter configurations where these bounds are attained. Outside of these regions, the optimal thresholds are infinite. Numerical experiments further demonstrate the accuracy and robustness of our heuristics, particularly when the initial queue length is high. Our proposed heuristics achieve costs within 0.5% of the optimal policy on average and significantly outperform benchmark policies that exhibit extreme sensitivity to system parameters, sometimes incurring costs exceeding 100% of the optimal."}
{"id": "2601.14070", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14070", "abs": "https://arxiv.org/abs/2601.14070", "authors": ["Tizian Wenzel", "Gabriele Santin"], "title": "On the optimal shape parameter for kernel methods: Sharp direct and inverse statements", "comment": null, "summary": "The search for the optimal shape parameter for Radial Basis Function (RBF) kernel approximation has been an outstanding research problem for decades. In this work, we establish a theoretical framework for this problem by leveraging a recently established theory on sharp direct, inverse and saturation statements for kernel based approximation. In particular, we link the search for the optimal shape parameter to superconvergence phenomena. Our analysis is carried out for finitely smooth Sobolev kernels, thereby covering large classes of radial kernels used in practice, including those emerging from current machine-learning methodologies. Our results elucidate how approximation regimes, kernel regularity, and parameter choices interact, thereby clarifying a question that has remained unresolved for decades."}
{"id": "2601.13688", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13688", "abs": "https://arxiv.org/abs/2601.13688", "authors": ["Xun Feng", "Chao Zhai"], "title": "Distributed Coverage Control on Poriferous Surface via Poly-Annulus Conformal Mapping", "comment": null, "summary": "The inherent non-convexity of poriferous surfaces typically entraps agents in local minima and complicates workload distribution. To resolve this, we propose a distributed diffeomorphic coverage control framework for the multi-agent system (MAS) in such surfaces. First, we establish a distributed poly-annulus conformal mapping that transforms arbitrary poriferous surfaces into a multi-hole disk. Leveraging this topological equivalence, a collision-free sectorial partition mechanism is designed in the multi-hole disk, which rigorously induces strictly connected subregions and workload balance on the poriferous surfaces. This mechanism utilizes a buffer-based sequence mechanism to ensure strict topological safety when bypassing obstacles. Furthermore, a pull-back Riemannian metric is constructed to define the length metric that encodes safety constraints. Based on this metric, a distributed gradient-based control law is synthesized to drive agents toward optimal configurations, ensuring simultaneous obstacle avoidance and coverage optimization. Theoretical analyses guarantee the Input-to-State Stability (ISS) of the partition dynamics and the asymptotic convergence of the closed-loop system. Numerical simulations confirm the reachability and robustness of the proposed coverage algorithm, offering a scalable solution for distributed coverage in poriferous surfaces."}
{"id": "2601.14189", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14189", "abs": "https://arxiv.org/abs/2601.14189", "authors": ["Leonard Peter Bos", "Lucia Romani", "Alberto Viscardi"], "title": "From big q-Jacobi and Chebyshev polynomials to exponential-reproducing subdivision: new identities", "comment": null, "summary": "In this paper we derive new identities satisfied by Chebyshev polynomials of the first kind and big q-Jacobi polynomials. An immediate benefit of the derived identities is the achievement of closed-form expressions for the Laurent polynomials that identify minimum-support interpolating subdivision schemes reproducing finite sets of integer powers of exponentials."}
{"id": "2601.13756", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13756", "abs": "https://arxiv.org/abs/2601.13756", "authors": ["Adam Kaminer", "Thomas Kriecherbauer", "Lars Grüne", "Michael Margaliot"], "title": "A turnpike property in an eigenvalue optimization problem", "comment": null, "summary": "We consider a constrained eigenvalue optimization problem that arises in an important nonlinear dynamical model for mRNA translation in the cell. We prove that the ordered list of optimal parameters admits a turnpike property, namely, it includes three parts with the first and third part relatively short, and the values in the middle part are all approximately equal. Turnpike properties have attracted considerable attention in econometrics and optimal control theory, but to the best of our knowledge this is the first rigorous proof of such a structure in an eigenvalue optimization problem."}
{"id": "2601.14198", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14198", "abs": "https://arxiv.org/abs/2601.14198", "authors": ["A. Jääskeläinen", "A. Vavilov", "J. Toivanen", "A. Hänninen", "V. Kolehmainen", "N. Hyvönen"], "title": "Local electrical impedance tomography via projections", "comment": "20 pages, 9 figures", "summary": "This paper introduces a method for approximately eliminating the effect that conductivity changes outside the region of interest have in electrical impedance tomography, allowing to form a local reconstruction in the region of interest only. The method considers the Jacobian matrix of the forward map, i.e., of the map that sends the discretized conductivity to the electrode measurements, at an initial guess for the conductivity. The Jacobian matrix is divided columnwise into two parts: one corresponding to the region of interest and a nuisance Jacobian corresponding to the rest of the domain. The leading idea is to project both the electrode measurements and the forward map onto the orthogonal complement of the span of a number of left-hand singular vectors for a suitably weighted nuisance Jacobian. The weighting can, e.g., account for the element sizes in a finite element discretization or to prior information on the conductivity outside the region of interest. The inverse problem is then solved by considering the projected relation between the measurements and the forward map, only reconstructing the conductivity in the region of interest. The functionality of the method is demonstrated by applying a reconstruction algorithm that combines lagged diffusivity iteration and total variation regularization to experimental data. In particular, data from a head-shaped water tank is considered, with the conductivity change in the region of interest mimicking growth of a hemorrhagic stroke and the changes outside the region of interest imitating physiological variations in the conductivity of the scalp."}
{"id": "2601.13848", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.13848", "abs": "https://arxiv.org/abs/2601.13848", "authors": ["Corrado Possieri"], "title": "Derivative free data-driven stabilization of continuous-time linear systems from input-output data", "comment": null, "summary": "This letter presents a data-driven framework for the design of stabilizing controllers from input-output data in the continuous-time, linear, and time-invariant domain. Rather than relying on measurements or reliable estimates of input and output time derivatives, the proposed approach uses filters to derive a parameterization of the system dynamics. This parameterization is amenable to the application of linear matrix inequalities enabling the design of stabilizing output feedback controllers from input-output data and the knowledge of the order of the system."}
{"id": "2601.14201", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14201", "abs": "https://arxiv.org/abs/2601.14201", "authors": ["Amy de Castro", "Hyesuk Lee"], "title": "Convergence analysis and a novel Lagrange multiplier partitioned method for fluid-poroelastic interaction", "comment": "5 figures", "summary": "We propose a partitioned method for the monolithic formulation of the Stokes-Biot system that incorporates Lagrange multipliers enforcing the interface conditions. The monolithic system is discretized using finite elements, and we establish convergence of the resulting approximation. A Schur complement based algorithm is developed together with an efficient preconditioner, enabling the fluid and poroelastic structure subproblems to be decoupled and solved independently at each time step. The Lagrange multipliers approximate the interface fluxes and act as Neumann boundary conditions for the subproblems, yielding parallel solution of the Stokes and Biot equations. Numerical experiments demonstrate the effectiveness of the proposed algorithm and validate the theoretical error estimate."}
{"id": "2601.13884", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13884", "abs": "https://arxiv.org/abs/2601.13884", "authors": ["Ewa Rokita-Magdziarz", "Barbara Gronostajska", "Marcin Magdziarz"], "title": "Optimizing the Geometry of an L-Shaped Building to Enhance Energy Efficiency and Sustainability", "comment": null, "summary": "The geometric form of a building strongly influences its material use, heat losses, and energy efficiency. This paper presents an analytical optimization of L-shaped residential buildings aimed at minimizing the external surface area for a prescribed volume. Both symmetric and asymmetric configurations are examined under realistic design constraints, including fixed or bounded wing aspect ratios and fixed building height. Using explicit optimization methods and Karush-Kuhn-Tucker conditions, closed-form expressions for the optimal geometric parameters and minimal envelope area are derived. The results show that unconstrained optimization leads to degenerate cuboid shapes, highlighting the importance of geometric constraints to preserve the L-shaped form. The obtained results provide practical design guidelines for architects and engineers, supporting informed early stage decisions that balance functional requirements, regulatory constraints, architectural intent, and energy performance. Case studies of existing houses demonstrate that the proposed approach can reduce external surface area or confirm near-optimality of practical designs, supporting energy-efficient early-stage architectural decisions."}
{"id": "2601.12633", "categories": ["math.PR", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12633", "abs": "https://arxiv.org/abs/2601.12633", "authors": ["Pierre Del Moral", "Ajay Jasra"], "title": "New Trends in the Stability of Sinkhorn Semigroups", "comment": null, "summary": "Entropic optimal transport problems play an increasingly important role in machine learning and generative modelling. In contrast with optimal transport maps which often have limited applicability in high dimensions, Schrodinger bridges can be solved using the celebrated Sinkhorn's algorithm, a.k.a. the iterative proportional fitting procedure. The stability properties of Sinkhorn bridges when the number of iterations tends to infinity is a very active research area in applied probability and machine learning. Traditional proofs of convergence are mainly based on nonlinear versions of Perron-Frobenius theory and related Hilbert projective metric techniques, gradient descent, Bregman divergence techniques and Hamilton-Jacobi-Bellman equations, including propagation of convexity profiles based on coupling diffusions by reflection methods. The objective of this review article is to present, in a self-contained manner, recently developed Sinkhorn/Gibbs-type semigroup analysis based upon contraction coefficients and Lyapunov-type operator-theoretic techniques. These powerful, off-the-shelf semigroup methods are based upon transportation cost inequalities (e.g. log-Sobolev, Talagrand quadratic inequality, curvature estimates), $φ$-divergences, Kantorovich-type criteria and Dobrushin contraction-type coefficients on weighted Banach spaces as well as Wasserstein distances. This novel semigroup analysis allows one to unify and simplify many arguments in the stability of Sinkhorn algorithm. It also yields new contraction estimates w.r.t. generalized $φ$-entropies, as well as weighted total variation norms, Kantorovich criteria and Wasserstein distances."}
{"id": "2601.13896", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13896", "abs": "https://arxiv.org/abs/2601.13896", "authors": ["Ewa Rokita-Magdziarz", "Barbara Gronostajska", "Marcin Magdziarz"], "title": "From geometry to sustainability: Optimal shapes of hip roof houses", "comment": null, "summary": "In this paper, we develop a rigorous mathematical framework for the optimization of hip roof house geometry, with the primary goal of minimizing the external surface of the building envelope for a given set of design constraints. Five optimization scenarios are systematically analyzed: fixed volume, fixed footprint ratio, fixed slenderness ratio, fixed floor area, and constrained height. For each case, explicit formulas for the optimal dimensions are derived, offering architects and engineers practical guidelines for improving material efficiency, reducing construction costs, and enhancing energy performance. To illustrate the practical relevance of the theoretical results, case studies of real-world hip roof houses are presented, revealing both inefficiencies in common practice and near-optimal examples. Furthermore, a freely available software application has been developed to support designers in applying the optimization methods directly to architectural projects. The findings confirm that square-based footprints combined with balanced slenderness ratios yield the most efficient forms, while deviations toward elongated or flattened proportions significantly increase energy and material demands. This work demonstrates how mathematical modeling and architectural design can be integrated to support sustainable architecture, providing both theoretical insight and practical tools for shaping energy-efficient, cost-effective, and aesthetically coherent residential buildings."}
{"id": "2601.13782", "categories": ["math.ST", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.13782", "abs": "https://arxiv.org/abs/2601.13782", "authors": ["Shir Tapiro-Moshe", "Yariv Aizenbud", "Barak Sober"], "title": "Moving Least Squares without Quasi-Uniformity: A Stochastic Approach", "comment": null, "summary": "Local Polynomial Regression (LPR) and Moving Least Squares (MLS) are closely related nonparametric estimation methods, developed independently in statistics and approximation theory. While statistical LPR analysis focuses on overcoming sampling noise under probabilistic assumptions, the deterministic MLS theory studies smoothness properties and convergence rates with respect to the \\textit{fill-distance} (a resolution parameter). Despite this similarity, the deterministic assumptions underlying MLS fail to hold under random sampling. We begin by quantifying the probabilistic behavior of the fill-distance $h_n$ and \\textit{separation} $δ_n$ of an i.i.d. random sample. That is, for a distribution satisfying a mild regularity condition, $h_n\\propto n^{-1/d}\\log^{1/d} (n)$ and $δ_n \\propto n^{-1/d}$. We then prove that, for MLS of degree $k\\!-\\!1$, the approximation error associated with a differential operator $Q$ of order $|m|\\le k-1$ decays as $h_n^{\\,k-|m|}$ up to logarithmic factors, establishing stochastic analogues of the classical MLS estimates. Additionally, We show that the MLS approximant is smooth with high probability. Finally, we apply the stochastic MLS theory to manifold estimation. Assuming that the sampled Manifold is $k$-times smooth, we show that the Hausdorff distance between the true manifold and its MLS reconstruction decays as $h_n^k$, extending the deterministic Manifold-MLS guarantees to random samples. This work provides the first unified stochastic analysis of MLS, demonstrating that -- despite the failure of deterministic sampling assumptions -- the classical convergence and smoothness properties persist under natural probabilistic models"}
{"id": "2601.13911", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13911", "abs": "https://arxiv.org/abs/2601.13911", "authors": ["Ewa Rokita-Magdziarz", "Barbara Gronostajska", "Marcin Magdziarz"], "title": "Designing sustainable barn-type houses: Optimal shapes for minimal envelope and energy use", "comment": null, "summary": "Barn-type houses have become one of the most popular single-family housing typologies in Poland and across Europe due to their simplicity, functionality, and potential for energy efficiency. Despite their widespread use, systematic methods for optimizing their geometry in terms of envelope area and energy performance remain limited. This paper develops a rigorous mathematical framework for determining the optimal proportions of barn-type houses with respect to minimizing the external surface area while satisfying constraints of either fixed volume or fixed floor area. Closed-form solutions for the optimal width, length, and height are derived as explicit functions of the roof slope, together with formulas for the minimal achievable surface. A recently introduced dimensionless compactness measure is also calculated, allowing quantitative assessment of how far a given design deviates from the theoretical optimum. The methodology is applied to case studies of three existing houses, showing that while some designs deviate significantly from optimal compactness, others already closely approximate it. The results confirm that theoretical optimization can lead to meaningful reductions in construction costs and energy demand. To support practical implementation, two original freely available software tools were developed, enabling architects and engineers to perform optimization analyses."}
{"id": "2601.13959", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13959", "abs": "https://arxiv.org/abs/2601.13959", "authors": ["Shikher Sharma", "Simeon Reich"], "title": "A Bregman Regularized Proximal Point Method for Solving Equilibrium Problems on Hadamard Manifolds", "comment": null, "summary": "In this paper we develop a Bregman regularized proximal point algorithm for solving monotone equilibrium problems on Hadamard manifolds. It has been shown that the regularization term induced by a Bregman function is, in general, nonconvex on Hadamard manifolds unless the curvature is zero. Nevertheless, we prove that the proposed Bregman regularization scheme does converge to a solution of the equilibrium problem on Hadamard manifolds in the presence of a strong assumption on the convexity of the set formed by the regularization term. Moreover, we employ a coercivity condition on the Bregman function which is weaker than those typically assumed in the existing literature on Bregman regularization. Numerical experiments on illustrative examples demonstrate the practical effectiveness of our proposed method."}
{"id": "2601.14138", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14138", "abs": "https://arxiv.org/abs/2601.14138", "authors": ["Feng Li"], "title": "A global stochastic maximum principle for delayed forward-backward stochastic control systems", "comment": null, "summary": "In this paper, we study a delayed forward-backward stochastic control system in which all the coefficients depend on the state and control terms, and the control domain is not necessarily convex. A global stochastic maximum principle is obtained by using a new method. More precisely, this method introduces first-order and second-order auxiliary equations and offers a novel approach to deriving the adjoint equations as well as the variational equation for $y^\\e - y^*$."}
{"id": "2601.14147", "categories": ["math.OC", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.14147", "abs": "https://arxiv.org/abs/2601.14147", "authors": ["Jieling Shi", "Kim-Chuan Toh", "Xin T. Tong", "Weng Kee Wong"], "title": "Gradient Flow for Finding E-optimal Designs", "comment": "43 pages, 8 figures", "summary": "We investigate the use of Wasserstein gradient flows for finding an $E$-optimal design for a regression model. Unlike the commonly used $D$- and $L$-optimality criteria, the $E$-criterion finds a design that maximizes the smallest eigenvalue of the information matrix, and so it is a non-differentiable criterion unless the minimum eigenvalue has geometric multiplicity equals to one. Such maximin design problems abound in statistical applications and present unique theoretical and computational challenges. Building on the differential structure of the $2$-Wasserstein space, we derive explicit formulas for the Wasserstein gradient of the $E$-optimality criterion in the simple-eigenvalue case. For higher multiplicities, we propose a Wasserstein steepest ascent direction and show that it can be computed exactly via a semidefinite programming (SDP) relaxation. We develop particle approximations that connect infinite-dimensional flows with finite-dimensional optimization, and provide approximation guarantees for empirical measures. Our framework extends naturally to constrained designs via projected Wasserstein gradient flows. Numerical experiments demonstrate that the proposed methods successfully recover $E$-optimal designs for both linear and nonlinear regression models, with competitive accuracy and scalability compared to existing heuristic approaches. This work highlights the potential of optimal transport-based dynamics as a unifying tool for studying challenging optimal design problems."}
{"id": "2601.11588", "categories": ["math.PR", "math.AP", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11588", "abs": "https://arxiv.org/abs/2601.11588", "authors": ["Shuhui Liu", "Xintian Liu", "Chenchen Mou", "Defeng Sun"], "title": "The global well-posedness for master equations of mean field games of controls", "comment": "27 pages", "summary": "In this manuscript, we establish the global well-posedness for master equations of mean field games of controls, where the interaction is through the joint law of the state and control. Our results are proved under two different conditions: the Lasry-Lions monotonicity and the displacement $λ$-monotonicity, both considered in their integral forms. We provide a detailed analysis of both the differential and integral versions of these monotonicity conditions for the corresponding nonseparable Hamiltonian and examine their relation. The proof of global well-posedness relies on the propagation of these monotonicity conditions in their integral forms and a priori uniform Lipschitz continuity of the solution with respect to the measure variable."}
{"id": "2601.13347", "categories": ["math.NA", "math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13347", "abs": "https://arxiv.org/abs/2601.13347", "authors": ["Aryeh Keating", "Mirjeta Pasha"], "title": "A Scalable Sequential Framework for Dynamic Inverse Problems via Model Parameter Estimation", "comment": "27 Pages, 8 Figures", "summary": "Large-scale dynamic inverse problems are often ill-posed due to model complexity and the high dimensionality of the unknown parameters. Regularization is commonly employed to mitigate ill-posedness by incorporating prior information and structural constraints. However, classical regularization formulations are frequently infeasible in this setting due to prohibitive memory requirements, necessitating sequential methods that process data and state information online, eliminating the need to form the full space-time problem. In this work, we propose a memory-efficient framework for reconstructing dynamic sequences of undersampled images from computerized tomography data that requires minimal hyperparameter tuning. The approach is based on a prior-informed, dimension-reduced Kalman filter with smoothing. While well suited for dynamic image reconstruction, practical deployment is challenging when the state transition model and covariance parameters must be initialized without prior knowledge and estimated in a single pass. To address these limitations, we integrate regularized motion models with expectation-maximization strategies for the estimation of state transition dynamics and error covariances within the Kalman filtering framework. We demonstrate the effectiveness of the proposed method through numerical experiments on limited-angle and single-shot computerized tomography problems, highlighting improvements in reconstruction accuracy, memory efficiency, and computational cost."}
{"id": "2601.13426", "categories": ["math.PR", "cs.DS", "econ.GN", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.13426", "abs": "https://arxiv.org/abs/2601.13426", "authors": ["Taha Ameen", "Flore Sentenac", "Sophie H. Yu"], "title": "A uniformity principle for spatial matching", "comment": null, "summary": "Platforms matching spatially distributed supply to demand face a fundamental design choice: given a fixed total budget of service range, how should it be allocated across supply nodes ex ante, i.e. before supply and demand locations are realized, to maximize fulfilled demand? We model this problem using bipartite random geometric graphs where $n$ supply and $m$ demand nodes are uniformly distributed on $[0,1]^k$ ($k \\ge 1$), and edges form when demand falls within a supply node's service region, the volume of which is determined by its service range. Since each supply node serves at most one demand, platform performance is determined by the expected size of a maximum matching. We establish a uniformity principle: whenever one service range allocation is more uniform than the other, the more uniform allocation yields a larger expected matching. This principle emerges from diminishing marginal returns to range expanding service range, and limited interference between supply nodes due to bounded ranges naturally fragmenting the graph. For $k=1$, we further characterize the expected matching size through a Markov chain embedding and derive closed-form expressions for special cases. Our results provide theoretical guidance for optimizing service range allocation and designing incentive structures in ride-hailing, on-demand labor markets, and drone delivery networks."}
