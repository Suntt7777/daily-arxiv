{"id": "2602.07224", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.07224", "abs": "https://arxiv.org/abs/2602.07224", "authors": ["I. Essadeq", "S. Nafiri", "S. Benjelloun", "A. E. Fettouh"], "title": "Stability and Convergence of Modal Approximations in Coupled Thermoelastic Systems: Theory and Simulation", "comment": null, "summary": "In this work, we review and analyze both the theoretical and numerical aspects of strongly and weakly coupled thermoelastic systems. By employing spectral analysis techniques and establishing uniform resolvent estimates, we derive uniform polynomial decay rates for the associated semigroups under a suitable class of boundary conditions. Particular attention is paid to the role of modal approximations in energy analysis. The theoretical results are complemented by numerical experiments that illustrate how the regularity of initial data, smooth versus nonsmooth, affects the observed decay rates, providing deeper insight into the interplay between spectral structure and energy dissipation."}
{"id": "2602.07225", "categories": ["math.NA", "physics.app-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.07225", "abs": "https://arxiv.org/abs/2602.07225", "authors": ["Thomas Roy", "Nicholas W. Brady", "Giovanna Bucci", "Nicholas R. Cross", "Victoria M. Ehlinger", "Tiras Y. Lin", "Hanyu Li", "Marcus A. Worsley"], "title": "Scalable Preconditioners for the Pseudo-4D DFN Lithium-ion Battery Model", "comment": "30 pages, 11 figures", "summary": "The pseudo-4D Doyle-Fuller-Newman (DFN) model enables predictive simulation of lithium-ion batteries with three-dimensional electrode architectures and particle-scale diffusion, extending the standard pseudo-2D (P2D) formulation to fully resolve cell geometry. This leads to large, nonlinear systems with strong coupling across multiple physical scales, posing significant challenges for scalable numerical solution. We introduce block-structured preconditioning strategies that exploit the mathematical properties of the coupled system, employing multigrid techniques for electrode-level operators and localized solvers for particle-scale diffusion. Comprehensive scalability studies are performed across a range of geometries, including homogeneous and heterogeneous cubic cells, flattened jelly-roll configurations, and triply periodic minimal surface electrodes, to assess solver robustness and parallel scalability. The proposed methods consistently deliver efficient convergence and enable the solution of battery models with hundreds of millions of degrees of freedom on large-scale parallel hardware."}
{"id": "2602.07250", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07250", "abs": "https://arxiv.org/abs/2602.07250", "authors": ["Changli Liu", "Tiexiang Li", "Jungong Xue", "Ren-Cang Li", "Wen-Wei Lin"], "title": "A Unifying Framework for Doubling Algorithms", "comment": null, "summary": "The existing doubling algorithms have been proven efficient for several important nonlinear matrix equations arising from real-world engineering applications. In a nutshell, the algorithms iteratively compute a basis matrix, in one of the two particular forms, for the eigenspace of some matrix pencil associated with its eigenvalues in certain complex region such as the left-half plane or the open unit disk, and their success critically depends on that the interested eigenspace do have a basis matrix taking one of the two particular forms. However, that requirement in general cannot be guaranteed. In this paper, a new doubling algorithm, called the $Q$-doubling algorithm, is proposed. It includes the existing doubling algorithms as special cases and does not require that the basis matrix takes one of the particular forms. An application of the $Q$-doubling algorithm to solve eigenvalue problems is investigated with numerical experiments that demonstrate its superior robustness to the existing doubling algorithms."}
{"id": "2602.07269", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07269", "abs": "https://arxiv.org/abs/2602.07269", "authors": ["Gabriela Ramon", "Geena Sarnoski", "Vasishta Tumuluri", "Hugo Díaz", "Arvind K. Saibaba"], "title": "Multifidelity sensor placement in Bayesian state estimation problems", "comment": "27 pages, 14 figures", "summary": "We study optimal sensor placement for Bayesian state estimation problems in which sensors vary in cost and fidelity, resulting in a budget-constrained multifidelity optimal experimental design problem. Sensor placement optimality is quantified using the D-optimality criterion, and the problem is approached by leveraging connections with the column subset selection problem in numerical linear algebra. We implement a greedy approach for this problem, whose computational efficiency we improve using rank-one updates via the Sherman-Morrison formula. We additionally present an iterative algorithm that, for each feasible allocation of sensors, greedily optimizes over each sensor fidelity subject to previous sensor choices, repeating this process until a termination criterion is satisfied. To the best of our knowledge, these algorithms are novel in the context of cost constrained multifidelity sensor placement. We evaluate our methods on several benchmark state estimation problems, including reconstructions of sea surface temperature and flow around a cylinder, and empirically demonstrate improved performance over random designs."}
{"id": "2602.07480", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.07480", "abs": "https://arxiv.org/abs/2602.07480", "authors": ["Kou Fujimori", "Koji Tsukuda"], "title": "Asymptotically normal estimators in high-dimensional linear regression", "comment": "8 pages", "summary": "We establish asymptotic normality for estimators in high-dimensional linear regression by proving weak convergence in a separable Hilbert space, thereby enabling direct use of standard asymptotic tools, for example, the continuous mapping theorem. The approach allows the number of non-zero coefficients to grow, provided only a fixed number have moderate magnitude. As an application, we test linear hypotheses with a statistic whose null limit is a finite weighted sum of independent chi-squared variables, yielding plug-in critical values with asymptotically correct size."}
{"id": "2602.07178", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07178", "abs": "https://arxiv.org/abs/2602.07178", "authors": ["A. Piunovskiy"], "title": "Constrained optimal impulse control and inventory model", "comment": "29 pages", "summary": "In this article, we consider the deterministic impulsively controlled system with infinite horizon and several discounted objective functionals. The constructed optimal control problem with functional constraints is reformulated as a Markov decision process, leading to (primal) convex and linear programs in the space of so-called occupation measures. We construct the dual programs and investigate the solvability of all the programs. Example of an inventory model illustrates the developed theory."}
{"id": "2602.07157", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07157", "abs": "https://arxiv.org/abs/2602.07157", "authors": ["Leonid Koralov", "Chenglin Liu"], "title": "Limiting Behavior of Randomly Perturbed Diffusions with Invariant Repelling Surfaces", "comment": null, "summary": "We study small perturbations of diffusion processes in $\\mathbb{R}^d$ that leave invariant a finite collection of hypersurfaces. Each surface is assumed to be repelling for the unperturbed process, and the unperturbed motion on each of the surfaces is assumed to be ergodic. These surfaces separate the space into a finite number of domains, each of which carries an invariant measure of the unperturbed process. We describe the asymptotics of the densities of the invariant measures near the invariant surfaces. We then describe the asymptotic behavior of the perturbed process: at different time scales (depending on the size of the perturbation), metastable distributions are described in terms of linear combinations of the ergodic invariant measures of the unperturbed system. The coefficients in the linear combination depend on the time scale but are shown not to depend on the perturbation."}
{"id": "2602.07437", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07437", "abs": "https://arxiv.org/abs/2602.07437", "authors": ["Carmen Scalone", "Nicola Guglielmi"], "title": "Convergence of a Low-Rank Strang Splitting for Stiff Matrix Differential Equations", "comment": null, "summary": "We propose and analyze a second-order Strang splitting method for a class of stiff matrix differential equations with Sylvester-type structure. The method splits the dynamics into a stiff linear part, treated exactly via matrix exponentials, and a nonlinear part, integrated by a second-order dynamical low-rank (DLR) scheme. Our main contribution is a rigorous convergence proof showing that, under suitable assumptions, the overall scheme achieves second-order accuracy. Numerical experiments confirm the theoretical results and demonstrate the robustness and efficiency of the proposed method."}
{"id": "2602.07665", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.07665", "abs": "https://arxiv.org/abs/2602.07665", "authors": ["Giovanni Pistone", "Fabio Rapallo", "Eva Riccomagno"], "title": "The Fisher score on the closed simplex", "comment": "Submitted", "summary": "We extend classical analytic tools for finite-state statistical models to allow zero probabilities. Using methods from algebraic statistics and information geometry, we develop a framework in which a smooth statistical model could hit the boundary of the simplex, for example, in contingency tables with non-structural zeros. The central object of our approach is the vector bundle whose fibres are the $p$-contrasts associated to each probability distribution $p$. In this framework, Fisher score and other key statistical concepts, such as entropy for one-dimensional statistical models, admit an algebraic representation also on the boundary of the simplex."}
{"id": "2602.07196", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07196", "abs": "https://arxiv.org/abs/2602.07196", "authors": ["Weijian Li", "Panos J. Antsaklis", "Hai Lin"], "title": "Primal-dual algorithm for distributed optimization: A dissipativity-based perspective", "comment": null, "summary": "We study a continuous-time primal-dual algorithm for distributed optimization with nonconvex local cost functions over weight-unbalanced digraphs, and analyze its performance from a dissipativity-based perspective. We first reformulate the algorithm as a Lure type system, consisting of a linear subsystem that relies on the communication topology and the algorithm gains, and a static nonlinear gradient feedback. We then show that the linear subsystem is dissipative with respect to a suitable supply rate, while the nonlinear feedback is not passive. Finally, we establish that, by properly selecting the gains or appropriately designing the communication network, this algorithm converges to an equilibrium at an exponential rate, and thus, achieves an optimal solution to the distributed problem. This work provides new insights into the roles of the network topology, algorithm gains, and cost functions in the performance of a distributed algorithm, and complements existing results from a different viewpoint."}
{"id": "2602.07167", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07167", "abs": "https://arxiv.org/abs/2602.07167", "authors": ["Sefika Kuzgun", "Felix Otto", "Christian Wagner"], "title": "Intermittency of geometric Brownian motion on $ \\textbf{SL}(n) $", "comment": "14 pages", "summary": "This short note is motivated by a recently discovered connection between a drift-diffusion process in $n$-dimensional Euclidean space with a divergence-free drift sampled from a stationary and isotropic Gaussian ensemble of critical scaling on the one hand, and a geometric Brownian motion on $\\textbf{SL}(n)$ on the other hand. This can be seen as a tensorial form of a stochastic exponential; it thus is naturally intermittent, which transfers to the pair distance of the drift-diffusion process.\n  In this note, we quantify the intermittency of the geometric Brownian motion $\\{F_τ\\}_{τ\\ge0}$ on $\\textbf{SL}(n)$ also in dimensions $n>2$. We do so in two (related) ways: 1) by identifying the exponential growth rate for the $2p$-th stochastic moment $\\mathbb{E}|F_τ|^{2p}$ with its anomalous dependence on $p$ (and $n$), and 2) by quantifying a non-tightness of $|F_τ|^2/\\mathbb{E}|F_τ|^2$ as $τ\\uparrow\\infty$. It is the second property that transmits to the drift-diffusion process.\n  The arguments rely on stochastic analysis: We write $\\{F_τ\\}_{τ\\geq 0}$ as the solution of $dF=F_τ\\circ dB$ with $\\{B_τ\\}_{τ\\geq 0}$ a Brownian motion on the Lie algebra $\\mathfrak{sl}(n)$. The arguments leverage isotropy: The diffusion projects onto the spectrum of the Gram matrix $G=F^*F$, as captured by ${\\rm tr}G^p$."}
{"id": "2602.07466", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07466", "abs": "https://arxiv.org/abs/2602.07466", "authors": ["Manuel Haas", "Thomas Grandits", "Thomas Pinetz", "Thomas Beiert", "Simone Pezzuto", "Alexander Effland"], "title": "Learned Finite Element-based Regularization of the Inverse Problem in Electrocardiographic Imaging", "comment": null, "summary": "Electrocardiographic imaging (ECGI) seeks to reconstruct cardiac electrical activity from body-surface potentials noninvasively. However, the associated inverse problem is severely ill-posed and requires robust regularization. While classical approaches primarily employ spatial smoothing, the temporal structure of cardiac dynamics remains underexploited despite its physiological relevance. We introduce a space-time regularization framework that couples spatial regularization with a learned temporal Fields-of-Experts (FoE) prior to capture complex spatiotemporal activation patterns. We derive a finite element discretization on unstructured cardiac surface meshes, prove Mosco-convergence, and develop a scalable optimization algorithm capable of handling the FoE term. Numerical experiments on synthetic epicardial data demonstrate improved denoising and inverse reconstructions compared to handcrafted spatiotemporal methods, yielding solutions that are both robust to noise and physiologically plausible."}
{"id": "2602.07669", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.07669", "abs": "https://arxiv.org/abs/2602.07669", "authors": ["Louigi Addario-Berry", "Omer Angel", "Gábor Lugosi", "Miklós Z. Rácz", "Tselil Schramm"], "title": "The statistical threshold for planted matchings and spanning trees", "comment": null, "summary": "In this paper, we study the problem of detecting the presence of a planted perfect matching or spanning tree in an Erdős--Rényi random graph. More precisely, we study the hypothesis testing problem where the statistician observes a graph on $n$ vertices. Under the null hypothesis, the graph is a realization of an Erdős--Rényi random graph $G(n,q)$, while under the alternative hypothesis, the graph is the union of an Erdős--Rényi random graph and a random perfect matching (or random spanning tree). In order to avoid trivial detection by counting edges, we adjust the alternative hypothesis so that the expected number of edges under both distributions coincides. We prove that in both problems, when $q\\gg n^{-1/2}$, no test can perform better than random guessing, while for $q\\ll n^{-1/2}$, there exist computationally efficient tests that guess correctly with high probability."}
{"id": "2602.07217", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07217", "abs": "https://arxiv.org/abs/2602.07217", "authors": ["Rui Gong", "Alejandro Toriello"], "title": "Dynamic Interval Scheduling with Random Start and End Times", "comment": null, "summary": "We study sequential interval scheduling when task start and end times are random. The set of tasks and their weights are known in advance, while each task's start and end times are drawn from known discrete distributions and revealed only upon commitment; this also eliminates tasks that conflict with the committed task, and remaining tasks are those that do not conflict. The objective is to maximize the expected weight of a conflict-free schedule. We propose two models that differ in how conflicts are enforced, develop LP relaxations and bounds for each, and present a computational study."}
{"id": "2602.07255", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07255", "abs": "https://arxiv.org/abs/2602.07255", "authors": ["Daniela Morale", "Leonardo Tarquini", "Stefania Ugolini"], "title": "Path-dependent McKean PDEs with reaction: a discussion on probabilistic interpretations and particle approximations", "comment": null, "summary": "In this paper, we discuss and compare two probabilistic approaches for associating a stochastic differential equation with a McKean-type partial differential equation featuring a reaction term and path-dependent coefficients. The non-conservative nature of the macroscopic dynamics leads to two possible interpretations of the sub-probability measure and of the associated SDE equation at the microscale: on the one hand, as a measure-valued solution of a Feynman-Kac-type equation; on the other hand, as the sub-probability associated with an SDE defined up to a survival time with a reaction-dependent rate. These different interpretations give rise to two different microscopic stochastic models and therefore to two different techniques of probabilistic analysis. Finally, by considering the interacting particle systems associated with both models, we discuss how their empirical densities provide two different kernel estimators for the PDE solution."}
{"id": "2602.07571", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07571", "abs": "https://arxiv.org/abs/2602.07571", "authors": ["Binghong Li", "Xiaoli Li", "Cheng Wang", "Jiang Yang"], "title": "Stability and error analysis of fully discrete original energy-dissipative and length-preserving scheme for the Landau-Lifshitz-Gilbert equation", "comment": "24 pages, 20 figures", "summary": "The Landau-Lifshitz-Gilbert (LLG) equation, regarded as a gradient flow with manifold constraint, is the fundamental model describing magnetization dynamics in ferromagnetic materials. It is well known that the normalized tangent plane method is able to simultaneously achieve the non-convex manifold constraint and original energy dissipation. However, the associated computational cost of this numerical approach is exceedingly high. By contrast, the projection method is more straightforward to implement, while it often compromises the inherent energy dissipative property of the continuous model, and the error analysis turns out to be even more challenging. In this work, we first construct a linear and fully discrete finite difference numerical scheme, based on the projection method for the LLG equation, which is capable of simultaneously preserving the non-convex manifold constraint \\(|\\mathbf{m}| = 1\\) and an unconditional original energy dissipation. In the error analysis, the classical theoretical technique becomes ineffective, due to the presence of the nonlinear Laplacian term, which in turn poses a significant challenge. To overcome this subtle difficulty, we carefully rewrite the numerical method in an equivalent weak form, in which a point-wise length preserving feature of the numerical solution plays an essential role. As a result of these estimates in the reformulated weak form, an optimal convergence rate could be theoretically established. In our knowledge, this numerical method is the first linear algorithm that preserves the following combined theoretical properties: (i) point-wise length preservation, (ii) unconditional original energy dissipation, (iii) a theoretical justification of convergence analysis and optimal rate error estimate."}
{"id": "2602.07944", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.07944", "abs": "https://arxiv.org/abs/2602.07944", "authors": ["Elsiddig Awadelkarim", "David Bolin", "Xiaotian Jin", "Alexandre B. Simas", "Jonas Wallin"], "title": "Geometric ergodicity of Gibbs samplers for linear latent models with GIG variance mixtures", "comment": null, "summary": "We study geometric ergodicity of the Gibbs sampler for linear latent non-Gaussian models (LLnGMs), a class of hierarchical models in which conditional Gaussian structure is preserved through generalized inverse Gaussian (GIG) variance-mixture augmentation. Two complementary routes to geometric ergodicity are developed for the marginal chain on the mixing variables. First, we show that the associated Markov operator is trace-class, and hence admits a spectral gap, over a large portion of the GIG parameter space. Second, for the remaining boundary and heavy-tail regimes, we establish geometric ergodicity via drift and minorization, subject to an explicit null-smallness condition that quantifies how the drift interacts with the null space of the observation operator. Together, these results cover the full GIG parameter space, including the normal-inverse Gaussian, generalized asymmetric Laplace, and Student-$t$ special cases. The geometric ergodicity of this chain underpins the consistency of Gibbs-based stochastic-gradient estimators for maximum likelihood estimation, and we provide conditions that make the required integrability checks transparent. Numerical experiments illustrate the theoretical findings, contrasting mixing efficiency across parameter regimes and probing the role of the null-smallness constant."}
{"id": "2602.07286", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07286", "abs": "https://arxiv.org/abs/2602.07286", "authors": ["Xiangting Liu", "Shengran Wang", "Kaile Yan", "Zhi-Hai Zhang"], "title": "Solving contextual chance-constrained programming under decision-dependent uncertainty", "comment": null, "summary": "We study contextual chance-constrained programming under decision-dependent uncertainty. In this setting, a decision not only needs to satisfy constraints but also alters the distribution of uncertain outcomes. This dependency makes the problem particularly difficult: because feasibility probabilities vary with decisions, it creates both statistical endogeneity and computational intractability. To address this, we propose a nonparametric approximation method based on Contextual Cluster Weights (CCW). For any given decision and context, CCW constructs a local neighborhood (cluster) of ``similar\" historical observations and assigns them equal weight. This approach successfully renders both the objective and chance constraints tractable, while providing uniform-in-decision consistency guarantees. Furthermore, we develop reformulations that use pre-calculated clusters. We show that under a specific nestedness condition, these reformulations yield a convex feasible region, which allows for efficient solving. Experiments, including a case study with JD.com, demonstrate that our method outperforms benchmarks in solution quality, feasibility reliability, and runtime. This framework offers a scalable and data-driven approach for firms to make reliable operational decisions when their actions influence uncertainty. It effectively balances performance, risk, and robustness, while remaining interpretable and implementable in practice."}
{"id": "2602.07290", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07290", "abs": "https://arxiv.org/abs/2602.07290", "authors": ["Tyler Gomez", "Jason Swanson", "Alexandru Tamasan"], "title": "A probabilistic model of X-ray computed tomography", "comment": "20 pages", "summary": "We consider a discrete stochastic process, indexed by lines through the unit disk in the plane, which models the observed photon counts in a medical X-ray tomography scan. We first prove a functional law of large numbers, showing that this process converges in $L^2$ to the X-ray transform of the underlying attenuation function. We then prove a family of functional central limit theorems, which show that the normalized observations converge to a white noise on the space of lines, provided the growth rate of the mean number of photons per line is greater than a certain power of the number of lines scanned. Using this family of theorems, we can reduce that power arbitrarily close to zero by adding correction terms to the normalization. We also prove a Berry-Esseen inequality that gives a concrete rate of convergence for each functional central limit theorem in our family of theorems."}
{"id": "2602.07653", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07653", "abs": "https://arxiv.org/abs/2602.07653", "authors": ["Daniel Hayes", "Jing-Mei Qiu", "Tianyi Shi"], "title": "An Efficient and Robust Projection Enhanced Interpolation Based Tensor Train Decomposition", "comment": "26 pages, 10 figures", "summary": "The tensor-train (TT) format is a data-sparse tensor representation commonly used in high dimensional data approximations. In order to represent data with interpretability in data science, researchers develop data-centric skeletonized low rank approximations. However, these methods might still suffer from accuracy degeneracy, nonrobustness, and high computation costs. In this paper, given existing skeletonized TT approximations, we propose a family of projection enhanced interpolation based algorithms to further improve approximation accuracy while keeping low computational complexity. We do this as a postprocessing step to existing interpolative decompositions, via oversampling data not in skeletons to include more information and selecting subsets of pivots for faster projections. We illustrate the performances of our proposed methods with extensive numerical experiments. These include up to 10D synthetic datasets such as tensors generated from kernel functions, and tensors constructed from Maxwellian distribution functions that arise in kinetic theory. Our results demonstrate significant accuracy improvement over original skeletonized TT approximations, while using limited amount of computational resources."}
{"id": "2602.08173", "categories": ["math.ST", "cs.IT", "cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.08173", "abs": "https://arxiv.org/abs/2602.08173", "authors": ["Shuyang Gong", "Dong Huang", "Zhangsong Li"], "title": "Fundamental Limits of Community Detection in Contextual Multi-Layer Stochastic Block Models", "comment": "49 pages, 5 figures", "summary": "We consider the problem of community detection from the joint observation of a high-dimensional covariate matrix and $L$ sparse networks, all encoding noisy, partial information about the latent community labels of $n$ subjects. In the asymptotic regime where the networks have constant average degree and the number of features $p$ grows proportionally with $n$, we derive a sharp threshold under which detecting and estimating the subject labels is possible. Our results extend the work of \\cite{MN23} to the constant-degree regime with noisy measurements, and also resolve a conjecture in \\cite{YLS24+} when the number of networks is a constant.\n  Our information-theoretic lower bound is obtained via a novel comparison inequality between Bernoulli and Gaussian moments, as well as a statistical variant of the ``recovery to chi-square divergence reduction'' argument inspired by \\cite{DHSS25}. On the algorithmic side, we design efficient algorithms based on counting decorated cycles and decorated paths and prove that they achieve the sharp threshold for both detection and weak recovery. In particular, our results show that there is no statistical-computational gap in this setting."}
{"id": "2602.07288", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07288", "abs": "https://arxiv.org/abs/2602.07288", "authors": ["Jihun Kim", "Javad Lavaei"], "title": "On the Necessity of Two-Stage Estimation for Learning Dynamical Systems under Both Noise and Node-Wise Attacks", "comment": "33 pages", "summary": "The least-squares estimator has achieved considerable success in learning linear dynamical systems from a single trajectory of length $T$. While it attains an optimal error of $\\mathcal{O}(1/\\sqrt{T})$ under independent zero-mean noise, it lacks robustness and is particularly susceptible to adversarial corruption. In this paper, we consider the identification of a networked system in which every node is subject to both noise and adversarial attacks. We assume that every node is independently corrupted with probability smaller than $0.5$ at each time, placing the overall system under almost-persistent local attack. We first show that no convex one-stage estimator can achieve a consistent estimate as $T$ grows under both noise and attacks. This motivates the development of a two-stage estimation method applied across nodes. In Stage I, we leverage the $\\ell_1$-norm estimator and derive an estimation error bound proportional to the noise level $σ_w$. This bound is subsequently used to detect and filter out attacks, producing a clean dataset for each node, to which we apply the least-squares estimator in Stage II. The resulting estimation error is on the order $\\mathcal{O}(1/\\sqrt{T})$ plus the product of $σ_w$ and the number of misclassifications. In the event of perfect separability between attack and non-attack data, which occurs when injected attacks are sufficiently large relative to the noise scale, our two-stage estimator is consistent for the true system."}
{"id": "2602.07304", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07304", "abs": "https://arxiv.org/abs/2602.07304", "authors": ["Arka Adhikari", "Izumi Okada"], "title": "Phase transition on the fluctuation of the structure of random walk ranges", "comment": null, "summary": "We investigate fluctuation phenomena for the graph distance and the number of cut points associated with random media arising from the range of a random walk. Our results demonstrate a sequence of dimension-dependent phase transitions in the scaling behavior of these fluctuations, leading to qualitatively different regimes across dimensions lower than six, equal to six, and higher than six. In particular, in six dimensions, we show that the convergence to the normal distribution occurs under a scaling different from that of the standard central limit theorem. We also give the related results for the effective resistance of the random walk range."}
{"id": "2602.07711", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07711", "abs": "https://arxiv.org/abs/2602.07711", "authors": ["Yury Gryazin", "Ron Gonzales", "Xiaoye Sherry Li"], "title": "High-Resolution Solvers for 3D Helmholtz Scattering Problems Using PFFT and Eigenvector-Based Preconditioning", "comment": null, "summary": "This paper presents an efficient Krylov subspace iterative solver for the three-dimensional (3D) Helmholtz equation with non-constant coefficients and absorbing boundary conditions, combining high-resolution compact schemes with low-order preconditioners. To mitigate numerical dispersion and reduce pollution error, we employ fourth- and sixth-order compact finite-difference schemes, thereby significantly softening the strict points-per-wavelength requirement. The resulting large, ill-conditioned linear systems are solved using a preconditioned GMRES method. The key innovation lies in the construction of the preconditioner: we introduce two highly efficient direct solvers - one based on a low-dimensional eigenvector transformation (EigT) and another on a partial Fast Fourier Transform (PFFT) algorithm - both derived from a lower-order approximation of the original problem that incorporates the absorbing boundary conditions. The motivation and efficacy of this lower-order preconditioning strategy for high-resolution schemes are analyzed through model problems, providing insight into the convergence rate. The theoretical analysis is validated by a comprehensive set of numerical experiments, demonstrating the method's performance for realistic problem sizes and parameters."}
{"id": "2602.08174", "categories": ["math.ST", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.08174", "abs": "https://arxiv.org/abs/2602.08174", "authors": ["Gökhan Gül"], "title": "Asymptotically Minimax Robust Likelihood Ratio Test", "comment": "29 pages, 10 figures. Submitted to IEEE Transactions on Information Theory", "summary": "This paper develops a unified framework for asymptotically minimax robust hypothesis testing under distributional uncertainty, applicable to both Bayesian and Neyman--Pearson formulations (Type-I and Type-II). Uncertainty classes based on the KL-divergence, $α$-divergence, and its symmetrized variant are considered. Using Sion's minimax theorem and Karush-Kuhn-Tucker conditions, the existence and uniqueness of the resulting robust tests are established. The least favorable distributions and corresponding robust likelihood ratio functions are derived in closed parametric forms, enabling computation via systems of nonlinear equations. It is proven that Dabak's approach does not yield an asymptotically minimax robust test. The proposed theory generalizes earlier work by offering a more systematic and comprehensive derivation of robust tests. Numerical simulations confirm the theoretical results and illustrate the behavior of the derived robust tests."}
{"id": "2602.07318", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07318", "abs": "https://arxiv.org/abs/2602.07318", "authors": ["Zihao Gu", "Jianfeng Zhang"], "title": "On Information Controls", "comment": null, "summary": "In this paper we study an optimization problem in which the control is information, more precisely, the control is a $σ$-algebra or a filtration. In a dynamic setting, assuming a condition slightly stronger than the (H)-hypothesis for the admissible filtration, we establish the dynamic programming principle and the law invariance of the value function. The latter enables us to define the value function on $\\mathcal P_2(\\mathcal P_2(\\mathbb R^d))$, the space of laws of random probability measures. By using a new Itô's formula for smooth functions on $\\mathcal P_2(\\mathcal P_2(\\mathbb R^d))$, we characterize the value function of the information control problem through an Hamilton-Jacobi-Bellman equation on this space."}
{"id": "2602.07500", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07500", "abs": "https://arxiv.org/abs/2602.07500", "authors": ["Kuldeep Kumar Kataria", "Rohini Bhagwanrao Pote"], "title": "On Time-Changed Birth-Death Processes with Catastrophes", "comment": null, "summary": "We study two time-changed variants of the birth-death process with catastrophe where the time-changing components are the first hitting times of the stable subordinator and the tempered stable subordinator. For both the processes, we derive the governing system of fractional differential equations for their state probabilities. The Laplace transforms of these state probabilities are obtained in terms of those of the corresponding time-changed birth-death processes without catastrophes. We obtain the distribution of catastrophe occurrence times as well as the sojourn times within non-zero states. We study distributional properties of the first visit time to state zero in a particular case. Also, the first occurrence time of an effective catastrophe is studied. Moreover, we study the time-changed linear birth-death processes with catastrophes, derive the explicit expressions for its state probabilities, expectation and variance. For a specific case, we compare the expectation plots across different parameter values and provide an algorithm for simulating sample paths with illustrative plots."}
{"id": "2602.07718", "categories": ["math.NA", "cs.SC", "math.AG"], "pdf": "https://arxiv.org/pdf/2602.07718", "abs": "https://arxiv.org/abs/2602.07718", "authors": ["Michael Burr", "Jonathan D. Hauenstein", "Kisun Lee"], "title": "Certified surface approximations using the interval Krawczyk test", "comment": "15 pages, 5 figures", "summary": "We propose an algorithm to construct a certified approximation of a surface by generalizing the Krawczyk test. The Krawczyk test is based on interval arithmetic, and confirms the existence and uniqueness of a solution to a square system of analytic equations in a region. By generalizing this test, we extend the reach of this technique to non-square systems and higher-dimensional varieties. We provide a prototype implementation and illustrate its use on several examples."}
{"id": "2602.08486", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.08486", "abs": "https://arxiv.org/abs/2602.08486", "authors": ["Lina Hidmi", "Asaf Weinstein"], "title": "Empirical Bayes Variable Selection with Lasso Statistics in the AMP Framework", "comment": null, "summary": "The Lasso is one of the most ubiquitous methods for variable selection in high-dimensional linear regression and has been studied extensively under different regimes. In a particular asymptotic setup entailing $n/p\\to \\text{constant}$, an i.i.d.~Gaussian $X$ matrix and linear sparsity, \\citet{su2017false} analyzed the Lasso selection path and presented negative results, showing that maintaining small levels of the false discovery proportion comes at a substantial cost in power. Followup work by \\citet{wang2020bridge} used the same framework to study the tradeoff between type I error and power for thresholded-Lasso selection, which ranks the variables based on the magnitude of the Lasso estimate instead of the order of appearance on the Lasso path, and demonstrated that significant improvements are possible if the regularization parameter is chosen appropriately. We take this line of research a step further, seeking an {\\em optimal} selection procedure in the AMP framework among procedures that order the variables by some univariate function of the Lasso estimate at a fixed value $λ$ of the regularization term. Observing that the model for the Lasso estimates effectively reduces asymptotically to a version of the well-studied two-groups model, we propose an empirical Bayes variable selection procedure based on an estimate of the local false discovery rate. We extend existing results in the AMP framework to obtain exact predictions for the curve describing the asymptotic tradeoff between type I error and power of this procedure. Additionally, we prove that the optimal $λ$ is the minimizer of the asymptotic mean squared error, and accordingly propose to use the empirical Bayes procedure with $λ$ estimated by cross-validation. The theoretical predictions imply that the gains in power can be substantial, and we confirm this by numerical studies under different settings."}
{"id": "2602.07476", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07476", "abs": "https://arxiv.org/abs/2602.07476", "authors": ["Jingrui Sun", "Lvning Yuan"], "title": "Partial Exponential Turnpike Phenomenon in Linear-Convex Optimal Control", "comment": null, "summary": "This paper studies the long-time behavior of optimal solutions for a class of linear-convex optimal control problems. We focus on a partial exponential turnpike property, established without imposing controllability or stabilizability assumptions, where the turnpike behavior holds only for a subset of initial states. By means of a refined decomposition of the completely uncontrollable dynamics, we derive necessary structural conditions for the turnpike property and explicitly characterize the set of feasible initial states. For each such initial state, we associate a static optimization problem whose unique solution determines the corresponding steady state-control pair. For a class of convex stage cost functions, we prove the partial exponential turnpike property and quantify the convergence rate of the averaged finite-horizon optimal cost toward the steady optimal value."}
{"id": "2602.07524", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07524", "abs": "https://arxiv.org/abs/2602.07524", "authors": ["Christophe Charlier"], "title": "Largest gaps between bulk eigenvalues of unitary-invariant random Hermitian matrices", "comment": "30 pages, no figures", "summary": "We study $n\\times n$ random Hermitian matrix ensembles that are invariant under unitary conjugation. Let $I$ be a finite union of intervals lying in the bulk, and let $m_{k}^{(n)}$ be the $k$-th largest gap between consecutive eigenvalues lying in $I$. We prove that the rescaled gap $\\smash{τ_{k}^{(n)}}$, which is defined by \\begin{align*} m_{k}^{(n)} = \\frac{1}{2π\\inf_{I}ρ} \\bigg( \\frac{\\sqrt{32 \\log n}}{n} + \\frac{3q-8}{2q} \\frac{ \\log(2\\log n)}{n \\sqrt{2\\log n}} + \\frac{4τ_{k}^{(n)}}{n \\sqrt{2\\log n}} \\bigg), \\end{align*} converges in distribution as $n\\to +\\infty$ to a gamma-Gumbel random variable that is shifted by an explicit constant $c_{V,I}$ depending only on $I$ and on the potential $V$. Here $ρ$ is the density of the equilibrium measure and $q\\in \\N_{>0}$ is the highest order at which $ρ(x)$ approaches $\\inf_{I}ρ$ with $x\\in I$; for example, if $ρ(x)=1/(π\\sqrt{x(1-x)})$, then $q=2$ if $\\frac{1}{2}\\in \\overline{I}$ and $q=1$ otherwise. This work extends a result of Feng and Wei beyond the Gaussian potential."}
{"id": "2602.07733", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07733", "abs": "https://arxiv.org/abs/2602.07733", "authors": ["Arun Govind Neelan"], "title": "Data-Driven Discovery of Sign-Indefinite Artificial Viscosity for Linear Convection -- A Space-Time Reconvolution Perspective", "comment": null, "summary": "Artificial viscosity is traditionally interpreted as a positive, spatially acting regularization introduced to stabilize numerical discretizations of hyperbolic conservation laws. In this work, we report a data-driven discovery that motivates a reinterpretation of this classical view. We consider the linear convection equation discretized using an unstable FTCS scheme augmented with a learnable artificial viscosity. Using automatic differentiation and gradient-based optimization, the viscosity field is inferred by minimizing the error with respect to the exact solution, without imposing any sign constraints. The optimized viscosity consistently becomes locally negative near extrema, while the numerical solution remains stable and nearly exact. This behavior is not readily explained within classical modified equation analysis and Lax-Wendroff-type arguments, which predict a strictly positive effective viscosity. To resolve this apparent contradiction, we reinterpret artificial viscosity as a space-time closure that compensates unresolved truncation errors while enforcing entropy stability through global dissipation balance rather than pointwise positivity. Within this framework, the Lax-Wendroff scheme corresponds to a degenerate projection in which temporal truncation errors are eliminated and reintroduced as spatial diffusion. We show that entropy stability constrains the integrated dissipation budget rather than the pointwise sign of spatial viscosity. As a result, locally negative viscosity naturally emerges as a numerical reconvolution operator that compensates for dispersive truncation errors. Negative viscosity is therefore not an unphysical diffusion process, but a scheme- and grid-dependent correction mechanism."}
{"id": "2602.08769", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.08769", "abs": "https://arxiv.org/abs/2602.08769", "authors": ["Edward Eriksson"], "title": "The Unseen Species Problem Revisited", "comment": null, "summary": "The unseen species problem is a classical problem in statistics. It asks us to, given n i.i.d. samples from an unknown discrete distribution over an unknown set, predict how many never before seen outcomes would be observed if m additional samples were collected. For small m we show the classical but poorly understood Good-Toulmin estimator to be minimax optimal to within a factor 2 and resolve the open problem of constructing principled prediction intervals for it. For intermediate m we propose a new estimator which achieves the minimax error for linear estimators up to an explicit multiplicative constant. Our estimator vastly outperforms the standard Smoothed Good-Toulmin estimator in the worst case and performs substantially better on several real data sets, namely those with many rare species. For large m we show that a previously mentioned estimator which did not have known rate guarantees actually achieves a marginally better rate than subsequent work. We find that this marginal rate improvement translates to meaningfully better performance in practice. We show in all three regimes that the same methods also achieve the same rate on incidence data, without further independence assumptions, provided that the sets are of bounded size. We establish, by means of bounded size biased couplings, concentration for some natural functionals of sequences of i.i.d. discrete-set-valued random variables which may be of independent interest."}
{"id": "2602.07507", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07507", "abs": "https://arxiv.org/abs/2602.07507", "authors": ["Yuan Chang", "Lizhong Jiang", "Tai-Fang Li", "Jun Fu"], "title": "A Taylor-Bernstein Inner Approximation Algorithm for Path-Constrained Dynamic Optimization", "comment": null, "summary": "A novel inner approximation algorithm is proposed for dynamic optimization problems to ensure strict satisfaction of path constraints. Distinct from traditional methods relying on interval analysis, the proposed algorithm leverages the convex hull property of Bernstein polynomials to tightly bound the polynomial components of the Taylor expansion, while incorporating the Log-Sum-Exp technique to smooth the non-differentiability arising from coefficient maximization. This approach yields a tighter upper bound function compared to interval methods, with a smaller approximation error. Theoretical analysis shows that the algorithm converges in a finite number of steps to a KKT solution of the original problem that satisfies the specified tolerances. Numerical simulations confirm that the proposed algorithm effectively reduces the number of constraints in the approximation problem, improving computational performance while ensuring strict feasibility."}
{"id": "2602.07537", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07537", "abs": "https://arxiv.org/abs/2602.07537", "authors": ["James Vuckovic"], "title": "Propagation of Chaos for Nonlinear Markov Chains", "comment": null, "summary": "We study 1-Wasserstein propagation of chaos for \"McKean-type\" nonlinear Markov chains and their associated interacting particle systems. This paper is organized into two parts: the first part combines arguments from various areas of nonlinear Markov theory into a systematic treatment of quantitative, nonasymptotic empirical measure estimates and propagation of chaos, with Lipschitz regularity as the primary tool. We also study extensions to uniform-in-time propagation of chaos and improved convergence rates under stronger assumptions such as transportation inequalities, modified metrics, or geometric ergodicity. The second part of this work consists of two detailed applications of our results to specific systems of interest: an Euler-Maruyama scheme for the standard McKean-Vlasov diffusion, and particle filtering via Feynman-Kac distribution flows."}
{"id": "2602.07752", "categories": ["math.NA", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2602.07752", "abs": "https://arxiv.org/abs/2602.07752", "authors": ["Runkai Feng", "Jie Shen", "Haijun Yu"], "title": "Fast Jacobi Spectral Methods and Closure Approximations for the Homogeneous FENE Model of Complex Fluids", "comment": null, "summary": "The Finitely Extensible Nonlinear Elastic (FENE) dumbbell model is a widely used mathematical model for complex fluids. Direct simulation of the FENE Fokker--Planck equation is computationally challenging due to high dimensionality and singularity of its potential. In this paper, we develop two fast Jacobi-Spherical Harmonic spectral methods for the spatially homogeneous FENE Fokker--Planck equation. These methods effectively resolve the singularity near the boundary by combining properly designed Jacobi polynomials with a weighted variational formulation. A semi-implicit backward differentiation formula of second-order (BDF2) is employed for time marching, and its energy stability is rigorously proved. The resulting linear algebraic system possesses a sparse structure and can be efficiently solved. Numerical results verify the spectral convergence and efficiency of the direct spectral solvers, establishing them as a reliable tool for generating reference solutions for challenging benchmark problems. Furthermore, to achieve an optimal trade-off between accuracy and efficiency, we compare several closure approximation models, including the industry workhorse Peterlin approximation (FENE-P), the quasi-equilibrium approximation (FENE-QE), and a novel neural network implementation for FENE-QE proposed in this paper (FENE-QE-NN). Numerical experiments in extensional and shear flows demonstrate the superior accuracy and efficiency of the proposed methods compared to traditional approaches."}
{"id": "2602.07856", "categories": ["math.NA", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.07856", "abs": "https://arxiv.org/abs/2602.07856", "authors": ["Babak Maboudi Afkham", "Tomas Soto", "Mirza Karamehmedovic", "Lassi Roininen"], "title": "Inhomogeneous Priors for Bayesian Inverse Problems", "comment": null, "summary": "Many inverse problems arising in engineering and applied sciences involve unknown quantities with pronounced spatial inhomogeneity, such as localized defects or spatially varying material properties, making reliable uncertainty quantification particularly challenging. While Bayesian inverse problem methodologies provide a principled framework for assessing reconstruction reliability, commonly used Gaussian priors, such as Whittle-Matern models, impose globally homogeneous assumptions that limit their ability to capture such structure in large-scale settings. We introduce a new class of inhomogeneous priors defined via convolution with white noise, yielding nonstationary Whittle-Matern-type random fields with a rigorous mathematical construction. These priors fit naturally within existing Bayesian well-posedness theory and enable efficient sampling by reducing prior realizations to the solution of a pseudo-differential equation, for which we develop numerical schemes with quantified approximation error. Numerical experiments in one-dimensional denoising and two-dimensional limited-angle X-ray tomography demonstrate significant improvements in reconstruction quality and uncertainty quantification, particularly in data-limited scenarios."}
{"id": "2602.07511", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07511", "abs": "https://arxiv.org/abs/2602.07511", "authors": ["Hidekazu Yoshioka", "Yumi Yoshioka", "Motoh Tsujimura", "Ayumi Hashiguchi"], "title": "Mathematical model for sustainable fisheries resource management accounting for size spectrum", "comment": null, "summary": "This paper proposes a novel modelling and control framework for growth models that incorporate a size spectrum in conjunction with numerical computation and extensive field surveys. In fisheries management, the size spectrum, characterized by individual differences in body weight and length, is a critical factor, as it influences the physiology and ecology of fish, as well as the preferences of anglers. However, a comprehensive theoretical framework for fisheries modelling and management that accounts for the size spectrum has yet to be established. We apply a growth model that considers the size spectrum to Plecoglossus altivelis altivelis (Ayu), an important inland fisheries resource in Japan. Additionally, we introduce a novel stochastic control theory for the resource management of Ayu, taking its size spectrum into account. The growth model is calibrated using data collected annually from a river system in Japan. Our control problem addresses the size spectrum of fishing benefits and terminal utility (nonlinear expectation) for sustainability, resulting in a nonstandard problem to which the dynamic programming principle does not apply. We address this difficulty using a time-inconsistent formalism, where solving the control problem is reduced to finding an appropriate solution to a system of nonlinear partial differential equations. We numerically compute the system using the finite difference method and explore the fisheries management of Ayu at the study site."}
{"id": "2602.07538", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07538", "abs": "https://arxiv.org/abs/2602.07538", "authors": ["Tuan Anh Nguyen", "Vitali Wachtel"], "title": "Random walks with drift in the positive quadrant", "comment": "23 pages", "summary": "We consider two dimensional random walks conditioned to stay in the positive quadrant. Assuming that the increments of the walk have finite second moments and that the drift vector is co-oriented with one of two axes, we construct positive harmonic functions for such walks and find tail asymptotics for the exit time from the positive quadrant. Moreover, we prove integral and local limit theorems. Finally, we apply our local limit theorems to singular lattice walks with steps $\\{(1,-1),(1,1),(-1,1)\\}$ and determine asymptotics for the number of walks of length $n$ which end on the line $\\{(k,1),\\ k\\ge1\\}$."}
{"id": "2602.07813", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07813", "abs": "https://arxiv.org/abs/2602.07813", "authors": ["Ke Chen", "Haizhao Yang", "Chugang Yi"], "title": "Data Completion for Electrical Impedance Tomography by Conditional Diffusion Models", "comment": null, "summary": "Data scarcity is a fundamental barrier in Electrical Impedance Tomography (EIT), as undersampled Dirichlet-to-Neumann (DtN) measurements can substantially degrade conductivity reconstructions. We address this bottleneck by completing partially observed DtN measurements using a diffusion based generative model. Specifically, we train a conditional diffusion model to learn the distribution of DtN data and to infer full measurement vectors given partial observations. Our approach supports flexible source receiver configurations and can be used as a plug in preprocessing step with off the shelf EIT solvers. Under mild assumptions on the polygon conductivity class, we derive nonasymptotic end to end bounds on the distributional discrepancy between the completed and ground truth DtN measurements. In numerical experiments, we couple the proposed diffusion completion procedure with a deep learning based inverse solver and compare its performance against the same solver with full measurement data. The results show that diffusion completion enables reconstructions comparable to the full data baseline while using only 1% of the measurements. In contrast, standard baselines such as matrix completion require 30% of the measurements to achieve similar reconstruction quality."}
{"id": "2602.08888", "categories": ["math.PR", "math.ST", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.08888", "abs": "https://arxiv.org/abs/2602.08888", "authors": ["Hongjian Wang", "Shubhada Agrawal", "Aaditya Ramdas"], "title": "Almost sure null bankruptcy of testing-by-betting strategies", "comment": null, "summary": "The bounded mean betting procedure serves as a crucial interface between the domains of (1) sequential, anytime-valid statistical inference, and (2) online learning and portfolio selection algorithms. While recent work in both domains has established the exponential wealth growth of numerous betting strategies under any alternative distribution, the tightness of the inverted confidence sets, and the pathwise minimax regret bounds, little has been studied regarding the asymptotics of these strategies under the null hypothesis. Under the null, a strategy induces a wealth martingale converging to some random variable that can be zero (bankrupt) or non-zero (non-bankrupt, e.g. when it eventually stops betting). In this paper, we show the conceptually intuitive but technically nontrivial fact that these strategies (universal portfolio, Krichevsky-Trofimov, GRAPA, hedging, etc.) all go bankrupt with probability one, under any non-degenerate null distribution. Part of our analysis is based on the subtle almost sure divergence of various sums of $\\sum O_p(n^{-1})$ type, a result of independent interest. We also demonstrate the necessity of null bankruptcy by showing that non-bankrupt strategies are all improvable in some sense. Our results significantly deepen our understanding of these betting strategies as they qualify their behavior on \"almost all paths\", whereas previous results are usually on \"all paths\" (e.g. regret bounds) or \"most paths\" (e.g. concentration inequalities and confidence sets)."}
{"id": "2602.07514", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.07514", "abs": "https://arxiv.org/abs/2602.07514", "authors": ["Jon Asier Bárcena-Petisco", "Salah-Eddine Chorfi", "Fouad Et-tahri", "Lahcen Maniar"], "title": "Averaged Controllability of Time-Fractional Schrödinger Equations with Random Quantum Diffusivity", "comment": null, "summary": "This paper addresses the problem of averaged controllability for the time-fractional Schrodinger equation, where the quantum diffusivity parameter is a random variable with a general probability distribution. First, by exploiting the analyticity of the Mittag-Leffler function and Muntz's theorem, we show that the simultaneous null controllability of the system can occur only for a countable set of realizations of the random diffusivity. In particular, this implies the impossibility of simultaneous null controllability for absolutely continuous random diffusivity. Next, we prove the lack of exact averaged controllability for absolutely continuous random variables, irrespective of the control time. Furthermore, we introduce a new two-parameter fractional characteristic function, which allows us to construct a class of random variables satisfying null averaged controllability at any time from any arbitrary sensor set of positive Lebesgue measure. This is achieved using an open-loop control belonging to L^\\infty and independent of the random parameter. In particular, we obtain the null controllability of the fractional biharmonic diffusion equation. Finally, we conclude with several remarks and open problems that merit future investigation."}
{"id": "2602.07563", "categories": ["math.PR", "cs.DM"], "pdf": "https://arxiv.org/pdf/2602.07563", "abs": "https://arxiv.org/abs/2602.07563", "authors": ["Johan Wästlund"], "title": "Moment generating functions in combinatorial optimization: Bipartite matching", "comment": "37 pages, 6 figures", "summary": "In a random model of minimum cost bipartite matching based on exponentially distributed edge costs, we show that the distribution of the cost of the optimal solution can be computed efficiently. The distribution is represented by its moment generating function, which in this model is always a rational function. The complex zeros of this function are of interest as the lack of zeros near the origin indicates a certain regularity of the distribution. We propose a conjecture according to which these moment generating functions never have complex zeros of smaller modulus than their first pole. For minimum cost perfect matching, also known as the assignment problem, such a zero-free disk would imply a Gaussian scaling limit."}
{"id": "2602.07817", "categories": ["math.NA", "math-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.07817", "abs": "https://arxiv.org/abs/2602.07817", "authors": ["Kumar Saurabh", "Makrand A. Khanwale", "Masado Ishii", "Hari Sundar", "Baskar Ganapathysubramanian"], "title": "Field conserving adaptive mesh refinement (AMR) scheme on massively parallel adaptive octree meshes", "comment": "22 pages", "summary": "Adaptive mesh refinement (AMR) is widely used to efficiently resolve localized features in time-dependent partial differential equations (PDEs) by selectively refining and coarsening the mesh. However, in long-horizon simulations, repeated intergrid interpolations can introduce systematic drift in conserved quantities, especially for variational discretizations with continuous basis functions. While interpolation from parent-to-child during refinement in continuous Galerkin (CG) discretizations is naturally conservative, the standard injection-based child-to-parent coarsening interpolation is generally not.\n  We propose a simple, scalable field-conserving coarsening operator for parallel, octree-based AMR. The method enforces discrete global conservation during coarsening by first computing field conserving coarse-element values at quadrature points and then recovering coarse nodal degrees of freedom via an $L^2$ projection (mass-matrix solve), which simultaneously controls the $L_2$ error. We evaluate the approach on mass-conserving phase-field models, including the Cahn--Hilliard and Cahn--Hilliard--Navier--Stokes systems, and compare against injection in terms of conservation error, solution quality, and computational cost."}
{"id": "2602.07663", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07663", "abs": "https://arxiv.org/abs/2602.07663", "authors": ["Owen Shen", "Haoran Xu", "Yinyu Ye", "Peter Glynn", "Patrick Jaillet"], "title": "A Two-Layer Framework for Joint Online Configuration Selection and Admission Control", "comment": null, "summary": "We study online configuration selection with admission control problem, which arises in LLM serving, GPU scheduling, and revenue management. In a planning horizon with $T$ periods, we consider a two-layer framework for the decisions made within each time period. In the first layer, the decision maker selects one of the $K$ configurations (ex. quantization, parallelism, fare class) which induces distribution over the reward-resource pair of the incoming request. In the second layer, the decision maker observes the request and then decides whether to accept it or not.\n  Benchmarking this framework requires care. We introduce a \\textbf{switching-aware fluid oracle} that accounts for the value of mixing configurations over time, provably upper-bounding any online policy. We derive a max-min formulation for evaluating the benchmark, and we characterize saddle points of the max-min problem via primal-dual optimality conditions linking equilibrium, feasibility, and complementarity. This guides the design of \\textbf{SP-UCB--OLP} algorithm, which solves an optimistic saddle point problem and achieves $\\tilde{O}(\\sqrt{KT})$ regret."}
{"id": "2602.07763", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07763", "abs": "https://arxiv.org/abs/2602.07763", "authors": ["Ryoki Fukushima", "Naoki Kubota"], "title": "Rate of divergence of time constant for frog model with vanishing initial density", "comment": "33 pages, 3 figures", "summary": "The frog model with a Bernoulli initial configuration is an interacting particle system on the $d$-dimensional lattice ($d \\geq 2$) with two types of particles: active and sleeping. Active particles perform independent simple random walks. In contrast, although the sleeping particles do not move at first, they become active and start moving once touched by the active particles. Initially, only the origin has a single active particle, and the other sites have sleeping particles according to a Bernoulli distribution. After the original active particle starts moving, further active particles are gradually generated under the above rule and propagate across the lattice. The time required for the propagation of active frogs is expected to increase as the parameter of the Bernoulli distribution decreases, since fewer frogs are available. The aim of this paper is to investigate this increase in the vanishing density limit. In particular, we observe that it diverges and the rate of divergence differs significantly between $d=2$ and $d \\geq 3$."}
{"id": "2602.07838", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07838", "abs": "https://arxiv.org/abs/2602.07838", "authors": ["Yizheng Wang", "Cosmin Anitescu", "Mohammad Sadegh Eshaghi", "Xiaoying Zhuang", "Timon Rabczuk", "Yinghua Liu"], "title": "Deep Energy Method with Large Language Model assistance: an open-source Streamlit-based platform for solving variational PDEs", "comment": null, "summary": "Physics-informed neural networks (PINNs) in energy form, also known as the deep energy method (DEM), offer advantages over strong-form PINNs such as lower-order derivatives and fewer hyperparameters, yet dedicated and user-friendly software for energy-form PINNs remains scarce. To address this gap, we present \\textbf{LM-DEM} (Large-Model-assisted Deep Energy Method), an open-source, Streamlit-based platform for solving variational partial differential equations (PDEs) in computational mechanics. LM-DEM integrates large language models (LLMs) for geometry modeling: users can generate Gmsh-compatible geometries directly from natural language descriptions or images, significantly reducing the burden of traditional geometry preprocessing. The solution process is driven by the deep energy method, while finite element solutions can be obtained in parallel. The framework supports built-in problems including Poisson, screened Poisson, linear elasticity, and hyperelasticity in two and three dimensions, as well as user-defined energy functionals analogous to the \\texttt{UMAT} interface in Abaqus. The source code is available at https://github.com/yizheng-wang/LMDEM, and a web-based version is accessible at https://ai4m.llmdem.com. LM-DEM aims to lower the barrier for practitioners and beginners to adopt energy-form PINNs for variational PDE problems."}
{"id": "2602.07770", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07770", "abs": "https://arxiv.org/abs/2602.07770", "authors": ["Karl Kunisch", "Donato Vásquez-Varas"], "title": "Structure Preserving Approximation of Semiconcave Functions", "comment": null, "summary": "This article addresses structure-preserving smooth approximation of semiconcave functions. semiconcave functions are of particular interest because they naturally arise in a variety of variational problems, including {optimal feedback control, game theory, and optimal transport}. We leverage the fact that any semiconcave function can be represented as the {infimum of a countable family of \\(C^2\\) functions}. This infimum is expressed in a form that allows {approximation by finitely many functions}, combined with {smoothing operations}, such that each element of the approximating sequence remains semiconcave. The {active sets of indices} contributing to the representation of the semiconcave function and its approximations are analyzed in detail. Moreover, we show that the {gradients of the elements in the expansion of the approximating functions form a probability distribution}, a property of particular interest for the {value function in optimal control}. Approximation results are established in \\(C(\\bar Ω)\\) and in \\(W^{1,p}(Ω)\\) for \\(p \\in [1,\\infty)\\) and \\(p = \\infty\\). Finally, {numerical results} are presented to illustrate the approach on a test example."}
{"id": "2602.07843", "categories": ["math.PR", "math.AP", "math.DG"], "pdf": "https://arxiv.org/pdf/2602.07843", "abs": "https://arxiv.org/abs/2602.07843", "authors": ["Maja Gwozdz"], "title": "Green--Wasserstein Inequality on Compact Surfaces", "comment": null, "summary": "Let $(M,g)$ be a compact connected two-dimensional Riemannian manifold without boundary. In this note, we answer a question posed by Steinerberger: can one remove the $\\sqrt{\\log n}$ factor in the two-dimensional Green--Wasserstein inequality while keeping the unrenormalized off-diagonal Green term? We show that this is impossible on any compact connected surface: there is no inequality of the same form that holds uniformly over point sets with an $O(n^{-1/2})$ remainder for all $n$. We argue by contradiction and combine a second-moment estimate for the random Green energy of i.i.d. samples with the semi-discrete random matching asymptotics of Ambrosio--Glaudo."}
{"id": "2602.07856", "categories": ["math.NA", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.07856", "abs": "https://arxiv.org/abs/2602.07856", "authors": ["Babak Maboudi Afkham", "Tomas Soto", "Mirza Karamehmedovic", "Lassi Roininen"], "title": "Inhomogeneous Priors for Bayesian Inverse Problems", "comment": null, "summary": "Many inverse problems arising in engineering and applied sciences involve unknown quantities with pronounced spatial inhomogeneity, such as localized defects or spatially varying material properties, making reliable uncertainty quantification particularly challenging. While Bayesian inverse problem methodologies provide a principled framework for assessing reconstruction reliability, commonly used Gaussian priors, such as Whittle-Matern models, impose globally homogeneous assumptions that limit their ability to capture such structure in large-scale settings. We introduce a new class of inhomogeneous priors defined via convolution with white noise, yielding nonstationary Whittle-Matern-type random fields with a rigorous mathematical construction. These priors fit naturally within existing Bayesian well-posedness theory and enable efficient sampling by reducing prior realizations to the solution of a pseudo-differential equation, for which we develop numerical schemes with quantified approximation error. Numerical experiments in one-dimensional denoising and two-dimensional limited-angle X-ray tomography demonstrate significant improvements in reconstruction quality and uncertainty quantification, particularly in data-limited scenarios."}
{"id": "2602.07793", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07793", "abs": "https://arxiv.org/abs/2602.07793", "authors": ["Shanjian Tang", "Jianjun Zhou"], "title": "Optimal Control of Unbounded Stochastic Evolution Systems in Hilbert Spaces", "comment": "57 pages", "summary": "Optimal control and the associated second-order Hamilton-Jacobi-Bellman (HJB) equation are studied for unbounded stochastic evolution systems in Hilbert spaces. A new notion of viscosity solution, featured by absence of B-continuity, is introduced for the second-order HJB equation in the sense of Crandall and Lions, and is shown to coincide with the classical solutions and to satisfy a stability property. The value functional is proved to be the unique continuous viscosity solution to the second-order HJB equation, with the coefficients being not necessarily B-continuous. Our result provides a new theory of viscosity solutions to the HJB equation for optimal control of stochastic evolutionary equations-driven by a linear unbounded operator-in a Hilbert space, and removes the B-continuity assumption on the coefficients which is used in the existing literature."}
{"id": "2602.07920", "categories": ["math.PR", "math.CO"], "pdf": "https://arxiv.org/pdf/2602.07920", "abs": "https://arxiv.org/abs/2602.07920", "authors": ["Raghavendra Tripathi"], "title": "On the position matrix of single-shelf shuffle and card guessing", "comment": "Comments Welcome. 16 pages. No figures", "summary": "Mechanical shufflers used in many casinos employ a card shuffling scheme called \\emph{shelf shuffling}. In a single-shelf shuffling, cards arrive sequentially, and each incoming card is independently placed on the top or the bottom of a shelf with equal probability. The position matrix of a single-shelf shuffling encodes the probability that the $i$-th incoming card is in position $j$ after one round of single-shelf shuffle. The spectral properties of the position matrix of card shuffling schemes are helpful in the analysis of card guessing games without feedback. In this paper, we determine the full spectrum and the corresponding eigenspaces of the position matrix $M$ of a single-shelf shuffle. This strengthens and resolves two conjectures in a recent work [arXiv:2507.10294]. As a consequence of these results, we show that the maximum number of expected correct guesses without feedback after $k\\geq (1+ε)$ many shuffles is of the order $1+O(n^{-2ε})$. On the other hand, the expected number of correct guesses after one shuffle is at most $\\sqrt{2n/π}+1+O(n^{-1/2})$, and we give a strategy (not optimal) that achieves $\\sqrt{2n/π}-1$ number of correct cards in expectation."}
{"id": "2602.07857", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07857", "abs": "https://arxiv.org/abs/2602.07857", "authors": ["Ben S. Ashby", "Alex Lukyanov", "Tristan Pryer"], "title": "Characteristic Sweeps and Source Iteration for Charged-Particle Transport with Continuous Slowing-Down and Angular Scattering", "comment": "30 pages, 16 figures", "summary": "We develop a semi-analytic deterministic framework for charged-particle transport with continuous slowing-down in energy and angular scattering. Directed transport and energy advection are treated by method-of-characteristics integration, yielding explicit directional sweeps defined by characteristic maps and inflow data. Scattering is incorporated through a fixed-point (source-iteration) scheme in which the angular gain is lagged, yielding a sequence of decoupled directional solves coupled only through angular sums.\n  The method is formulated variationally in a transport graph space adapted to the charged particle drift. Under standard monotonicity and positivity assumptions on the stopping power and boundedness assumptions on cross sections, we establish coercivity and boundedness of the transport bilinear form, prove contraction of the source iteration under a subcriticality condition and derive a rigorous a posteriori bound for the iteration error, providing an efficient stopping criterion.\n  We further analyse an elastic discrete-ordinates approximation, including conservation properties and a decomposition of angular error into quadrature, cone truncation and finite iteration effects. Numerical experiments for proton transport validate the characteristic sweep against an exact ballistic benchmark and demonstrate the predicted fixed-point convergence under forward-peaked scattering. Carbon-ion simulations with tabulated stopping powers and a reduced multi-species coupling illustrate Bragg peak localisation and distal tail formation driven by secondary charged fragments."}
{"id": "2602.07844", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07844", "abs": "https://arxiv.org/abs/2602.07844", "authors": ["Chunfeng Cui", "Liqun Qi", "Yi Xu"], "title": "Biquadratic SOS Rank: Sum of Squares Decompositions and Rank Bounds for Biquadratic Forms", "comment": null, "summary": "We prove that every $3 \\times 3$ sum-of-squares (SOS) biquadratic form can be expressed as the sum of at most \\textbf{six} squares of bilinear forms, establishing $\\mathrm{BSR}(3,3) = 6$. We also determine the exact SOS rank for $4 \\times 3$ biquadratic forms: $\\mathrm{BSR}(4,3)=7$. These results fit the pattern $\\mathrm{BSR}(m,n)=m+n$, leading to the conjecture that this linear formula holds for all $m,n \\ge 3$. Furthermore, we extend our geometric-analytic method to general dimensions and show that for any integers $m,n \\ge 2$ with $(m,n)\\neq(2,2)$, every $m \\times n$ SOS biquadratic form is a sum of at most $mn-2$ squares, improving the general upper bound of $mn-1$ established in earlier work. For the $3 \\times 3$ case, we provide a complete geometric analysis of the SOS cone structure, and for general dimensions we establish a systematic framework that applies to all $m \\times n$ biquadratic forms except the degenerate $(2,2)$ case.\n  We note that the lower bound of 6 for $3 \\times 3$ forms is achieved by a simple biquadratic form, and for general $m,n\\ge 3$, it is known that the maximum SOS rank is at least $m+n$. Our results establish new upper bounds and significantly reduce the gap between the lower and upper bounds for the worst-case SOS rank of biquadratic forms across all dimensions."}
{"id": "2602.07968", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.07968", "abs": "https://arxiv.org/abs/2602.07968", "authors": ["Xingyu Wang", "Chang-Han Rhee"], "title": "First-Exit Time Analysis for Truncated Heavy-Tailed Dynamical Systems", "comment": "42 pages, 1 figure", "summary": "In this paper, we study the first-exit time of stochastic difference equation $X^η_{j+1}(x) = X^η_{j}(x) + ηa\\big( X^η_{j}(x)\\big) + ησ\\big( X^η_{j}(x)\\big)Z_{j+1}$ and its truncated variant $X^{η|b}_{j+1}(x) = X^{η|b}_{j}( x) + \\varphi_b\\big(ηa\\big( X^{η|b}_{j}( x)\\big) + ησ\\big( X^{η|b}_{j}( x)\\big) Z_{j+1}\\big)$, where $\\varphi_b(x) = (x/|x|)\\min\\{|x|, b\\}$ and the law of the noise $Z_t$ is multivariate regularly varying. The truncation operator $\\varphi_b(\\cdot)$ is often introduced as a modulation mechanism in heavy-tailed systems, such as stochastic gradient descent algorithms in deep learning. By developing a framework that connects large deviations with metastability, we leverage the locally uniform sample-path large deviations for both processes in Wang and Rhee (2024) to obtain precise characterizations of the joint distributions of the first exit times and exit locations. The resulting limit theorem unveils a discrete hierarchy of phase transitions (i.e., exit times) as the truncation threshold $b$ varies, and manifests the catastrophe principle, whereby key events or metastable behaviors in heavy-tailed systems are driven by catastrophic behavior in a few components while the rest of the system behaves nominally. These developments lead to a comprehensive heavy-tailed counterpart of the classical Freidlin-Wentzell theory."}
{"id": "2602.07862", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07862", "abs": "https://arxiv.org/abs/2602.07862", "authors": ["Lei-Hong Zhang"], "title": "Optimality Conditions for Rational Minimax Approximations: Bridging Ruttan's Criteria to Dual-Based Methods", "comment": "26 pages", "summary": "This paper presents a theoretical discussion on Ruttan's optimality conditions for rational minimax approximations in discrete and continuum settings, integrating analytical foundations with computational practice. We develop extended second-order optimality criteria for the discrete case, demonstrating that Ruttan's sufficient condition for global solutions [Ruttan, {Constr. Approx.}, 1 (1985), 287-296] becomes necessary when the number of extreme points is minimal. Our analysis further uncovers fundamental relationships between these conditions and the dual-based {d-Lawson} method [L.-H. Zhang et al., {Math. Comp.}, 94 (2025), 2457-2494], proving that strong duality in {d-Lawson} ensures simultaneous satisfaction of both Ruttan's and Kolmogorov's criteria. Additionally, we show that minimax approximants on a continuum satisfying Ruttan's sufficient global optimality can be captured through discrete minimax approximations at properly chosen boundary points, thereby enabling efficient computation of minimax approximants on a continuum using discrete methods."}
{"id": "2602.07851", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07851", "abs": "https://arxiv.org/abs/2602.07851", "authors": ["Regina S. Burachik", "Bethany I. Caldwell", "C. Yalçın Kaya", "Walaa M. Moursi"], "title": "Best Approximation Optimal Control for Infeasible Double Integrator and Douglas--Rachford Algorithm", "comment": null, "summary": "We consider the problem of finding (in some sense) the best approximation control for an infeasible double integrator. The control function is constrained by upper and lower bounds that are too tight and thus cause infeasibility. The infeasibility is characterized by a gap function (representing the separation between two constraint sets) whose squared ${\\cal L}^2$-norm is to be minimized to find the best approximation control solution. First, we review the existing results for problems involving a general linear control system. Then, for the infeasible double integrator problem, we present an analytical solution for the bang--bang control with at most one switching. The infinite-dimensional optimization problem is reduced to the problem of solving two algebraic equations in two variables, to compute the switching time and gap function. We discuss numerical approaches to solving the system of equations. Finally, we describe the (relaxed) Douglas--Rachford algorithm for the double integrator problem and carry out numerical experiments to illustrate the implementation of the algorithm and test performance."}
{"id": "2602.08093", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.08093", "abs": "https://arxiv.org/abs/2602.08093", "authors": ["Alexander Iksanov", "Valeriya Kotelnikova"], "title": "On tail behavior of infinite sums of independent indicators", "comment": "50 pages", "summary": "Let $Y=\\sum_{k\\ge 1} 1_{A_k}$ be an infinite sum of the indicators of independent events. We investigate a precise (as opposed to logarithmic) first-order asymptotic behavior of the tail probabilities $\\mathbb{P}\\{Y\\ge n\\}$ and the point probabilities $\\mathbb{P}\\{Y=n\\}$ as $n\\to\\infty$. Our analysis provides a reasonably complete classification of the asymptotic behaviors covering most cases of practical interest. These general results are then applied to specific examples where the success probabilities $r_k:=\\mathbb{P}(A_k)$ decay polynomially $r_k\\sim ck^{-β}$ or (sub-, super-) exponentially $r_k\\sim ce^{-k^β}$, yielding the asymptotic tail and point probabilities in explicit forms.\n  As briefly discussed in the paper, infinite sums of independent indicators arise naturally in numerous settings as diverse as the range of Poissonized samples, the infinite Ginibre point processes and decoupled renewal processes, and records in the $F^α$ scheme. We also explore the connection of our research to the theory of Hayman-admissible functions and the notion of total positivity."}
{"id": "2602.07945", "categories": ["math.NA", "cs.PF", "physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.07945", "abs": "https://arxiv.org/abs/2602.07945", "authors": ["N. R. Rapaka", "R. Peddinti", "E. Tiunov", "N. J. Faraj", "A. N. Alkhooori", "L. Aolita", "Y. Addad", "M. K. Riahi"], "title": "A quantum-inspired multi-level tensor-train monolithic space-time method for nonlinear PDEs", "comment": "29", "summary": "We propose a multilevel tensor-train (TT) framework for solving nonlinear partial differential equations (PDEs) in a global space-time formulation. While space-time TT solvers have demonstrated significant potential for compressed high-dimensional simulations, the literature contains few systematic comparisons with classical time-stepping methods, limited error convergence analyses, and little quantitative assessment of the impact of TT rounding on numerical accuracy. Likewise, existing studies fail to demonstrate performance across a diverse set of PDEs and parameter ranges. In practice, monolithic Newton iterations may stagnate or fail to converge in strongly nonlinear, stiff, or advection-dominated regimes, where poor initial guesses and severely ill-conditioned space-time Jacobians hinder robust convergence. We overcome this limitation by introducing a coarse-to-fine multilevel strategy fully embedded within the TT format. Each level refines both spatial and temporal resolutions while transferring the TT solution through low-rank prolongation operators, providing robust initializations for successive Newton solves. Residuals, Jacobians, and transfer operators are represented directly in TT and solved with the adaptive-rank DMRG algorithm. Numerical experiments for a selection of nonlinear PDEs including Fisher-KPP, viscous Burgers, sine-Gordon, and KdV cover diffusive, convective, and dispersive dynamics, demonstrating that the multilevel TT approach consistently converges where single-level space-time Newton iterations fail. In dynamic, advection-dominated (nonlinear) scenarios, multilevel TT surpasses single-level TT, achieving high accuracy with significantly reduced computational cost, specifically when high-fidelity numerical simulation is required."}
{"id": "2602.07874", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07874", "abs": "https://arxiv.org/abs/2602.07874", "authors": ["Ziliang Wang", "Axel Ringh", "Han Zhang"], "title": "Consistent inverse optimal control for infinite time-horizon discounted nonlinear systems under noisy observations", "comment": null, "summary": "Inverse optimal control (IOC) aims to estimate the underlying cost that governs the observed behavior of an expert system. However, in practical scenarios, the collected data is often corrupted by noise, which poses significant challenges for accurate cost function recovery. In this work, we propose an IOC framework that effectively addresses the presence of observation noise. In particular, compared to our previous work \\cite{wang2025consistent}, we consider the case of discrete-time, infinite-horizon, discounted MDPs whose transition kernel is only weak Feller. By leveraging the occupation measure framework, we first establish the necessary and sufficient optimality conditions for the expert policy and then construct an infinite dimensional optimization problem based on these conditions. This problem is then approximated by polynomials to get a finite-dimensional numerically solvable one, which relies on the moments of the state-action trajectory's occupation measure. More specifically, the moments are robustly estimated from the noisy observations by a combined misspecified Generalized Method of Moments (GMM) estimator derived from observation model and system dynamics. Consequently, the entire algorithm is based on convex optimization which alleviates the issues that arise from local minima and is asymptotically and statistically consistent. Finally, the performance of the proposed method is illustrated through numerical examples."}
{"id": "2602.08118", "categories": ["math.PR", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08118", "abs": "https://arxiv.org/abs/2602.08118", "authors": ["Yifan Jiang", "Renyuan Xu", "Luhao Zhang"], "title": "Schrödinger bridge with transport relaxation", "comment": "27 pages, 5 figures", "summary": "Motivated by modern machine learning applications where we only have access to empirical measures constructed from finite samples, we relax the marginal constraints of the classical Schrödinger bridge problem by penalizing the transport cost between the bridge's marginals and the prescribed marginals. We derive a duality formula for this transport-relaxed bridge and demonstrate that it reduces to a finite-dimensional concave optimization problem when the prescribed marginals are discrete and the reference distribution is absolutely continuous. We establish the existence and uniqueness of solutions for both the primal and dual problems. Moreover, as the penalty blows up, we characterize the limiting bridge as the solution to a discrete Schrödinger bridge problem and identify a leading-order logarithmic divergence. Finally, we propose gradient ascent and Sinkhorn-type algorithms to numerically solve the transport-relaxed Schrödinger bridge, establishing a linear convergence rate for both algorithms."}
{"id": "2602.07990", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.07990", "abs": "https://arxiv.org/abs/2602.07990", "authors": ["Oussama Al Jarroudi", "Marcus J. Grote"], "title": "Finite Element Convergence Analysis For Wave Equations With Time-Dependent Coefficients", "comment": null, "summary": "Error estimates are proved for finite element approximations to the solution of second-order hyperbolic partial differential equations with coefficients varying in both space and time. Optimal rates of convergence in the energy norm are proved for the semi-discrete Galerkin finite element solution by introducing a time-dependent Ritz-like projection. Numerical experiments corroborate the rates of convergence and illustrate the localized wave field enhancement in a chain of time-modulated subwavelength resonators."}
{"id": "2602.07961", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07961", "abs": "https://arxiv.org/abs/2602.07961", "authors": ["Xiaojun Chen", "C. T. Kelley", "Lei Wang"], "title": "Complexity of Projected Gradient Methods for Strongly Convex Optimization with Hölder Continuous Gradient Terms", "comment": null, "summary": "This paper studies the complexity of projected gradient descent methods for a class of strongly convex constrained optimization problems where the objective function is expressed as a summation of $m$ component functions, each possessing a gradient that is Hölder continuous with an exponent $α_i \\in (0, 1]$. Under this formulation, the gradient of the objective function may fail to be globally Hölder continuous, thereby rendering existing complexity results inapplicable to this class of problems. Our theoretical analysis reveals that, in this setting, the complexity of projected gradient methods is determined by $\\hatα = \\min_{i \\in \\{1, \\dotsc, m\\}} α_i$. We first prove that, with an appropriately fixed stepsize, the complexity bound for finding an approximate minimizer with a distance to the true minimizer less than $\\varepsilon$ is $O (\\log (\\varepsilon^{-1}) \\varepsilon^{2 (\\hatα - 1) / (1 + \\hatα)})$, which extends the well-known complexity result for $\\hatα = 1$. Next we show that the complexity bound can be improved to $O (\\log (\\varepsilon^{-1}) \\varepsilon^{2 (\\hatα - 1) / (1 + 3 \\hatα)})$ if the stepsize is updated by the universal scheme. We illustrate our complexity results by numerical examples arising from elliptic equations with a non-Lipschitz term."}
{"id": "2602.08130", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.08130", "abs": "https://arxiv.org/abs/2602.08130", "authors": ["N. V. Krylov"], "title": "On the parabolic Adams theorem and its applications to diffusion processes", "comment": "24 pages", "summary": "We show how the parabolic version of the Adams theorem and its corollary can be used to estimate in $L_{p}$ the evolution family associated to a divergence form second-order parabolic operator with parabolic Morrey lower-order terms and also how to estimate the moments of the derivatives of solutions of Itô equations with respect to the initial data when the drift term has singularities."}
{"id": "2602.08291", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.08291", "abs": "https://arxiv.org/abs/2602.08291", "authors": ["Jean-Luc Guermond", "Eric J. Tovar"], "title": "Invariant-domain preserving IMEX schemes for the nonequilibrium Gray Radiation-Hydrodynamics equations Part I", "comment": null, "summary": "In this work we introduce an implicit-explicit invariant-domain\n  preserving approximation of the nonequilibrium gray\n  radiation-hydrodynamics equations. A time and space approximation\n  of the system is proposed using a novel split of the equations\n  composed of three elementary subsystems, two hyperbolic and one\n  parabolic. The approximation thus realized is proved to be\n  consistent, conservative, invariant-domain preserving, and\n  first-order accurate. The proposed method is a stepping stone for\n  achieving higher-order accuracy in space and time in the forthcoming\n  second part of this work. The method is numerically illustrated and\n  shown to converge as advertised. This paper is dedicated to the memory\n  of Peter Lax."}
{"id": "2602.07975", "categories": ["math.OC", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07975", "abs": "https://arxiv.org/abs/2602.07975", "authors": ["Yuhan Chen", "Tao Liu", "Jie Huang"], "title": "Leader-following Consensus over Jointly Connected Switching Networks is Achievable for Exponentially Unstable Linear Systems", "comment": null, "summary": "The leader-following consensus problem for general linear multi-agent systems over jointly connected switching networks has been a challenging problem and the solvability of the problem has been limited to the class of linear multi-agent systems whose system matrix is marginally stable. This condition is restrictive since it even excludes the most commonly used double-integrator system. This paper presents a breakthrough by demonstrating that leader-following exponential consensus is achievable for general linear multi-agent systems over jointly connected switching networks, even when the system matrix is exponentially unstable. The degree of instability can be explicitly characterized by two key quantities that arise from the jointly connected condition on a switching graph. By exploiting duality, we further show that the output-based distributed observer design problem for a general leader system is solvable over jointly connected switching networks, even when the system matrix is exponentially unstable. This is also in sharp contrast to the existing distributed observers, which rely on the assumption that the leader system is marginally stable."}
{"id": "2602.08279", "categories": ["math.PR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.08279", "abs": "https://arxiv.org/abs/2602.08279", "authors": ["Laigang Guo", "Tao Guo", "Raymond W. Yeung"], "title": "Characterizations of Conditional Mutual Independence: Equivalence and Implication", "comment": null, "summary": "Conditional independence, and more generally conditional mutual independence, are central notions in probability theory. In their general forms, they include functional dependence as a special case. In this paper, we tackle two fundamental problems related to conditional mutual independence. Let $K$ and $K'$ be two conditional mutual independncies (CMIs) defined on a finite set of discrete random variables. We have obtained a necessary and sufficient condition for i) $K$ is equivalent to $K'$; ii) $K$ implies $K'$. These characterizations are in terms of a canonical form introduced for conditional mutual independence."}
{"id": "2602.08325", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.08325", "abs": "https://arxiv.org/abs/2602.08325", "authors": ["Liangcai Huang", "Lin Li", "Shujuan Lü"], "title": "A numerical study for tempered time-fractional advection-dispersion equation on graded meshes", "comment": null, "summary": "In this paper, we develop a second-order accurate time-stepping scheme for the tempered time-fractional advection-dispersion equation based on a sum-of-exponentials (SOE) approximation to the convolution kernel involved in the fractional derivative. To effectively resolve the weak initial-time singularity at t=0, graded temporal meshes are employed. A fully discrete scheme is constructed by coupling the proposed half-time-level temporal discretization with a finite difference method in space. Compared with the classical L1 scheme, the proposed SOE-based method achieves the same global convergence order while reducing both storage requirements and computational cost. Specifically, the storage demand is reduced from O(MN) to O(MN_exp), and the computational complexity is lowered from O(MN^2) to O(MN N_exp), where M and N denote the numbers of spatial and temporal grid points, respectively, and N_exp is the number of exponential terms used in the SOE approximation. The unique solvability, stability and accuracy of the resulting scheme are rigorously analyzed. Several numerical results are presented to confirm the sharpness of the error analysis and to demonstrate the efficiency of the proposed method."}
{"id": "2602.08018", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08018", "abs": "https://arxiv.org/abs/2602.08018", "authors": ["Yulin Feng", "Xianyu Li", "Steven X. Ding", "Hao Ye", "Chao Shang"], "title": "Sinkhorn Distributionally Robust State Estimation via System Level Synthesis", "comment": "15 pages, 5 figures", "summary": "In state estimation tasks, the usual assumption of exactly known disturbance distribution is often unrealistic and renders the estimator fragile in practice. The recently emerging Wasserstein distributionally robust state estimation (DRSE) design can partially mitigate this fragility; however, its worst-case distribution is provably discrete, which deviates from the inherent continuity of real-world distributions and results in over-pessimism. In this work, we develop a new Sinkhorn DRSE design within system level synthesis scheme with the aim of shaping the closed-loop errors under the unknown continuous disturbance distribution. For uncertainty description, we adopt the Sinkhorn ambiguity set that includes an entropic regularizer to penalize non-smooth and discrete distributions within a Wasserstein ball. We present the first result of finite-sample probabilistic guarantee of the Sinkhorn ambiguity set. Then we analyze the limiting properties of our Sinkhorn DRSE design, thereby highlighting its close connection with the generic $\\mathcal{H}_2$ design and Wasserstein DRSE. To tackle the min-max optimization problem, we reformulate it as a finite-dimensional convex program through duality theory. By identifying a compact subset of the feasible set guaranteed to enclose the global optimum, we develop a tailored Frank-Wolfe solution algorithm and formally establish its convergence rate. The advantage of Sinkhorn DRSE over existing design schemes is verified through numerical case studies."}
{"id": "2602.08460", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.08460", "abs": "https://arxiv.org/abs/2602.08460", "authors": ["Alexandra Blessing", "Nicolas Perkowski", "Chara Zhu"], "title": "Renormalization destroys a finite time bifurcation in the $Φ^4_2$ equation", "comment": "18 pages", "summary": "We study the singular $Φ^4_2$ equation at a pitchfork bifurcation of the underlying deterministic dynamics. To this aim, we linearize the SPDE along its stationary solution and show that the support of its finite-time Lyapunov exponents (FTLEs) is the real line, regardless of the bifurcation parameter and in sharp contrast to the non-singular $Φ^4_1$ equation. The proof relies on a support theorem for the stationary solution and its renormalized square."}
{"id": "2602.08481", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.08481", "abs": "https://arxiv.org/abs/2602.08481", "authors": ["Simone Göttlich", "Michael Schuster", "Alena Ulke"], "title": "On the Existence of Steady States for Blended Gas Flow with Non-Constant Compressibility Factor on Networks", "comment": null, "summary": "In this paper, we study hydrogen-natural gas mixtures transported through pipeline networks. The flow is modeled by the isothermal Euler equations with a pressure law involving a non-constant, composition-dependent compressibility factor. For a broad class of such compressibility models, we prove the existence of steady-state solutions on networks containing compressor stations. The analysis is based on an implicit representation of the pressure profiles and a continuity argument that overcomes the discontinuous dependence of the gas composition on the flow direction. Numerical examples illustrate the influence of different compressibility models on the resulting states."}
{"id": "2602.08066", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08066", "abs": "https://arxiv.org/abs/2602.08066", "authors": ["Mamadou Pathe LY", "Ravikumar Kasinathan", "Ramkumar Kasinathan", "Dimplekumar Chalishajar", "Mamadou Abdoul Diop"], "title": "Approximate Controllability of Nonlocal Stochastic Integrodifferential System in Hilbert Spaces", "comment": "26 pages", "summary": "This project investigates the approximate controllability of a class of stochastic integrodifferential equations in Hilbert space with non-local beginning conditions. In a departure from the conventional concerns expressed in the literature, we will not consider compactness or the Lipschitz criteria concerning the nonlocal term. We use the fact that the resolvent operator is compact. We first prove the controllability of the nonlinear system using Schauder's fixed point theorem, a method known for its robustness; as well, we also use Grimmer's resolvent operator theory. Subsequently, we employ the reliable approximation methods and the powerful diagonal argument to determine the approximate controllability of the stochastic system. To conclude, we present an example that validates our theoretical statement."}
{"id": "2602.08581", "categories": ["math.PR", "math.MG"], "pdf": "https://arxiv.org/pdf/2602.08581", "abs": "https://arxiv.org/abs/2602.08581", "authors": ["Zakhar Kabluchko"], "title": "Random Polyhedral Cones: Distributional Results via Gale Duality", "comment": "35 pages", "summary": "Let $U_1,\\ldots,U_n$ be independent random vectors uniformly distributed on the unit sphere $\\mathbb S^{d-1}\\subseteq\\mathbb R^d$, where $n\\ge d$, and consider the random polyhedral cone \\[ \\mathcal W_{n,d}:=\\mathop{\\mathrm{pos}} (U_1,\\ldots,U_n) = \\{λ_1 U_1+ \\ldots + λ_n U_n: λ_1\\geq 0, \\ldots, λ_n \\geq 0\\}. \\] We establish several distributional results for $\\mathcal W_{n,d}$ and the associated spherical polytope $\\mathcal W_{n,d}\\cap\\mathbb S^{d-1}$. Our main contributions include:\n  (i) Let $α_d$ denote the solid angle of $\\mathcal W_{d,d}$ and write $m(d,k):=\\mathbb E[α_d^k]$ for its $k$-th moment. We prove the symmetry $m(d,k)=m(k,d)$. As an application, we compute $\\mathop{\\mathrm{Var}}[α_d]=2^{-d}(d+1)^{-1}-4^{-d}$ and derive a closed formula for the third moment.\n  (ii) For $n=d+1,d+2,d+3$ we determine the probability that $\\mathcal W_{n,d}\\cap\\mathbb S^{d-1}$ is a spherical simplex, a spherical analogue of the classical Sylvester problem. In the case $n=d+2$ we also determine the distribution of the number of vertices of $\\mathcal W_{d+2,d}\\cap\\mathbb S^{d-1}$.\n  (iii) Let $f_\\ell(\\mathcal W_{n,d})$ denote the number of $\\ell$-dimensional faces of $\\mathcal W_{n,d}$. We prove a distributional limit theorem for $f_\\ell(\\mathcal W_{n,d})$ in the regime $n=d+k$ and $\\ell=d-q$, where $k,q\\in\\mathbb N$ are fixed and $d\\to\\infty$. The limit law is a weighted sum of independent chi squared variables, with weights given by explicit eigenvalues of a convolution operator on the sphere.\n  A unifying ingredient is an explicit coupling producing i.i.d. uniform vectors $U_1,\\ldots,U_n\\in\\mathbb S^{d-1}$ together with i.i.d. uniform vectors $V_1,\\ldots,V_n\\in\\mathbb S^{n-d-1}$ whose associated oriented matroids are Gale dual."}
{"id": "2602.08515", "categories": ["math.NA", "cs.LG", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08515", "abs": "https://arxiv.org/abs/2602.08515", "authors": ["Muhammad Luthfi Shahab", "Imam Mukhlash", "Hadi Susanto"], "title": "Do physics-informed neural networks (PINNs) need to be deep? Shallow PINNs using the Levenberg-Marquardt algorithm", "comment": null, "summary": "This work investigates the use of shallow physics-informed neural networks (PINNs) for solving forward and inverse problems of nonlinear partial differential equations (PDEs). By reformulating PINNs as nonlinear systems, the Levenberg-Marquardt (LM) algorithm is employed to efficiently optimize the network parameters. Analytical expressions for the neural network derivatives with respect to the input variables are derived, enabling accurate and efficient computation of the Jacobian matrix required by LM. The proposed approach is tested on several benchmark problems, including the Burgers, Schrödinger, Allen-Cahn, and three-dimensional Bratu equations. Numerical results demonstrate that LM significantly outperforms BFGS in terms of convergence speed, accuracy, and final loss values, even when using shallow network architectures with only two hidden layers. These findings indicate that, for a wide class of PDEs, shallow PINNs combined with efficient second-order optimization methods can provide accurate and computationally efficient solutions for both forward and inverse problems."}
{"id": "2602.08069", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08069", "abs": "https://arxiv.org/abs/2602.08069", "authors": ["Amal Alphonse", "Pavel Dvurechensky", "Clemens Sirotenko"], "title": "Skip the Hessian, Keep the Rates: Globalized Semismooth Newton with Lazy Hessian Updates", "comment": null, "summary": "Second-order methods are provably faster than first-order methods, and their efficient implementations for large-scale optimization problems have attracted significant attention. Yet, optimization problems in ML often have nonsmooth derivatives, which makes the existing convergence rate theory of second-order methods inapplicable. In this paper, we propose a new semismooth Newton method (SSN) that enjoys both global convergence rates and asymptotic superlinear convergence without requiring second-order differentiability. Crucially, our method does not require (generalized) Hessians to be evaluated at each iteration but only periodically, and it reuses stale Hessians otherwise (i.e., it performs lazy Hessian updates), saving compute cost and often leading to significant speedups in time, whilst still maintaining strong global and local convergence rate guarantees. We develop our theory in an infinite-dimensional setting and illustrate it with numerical experiments on matrix factorization and neural networks with Lipschitz constraints."}
{"id": "2602.08591", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.08591", "abs": "https://arxiv.org/abs/2602.08591", "authors": ["Nguyen Viet Dang", "Elias Nohra"], "title": "The Yang--Mills measure on compact surfaces as a universal scaling limit of lattice gauge models", "comment": null, "summary": "In this article, we study the 2 dimensional Yang-Mills measure on compact surfaces from a unified continuum and discrete perspective. We construct the Yang-Mills measure as a random distributional 1-form on surfaces of arbitrary genus equipped with an arbitrary smooth area form, using geometric tools based on zero-area bands and cylindrical resolutions. This yields a canonical bulk-singular decomposition of the measure, reflecting the topology of the surface.\n  We prove a universality theorem stating that the continuum Yang-Mills measure arises as the scaling limit of a wide class of lattice gauge theories, including Wilson, Manton, and Villain actions, on any compact surface. We study the convergence in natural spaces of distributions with anisotropic regularity. As further consequences, we obtain a new intrinsic construction of the Yang-Mills measure, independent of the previous constructions in the literature, and prove the convergence of correlation functions and Segal amplitudes on all compact surfaces."}
{"id": "2602.08639", "categories": ["math.NA", "cs.MS", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.08639", "abs": "https://arxiv.org/abs/2602.08639", "authors": ["Jimmy Kornelije Gunnarsson", "Robert Klöfkorn"], "title": "Comparison of Structure Preserving Schemes for the Cahn-Hilliard-Navier-Stokes Equations with Degenerate Mobility and Adaptive Mesh Refinement", "comment": "51 pages, 19 figures", "summary": "The Cahn-Hilliard-Navier-Stokes (CHNS) system utilizes a diffusive phase-field for interface tracking of multi-phase fluid flows. Recently structure preserving methods for CHNS have moved into focus to construct numerical schemes that, for example, are mass conservative or obey initial bounds of the phase-field variable. In this work decoupled implicit-explicit formulations based on the Discontinuous Galerkin (DG) methodology are considered and compared to existing schemes from the literature.\n  For the fluid flow a standard continuous Galerkin approach is applied. An adaptive conforming grid is utilized to further draw computational focus on the interface regions, while coarser meshes are utilized around pure phases. All presented methods are compared against each other in terms of bound preservation, mass conservation, and energy dissipation for different examples found in the literature, including a classical rising droplet problem."}
{"id": "2602.08075", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08075", "abs": "https://arxiv.org/abs/2602.08075", "authors": ["Yiyuan Wang"], "title": "Reinforcement Learning Method for Zero-Sum Linear-Quadratic Stochastic Differential Games in Infinite Horizons", "comment": null, "summary": "In this work, we propose, for the first time, a reinforcement learning framework specifically designed for zero-sum linear-quadratic stochastic differential games. This approach offers a generalized solution for scenarios in which accurate system parameters are difficult to obtain, thereby overcoming a key limitation of traditional iterative methods that rely on complete system information. In correspondence with the game-theoretic algebraic Riccati equations associated with the problem, we develop both semi-model-based and model-free reinforcement learning algorithms by combining an iterative solution scheme with dynamic programming principles. Notably, under appropriate rank conditions on data sampling, the convergence of the proposed algorithms is rigorously established through theoretical analysis. Finally, numerical simulations are conducted to verify the effectiveness and feasibility of the proposed method."}
{"id": "2602.08680", "categories": ["math.PR", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.08680", "abs": "https://arxiv.org/abs/2602.08680", "authors": ["Eliseo Luongo", "Francesco Triggiano"], "title": "Averaging Dynamics and Wong-Zakai approximations for a Fast-Slow Navier-Stokes System Driven by fractional Brownian Motion", "comment": null, "summary": "We study a slow-fast system of coupled two- and three-dimensional Navier-Stokes equations in which the fast component is perturbed by an additive fractional Brownian noise with Hurst parameter $H>\\frac{1}{3}$. The system is analyzed using rough path theory, and the limiting behaviour strongly depends on the value of $H$. We prove convergence in law of the slow component to a Navier-Stokes system with an additional Itô-Stokes drift when $H<\\frac{1}{2}$. In contrast, for $H\\in (\\frac{1}{2},1)$, the limit equation features only a transport noise driven by a rough path."}
{"id": "2602.08791", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.08791", "abs": "https://arxiv.org/abs/2602.08791", "authors": ["Aaron Brunk", "Marco F. P. ten Eikelder", "Marvin Fritz", "Dennis Höhn", "Dennis Trautwein"], "title": "Review of thermodynamic structures and structure-preserving discretisations of Cahn--Hilliard-type models", "comment": "12 pages, 2 figures; submitted to ENUMATH25 proceedings", "summary": "The Cahn-Hilliard equation and extensions, notably the Cahn-Hilliard-Darcy and Cahn-Hilliard-Navier-Stokes systems, provide widely used frameworks for coupling interfacial thermodynamics with flow. This review surveys the thermodynamic structures underlying these models, focusing on the formulation of free energy functionals, dissipation mechanisms, and variational principles. We compare structural properties, emphasizing how these models encode conservation laws and energy dissipation. A central theme is the translation of these thermodynamic structures into numerical practice by providing representative discretisation strategies that aim to preserve mass conservation, stability, and energy decay. Particular attention is paid to the trade-offs between accuracy, efficiency, and structure preservation in large-scale simulations."}
{"id": "2602.08119", "categories": ["math.OC", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.08119", "abs": "https://arxiv.org/abs/2602.08119", "authors": ["Hoang Giang Pham", "Tien Mai"], "title": "Constrained Pricing under Finite Mixtures of Logit", "comment": null, "summary": "The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer segment, we show that the constrained pricing problem admits a polynomial-time approximation scheme (PTAS) via a reformulation based on exponential cone programming, yielding an $\\varepsilon$-optimal solution in polynomial time. For finite mixed logit models with $T$ customer segments, we reformulate the problem as a bilinear exponential cone program with $O(T)$ bilinear terms. This structure enables a Branch-and-Bound algorithm whose complexity is exponential only in $T$. Consequently, constrained pricing under finite mixtures of logit admits a PTAS when the number of customer segments is bounded. Numerical experiments demonstrate strong performance relative to state-of-the-art baselines."}
{"id": "2602.08712", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.08712", "abs": "https://arxiv.org/abs/2602.08712", "authors": ["Rinaldo B. Schinazi"], "title": "How far from the edge need a population be to survive? A probability model", "comment": null, "summary": "Let $N$ be a natural number. We consider a population which lives on $I_N=\\{-N,-N+1,\\dots,N-1,N\\}$. Each individual gives birth at rate $λ$ on each of its neighboring sites and dies at rate 1. No births are allowed from the inside of $I_N$ to the outside or vice-versa.\n  The population on the whole line (i.e. $N=+\\infty$) survives with positive probability if and only if $λ>1/2$. On the other hand for any $1/2< λ\\leq \\sqrt 2/2$ there exists a natural number $N_c$ such that the population survives on $I_N$ for $N\\geq N_c$ but dies out for $N<N_c$. There is no limit on the number of individuals per site so the population could grow at the center where the birth rates are maximum. Our result shows that it does not if the edge is too close."}
{"id": "2602.08967", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.08967", "abs": "https://arxiv.org/abs/2602.08967", "authors": ["Erik Burman", "Marvin Knöller", "Lauri Oksanen", "Andreas Rupp"], "title": "Convergence Analysis for the Recovery of the Friction Threshold in a Scalar Tresca Model", "comment": null, "summary": "We consider a scalar valued elliptic partial differential equation on a sufficiently smooth domain $Ω$, subject to a regularized Tresca friction-type boundary condition on a subset $Γ$ of $\\partial Ω$. The friction threshold, a positive function appearing in this boundary condition, is assumed to be unknown and serves as the coefficient to be recovered in our inverse problem. Assuming that (i) the friction threshold lies in a finite dimensional space with known basis functions, (ii) the right hand sides of the partial differential equation are known, and (iii) the solution to the partial differential equation on some small open subset $ω\\subset Ω$ is available, we develop an iterative computational method for the recovery of the friction threshold. This algorithm is simple to implement and is based on piecewise linear finite elements. We show that the proposed algorithm converges in second order to a function $a_h$ and, moreover, that $a_h$ converges in second order in the finite element's mesh size $h$ to the true (unknown) friction threshold. We highlight our theoretical results by simulations that confirm our rates numerically."}
{"id": "2602.08127", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08127", "abs": "https://arxiv.org/abs/2602.08127", "authors": ["Nicholas Pischke"], "title": "On Busemann subgradient methods for stochastic minimization in Hadamard spaces", "comment": "25 pages", "summary": "We study the recently introduced Busemann subgradient method due to Goodwin, Lewis, Nicolae and López-Acedo, extending it to minimize the mean of a stochastic function over general Hadamard spaces. We prove a strong convergence theorem under a local compactness assumption and further prove weak ergodic convergence of the method over Hadamard spaces satisfying condition $(\\overline{Q}_4)$, a slight extension of the $(Q_4)$ condition of Kirk and Payanak, which in particular includes Hilbert spaces, $\\mathbb{R}$-trees and spaces of constant curvature. The proof is based on a general (weak) convergence theorem for stochastic processes in Hadamard spaces which confine to a stochastic variant of quasi-Fejér monotonicity, together with a nonlinear variant of Pettis' theorem, which are of independent interest. Lastly, we provide a strong convergence result under a strong convexity assumption, and in that case in particular derive explicit rates of convergence."}
{"id": "2602.08739", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.08739", "abs": "https://arxiv.org/abs/2602.08739", "authors": ["Theodoros Assiotis", "Joseph Najnudel"], "title": "Moments of C$β$E field partition function, $\\mathsf{Sine}_β$ correlations and stochastic zeta", "comment": "35 pages", "summary": "We prove a conjecture of Fyodorov and Keating on the supercritical moments of the partition function of the C$β$E field or equivalently the supercritical moments of moments of the characteristic polynomial of the C$β$E ensemble for general $β>0$ and general real moment exponents. Moreover, we give the first expression for all correlation functions of the $\\mathsf{Sine}_β$ point process for all $β>0$. The main object behind both results is the Hua-Pickrell stochastic zeta function introduced by Li and Valkó."}
{"id": "2602.08161", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08161", "abs": "https://arxiv.org/abs/2602.08161", "authors": ["Hyunho Jang", "Dongjin Lee"], "title": "Robust design optimization for a nonlinear system via Bayesian neural network enhanced polynomial dimensional decomposition", "comment": "22 pages, 13 figures", "summary": "Uncertainties such as manufacturing tolerances cause performance variations in complex engineering systems, making robust design optimization (RDO) essential. However, simulation-based RDO faces high computational cost for statistical moment estimation, and strong nonlinearity limits the accuracy of conventional surrogate models. This study proposes a novel RDO method that integrates Bayesian neural networks (BNN) with polynomial dimensional decomposition (PDD). The method employs uncertainty-based active learning to enhance BNN surrogate accuracy and a multi-point single-step strategy that partitions the design space into dynamically adjusted subregions, within which PDD analytically estimates statistical moments from BNN predictions. Validation through a mathematical benchmark and an electric motor shape optimization demonstrates that the method converges to robust optimal solutions with significantly fewer function evaluations. In the ten-dimensional benchmark, the proposed method achieved a 99.97% mean reduction, while Gaussian process-based and Monte Carlo approaches failed to locate the global optimum. In the motor design problem, the method reduced cogging torque by 94.75% with only 6644 finite element evaluations, confirming its computational efficiency for high-dimensional, strongly nonlinear engineering problems."}
{"id": "2602.08888", "categories": ["math.PR", "math.ST", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.08888", "abs": "https://arxiv.org/abs/2602.08888", "authors": ["Hongjian Wang", "Shubhada Agrawal", "Aaditya Ramdas"], "title": "Almost sure null bankruptcy of testing-by-betting strategies", "comment": null, "summary": "The bounded mean betting procedure serves as a crucial interface between the domains of (1) sequential, anytime-valid statistical inference, and (2) online learning and portfolio selection algorithms. While recent work in both domains has established the exponential wealth growth of numerous betting strategies under any alternative distribution, the tightness of the inverted confidence sets, and the pathwise minimax regret bounds, little has been studied regarding the asymptotics of these strategies under the null hypothesis. Under the null, a strategy induces a wealth martingale converging to some random variable that can be zero (bankrupt) or non-zero (non-bankrupt, e.g. when it eventually stops betting). In this paper, we show the conceptually intuitive but technically nontrivial fact that these strategies (universal portfolio, Krichevsky-Trofimov, GRAPA, hedging, etc.) all go bankrupt with probability one, under any non-degenerate null distribution. Part of our analysis is based on the subtle almost sure divergence of various sums of $\\sum O_p(n^{-1})$ type, a result of independent interest. We also demonstrate the necessity of null bankruptcy by showing that non-bankrupt strategies are all improvable in some sense. Our results significantly deepen our understanding of these betting strategies as they qualify their behavior on \"almost all paths\", whereas previous results are usually on \"all paths\" (e.g. regret bounds) or \"most paths\" (e.g. concentration inequalities and confidence sets)."}
{"id": "2602.08177", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08177", "abs": "https://arxiv.org/abs/2602.08177", "authors": ["Cédric Josz"], "title": "Implicit regularization of normalized gradient descent", "comment": null, "summary": "How to find flat minima? We propose running normalized gradient descent, usually reserved for nonsmooth optimization, with sufficiently slowly diminishing step sizes. This induces implicit regularization towards flat minima if an appropriate Lyapunov functions exists in the gradient dynamics. Our analysis shows that implicit regularization is intrinsically a question of nonsmooth analysis, for which we deploy the full power of variational analysis and stratification theory."}
{"id": "2602.07856", "categories": ["math.NA", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.07856", "abs": "https://arxiv.org/abs/2602.07856", "authors": ["Babak Maboudi Afkham", "Tomas Soto", "Mirza Karamehmedovic", "Lassi Roininen"], "title": "Inhomogeneous Priors for Bayesian Inverse Problems", "comment": null, "summary": "Many inverse problems arising in engineering and applied sciences involve unknown quantities with pronounced spatial inhomogeneity, such as localized defects or spatially varying material properties, making reliable uncertainty quantification particularly challenging. While Bayesian inverse problem methodologies provide a principled framework for assessing reconstruction reliability, commonly used Gaussian priors, such as Whittle-Matern models, impose globally homogeneous assumptions that limit their ability to capture such structure in large-scale settings. We introduce a new class of inhomogeneous priors defined via convolution with white noise, yielding nonstationary Whittle-Matern-type random fields with a rigorous mathematical construction. These priors fit naturally within existing Bayesian well-posedness theory and enable efficient sampling by reducing prior realizations to the solution of a pseudo-differential equation, for which we develop numerical schemes with quantified approximation error. Numerical experiments in one-dimensional denoising and two-dimensional limited-angle X-ray tomography demonstrate significant improvements in reconstruction quality and uncertainty quantification, particularly in data-limited scenarios."}
{"id": "2602.08232", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08232", "abs": "https://arxiv.org/abs/2602.08232", "authors": ["Ruichen Jiang", "Zakaria Mhammedi", "Mehryar Mohri", "Aryan Mokhtari"], "title": "Adaptive Matrix Online Learning through Smoothing with Guarantees for Nonsmooth Nonconvex Optimization", "comment": "37 pages, 1 figure", "summary": "We study online linear optimization with matrix variables constrained by the operator norm, a setting where the geometry renders designing data-dependent and efficient adaptive algorithms challenging. The best-known adaptive regret bounds are achieved by Shampoo-like methods, but they require solving a costly quadratic projection subproblem. To address this, we extend the gradient-based prediction scheme to adaptive matrix online learning and cast algorithm design as constructing a family of smoothed potentials for the nuclear norm. We define a notion of admissibility for such smoothings and prove any admissible smoothing yields a regret bound matching the best-known guarantees of one-sided Shampoo. We instantiate this framework with two efficient methods that avoid quadratic projections. The first is an adaptive Follow-the-Perturbed-Leader (FTPL) method using Gaussian stochastic smoothing. The second is Follow-the-Augmented-Matrix-Leader (FAML), which uses a deterministic hyperbolic smoothing in an augmented matrix space. By analyzing the admissibility of these smoothings, we show both methods admit closed-form updates and match one-sided Shampoo's regret up to a constant factor, while significantly reducing computational cost. Lastly, using the online-to-nonconvex conversion, we derive two matrix-based optimizers, Pion (from FTPL) and Leon (from FAML). We prove convergence guarantees for these methods in nonsmooth nonconvex settings, a guarantee that the popular Muon optimizer lacks."}
{"id": "2602.07944", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.07944", "abs": "https://arxiv.org/abs/2602.07944", "authors": ["Elsiddig Awadelkarim", "David Bolin", "Xiaotian Jin", "Alexandre B. Simas", "Jonas Wallin"], "title": "Geometric ergodicity of Gibbs samplers for linear latent models with GIG variance mixtures", "comment": null, "summary": "We study geometric ergodicity of the Gibbs sampler for linear latent non-Gaussian models (LLnGMs), a class of hierarchical models in which conditional Gaussian structure is preserved through generalized inverse Gaussian (GIG) variance-mixture augmentation. Two complementary routes to geometric ergodicity are developed for the marginal chain on the mixing variables. First, we show that the associated Markov operator is trace-class, and hence admits a spectral gap, over a large portion of the GIG parameter space. Second, for the remaining boundary and heavy-tail regimes, we establish geometric ergodicity via drift and minorization, subject to an explicit null-smallness condition that quantifies how the drift interacts with the null space of the observation operator. Together, these results cover the full GIG parameter space, including the normal-inverse Gaussian, generalized asymmetric Laplace, and Student-$t$ special cases. The geometric ergodicity of this chain underpins the consistency of Gibbs-based stochastic-gradient estimators for maximum likelihood estimation, and we provide conditions that make the required integrability checks transparent. Numerical experiments illustrate the theoretical findings, contrasting mixing efficiency across parameter regimes and probing the role of the null-smallness constant."}
{"id": "2602.08385", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08385", "abs": "https://arxiv.org/abs/2602.08385", "authors": ["Johannes Schrotshamer", "Bernd Kolar", "Markus Schöberl"], "title": "Testing Backward-Flatness of Nonlinear Discrete-Time Systems", "comment": null, "summary": "Despite ongoing research, testing the flatness of discrete-time systems remains a challenging problem. To date, only the property of forward-flatness - a special case of difference-flatness - can be checked in a computationally efficient manner. In this paper, we propose a systematic approach for testing backward-flatness, which is another special case of difference-flatness, and for deriving a corresponding backward-flat output. Additionally, we discuss the relationship between the Jacobian matrices associated with the flat parameterization of backward- and forward-flat systems and illustrate our results by an academic example."}
{"id": "2602.08173", "categories": ["math.ST", "cs.IT", "cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.08173", "abs": "https://arxiv.org/abs/2602.08173", "authors": ["Shuyang Gong", "Dong Huang", "Zhangsong Li"], "title": "Fundamental Limits of Community Detection in Contextual Multi-Layer Stochastic Block Models", "comment": "49 pages, 5 figures", "summary": "We consider the problem of community detection from the joint observation of a high-dimensional covariate matrix and $L$ sparse networks, all encoding noisy, partial information about the latent community labels of $n$ subjects. In the asymptotic regime where the networks have constant average degree and the number of features $p$ grows proportionally with $n$, we derive a sharp threshold under which detecting and estimating the subject labels is possible. Our results extend the work of \\cite{MN23} to the constant-degree regime with noisy measurements, and also resolve a conjecture in \\cite{YLS24+} when the number of networks is a constant.\n  Our information-theoretic lower bound is obtained via a novel comparison inequality between Bernoulli and Gaussian moments, as well as a statistical variant of the ``recovery to chi-square divergence reduction'' argument inspired by \\cite{DHSS25}. On the algorithmic side, we design efficient algorithms based on counting decorated cycles and decorated paths and prove that they achieve the sharp threshold for both detection and weak recovery. In particular, our results show that there is no statistical-computational gap in this setting."}
{"id": "2602.08606", "categories": ["math.OC", "cs.LG", "math.AP", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.08606", "abs": "https://arxiv.org/abs/2602.08606", "authors": ["Borjan Geshkovski", "Domènec Ruiz-Balet"], "title": "Constructive conditional normalizing flows", "comment": null, "summary": "Motivated by applications in conditional sampling, given a probability measure $μ$ and a diffeomorphism $φ$, we consider the problem of simultaneously approximating $φ$ and the pushforward $φ_{\\#}μ$ by means of the flow of a continuity equation whose velocity field is a perceptron neural network with piecewise constant weights. We provide an explicit construction based on a polar-like decomposition of the Lagrange interpolant of $φ$. The latter involves a compressible component, given by the gradient of a particular convex function, which can be realized exactly, and an incompressible component, which -- after approximating via permutations -- can be implemented through shear flows intrinsic to the continuity equation. For more regular maps $φ$ -- such as the Knöthe-Rosenblatt rearrangement -- we provide an alternative, probabilistic construction inspired by the Maurey empirical method, in which the number of discontinuities in the weights doesn't scale inversely with the ambient dimension."}
{"id": "2602.08606", "categories": ["math.OC", "cs.LG", "math.AP", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.08606", "abs": "https://arxiv.org/abs/2602.08606", "authors": ["Borjan Geshkovski", "Domènec Ruiz-Balet"], "title": "Constructive conditional normalizing flows", "comment": null, "summary": "Motivated by applications in conditional sampling, given a probability measure $μ$ and a diffeomorphism $φ$, we consider the problem of simultaneously approximating $φ$ and the pushforward $φ_{\\#}μ$ by means of the flow of a continuity equation whose velocity field is a perceptron neural network with piecewise constant weights. We provide an explicit construction based on a polar-like decomposition of the Lagrange interpolant of $φ$. The latter involves a compressible component, given by the gradient of a particular convex function, which can be realized exactly, and an incompressible component, which -- after approximating via permutations -- can be implemented through shear flows intrinsic to the continuity equation. For more regular maps $φ$ -- such as the Knöthe-Rosenblatt rearrangement -- we provide an alternative, probabilistic construction inspired by the Maurey empirical method, in which the number of discontinuities in the weights doesn't scale inversely with the ambient dimension."}
{"id": "2602.08618", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08618", "abs": "https://arxiv.org/abs/2602.08618", "authors": ["Keiya Sakabe"], "title": "Nesterov's accelerated gradient for unbounded convex functions finds the minimum-norm point in the dual space", "comment": "35 pages, 2 figures", "summary": "We study the behavior of first-order methods applied to a lower-unbounded convex function $f$, i.e., $\\inf f = -\\infty$. Such a setting has received little attention since the trajectories of gradient descent and Nesterov's accelerated gradient method diverge. In this paper, we establish quantitative convergence results describing their speeds and directions of divergence, with implications for unboundedness judgment. A key idea is a relation to a norm-minimization problem in the dual space: minimize $\\|p\\|^2/2$ over $p \\in \\mathrm{dom}f^\\ast$, which can be naturally solved via mirror descent by taking the Legendre--Fenchel conjugate $f^\\ast$ as the distance-generating function. It then turns out that gradient descent for $f$ coincides with mirror descent for this norm-minimization problem, and thus it simultaneously solves both problems at $\\mathcal{O}(k^{-1})$. This result admits acceleration; Nesterov's accelerated gradient method, without any modifications, simultaneously solves the original minimization and the dual norm-minimization problems at $\\mathcal{O}(k^{-2})$, providing a quantitative characterization of divergence in unbounded convex optimization."}
{"id": "2602.08659", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08659", "abs": "https://arxiv.org/abs/2602.08659", "authors": ["Haonan Wang", "Xinlei Yi", "Yiguang Hong", "Minghui Liwang"], "title": "Heterogeneous Distributed Zeroth-Order Nonconvex Optimization with Communication Compression", "comment": null, "summary": "Distributed zeroth-order optimization is increasingly applied in heterogeneous scenarios where agents possess distinct data distributions and objectives. This heterogeneity poses fundamental challenges for convergence analysis, as existing convergence analyses rely on relatively strong assumptions to ensure theoretical guarantees. Specifically, at least one of the following three assumptions is usually required: (i) data homogeneity across agents, (ii) $\\mathcal{O}(pn)$ function evaluations per iteration with $p$ denoting the dimension and $n$ the number of agents, or (iii) the Polyak--Łojasiewicz (P--L) or strong convexity condition with a known corresponding constant. To overcome these limitations, we propose a Heterogeneous Distributed Zeroth-Order Compressed (HEDZOC) algorithm, which is based on a two-point zeroth-order gradient estimator and a general class of compressors. Without assuming data homogeneity, we develop the analysis covering three settings: general nonconvex functions, functions satisfying the P--L condition without knowing the P--L constant, and those with a known constant. To the best of our knowledge, the proposed HEDZOC algorithm is the first distributed zeroth-order method that establishes convergence without relying on the above three assumptions. Moreover, it achieves linear speedup convergence rate, which is comparable to state-of-the-art results attainable under data homogeneity and exact communication assumptions. Finally, experiments on heterogeneous adversarial example generation validate the theoretical results."}
{"id": "2602.08673", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08673", "abs": "https://arxiv.org/abs/2602.08673", "authors": ["Lukas Eveborn", "Elina Rönnberg"], "title": "Branch-Price-and-Cut Accelerated with a Pricing for Integrality Heuristic for the Electrical Vehicle Routing Problem with Time Windows and Charging Time Slots", "comment": "34 pages, 2 figures", "summary": "Branch-price-and-cut is the state-of-the-art exact method for solving many types of vehicle routing problems, and is particularly effective for vehicle routing problems with time windows. A well-known challenge in branch-price-and-cut is that the generation of columns is guided by information from the linear relaxation of the master problem, with no guarantee that they will be useful from an integer perspective. As a consequence, high-quality primal solutions are often found only after significant cutting and branching or the use of primal heuristics. In this work, based on the ideas of pricing for integrality, we propose a new primal heuristic for vehicle routing problems.The heuristic is designed to generate columns that are more likely to be part of high-quality integer solutions. It begins by constructing a partial integer solution from a given column pool and then iteratively searches for columns that complement this solution. The search is done by modifying the pricing problem with respect to the partial solution, linear program dual information as well as previously generated columns in the heuristic. Computational tests are performed on the electrical vehicle routing problem with time windows extended with charging time slots, a problem that has both scheduling and routing aspects, making it well-suited to evaluate the performance of the proposed heuristic. The results show that the proposed heuristic closes 30% - 40% of the root node gap on average in comparison to a restricted master heuristic."}
{"id": "2602.08906", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08906", "abs": "https://arxiv.org/abs/2602.08906", "authors": ["Christian Meyer", "Alimhan Musalatov"], "title": "Switching Point Optimization for Abstract Parabolic Equations", "comment": null, "summary": "This work is concerned with a switching point optimization problem governed by a semilinear parabolic equation in abstract function spaces. It is shown that the switching-point-to-control mapping is continuously Fréchet-differentiable when considered with values in the dual of Hölder continuous functions in time. By treating the state equation in weak form based on the concept of maximal parabolic regularity, one can then show that the reduced objective is continuously differentiable w.r.t.\\ the switching points which allows to use gradient-based method like the proximal gradient method for its minimization. In order to apply the known convergence results of this method, the gradient of the reduced objective must be Lipschitz continuous, which requires additional assumptions on the data. Numerical experiments confirm our theoretical findings, but also illustrate that such a method will in general not be able to solve the problem up to global optimality due to the non-convex nature of the switching-point-to-control map."}
{"id": "2602.07269", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07269", "abs": "https://arxiv.org/abs/2602.07269", "authors": ["Gabriela Ramon", "Geena Sarnoski", "Vasishta Tumuluri", "Hugo Díaz", "Arvind K. Saibaba"], "title": "Multifidelity sensor placement in Bayesian state estimation problems", "comment": "27 pages, 14 figures", "summary": "We study optimal sensor placement for Bayesian state estimation problems in which sensors vary in cost and fidelity, resulting in a budget-constrained multifidelity optimal experimental design problem. Sensor placement optimality is quantified using the D-optimality criterion, and the problem is approached by leveraging connections with the column subset selection problem in numerical linear algebra. We implement a greedy approach for this problem, whose computational efficiency we improve using rank-one updates via the Sherman-Morrison formula. We additionally present an iterative algorithm that, for each feasible allocation of sensors, greedily optimizes over each sensor fidelity subject to previous sensor choices, repeating this process until a termination criterion is satisfied. To the best of our knowledge, these algorithms are novel in the context of cost constrained multifidelity sensor placement. We evaluate our methods on several benchmark state estimation problems, including reconstructions of sea surface temperature and flow around a cylinder, and empirically demonstrate improved performance over random designs."}
{"id": "2602.08118", "categories": ["math.PR", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08118", "abs": "https://arxiv.org/abs/2602.08118", "authors": ["Yifan Jiang", "Renyuan Xu", "Luhao Zhang"], "title": "Schrödinger bridge with transport relaxation", "comment": "27 pages, 5 figures", "summary": "Motivated by modern machine learning applications where we only have access to empirical measures constructed from finite samples, we relax the marginal constraints of the classical Schrödinger bridge problem by penalizing the transport cost between the bridge's marginals and the prescribed marginals. We derive a duality formula for this transport-relaxed bridge and demonstrate that it reduces to a finite-dimensional concave optimization problem when the prescribed marginals are discrete and the reference distribution is absolutely continuous. We establish the existence and uniqueness of solutions for both the primal and dual problems. Moreover, as the penalty blows up, we characterize the limiting bridge as the solution to a discrete Schrödinger bridge problem and identify a leading-order logarithmic divergence. Finally, we propose gradient ascent and Sinkhorn-type algorithms to numerically solve the transport-relaxed Schrödinger bridge, establishing a linear convergence rate for both algorithms."}
{"id": "2602.08515", "categories": ["math.NA", "cs.LG", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08515", "abs": "https://arxiv.org/abs/2602.08515", "authors": ["Muhammad Luthfi Shahab", "Imam Mukhlash", "Hadi Susanto"], "title": "Do physics-informed neural networks (PINNs) need to be deep? Shallow PINNs using the Levenberg-Marquardt algorithm", "comment": null, "summary": "This work investigates the use of shallow physics-informed neural networks (PINNs) for solving forward and inverse problems of nonlinear partial differential equations (PDEs). By reformulating PINNs as nonlinear systems, the Levenberg-Marquardt (LM) algorithm is employed to efficiently optimize the network parameters. Analytical expressions for the neural network derivatives with respect to the input variables are derived, enabling accurate and efficient computation of the Jacobian matrix required by LM. The proposed approach is tested on several benchmark problems, including the Burgers, Schrödinger, Allen-Cahn, and three-dimensional Bratu equations. Numerical results demonstrate that LM significantly outperforms BFGS in terms of convergence speed, accuracy, and final loss values, even when using shallow network architectures with only two hidden layers. These findings indicate that, for a wide class of PDEs, shallow PINNs combined with efficient second-order optimization methods can provide accurate and computationally efficient solutions for both forward and inverse problems."}
