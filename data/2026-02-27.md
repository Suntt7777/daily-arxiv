<div id=toc></div>

# Table of Contents

- [math.PR](#math.PR) [Total: 12]
- [math.OC](#math.OC) [Total: 16]
- [math.ST](#math.ST) [Total: 6]
- [math.NA](#math.NA) [Total: 6]


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [1] [Sum of Gaussian vectors and large sets](https://arxiv.org/abs/2602.22342)
*Antoine Song*

Main category: math.PR

TL;DR: 该论文证明了任何中心化的κ-次高斯随机变量可以表示为三个标准高斯随机变量之和，验证了Talagrand的猜想。同时证明了在特定条件下，任何中心化随机向量可以表示为有限个标准高斯随机向量之和。


<details>
  <summary>Details</summary>
Motivation: 解决M. Talagrand关于次高斯随机变量分解为高斯随机变量之和的猜想，并研究随机向量的高斯分解问题，为凸性问题和高斯空间中集合的包含关系提供理论支持。

Method: 使用概率论和随机分析的方法，通过构造性证明和不等式估计，建立次高斯随机变量与高斯随机变量之间的等价关系。对于随机向量，利用协方差矩阵的范数条件和有界性假设。

Result: 1. 存在常数κ>0，使得任何中心化的κ-次高斯随机变量等于三个标准高斯随机变量之和；2. 在给定条件下，任何中心化随机向量可以表示为有限个标准高斯随机向量之和；3. 中心化随机向量是次高斯的当且仅当它是有限个高斯随机向量之和。

Conclusion: 该研究完全解决了Talagrand的猜想，建立了次高斯随机变量与高斯随机变量之间的深刻联系，并成功应用于凸性问题和高斯空间中椭球包含关系的估计，为相关领域提供了重要的理论工具。

Abstract: We show that for some constant $κ>0$, any centered $κ$-subgaussian random variable is equal to the sum of three standard Gaussian random variables, confirming a conjecture of M. Talagrand. We also prove that given $Λ\geq 1$, any centered random vector $X$ in $\mathbb{R}^n$ such that $\|X\|\leq Λ$ almost surely and $\|\mathrm{Cov}(X)\|\leq {Λ^2 }{e^{-Λ^2}}$ is equal to the sum of a universal number of standard Gaussian random vectors. In particular, a centered random vector is subgaussian if and only if it is a finite sum of Gaussian random vectors. We apply these results to settle the permutation invariant case of M. Talagrand's convexity problem, and to give optimal estimates on the largest ellipsoid contained in a sum of large sets in Gaussian spaces.

</details>


### [2] [IDS for subordinate Brownian motions in Poisson random environment on nested fractals](https://arxiv.org/abs/2602.22348)
*Hubert Balsam,Kamil Kaleta,Mariusz Olszewski,Katarzyna Pietruska-Pałuba*

Main category: math.PR

TL;DR: 该论文证明了在具有良好标记性质的平面无界嵌套分形上，随机薛定谔算子的积分态密度存在Lifshitz奇异性，涵盖了相对论模型等更广泛的Bernstein函数类。


<details>
  <summary>Details</summary>
Motivation: 研究分形上随机薛定谔算子的谱性质，特别是积分态密度的Lifshitz奇异性。传统方法在处理分形上的泊松随机势时存在局限性，特别是对于相对论模型等更广泛的Bernstein函数类。

Method: 将泊松随机势的研究有效简化为合金型势的分析，其中位点不再是经典晶格点，而是分形复合体。采用在泊松随机场背景下新的方法，能够处理广泛的Bernstein函数φ。

Result: 建立了在具有良好标记性质的平面无界嵌套分形上，随机薛定谔算子的积分态密度存在Lifshitz奇异性。特别涵盖了φ(λ)=(λ+m^{d_w/ϑ})^{ϑ/d_w}-m形式的相对论模型，这在分形上以前的方法无法处理。

Conclusion: 通过将泊松随机势简化为分形复合体上的合金型势，发展了一种新方法，成功证明了分形上随机薛定谔算子积分态密度的Lifshitz奇异性，扩展了可处理的模型范围，特别是包含了相对论模型。

Abstract: We establish the Lifshitz singularity of the integrated density of states (IDS) for random Schrödinger operators \[ H^ω = φ(-\mathcal{L}) + V^ω \] on planar unbounded nested fractals with the Good Labeling Property. Here, $\mathcal{L}$ is the Laplacian on the fractal, $φ$ is an operator monotone function with mild regularity, and $V^ω$ is a Poissonian random potential with a sufficiently regular profile. The main novelty of our work lies in showing that the study of $V^ω$ can be effectively reduced to the analysis of certain alloy-type potential, where the sites are no longer lattice points as in the classical $\mathbb{Z}^d$ case, but fractal complexes. This observation enables us to apply an approach, new in the setting of Poissonian random fields, which allows us to treat a broad class of Bernstein functions $φ$. In particular, it covers the case $φ(λ)=(λ+m^{d_w/\vartheta})^{\vartheta/d_w}-m$, $\vartheta \in (0,d_w)$, $m>0$, corresponding to relativistic models, which were previously unattainable on fractals by known methods.

</details>


### [3] [Fluctuations in the weakly coupled 4D Anderson Hamiltonian](https://arxiv.org/abs/2602.22509)
*Simon Gabriel,Tommaso Rosati*

Main category: math.PR

TL;DR: 研究四维临界维度下Anderson哈密顿量的弱耦合极限，证明格林函数的高斯涨落，并预测耦合常数临界值处的相变


<details>
  <summary>Details</summary>
Motivation: 研究临界维度d=4下Anderson哈密顿量的弱耦合极限行为，理解量子场论中重整化现象和相变机制

Method: 基于费曼图的组合分析，详细研究BPHZ重整化方案，使用原始爆破方法表征极限分布

Result: 证明了格林函数的高斯涨落，给出了显式有效方差表达式，发现无拉普拉斯重整化现象，预测了耦合常数临界值处的相变

Conclusion: 在四维临界维度下，Anderson哈密顿量的弱耦合极限呈现高斯涨落，该方法可推广到更广泛的方程类别

Abstract: We study the weak coupling limit of the Anderson Hamiltonian in the critical dimension $d=4$. In a perturbative sense, we prove Gaussian fluctuations about the Green's function of the Laplacian. The fluctuations are described by an explicit effective variance, up to a critical value of the coupling constant at which we expect a phase transition in the structure of the fluctuations. The proof is based on a combinatorial analysis of Feynman diagrams, and on a detailed study of the BPHZ renormalisation of the model. We characterise the limiting distribution in terms of primitive blow-ups, and prove that no Laplacian renormalisation is present. Our approach seems applicable to a broad class of equations.

</details>


### [4] [Mean-field games with rough common noise: the compactification approach](https://arxiv.org/abs/2602.22602)
*Erhan Bayraktar,Xihao He,Xiang Yu,Fengyi Yuan*

Main category: math.PR

TL;DR: 研究具有粗糙公共噪声的均值场博弈问题，证明路径均值场均衡的存在性，并建立与经典随机化布朗公共噪声MFG问题的关系


<details>
  <summary>Details</summary>
Motivation: 研究具有粗糙公共噪声的均值场博弈问题，其中代表性状态动态由受控粗糙随机微分方程驱动，包含个体布朗运动和影响整个群体的确定性粗糙路径噪声

Method: 引入基于松弛控制和粗糙鞅问题的规范弱表述；开发新的紧化技术工具以适应粗糙积分，显著偏离文献中的经典紧化论证

Result: 证明了在此背景下路径均值场均衡的存在性；建立了路径问题与经典随机化布朗公共噪声MFG问题之间的关系：条件化几乎必然得到路径问题；反之，在适当的因果性/可测选择要求下，路径均值场均衡可以聚合产生经典问题中的随机化均值场均衡

Conclusion: 成功建立了具有粗糙公共噪声的均值场博弈理论框架，证明了均衡存在性，并阐明了与经典随机化布朗公共噪声MFG问题的双向关系

Abstract: We study mean-field game (MFG) problems with rough common noise where the representative state dynamics is governed by a controlled rough stochastic differential equation driven by an idiosyncratic Brownian motion and a deterministic rough path noise affecting the whole population. Within this new framework, we introduce a canonical weak formulation based on relaxed controls and rough martingale problems. We prove the existence of a pathwise mean-field equilibrium in this context by developing new technical tools for compactification to accommodate rough integration, which deviate substantially from classical compactification arguments in the literature. Finally, we discuss the relationship between the pathwise problem and the classical MFG problem with randomized Brownian common noise: conditioning yields the pathwise problem almost surely; and conversely, under a suitable causality/measurable-selection requirement, pathwise mean-field equilibria can be aggregated to produce randomized mean-field equilibria in the classical problem.

</details>


### [5] [Branching random walks with ageing](https://arxiv.org/abs/2602.22783)
*Daniela Bertacchi,Elena Montanaro,Fabio Zucca*

Main category: math.PR

TL;DR: 研究老龄化对分支过程行为的影响，以及如何通过修改参数和繁殖率来影响过程的命运


<details>
  <summary>Details</summary>
Motivation: 经典分支过程假设个体繁殖能力在其生命周期内保持不变，但现实世界中繁殖能力通常会经历老龄化过程，在达到峰值后随时间下降。需要研究老龄化对种群动态的影响。

Method: 研究老龄化对分支过程行为的影响，分析修改过程参数和繁殖率如何影响过程的命运

Result: 未在摘要中明确说明具体结果，但研究关注老龄化对过程行为的影响以及参数调整的效果

Conclusion: 老龄化是影响分支过程动态的重要现实因素，理解其影响有助于更准确地模拟真实种群演化

Abstract: Branching processes are models used to describe populations that reproduce and die over time. In the classical setting, an individual's reproductive capacity remains constant throughout its lifetime. However, in real-world situations, reproductive capacity typically undergoes ageing - that is, after reaching a peak, it decreases over time. In this work, we study the influence of ageing on the behaviour of the process and how modifying its parameters, along with reproduction rates, affects the destiny of the process.

</details>


### [6] [Pfaffian point processes for coalescing particles via checkerboard duality](https://arxiv.org/abs/2602.22885)
*Piotr Śniady*

Main category: math.PR

TL;DR: 该论文提出了一种基于棋盘对偶性的新方法，用于分析线上凝聚粒子的Pfaffian点过程结构，适用于任意非齐次动力学。


<details>
  <summary>Details</summary>
Motivation: 现有证明依赖于时间齐次动力学的解析方法，限制了应用范围。需要找到更通用的结构原因来解释Pfaffian点过程的形成。

Method: 利用离散平面图上的棋盘对偶性，将粒子凝聚问题转化为互补非交叉森林问题。通过祖先谱系追踪和域边界传播，将区间无粒子事件转化为端点处的祖先谱系凝聚，再通过可消标记转化为湮灭问题。

Result: 得到了适用于任意具有棋盘结构的离散图和任意非齐次边概率的空区间概率公式，无需对称性或特定分布假设。该方法可处理完全不对称动力学和位置依赖转移规则等现有方法无法覆盖的情况。

Conclusion: 棋盘对偶性是Pfaffian点过程的结构性原因，提供了比传统解析方法更通用和统一的框架。对于布朗运动情况，该方法恢复了已知的Pfaffian点过程和通过PDE方法推导的空区间概率。

Abstract: Coalescing particles on a line merge when they meet. When every site is initially occupied, only finitely many particles survive at any positive time, and their positions form a Pfaffian point process: all correlation functions are determined by pairwise quantities arranged in antisymmetric matrices. Previous proofs of this structure relied on analytic methods specific to time-homogeneous dynamics. We identify the checkerboard duality as the structural reason for the Pfaffian: on a discrete planar graph, binary random choices create two complementary non-crossing forests, one tracing ancestral lineages backward and the other carrying the coalescing particles forward as domain boundaries. This duality converts the absence of particles in an interval into coalescence of ancestral lineages at its endpoints. A cancellative labeling then converts coalescence into annihilation, for which a companion paper provides a Pfaffian formula. The resulting empty-interval formula holds for any discrete graph with the checkerboard structure and arbitrary inhomogeneous edge probabilities, requiring no symmetry or specific distributions. This covers settings beyond existing methods, including totally asymmetric dynamics and position-dependent transition rules, and yields an explicit Pfaffian point process in each setting. For Brownian motion, the formula recovers the known Pfaffian point process and the empty-interval probabilities previously derived by PDE methods.

</details>


### [7] [Non-Markovian chains with long-range dependence and their scaling limits](https://arxiv.org/abs/2602.23049)
*Lorenzo Facciaroni,Costantino Ricciuti,Enrico Scalas*

Main category: math.PR

TL;DR: 本文研究了超越半马尔可夫框架的非马尔可夫链，重点关注具有长记忆行为的para-Markov链和时间变换马尔可夫链，建立了统一的马尔可夫链时间变换理论。


<details>
  <summary>Details</summary>
Motivation: 现有理论主要关注半马尔可夫链和连续时间随机游走与时间分数阶方程及反常扩散的联系。本文旨在超越半马尔可夫框架，研究具有长记忆行为的非马尔可夫链，特别是等待时间存在随机依赖性的情况。

Method: 主要研究两种模型：1) para-Markov链，其等待时间具有与半马尔可夫链相同的边际分布但相互依赖，联合分布为Schur-constant类型；2) 时间变换马尔可夫链，其中随机时间是递增稳定过程的逆过程，推广了文献中仅关注Levy稳定从属过程逆的模型。

Result: 建立了统一的马尔可夫链时间变换理论框架，将上述两种模型统一起来。para-Markov链的等待时间依赖结构通过Schur-constant分布、完全Bernstein函数和De Finetti定理进行描述。

Conclusion: 本文超越了传统的半马尔可夫框架，研究了具有长记忆行为的非马尔可夫链，特别是para-Markov链和时间变换马尔可夫链，并通过统一的马尔可夫链时间变换理论将这些模型联系起来，为反常扩散和分数阶方程的研究提供了更广泛的数学框架。

Abstract: There is a well-established theory linking certain semi-Markov chains and continuous-time random walks to time-fractional equations and anomalous diffusion. In this work, we go beyond the semi-Markov framework by considering some non-Markovian chains, which exhibit long-memory behaviour, due to stochastic dependence among their waiting times. Particular attention is devoted to the so-called para-Markov chains. Their waiting times share the same marginal distributions as those of the above mentioned semi-Markov chains, but they are dependent; their joint distribution is of Schur-constant type and is closely related to complete Bernstein functions and De Finetti's theorems. A second model that we focus on is given by time-changed Markov chains, where the random time is the inverse of an increasing stable process. This generalizes well-known semi-Markov models available in the literature, which typically focus solely on the inverse of the Levy stable subordinator. The above mentioned models are unified by a general theory of time change of Markov chains.

</details>


### [8] [Asymptotics of randomly weighted sums without moment conditions of random weights](https://arxiv.org/abs/2602.23112)
*Qingwu Gao,Dimitrios G. Konstantinides,Charalampos D. Passalidis,Yuebao Wang,Hui Xu*

Main category: math.PR

TL;DR: 研究随机加权和与随机加权停止和的渐近性质，应用于离散时间风险模型的破产概率估计


<details>
  <summary>Details</summary>
Motivation: 研究在无随机权重矩条件限制下，具有上尾渐近独立增量的随机加权和与随机加权停止和的渐近性质，并将其应用于风险模型中的破产概率估计

Method: 首先研究相应加权和的一致渐近性质，获得比现有结果更大的收敛范围；然后利用这些结果估计离散时间风险模型中的有限时间和随机时间破产概率；在正则变差增量情况下，通过扩展的Breiman定理给出更明确的估计

Result: 获得了随机加权和与随机加权停止和的渐近估计，给出了风险模型中破产概率的渐近估计，在正则变差情况下得到更明确的表达式，并通过示例说明条件比现有结果更宽松清晰，且存在上尾渐近独立而非尾渐近独立的随机变量

Conclusion: 在适当条件下研究了随机加权和与随机加权停止和的渐近性质，成功应用于风险模型的破产概率估计，扩展了Breiman定理，并通过示例验证了条件的必要性和结果的优越性

Abstract: In the paper, under a suitable condition, we study the asymptotics of randomly weighted sums and randomly weighted stopped sums with upper tail asymptotically independent increments, where no moment condition is made on random weights, and we provide an example to show the suitable condition is necessary in some sense. To this end, we firstly consider the uniform asymptotics of the corresponding weighted sums with a large convergence range than the existing results. Then, using the above results, we obtain an asymptotic estimation of the finite-time and random-time ruin probabilities in a discrete-time risk model. In the case of regular variation increments, a more explicit estimation is given by an extended Breiman's theorem. Finally, through some examples we illustrate that the conditions of the above results are relaxed and clear, and that there exist random variables are upper tail asymptotically independent rather than tail asymptotically independent.

</details>


### [9] [Necessary and Sufficient Conditions for the Lacunary/Hereditary Laws of Large Numbers](https://arxiv.org/abs/2602.23124)
*Istvan Berkes,Ioannis Karatzas,Walter Schachermayer*

Main category: math.PR

TL;DR: 该论文改进了Komlos定理，为序列的"间隙/遗传"强/弱大数定律建立了必要且充分的条件，解决了长期开放的问题。


<details>
  <summary>Details</summary>
Motivation: Komlos定理表明L1有界性足以保证函数序列存在子序列，使得该子序列及其所有进一步子序列都满足强大数定律。本文旨在寻找比L1有界性更弱的条件，并建立必要且充分的条件。

Method: 作者识别了Egorov类型的较弱条件，这些条件不仅在此背景下是充分的，而且也是必要的。为一般序列的"间隙/遗传"弱大数定律以及可交换序列背景下的弱大数定律建立了必要且充分的条件。

Result: 成功建立了比Komlos定理中L1有界性更弱的Egorov类型条件，这些条件对于"间隙/遗传"强/弱大数定律既是充分的也是必要的，解决了长期开放的问题。

Conclusion: 本文改进了Komlos定理，为序列的"间隙/遗传"大数定律提供了更精确的必要且充分条件，解决了该领域的重要开放问题。

Abstract: The celebrated theorem of Komlos asserts that L1-boundedness is sufficient for a given sequence of functions to contain a subsequence along which (in a "lacunary" manner), and along whose every further subsequence ("hereditarily"), a strong law of large numbers holds. We identify here slightly weaker, Egorov-type conditions, as not only sufficient in this context, but necessary as well. Necessary and sufficient conditions are developed also for the lacunary/hereditary version of the weak law of large numbers for general sequences, as well as for the weak law of large numbers in the context of exchangeable sequences, both long-open questions.

</details>


### [10] [Gaussian fluctuations for hyperbolic Anderson model with Lévy colored noise](https://arxiv.org/abs/2602.23137)
*Raluca M. Balan,William D. Stephenson*

Main category: math.PR

TL;DR: 研究一维双曲Anderson模型中空间积分F_R(t)的渐近行为，证明其在R→∞时标准化后收敛于标准正态分布，并给出收敛速率估计


<details>
  <summary>Details</summary>
Motivation: 研究由Lévy彩色噪声驱动的双曲Anderson模型空间积分的渐近统计特性，特别是中心极限定理类型的收敛行为

Method: 应用Trauthwein (2025)的最新结果，考虑噪声空间核函数的两种情形（可积或Riesz核），假设Lévy测度具有有限矩

Result: 证明F_R(t)/√Var(F_R(t))在R→∞时收敛于标准正态分布，给出Fortet-Mourier距离、1-Wasserstein距离和Kolmogorov距离下的收敛速率估计，并提供相应的泛函极限结果

Conclusion: 在一维双曲Anderson模型中，空间积分的标准化形式满足中心极限定理，并可以量化其收敛速率，这扩展了随机偏微分方程渐近理论的结果

Abstract: In this article, we study the asymptotic behaviour of the spatial integral $F_R(t)$ of the solution to the hyperbolic Anderson model in dimension $d=1$, driven by the Lévy colored noise introduced in Balan and Jiménez (2026). We assume that the spatial coloration kernel of the noise is either integrable on $\mathbb{R}$, or is the Riesz kernel of order $α\in (0,1)$, and the Lévy measure of the noise has finite moments of order $p$ and $2p$ for some $p \in (1,2]$. By applying a recent result of Trauthwein (2025), we prove that $F_R(t)/\sqrt{{\rm Var}\big(F_R(t)\big)}$ converges to the standard normal distribution as $R \to \infty$, and we give an estimate for the rate of this convergence in the Fortet-Mourier distance, the 1-Wasserstein distance, or the Kolmogorov distance. We also provide the corresponding functional limit result.

</details>


### [11] [Interface for variants of the contact process](https://arxiv.org/abs/2602.23149)
*Isabella Alvarenga,Daniel Valesin*

Main category: math.PR

TL;DR: 研究一维接触过程的两个变体：接触-屏障过程和多种类型接触过程，证明它们具有紧致界面，且界面位置在减去确定性速度后满足中心极限定理。


<details>
  <summary>Details</summary>
Motivation: 研究两种一维接触过程变体的界面行为，这些模型在种群动力学和竞争生态学中有重要应用，需要理解界面如何随时间演化及其统计特性。

Method: 采用基于"拼凑构造"的更新时方法，通过将过程在随机长度的时间区间上的时空演化拼接起来，为证明提供更便利的更新时框架。

Result: 证明两个模型都表现出紧致界面，且界面位置在减去适当的确定性速度后满足中心极限定理。

Conclusion: 通过创新的拼凑构造方法，成功分析了两种一维接触过程变体的界面行为，为理解这类随机过程的界面动力学提供了新的理论工具。

Abstract: We study two one-dimensional variants of the contact process: the contact-and-barrier process, where the population evolves in a region delimited by a randomly moving barrier, and the multitype contact process, in which two species compete for space. The contact-and-barrier process is started with the barrier at the origin and all sites to its right occupied, while the multitype contact process is started from the Heaviside configuration with species 1 to the left of the origin and species 2 to the right. We prove that both models exhibit tight interfaces and that, after centring by an appropriate deterministic speed, the interface position satisfies a central limit theorem. Our analysis relies on a renewal-time method based on a novel construction called patchwork construction, in which the processes are built by concatenating space-time evolutions over successive time intervals of random length, providing a more convenient framework for defining the renewal times that drive the proofs.

</details>


### [12] [Spin Glass Concepts in Computer Science, Statistics, and Learning](https://arxiv.org/abs/2602.23326)
*Andrea Montanari*

Main category: math.PR

TL;DR: 该论文探讨了自旋玻璃理论在理解高维随机函数近极小值结构方面的应用，及其在统计学、机器学习和优化算法中的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将自旋玻璃理论的传统方法扩展到计算机科学、统计学和机器学习领域，这些领域提出了物理学和数学物理中通常不涉及的新问题。作者旨在展示自旋玻璃理论如何为这些领域的最新发展提供理论基础。

Method: 通过回顾和整合自旋玻璃理论的核心思想，特别是关于高维随机函数子水平集和极小值（或近极小值）结构的研究，并将其应用于统计学、机器学习和优化算法的平均情况分析中。

Result: 论文展示了自旋玻璃理论为理解高维统计学习中的经验风险最小化、优化算法的平均情况分析以及随机函数近极小值的结构提供了有力的理论框架和工具。

Conclusion: 自旋玻璃理论的思想和方法已经超越了传统物理学领域，为计算机科学、统计学和机器学习中的关键问题提供了深刻的见解和理论基础，特别是在高维随机函数分析和优化方面。

Abstract: Spin glass theory studies the structure of sublevel sets and minima (or near-minima) of certain classes of random functions in high dimension. Near-minima of random functions also play an important role in high-dimensional statistics and statistical learning, where minimizing the empirical risk (which is a random function of the model parameters) is the method of choice for learning a statistical model from noisy data. Finally, near-minima of random functions are obviously central to average-case analysis of optimization algorithms. Computer science, statistics, and machine learning naturally lead to questions that are traditionally not addressed within physics and mathematical physics. I will try to explain how ideas from spin glass theory have seeded recent developments in these fields.
  (This article was written on the occasion of the 2024 Abel Prize to Michel Talagrand.)

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [13] [Huge-Scale Assortment Optimization with Customer Choice: A Parallel Primal-Dual Approach](https://arxiv.org/abs/2602.22421)
*Donghao Zhu,Hanzhang Qin,Ching-pei Lee,Yuki Saito,Takahiro Kawashima,Kenji Fukumizu*

Main category: math.OC

TL;DR: 提出SPFOM算法解决大规模选择型线性规划问题，在运输、零售等行业中优化商品组合以最大化预期收入，相比现有方法具有计算效率和并行优势。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以解决涉及数百万客户选择的大规模选择型线性规划问题，缺乏利用问题结构的算法设计，导致计算瓶颈。

Method: 提出一阶原始对偶方法SPFOM，每次迭代计算成本小，具有可证明的近最优收敛率，可扩展到并行计算环境，并扩展到带库存约束的多周期优化。

Result: SPFOM在计算和实际性能上优于最先进的大规模线性规划求解器，在ZOZOTOWN平台真实数据案例中验证了有效性，能提高收入表现同时保持库存平衡。

Conclusion: SPFOM为解决大规模选择优化问题提供了高效计算框架，相比传统方法在计算效率和实际应用效果上都有显著优势。

Abstract: We study huge-scale assortment optimization problems to maximize expected revenue under customer choice, addressing a fundamental challenge in industries such as transportation, retail, and healthcare. The choice-based linear programming (CBLP) formulation provides a powerful framework for optimizing sales allocations across customer segments, yet traditional approaches often fail to solve CBLPs of huge scale (involving millions of customer choices) due to the lack of algorithmic designs that exploit problem structure. To overcome this computational bottleneck, we propose a first-order primal-dual method, SPFOM, which requires only a small computational cost per iteration, achieves a provably near-optimal convergence rate, and can be readily extended to parallel computing environments. Computational experiments demonstrate the computational and practical superiority of SPFOM over state-of-the-art solvers for large-scale linear programs. The framework is extended to a multi-period assortment optimization setting with inventory constraints, where SPFOM estimates global shadow prices that enhance classical bid-price control policies compared with benchmark methods such as market segment decomposition. Numerical experiments and a case study using real-world data from the ZOZOTOWN platform validate the practical effectiveness of SPFOM, highlighting its advantages in improving revenue performance while maintaining balanced inventory levels.

</details>


### [14] [Model Predictive Control for output tracking with prescribed performance](https://arxiv.org/abs/2602.22458)
*Dario Dennstädt*

Main category: math.OC

TL;DR: 该论文提出了一种用于非线性连续时间系统的漏斗MPC框架，通过漏斗惩罚函数确保跟踪误差在时变边界内，结合模型自由反馈补偿模型失配，集成数据驱动学习提高预测精度，并推导采样率界限保证数字实现稳定性。


<details>
  <summary>Details</summary>
Motivation: 模型预测控制（MPC）在处理约束和多目标优化方面具有优势，但在实际应用中面临初始和递归可行性、模型失配鲁棒性以及采样数据约束等挑战。该论文旨在为非线性连续时间系统开发一个能够保证输出跟踪误差在规定范围内的MPC框架，系统性地解决这些挑战。

Method: 1. 提出漏斗MPC算法，使用漏斗惩罚函数作为状态成本，惩罚跟踪误差偏离时变边界，无需终端条件或长预测时域；2. 将漏斗MPC与模型自由漏斗反馈结合为混合架构，通过自适应反馈补偿模型失配和未知扰动；3. 集成数据驱动学习框架，利用系统测量迭代优化模型；4. 形式化采样数据实现，推导采样率和控制量的显式界限以保证稳定性。

Result: 建立了一个完整的MPC框架，能够：1. 确保可行性并严格保证跟踪性能；2. 在存在结构模型失配、未建模动态和未知扰动的情况下实现规定的跟踪性能；3. 通过数据驱动学习提高长期性能而不损害鲁棒性；4. 为数字硬件部署提供采样率界限保证稳定性。

Conclusion: 该论文通过解决可行性、鲁棒性、学习和采样问题，建立了一个用于在规定边界内进行输出跟踪的完整框架，为学习增强和鲁棒MPC的未来发展奠定了基础。

Abstract: Model Predictive Control (MPC) offers a versatile framework for constraint handling and multi-objective optimisation, yet practical application faces challenges regarding initial and recursive feasibility, robustness against model mismatches, and sampled-data constraints. This thesis develops a novel MPC framework for a class of non-linear continuous-time systems governed by functional differential equations. It targets output tracking within prescribed error bounds while systematically overcoming these challenges.
  First, we introduce funnel MPC, an algorithm eliminating reliance on terminal conditions or restrictive long prediction horizons. Utilising funnel penalty functions -- state costs penalising tracking error deviations from time-varying boundaries -- this framework ensures feasibility while rigorously enforcing tracking performance guarantees.
  Next, we unify funnel MPC with model-free funnel feedback into a hybrid architecture. This synergises model-based optimisation with adaptive feedback compensation, achieving prescribed tracking performance despite structural model-plant mismatches, unmodelled dynamics, and unknown disturbances.
  To further enhance predictive accuracy, we integrate a data-driven learning framework that iteratively refines the model using system measurements, improving long-term performance without compromising robustness.
  Finally, we formalise the transition to sampled-data implementations. We derive explicit bounds on sampling rates and control effort to guarantee stability under piecewise constant control signals, a critical step for digital hardware deployment.
  By addressing feasibility, robustness, learning, and sampling, this thesis establishes a cohesive framework for output tracking within prescribed bounds, paving the way for future advances in learning-enhanced and robust MPC.

</details>


### [15] [A Fast and Practical Column Generation Approach for Identifying Carcinogenic Multi-Hit Gene Combinations](https://arxiv.org/abs/2602.22551)
*Rick S. H. Willemsen,Tenindra Abeywickrama,Ramu Anandakrishnan*

Main category: math.OC

TL;DR: 本文提出基于约束规划和混合整数规划的方法解决多基因突变组合识别问题，相比现有方法显著降低计算复杂度，可在普通CPU上一分钟内完成。


<details>
  <summary>Details</summary>
Motivation: 癌症通常由2-9个基因突变组合驱动，识别这些多基因突变组合对于理解致癌机制和设计靶向治疗至关重要。现有方法通常依赖穷举搜索和超级计算基础设施，计算成本高昂。

Method: 将多基因癌症驱动集覆盖问题（MHCDSCP）形式化为约束规划和混合整数规划问题，并提出列生成启发式算法，可在小型实例上获得最优解。

Result: 在真实癌症基因组数据上的评估显示，该方法性能与最先进方法相当，但只需在单个普通CPU上运行不到一分钟，显著降低了计算复杂度。

Conclusion: 解决MHCDSCP问题的计算复杂度比先前认为的要低，这为探索建模假设开辟了新的研究方向，使更高效的多基因突变组合识别成为可能。

Abstract: Cancer is often driven by specific combinations of an estimated two to nine gene mutations, known as multi-hit combinations. Identifying these combinations is critical for understanding carcinogenesis and designing targeted therapies. We formalise this challenge as the Multi-Hit Cancer Driver Set Cover Problem (MHCDSCP), a binary classification problem that selects gene combinations to maximise coverage of tumor samples while minimising coverage of normal samples. Existing approaches typically rely on exhaustive search and supercomputing infrastructure. In this paper, we present constraint programming and mixed integer programming formulations of the MHCDSCP. Evaluated on real-world cancer genomics data, our methods achieve performance comparable to state-of-the-art methods while running on a single commodity CPU in under a minute. Furthermore, we introduce a column generation heuristic capable of solving small instances to optimality. These results suggest that solving the MHCDSCP is less computationally intensive than previously believed, thereby opening research directions for exploring modelling assumptions.

</details>


### [16] [Directional first order approach for a class of bilevel programs](https://arxiv.org/abs/2602.22573)
*Kuang Bai,Wei Yao,Jane J. Ye,Jin Zhang*

Main category: math.OC

TL;DR: 本文提出了一种处理双层优化问题的方向性一阶方法，该方法不要求下层规划具有凸性，通过方向邻域上的最优性条件来等价刻画下层规划。


<details>
  <summary>Details</summary>
Motivation: 传统双层优化方法存在局限性：一阶方法要求下层规划具有凸性，而基于值函数的重构方法会导致困难的优化问题。本文旨在克服这些限制，特别是针对下层规划非凸的情况。

Method: 提出方向性一阶方法：首先在合理假设下，证明下层规划可以通过其在一阶条件在方向邻域上的等价刻画；然后将双层问题转化为单层优化问题；最后在常见约束规范下建立方向性必要最优性条件。

Result: 成功建立了方向性必要最优性条件，并通过一个下层规划非凸的双层优化示例，展示了传统一阶方法的失效以及方向性方法的有效性。

Conclusion: 方向性一阶方法为处理下层规划非凸的双层优化问题提供了有效的理论框架，克服了传统方法的局限性，具有重要的理论和应用价值。

Abstract: In this paper, we study a class of bilevel optimization program (BP), where the feasible set of the lower level program is independent of the upper level variable. For bilevel programs it is known that the first order approach requires the convexity of the lower level program while reformulations involving the value function results in difficult optimization problems. In this paper we propose a directional first order approach which does not require the convexity of the lower level program. First, under some reasonable assumptions, we show that the lower level program can be equivalently characterized by its first order condition over a directional neighborhood. Next, for the resulting single level optimization problem, under common constraint qualifications, we establish directional necessary optimality conditions. Finally, an example of BP with nonconvex lower level program is given, where we demonstrate the failure of the classical first order approach and derive necessary optimality conditions using its directional counterpart.

</details>


### [17] [Gradient Dominance in the Linear Quadratic Regulator: A Unified Analysis for Continuous-Time and Discrete-Time Systems](https://arxiv.org/abs/2602.22577)
*Yuto Watanabe,Yang Zheng*

Main category: math.OC

TL;DR: 该论文提出了一个统一的梯度优势性质，适用于连续时间和离散时间线性二次调节器（LQR），基于共同的李雅普诺夫不等式表示和变量变换过程。


<details>
  <summary>Details</summary>
Motivation: 尽管连续时间和离散时间LQR的梯度优势性质已被广泛研究，但两者通常被分开分析，依赖不同的假设、证明策略和保证。作者希望建立一个统一的框架来同时处理这两种时间模型。

Method: 基于共同的李雅普诺夫不等式表示和统一的变量变换过程，通过凸重构方法建立单一证明框架。这种凸提升视角使得同一证明框架适用于两种时间模型。

Result: 在温和的可稳定性和可检测性假设下，为连续时间和离散时间LQR建立了统一的梯度优势性质。数值示例支持了理论发现。

Conclusion: 统一处理澄清了连续时间和离散时间动态之间的差异如何影响理论保证，并揭示了两种表述之间更深层次的结构对称性。

Abstract: Despite its nonconvexity, policy optimization for the Linear Quadratic Regulator (LQR) admits a favorable structural property known as gradient dominance, which facilitates linear convergence of policy gradient methods to the globally optimal gain. While gradient dominance has been extensively studied, continuous-time and discrete-time LQRs have largely been analyzed separately, relying on slightly different assumptions, proof strategies, and resulting guarantees. In this paper, we present a unified gradient dominance property for both continuous-time and discrete-time LQRs under mild stabilizability and detectability assumptions. Our analysis is based on a convex reformulation derived from a common Lyapunov inequality representation and a unified change-of-variables procedure. This convex-lifting perspective yields a single proof framework applicable to both time models. The unified treatment clarifies how differences between continuous-time and discrete-time dynamics influence theoretical guarantees and reveals a deeper structural symmetry between the two formulations. Numerical examples illustrate and support the theoretical findings.

</details>


### [18] [Dantzig-Wolfe and Arc-Flow Reformulations: A Systematic Comparison](https://arxiv.org/abs/2602.22589)
*Daniel Yamin,Willem-Jan van Hoeve,Ted K. Ralphs*

Main category: math.OC

TL;DR: 本文系统比较了Dantzig-Wolfe和Arc-Flow两种整数规划重构技术，建立了统一的理论框架，分析了它们的理论联系、计算权衡，并在车辆路径问题中进行了实证评估。


<details>
  <summary>Details</summary>
Motivation: 虽然Dantzig-Wolfe重构在分支定界方法中广泛应用，Arc-Flow重构作为动态规划相关技术近年重新受到关注，但两者之间的理论联系和计算权衡缺乏系统研究。本文旨在澄清这两种重构技术的关系，为大规模整数优化提供选择指导。

Method: 建立统一公式和符号体系，从理论上分析两种重构的LP松弛等价性，研究有效不等式在不同空间中的转换条件，重新解释迭代强化方法（如递减状态空间松弛和列消除）作为割平面的视角。在车辆路径问题时间窗口约束下进行实证比较，使用最先进的列生成和割生成技术。

Result: 理论分析确认两种重构的LP松弛提供相同的对偶界，并建立了有效不等式跨空间转换的条件。实证结果显示：Arc-Flow重构收敛更快，在子问题高度松弛或低维时表现最佳；Dantzig-Wolfe重构在主问题保持紧凑时更高效。

Conclusion: 研究提供了Dantzig-Wolfe和Arc-Flow重构的统一视角和实用选择指南：Arc-Flow适合子问题高度松弛或低维场景，Dantzig-Wolfe适合主问题紧凑场景。这些见解有助于在大规模整数优化中选择合适的重构技术。

Abstract: Dantzig-Wolfe reformulation is a widely used technique for obtaining stronger relaxations in the context of branch-and-bound methods for solving integer optimization problems. Arc-Flow reformulations are a lesser known technique related to dynamic programming that has experienced a resurgence as result of the recent popularization of decision diagrams as a tool for solving integer programs. Although these two reformulation techniques arose independently, the recently proposed solution paradigm known as column elimination has revealed that they are in fact closely connected. Building on a unified formulation and notation, this study clarifies the theoretical connections and computational trade-offs between these two reformulations.
  We first revisit the known fact that the LP relaxations of these two reformulations yield the same dual bound. We then dig deeper, establishing conditions under which valid inequalities in the original, Dantzig-Wolfe, or Arc-Flow spaces can be translated across reformulations without loss of strength, and reinterpreting iterative strengthening methods, such as decremental state-space relaxation and column elimination, through the lens of cutting planes. To assess the potential impact of these insights empirically, we benchmark both reformulations under identical conditions on the vehicle routing problem with time windows using state-of-the-art column- and cut-generation techniques. The results identify clear contrasts: the Arc-Flow reformulation benefits from faster convergence and performs best when subproblems are highly relaxed or low-dimensional, whereas the Dantzig-Wolfe reformulation is more efficient when the master problem remains compact. Overall, our study provides a unified perspective and practical guidelines for choosing between Dantzig-Wolfe and Arc-Flow reformulations in large-scale integer optimization.

</details>


### [19] [Lower Bounds for Linear Minimization Oracle Methods Optimizing over Strongly Convex Sets](https://arxiv.org/abs/2602.22608)
*Benjamin Grimmer,Ning Liu*

Main category: math.OC

TL;DR: 本文研究了约束凸优化问题的oracle复杂度下界，证明了在强凸约束集上确定性LMO方法的最优复杂度为Ω(√(L·diam(S)²/ε))，与加速Frank-Wolfe方法匹配。


<details>
  <summary>Details</summary>
Motivation: 研究约束凸优化问题的计算复杂度下界，特别是在线性最小化oracle(LMO)和梯度oracle访问下的最优迭代复杂度。现有Frank-Wolfe方法及其变种在该模型下运行，需要确定这些方法是否已达到最优性能。

Method: 采用理论分析框架，建立确定性LMO方法的复杂度下界。首先针对强凸约束集S，证明任何确定性方法都需要至少Ω(√(L·diam(S)²/ε))次迭代才能保证目标函数间隙小于ε。其次针对β-光滑集，分析在β=Ω(1/√ε)的中等光滑度下，基于span的LMO方法相对于紧凸集或强凸集没有复杂度改进。

Result: 1. 对于强凸约束集S，确定性LMO方法的最优复杂度下界为Ω(√(L·diam(S)²/ε))，与Garber和Hazan(2015)的加速Frank-Wolfe理论匹配。2. 对于β-光滑集，在β=Ω(1/√ε)的中等光滑度下，基于span的LMO方法相对于紧凸集或强凸集没有复杂度改进。

Conclusion: 本文建立了约束凸优化中确定性LMO方法的最优复杂度下界，证明了加速Frank-Wolfe方法在强凸约束集上已达到最优性能。同时表明在中等光滑度下，基于span的LMO方法相对于更一般的约束集类型没有计算优势。

Abstract: We consider the oracle complexity of constrained convex optimization given access to a Linear Minimization Oracle (LMO) for the constraint set and a gradient oracle for the $L$-smooth, strongly convex objective. This model includes Frank-Wolfe methods and their many variants. Over the problem class of strongly convex constraint sets $S$, our main result proves that no such deterministic method can guarantee a final objective gap less than $\varepsilon$ in fewer than $Ω(\sqrt{L\, \mathrm{diam}(S)^2/\varepsilon})$ iterations. Our lower bound matches, up to constants, the accelerated Frank-Wolfe theory of Garber and Hazan (2015). Together, these establish this as the optimal complexity for deterministic LMO methods over strongly convex constraint sets. Second, we consider optimization over $β$-smooth sets, finding that in the modestly smooth regime of $β=Ω(1/\sqrt{\varepsilon})$, no complexity improvement for span-based LMO methods is possible against either compact convex sets or strongly convex sets.

</details>


### [20] [Efficient exact sequential lifting algorithm for binary knapsack set](https://arxiv.org/abs/2602.22640)
*Xintong Wang,Liang Chen,Yu-Hong Dai*

Main category: math.OC

TL;DR: 提出了一种用于二元背包集合的精确顺序提升算法，利用支配列表结构减少动态规划数组中的冗余存储和计算，提高了大规模实例的计算效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 提升是混合整数规划中生成强有效不等式（切割平面）的关键技术，但现有方法在处理大规模、大容量实例时存在效率和稳定性问题，特别是对于非整数系数约束。

Method: 1. 提出基于支配列表结构的精确顺序提升算法，消除动态规划数组中的冗余存储和计算；2. 开发在特定条件下的提升过程简化方法；3. 算法保持尺度不变性并能有效处理非整数系数约束。

Result: 数值实验表明，该算法在效率和稳定性方面优于传统动态规划数组方法，尤其在大规模、大容量实例上表现更佳，并能处理非整数权重和大容量的二元背包集合。

Conclusion: 该算法为混合整数规划求解器提供了高效的精确顺序提升方法，能够直接应用于现代MIP求解器中，提升二元背包集合的切割平面生成能力。

Abstract: Lifting is a crucial technique in mixed integer programming (MIP) for generating strong valid inequalities, which serve as cutting planes to improve the branch-and-cut algorithm. We first propose an exact sequential lifting algorithm for the binary knapsack set, which employs the dominance list structure to remove redundant storage and computation in the dynamic programming (DP) array. This structure preserves scale invariance and effectively handles constraints with non-integer coefficients. Then, a reduction method is developed for the lifting procedure under some conditions, further enhancing computational efficiency. Finally, numerical experiments demonstrate that the proposed algorithm outperforms DP with arrays in terms of both efficiency and stability, particularly for large-scale and large-capacity instances. Moreover, it enables exact sequential lifting for binary knapsack sets with non-integer weights and large capacities, making it directly applicable in modern MIP solvers.

</details>


### [21] [Generalized fluctuation bounds for stochastic algorithms in the presence of compactness](https://arxiv.org/abs/2602.22741)
*Morenikeji Neri,Nicholas Pischke,Thomas Powell*

Main category: math.OC

TL;DR: 该论文为度量空间中满足随机拟Fejér单调性条件的随机变量序列提供了定量收敛结果，通过证明挖掘方法构建了元稳定点态收敛率，并应用于随机Krasnoselskii-Mann方案求解非扩张映射的随机公共不动点问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于将逻辑基础的证明挖掘方法应用于概率论，特别是为随机拟Fejér单调序列提供定量收敛分析。传统结果多为定性收敛，缺乏有效的收敛速率估计，而证明挖掘方法能够从存在性证明中提取计算信息。

Method: 方法包括：1) 在度量空间中建立随机拟Fejér单调序列的收敛理论；2) 开发有限理论，特别是完全有限形式的Robbins-Siegmund定理；3) 使用模函数量化序列和度量空间的关键性质；4) 构建元稳定点态收敛率作为广义波动界限；5) 将结果应用于随机Krasnoselskii-Mann方案求解Hadamard空间中的随机公共不动点问题。

Result: 主要结果：1) 在局部紧致性假设下，为度量空间中的随机拟Fejér单调序列提供了定量收敛定理；2) 开发了有限理论，特别是完全有限形式的Robbins-Siegmund定理；3) 构建了仅依赖于少数模函数的显式有效构造，提供元稳定点态收敛率；4) 将结果特化到可分离Hilbert空间中的Combettes和Pesquet经典工作；5) 为求解Hadamard空间中非扩张映射随机公共不动点问题的随机Krasnoselskii-Mann方案提供了元稳定收敛率。

Conclusion: 结论：该研究成功将证明挖掘方法应用于概率论，为随机拟Fejér单调序列提供了迄今为止最复杂的定量收敛分析案例。所开发的有限理论和定量结果不仅推广了经典理论，还为随机优化算法提供了有效的收敛速率估计，在概率分析和优化理论中具有重要应用价值。

Abstract: We provide a convergence result for sequences of random variables taking values in a metric space that satisfy a stochastic quasi-Fejér monotonicity condition, in the context of a (local) compactness assumption. Our result is quantitative in that we derive an explicit and effective construction which, in terms of only a few moduli representing quantitative witnesses to key properties of the sequence of random variables and the underlying metric space involved, provides a metastable rate of pointwise convergence, a type of generalized fluctuation bound. That quantitative result in particular relies on the development of a finitary theory of martingales, culminating in a fully finitary Robbins-Siegmund theorem. We outline how this result particularises to the circumstances of the seminal work of Combettes and Pesquet on stochastic quasi-Fejér monotone sequences in separable Hilbert spaces, and we provide an initial application by illustrating how these results can be used to provide a metastable rate of pointwise convergence for a stochastic Krasnoselskii-Mann scheme solving a stochastic common fixed point problem for nonexpansive maps over proper Hadamard spaces. This work is set in the context of recent applications of the logic-based methodology of proof mining to probability theory, and represents its most sophisticated case study to date.

</details>


### [22] [Existence of Quantum Splines via Fourth-Order Gradient Flows](https://arxiv.org/abs/2602.22888)
*Chun-Chi Lin,Yang-Kai Lue,Dung The Tran*

Main category: math.OC

TL;DR: 本文为量子样条建立了严格的数学存在性理论，这些曲线描述了最优控制的量子演化，通过几何梯度流框架构造了适定的四阶演化方程。


<details>
  <summary>Details</summary>
Motivation: Brody、Holm和Meier在2012年提出的量子样条描述了最优控制的量子演化，但缺乏严格的数学基础。本文旨在为这些变分问题建立严谨的存在性理论，为量子控制轨迹的变分描述提供数学基础。

Method: 在黎曼样条插值的几何梯度流框架内重新表述问题，构造适定的四阶演化方程。通过调整变分结构以适应物理模型要求的边界条件，这些边界条件在现有的梯度流框架中难以直接处理。

Result: 证明了修改后的系统允许严格的解析处理，既获得了存在性结果，又提供了生成量子样条的构造性方法。四阶演化方程的渐近极限实现了所需的量子样条。

Conclusion: 为量子样条的变分描述建立了数学基础，阐明了其形成的解析结构，为平滑量子控制轨迹提供了严谨的理论支持。

Abstract: We establish a rigorous existence theory for the quantum splines introduced by Brody, Holm, and Meier in Physical Review Letters (2012). These curves arise as solutions of a variational problem on the unitary group describing optimally controlled quantum evolutions. By formulating the problem within a geometric gradient flow framework for Riemannian spline interpolation, we construct a well-posed fourth order evolution whose asymptotic limits realize the desired quantum splines. The analysis requires adapting the variational structure to boundary conditions dictated by the physical model, which are not directly amenable to the setting in our recently developed framework for gradient flows of Riemannian spline interpolation. We show that, despite these difficulties, the modified system admits a rigorous analytical treatment, yielding both existence and a constructive procedure for generating quantum splines. Our results provide a mathematical foundation for the variational description of smooth quantum control trajectories and clarify the analytical structure underlying their formation.

</details>


### [23] [Iteration Complexity of Frank-Wolfe and Its Variants for Bilevel Optimization](https://arxiv.org/abs/2602.23076)
*Anthony Palmieri,Francesco Rinaldi,Saverio Salzo,Sara Venturini*

Main category: math.OC

TL;DR: 研究Frank-Wolfe方法在双层优化中的应用，考虑下层问题近似求解导致的超梯度偏差和误差，分析多种FW变体的收敛性，并在实际应用中验证理论。


<details>
  <summary>Details</summary>
Motivation: 在双层优化问题中，当下层问题只能近似求解时，会产生有偏差和不精确的超梯度。现有研究对这种不精确超梯度下的Frank-Wolfe方法收敛性分析不足，需要系统研究其理论保证和实际效果。

Method: 研究不精确的Frank-Wolfe方法变体，包括标准FW、away-step FW和pairwise FW，分析它们在非凸设置下梯度误差的收敛速率。结合迭代和近似隐式微分的最新超梯度误差界限，推导双层FW的整体迭代复杂度保证。

Result: 为不精确Frank-Wolfe方法提供了收敛速率分析，结合超梯度误差界限得到了双层FW的迭代复杂度保证。在两个实际应用中的实验验证了理论分析，并展示了方法的实际有效性。

Conclusion: 该研究系统分析了不精确超梯度下Frank-Wolfe方法在双层优化中的收敛性，建立了理论保证，并通过实验验证了方法的实用性，为处理近似求解的双层优化问题提供了有效工具。

Abstract: We study Frank-Wolfe (FW) methods for constrained bilevel optimization when the lower-level problem is solved only approximately, yielding biased and inexact hypergradients. We analyze inexact variants of vanilla FW as well as away-step and pairwise FW, and provide convergence rates in the nonconvex setting under gradient errors. By combining these results with recent bounds on hypergradient errors from iterative and approximate implicit differentiation, we derive overall iteration complexity guarantees for bilevel FW. Experiments on two real-world applications validate the theory and demonstrate practical effectiveness.

</details>


### [24] [Stochastic Differential Inclusions driven by Maximal Monotone Operators with empty interiors](https://arxiv.org/abs/2602.23145)
*Juan Guillermo Garrido,Pedro Pérez-Aros,Mathias Staudigl*

Main category: math.OC

TL;DR: 研究随机微分包含在最大单调算子驱动下的长时间行为，扩展了连续时间一阶优化方法在噪声或近似算子信息下的收敛性保证


<details>
  <summary>Details</summary>
Motivation: 研究连续时间一阶优化方法在噪声或近似算子信息下的模型，需要处理算子定义域可能为空的情况，扩展收敛性保证到更一般的非光滑、非Lipschitz和非全定义域的情况

Method: 采用适当的解概念建立适定性，分析随机动力学的渐近性质，并考虑Tikhonov型正则化方法

Result: 建立了无需算子定义域内部非空假设的适定性理论，扩展了收敛性保证到更一般的设置，证明了正则化方法的适定性和长时间收敛结果

Conclusion: 该研究为随机微分包含在最大单调算子驱动下的理论提供了更一般的框架，扩展了连续时间优化方法在噪声环境下的收敛性分析

Abstract: This paper studies the long-time behavior of stochastic differential inclusions driven by maximal monotone operators, motivated by continuous-time models of first-order optimization methods under noisy or approximate operator information. We first address well-posedness and show that existence and uniqueness can be established without the customary requirement that the operator's domain has nonempty interior, by adopting an appropriate notion of solution. We then analyze asymptotic properties of the resulting stochastic dynamics, extending convergence guarantees beyond previously studied settings that rely on smooth potentials, full-domain subdifferentials, or Lipschitz monotone operators. In addition, we consider a Tikhonov-type regularization of the stochastic inclusion and prove corresponding well-posedness and long-time convergence results.

</details>


### [25] [Operator learning for prescribed-time stabilization of reaction-diffusion systems](https://arxiv.org/abs/2602.23157)
*Kaijing Lyu,Umberto Biccari,Jun-Min Wang*

Main category: math.OC

TL;DR: 该论文提出了一种基于神经算子的方法，用于解决具有时空变化系数的热方程边界规定时间镇定问题，通过离线训练神经算子来近似反步核映射，大幅降低了计算成本，实现了实时控制。


<details>
  <summary>Details</summary>
Motivation: 传统反步设计需要实时求解二维时变核PDE，计算负担过重，限制了具有时空变化系数的热方程规定时间镇定在实际应用中的实时可行性。

Method: 提出神经算子方法，离线训练从时变系统系数到相应反步核的映射算子，在线部署生成时变核；同时研究了直接近似完整反馈律的方法。

Result: 神经算子方法将核生成的计算成本降低了几个数量级，实现了实时规定时间镇定；通过Lyapunov分析证明了在算子近似误差满足显式界时保持规定时间稳定性。

Conclusion: 基于神经算子的方法有效解决了具有时空变化系数的热方程规定时间镇定中的计算瓶颈问题，为实时控制应用提供了可行方案。

Abstract: This paper addresses boundary prescribed-time stabilization of a one-dimensional heat equation with spatially and temporally varying coefficients. In contrast to asymptotic or exponential stabilization, prescribed-time stabilization ensures convergence to equilibrium within a user-defined time that is independent of the initial condition, a property that is particularly attractive in applications with stringent transient performance requirements. The backstepping design for this problem requires solving, at each time instant, a two-dimensional time-dependent kernel Partial Differential Equation (PDE) whose solution continuously varies with the plant coefficients. The repeated numerical solution of this parabolic kernel PDE results in a prohibitive computational burden, thereby limiting real-time applicability. To overcome this limitation, we propose a neural-operator-based approximation of the mapping from the time-varying system coefficient to the corresponding backstepping kernel. The operator is trained offline using representative solutions of the kernel PDE and subsequently deployed online to generate the required time-varying kernels in real time. We establish, via Lyapunov analysis, that the resulting neural-operator-based controller preserves prescribed-time stability provided that the operator approximation error satisfies an explicit bound. Furthermore, we investigate a direct approximation of the full feedback law mapping the plant parameter functions and state measurements to the boundary control input. For this setting, we prove semiglobal practical prescribed-time stability of the closed-loop system. Numerical experiments demonstrate that the proposed approach reduces the computational cost of kernel generation by several orders of magnitude, thereby enabling real-time prescribed-time stabilization for heat equations with spatially and temporally varying coefficients.

</details>


### [26] [Hierarchy of bounds in free orthotropic material optimization: From convex relaxations to Hashin-Shtrikman via sequential global programming](https://arxiv.org/abs/2602.23180)
*Marek Tyburec,Michael Stingl,Shenyuan Ma*

Main category: math.OC

TL;DR: 研究二维平面应力合规性最小化的自由正交各向异性材料优化，使用两种有序各向同性相，旨在缩小经典自由材料优化中允许的张量与复合材料可实现张量之间的差距。


<details>
  <summary>Details</summary>
Motivation: 经典自由材料优化中允许的张量与复合材料可实现张量之间存在差距，需要构建更接近实际可实现性的材料优化模型。

Method: 构建由零阶、Voigt和Hashin-Shtrikman能量界限诱导的可实现性感知允许集层次结构，从凸松弛到更紧的非凸模型。通过主动约束分析和显式体积表征推导简化公式，并使用顺序全局规划求解非凸正交各向异性HS问题。

Result: Voigt集在中间体积分数时严格更紧，在纯相端点与零阶集重合；HS约束可重写为Voigt项减去非负修正项，其凸包等于Voigt集；单载荷情况下HS松弛与Allaire-Kohn松弛问题紧密匹配，多载荷情况下提供一般微结构最优合规性的下界。

Conclusion: 所提出的可实现性感知材料优化方法有效缩小了理论允许张量与可实现张量之间的差距，数值结果证实了合规性层次结构，并与有限秩层压参考结果高度一致。

Abstract: We study free orthotropic material optimization for two-dimensional plane-stress compliance minimization with two well-ordered isotropic phases, motivated by the gap between tensors admissible in classical free-material optimization and tensors realizable by composites. To reduce this gap, we construct a hierarchy of realizability-aware admissible sets induced by zeroth-order, Voigt, and Hashin--Shtrikman (HS) energy bounds, moving from convex relaxations to a tighter nonconvex model. In the convex zeroth-order and Voigt settings, the Voigt set is strictly tighter for intermediate volume fractions and coincides with the zeroth-order set at pure-phase endpoints, and the Voigt model reduces to an isotropic variable-thickness-sheet formulation. In the single-loadcase continuum zeroth-order problem, at least one optimal solution can be chosen orthotropic. For HS constraints, we rewrite the bound as a Voigt term minus a nonnegative correction, clarifying strict tightening for interior volume fractions and local nonconvexity. We further prove that the convex hull of the HS feasible set equals the Voigt set and derive reduced formulations via active-constraint analysis and explicit elementwise volume characterization, including reductions specialized to orthotropic effective tensors. In the single-loadcase continuum setting, the HS relaxation is tight with the Allaire--Kohn relaxed problem, attained in the relaxation sense by sequential laminates, whereas in generic multi-loadcase settings it provides a lower bound on optimal compliance over general microstructures. The resulting nonconvex orthotropic HS problem is solved by sequential global programming, and numerical results confirm the predicted compliance hierarchy and show close agreement with finite-rank laminate references.

</details>


### [27] [Efficient Interior-Point Methods for Hyperbolic Programming via Straight-Line Programs](https://arxiv.org/abs/2602.23260)
*Mehdi Karimi,Levent Tuncel*

Main category: math.OC

TL;DR: DDS 3.0是一个针对双曲规划的高效内点法求解器，通过新的直线程序表示和改进的校正步骤，显著提升了大规模双曲规划问题的计算性能。


<details>
  <summary>Details</summary>
Motivation: 双曲规划作为半定规划和二阶锥规划的推广，虽然理论上有很大进展，但大规模双曲规划的高效计算工具仍然有限。现有方法在计算效率和可扩展性方面存在不足。

Method: 提出了DDS 3.0求解器，采用新的直线程序表示来紧凑表示双曲多项式及其梯度和Hessian矩阵。通过批量反向-前向微分方案，使Hessian计算复杂度与梯度相同。同时改进了原始-对偶内点法的校正步骤，增强了在仅能高效计算原始自协调障碍函数的凸集上的稳定性和收敛性。

Result: 数值实验表明，DDS 3.0相比一阶Frank-Wolfe算法、同伦方法以及使用SDP松弛的SDP软件，在性能上有显著提升。创建了超越基本对称多项式的综合基准库。

Conclusion: DDS 3.0为大规模双曲规划问题提供了高效的计算工具，通过创新的直线程序表示和改进的内点法校正步骤，在计算效率和稳定性方面取得了重要进展。

Abstract: Hyperbolic (HB) programming generalizes many popular convex optimization problems, including semidefinite and second-order cone programming. Despite substantial theoretical progress on HB programming, efficient computational tools for solving large-scale hyperbolic programs remain limited. This paper presents DDS 3.0, a new release of the Domain-Driven Solver, which provides an efficient interior-point implementation tailored for hyperbolic programming. A key innovation lies in a new straight-line program (SLP) representation that enables compact representation and efficient computation of hyperbolic polynomials, their gradients, and Hessians. The SLP structure significantly reduces computational cost, allowing the Hessian to be computed in the same asymptotic complexity as the gradient through a batched reverse-over-forward differentiation scheme. We further introduce an improved corrector step for the primal-dual interior-point method, enhancing stability and convergence on convex sets where only the primal self-concordant barrier is efficiently computable. We create a comprehensive benchmark library beyond the elementary symmetric polynomials, using several different techniques. Numerical experiments demonstrate substantial performance gains of DDS 3.0 compared to first-order Frank-Wolfe algorithm, homotopy method, and SDP software utilizing SDP relaxations.

</details>


### [28] [Modeling Large-Scale Adversarial Swarm Engagements using Optimal Control](https://arxiv.org/abs/2602.23323)
*Claire Walton,Isaac Kaminer,Qi Gong,Abram H. Clark,Theodoros Tsatsanifos*

Main category: math.OC

TL;DR: 研究大规模自主系统在对抗条件下的最优控制，考虑随时间概率性损毁的智能体，提出三种近似数值建模方法，应用于防御高价值单位对抗攻击群的场景。


<details>
  <summary>Details</summary>
Motivation: 现有理论和建模框架通常忽略智能体在运行过程中的随机损耗，而对抗性自主系统中智能体损耗和空间动态都是关键因素，需要同时考虑才能实现有效建模和控制。

Method: 提出三种近似数值建模方法，将智能体生存概率基于相对位置随时间确定性递减，应用于防御高价值单位对抗攻击群的场景，紧密整合损耗和空间定位因素。

Result: 这些模型能有效捕捉此类对抗交互的动态特性，前提是损耗和空间定位被紧密整合，研究结果适用于智能体定位和生存概率都起关键作用的广泛对抗性自主场景。

Conclusion: 在对抗性自主系统控制中，必须同时考虑智能体损耗和空间动态，提出的近似建模方法能有效处理这类复杂问题，为大规模自主系统在对抗条件下的控制提供了实用框架。

Abstract: We investigate the optimal control of large-scale autonomous systems under explicitly adversarial conditions, incorporating the probabilistic destruction of agents over time. In many such systems, adversarial interactions arise as different agents or groups compete against one another. A crucial yet often overlooked factor in existing theoretical and modeling frameworks is the random attrition of agents during operation. Effective modeling and control strategies must therefore account for both agent attrition and spatial dynamics.
  Given the inherently random nature of agent survival, directly solving this problem is challenging. To address this, we propose and evaluate three approximate numerical modeling approaches in which agent survival probabilities decrease deterministically over time based on their relative positions. We apply these schemes to a scenario where agents defend a high-value unit against an attacking swarm. Our results demonstrate that these models can effectively capture the dynamics of such interactions, provided that attrition and spatial positioning are tightly integrated. These findings are relevant to a broad range of adversarial autonomy scenarios where both agent positioning and survival probabilities play a critical role.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [29] [Sampling from Constrained Gibbs Measures: with Applications to High-Dimensional Bayesian Inference](https://arxiv.org/abs/2602.22369)
*Ruixiao Wang,Xiaohong Chen,Sinho Chewi*

Main category: math.ST

TL;DR: 论文研究低温度Gibbs分布采样问题，特别关注模式部分坐标位于边界的情况，在拉普拉斯近似不成立的"前渐近"区域，证明了分布集中在模式邻域内，并分析了Langevin动力学的谱隙来提供非渐近采样保证。


<details>
  <summary>Details</summary>
Motivation: 研究低温度Gibbs分布的采样问题，特别是当分布的某些坐标位于边界时（称为非正则部分），在拉普拉斯近似尚未成立的"前渐近"区域，需要理解分布的结构并开发有效的采样方法。

Method: 首先证明低温度Gibbs分布集中在模式邻域内，在该区域内分布是有界扰动的乘积测度：正则部分是强对数凹分布，非正则部分每个坐标是一维指数型分布。然后通过分析Langevin动力学的谱隙来提供非渐近采样保证。

Result: 在"前渐近"区域，低温度Gibbs分布集中在模式邻域内，分布结构为有界扰动的乘积测度。通过分析Langevin动力学的谱隙，获得了非渐近采样保证。在三个典型贝叶斯后验模型（高维逻辑回归、泊松线性模型、高斯混合模型）上验证了结果。

Conclusion: 对于支持集受约束且模式部分坐标位于边界的低温度Gibbs分布，在拉普拉斯近似不成立的"前渐近"区域，分布具有特定的乘积结构，Langevin动力学能够提供有效的非渐近采样保证，适用于多种贝叶斯后验模型。

Abstract: This paper considers a non-standard problem of generating samples from a low-temperature Gibbs distribution with \emph{constrained} support, when some of the coordinates of the mode lie on the boundary. These coordinates are referred to as the non-regular part of the model. We show that in a ``pre-asymptotic'' regime in which the limiting Laplace approximation is not yet valid, the low-temperature Gibbs distribution concentrates on a neighborhood of its mode. Within this region, the distribution is a bounded perturbation of a product measure: a strongly log-concave distribution in the regular part and a one-dimensional exponential-type distribution in each coordinate of the non-regular part. Leveraging this structure, we provide a non-asymptotic sampling guarantee by analyzing the spectral gap of Langevin dynamics. Key examples of low-temperature Gibbs distributions include Bayesian posteriors, and we demonstrate our results on three canonical examples: a high-dimensional logistic regression model, a Poisson linear model, and a Gaussian mixture model.

</details>


### [30] [Remarks on stationary GARCH processes under heavy tail distributions](https://arxiv.org/abs/2602.22929)
*Marc Taberner-Ortiz,Manfred Denker*

Main category: math.ST

TL;DR: 该论文研究了GARCH过程的平方项均值估计问题，提出了数值近似方法来构建置信区间，并与传统正态近似方法比较精度，同时针对重尾创新过程改进了重采样方法。


<details>
  <summary>Details</summary>
Motivation: 对于GARCH过程，当观测到平方项序列时，需要估计其均值的置信区间。传统基于正态近似的方法可能不够准确，特别是在重尾创新分布的情况下，需要更精确的数值方法和改进的重采样技术。

Method: 1. 定义GARCH过程平方项标准化和的分布μ_n；2. 当观测到x_1,...,x_n时，推导μ_n的数值近似方法；3. 基于此近似构建均值μ=E(X_0^2)的置信区间；4. 针对重尾创新分布，提出新的重采样方法来改进方法。

Result: 1. 推导了GARCH过程平方项均值估计的数值近似方法；2. 构建了相应的置信区间；3. 比较了该方法与标准正态近似方法的精度；4. 针对重尾情况改进了重采样方法，提高了估计精度。

Conclusion: 该论文为GARCH过程的平方项均值估计提供了更精确的数值方法和置信区间构建技术，特别是在重尾创新分布情况下，改进的重采样方法能够获得更好的统计推断结果。

Abstract: Let $(X_n)_{n\in \mathbb Z}$ be a GARCH process with $E(X_0^4)<\infty$, and let $μ_n$ denote the distribution of $\frac 1{\sqrt n}\sum_{i=1}^n [X_i^2-\mathbb E(X_0^2)]$. We derive a numerical approximation of $μ_n$ when $x_1,...,x_n$ are observed. This yields the derivation of confidence intervals for $μ= E(X_0^2)$ and we investigate the accuracy of these confidence intervals in comparison with standard ones based on normal approximation. Moreover, when the innovation process has heavy tail distribution, we improve the method using a new resampling method.

</details>


### [31] [Effective sample size approximations as entropy measures](https://arxiv.org/abs/2602.22954)
*L. Martino,V. Elvira*

Main category: math.ST

TL;DR: 本文分析了重要性采样算法中替代有效样本量（ESS）度量，探讨了其扩展应用范围，揭示了ESS表达式与Rényi和Tsallis熵的关系，证明了Huggins-Roy ESS族满足所有理论条件，并展示了ESS在变量选择等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 研究重要性采样算法中替代有效样本量（ESS）度量的理论性质和应用范围，建立ESS与信息论中熵概念的联系，探索ESS在不同领域的交叉应用价值。

Method: 通过理论分析建立ESS表达式与Rényi熵和Tsallis熵的数学关系，证明Huggins-Roy ESS族的理论完备性，通过数值模拟比较不同ESS表达式的性能，并在变量选择问题中应用ESS公式。

Result: 证明了所有Huggins-Roy ESS族函数都满足理想的理论条件，建立了ESS与生态学中的Hill数、经济学中的基尼系数、机器学习中的基尼不纯度等多个领域的联系，数值模拟验证了不同ESS表达式的性能。

Conclusion: ESS度量与信息论中的熵概念有深刻联系，Huggins-Roy ESS族具有理论完备性，ESS在不同领域有广泛的应用潜力，为重要性采样算法的评估提供了理论基础。

Abstract: In this work, we analyze alternative effective sample size (ESS) metrics for importance sampling algorithms, and discuss a possible extended range of applications. We show the relationship between the ESS expressions used in the literature and two entropy families, the Rényi and Tsallis entropy. The Rényi entropy is connected to the Huggins-Roy's ESS family introduced in \cite{Huggins15}. We prove that that all the ESS functions included in the Huggins-Roy's family fulfill all the desirable theoretical conditions. We analyzed and remark the connections with several other fields, such as the Hill numbers introduced in ecology, the Gini inequality coefficient employed in economics, and the Gini impurity index used mainly in machine learning, to name a few.
  Finally, by numerical simulations, we study the performance of different ESS expressions contained in the previous ESS families in terms of approximation of the theoretical ESS definition, and show the application of ESS formulas in a variable selection problem.

</details>


### [32] [On the errors committed by sequences of estimator functionals](https://arxiv.org/abs/2602.23021)
*Steffen Grønneberg,Nils Lid Hjort*

Main category: math.ST

TL;DR: 论文研究了几乎必然收敛的估计量序列，识别了估计量最后一次偏离真实参数超过ε时的渐近极限，并基于此构建了序列固定宽度置信区域。


<details>
  <summary>Details</summary>
Motivation: Hjort和Fenstad（1992）在欧几里得参数空间上推导了类似结果，本文的动机是将这些结果推广到涉及参数泛函的情况，扩展理论适用范围。

Method: 在弱光滑性条件下，假设估计量接近经验分布的Hadamard可微泛函，识别估计量最后一次偏离真实参数超过ε时的渐近极限，并基于此构建序列固定宽度置信区域。

Result: 得到了估计量最后一次偏离真实参数超过ε时的渐近极限，构建了序列固定宽度置信区域并给出解析近似，还将结果应用于Nelson-Aalen估计量的累积风险函数置信集和随机规划中的计算复杂度问题。

Conclusion: 成功将欧几里得参数空间的结果推广到参数泛函情况，发展了可用于分析几乎必然收敛估计量序列尾部行为的理论框架，具有广泛的应用价值。

Abstract: Consider a sequence of estimators $\hat θ_n$ which converges almost surely to $θ_0$ as the sample size $n$ tends to infinity. Under weak smoothness conditions, we identify the asymptotic limit of the last time $\hat θ_n$ is further than $\eps$ away from $θ_0$ when $\eps \rightarrow 0^+$. These limits lead to the construction of sequentially fixed width confidence regions for which we find analytic approximations. The smoothness conditions we impose is that $\hat θ_n$ is to be close to a Hadamard-differentiable functional of the empirical distribution, an assumption valid for a large class of widely used statistical estimators. Similar results were derived in Hjort and Fenstad (1992, Annals of Statistics) for the case of Euclidean parameter spaces; part of the present contribution is to lift these results to situations involving parameter functionals. The apparatus we develop is also used to derive appropriate limit distributions of other quantities related to the far tail of an almost surely convergent sequence of estimators, like the number of times the estimator is more than $\eps$ away from its target. We illustrate our results by giving a new sequential simultaneous confidence set for the cumulative hazard function based on the Nelson--Aalen estimator and investigate a problem in stochastic programming related to computational complexity.

</details>


### [33] [Low-degree Lower bounds for clustering in moderate dimension](https://arxiv.org/abs/2602.23023)
*Alexandra Carpentier,Nicolas Verzelen*

Main category: math.ST

TL;DR: 本文研究了高斯混合模型中聚类问题的计算复杂性，特别关注中等维度下最小均值距离Δ的阈值，揭示了与高维情况不同的非参数速率现象。


<details>
  <summary>Details</summary>
Motivation: 高斯混合模型聚类问题的信息论极限与多项式时间算法性能之间存在显著差距。虽然高维情况（n ≤ dK）已有研究，但中等维度（n ≥ dK）的计算复杂性尚未充分探索，特别是当d ≥ K时。

Method: 建立了中等维度情况下新的低阶多项式下界，分析了聚类难度的驱动因素，并提出了匹配该速率的新型非谱算法。

Result: 发现中等维度聚类问题涉及更微妙的现象，导致"非参数速率"，与高维情况主要受降维和谱方法驱动不同。提出的非谱算法能够匹配这一速率。

Conclusion: 研究揭示了中等维度下聚类问题的计算极限，为理解高斯混合模型聚类在不同维度下的计算复杂性提供了新视角，并展示了非谱方法在中等维度下的有效性。

Abstract: We study the fundamental problem of clustering $n$ points into $K$ groups drawn from a mixture of isotropic Gaussians in $\mathbb{R}^d$. Specifically, we investigate the requisite minimal distance $Δ$ between mean vectors to partially recover the underlying partition. While the minimax-optimal threshold for $Δ$ is well-established, a significant gap exists between this information-theoretic limit and the performance of known polynomial-time procedures. Although this gap was recently characterized in the high-dimensional regime ($n \leq dK$), it remains largely unexplored in the moderate-dimensional regime ($n \geq dK$). In this manuscript, we address this regime by establishing a new low-degree polynomial lower bound for the moderate-dimensional case when $d \geq K$. We show that while the difficulty of clustering for $n \leq dK$ is primarily driven by dimension reduction and spectral methods, the moderate-dimensional regime involves more delicate phenomena leading to a "non-parametric rate". We provide a novel non-spectral algorithm matching this rate, shedding new light on the computational limits of the clustering problem in moderate dimension.

</details>


### [34] [Accelerated Online Risk-Averse Policy Evaluation in POMDPs with Theoretical Guarantees and Novel CVaR Bounds](https://arxiv.org/abs/2602.23073)
*Yaacov Pariente,Vadim Indelman*

Main category: math.ST

TL;DR: 提出一种在部分可观测马尔可夫决策过程中加速条件风险价值评估的理论框架，通过简化模型建立上下界估计，实现安全动作消除和计算加速。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测环境中进行风险规避决策是人工智能的核心挑战，但求解POMDPs通常计算不可行，现有近似方法依赖昂贵的未来轨迹模拟，需要更高效的CVaR评估方法。

Method: 1) 推导基于辅助随机变量的CVaR新边界；2) 在简化信念MDP中建立CVaR值函数上下界；3) 在粒子信念MDP框架内开发具有概率保证的边界估计器；4) 通过边界进行动作消除，在简化模型中安全丢弃次优动作。

Result: 经验评估表明，该方法在多个POMDP领域中能够可靠地区分安全与危险策略，同时在简化模型下实现显著的计算加速。

Conclusion: 该工作为POMDPs中的CVaR值函数评估提供了理论加速框架，通过形式化性能保证实现了计算效率提升，同时保持与原始问题的决策一致性。

Abstract: Risk-averse decision-making under uncertainty in partially observable domains is a central challenge in artificial intelligence and is essential for developing reliable autonomous agents. The formal framework for such problems is the partially observable Markov decision process (POMDP), where risk sensitivity is introduced through a risk measure applied to the value function, with Conditional Value-at-Risk (CVaR) being a particularly significant criterion. However, solving POMDPs is computationally intractable in general, and approximate methods rely on computationally expensive simulations of future agent trajectories. This work introduces a theoretical framework for accelerating CVaR value function evaluation in POMDPs with formal performance guarantees. We derive new bounds on the CVaR of a random variable X using an auxiliary random variable Y, under assumptions relating their cumulative distribution and density functions; these bounds yield interpretable concentration inequalities and converge as the distributional discrepancy vanishes. Building on this, we establish upper and lower bounds on the CVaR value function computable from a simplified belief-MDP, accommodating general simplifications of the transition dynamics. We develop estimators for these bounds within a particle-belief MDP framework with probabilistic guarantees, and employ them for acceleration via action elimination: actions whose bounds indicate suboptimality under the simplified model are safely discarded while ensuring consistency with the original POMDP. Empirical evaluation across multiple POMDP domains confirms that the bounds reliably separate safe from dangerous policies while achieving substantial computational speedups under the simplified model.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [35] [A Reduced Order Model approach for First-Principles Molecular Dynamics Computations](https://arxiv.org/abs/2602.22390)
*Siu Wun Cheung,Youngsoo Choi,Jean-Luc Fattebert,Jonas Kaufman,Daniel Osei-Kuffuor*

Main category: math.NA

TL;DR: 提出一种数据驱动的Kohn-Sham密度泛函理论建模框架，通过构建低维基函数近似电子结构子空间，避免显式优化电子波函数，实现高效的第一性原理分子动力学模拟。


<details>
  <summary>Details</summary>
Motivation: 利用第一性原理分子动力学中每一步电子结构计算之间的冗余性，开发更高效的电子结构求解方法，避免传统方法中耗时的迭代波函数优化过程。

Method: 1) 先验采样代表性原子构型；2) 构建低维基函数高效近似电子结构子空间；3) 在约化基函数上使用直接求解器计算电子单粒子密度矩阵；4) 应用于Born-Oppenheimer分子动力学模拟。

Result: 在水分子Born-Oppenheimer分子动力学模拟中，该方法准确再现了完整第一性原理分子动力学获得的关键结构性质（键长、键角），证明了方法的有效性。

Conclusion: 该工作展示了数据驱动方法开发高效电子结构求解器的潜力，为第一性原理模拟提供了新的计算框架，能够显著提高计算效率同时保持准确性。

Abstract: To leverage the redundancy between the electronic structure computed at each step of first-principles molecular dynamics, we present a data-driven modeling framework for Kohn-Sham Density Functional Theory that bypasses the explicit optimization of electronic wavefunctions. We sample a priori representative atomic configurations and construct a low-dimensional basis that efficiently approximates the electronic structure subspace. Subsequently, we employ this reduced basis in a direct solver for the electronic single particle density matrix, thereby enabling the efficient determination of ground state without iterative wavefunction optimization. We demonstrate the efficacy of our approach in a Born-Oppenheimer molecular dynamics of a water molecule, showing that the resulting simulations accurately reproduce key structural properties, such as bond lengths and bond angle, obtained from full first-principles molecular dynamics. This work highlights the potential of data-driven approaches to develop efficient electronic structure solvers for first-principles simulations.

</details>


### [36] [Error Analysis of Parameter Prediction via Gaussian Process Regression and Its Application to Weighted Jacobi Iteration](https://arxiv.org/abs/2602.22679)
*Tiantian Sun,Juan Zhang*

Main category: math.NA

TL;DR: 提出基于函数空间分解的高斯过程回归误差分析理论框架，开发了利用高斯过程回归进行参数预测的加权雅可比迭代方法，并提供了收敛性分析。


<details>
  <summary>Details</summary>
Motivation: 传统雅可比迭代方法收敛速度较慢，需要更有效的参数预测方法来加速收敛。高斯过程回归在参数预测方面具有潜力，但缺乏相应的理论分析框架。

Method: 1. 建立基于函数空间分解的高斯过程回归误差分析理论框架；2. 开发加权雅可比迭代方法，利用高斯过程回归进行参数预测；3. 提供收敛性分析，设计与其他误差界兼容的收敛条件。

Result: 实验结果表明，基于高斯过程回归预测的参数显著加速了雅可比迭代的收敛速度。收敛条件设计具有普适性，能够与其他误差界兼容。

Conclusion: 提出的理论框架和方法有效结合了高斯过程回归和雅可比迭代，通过智能参数预测显著提升了迭代收敛性能，为数值计算中的迭代方法优化提供了新思路。

Abstract: In this paper, we introduce a novel theoretical framework for Gaussian process regression error analysis, leveraging a function-space decomposition. Based on this framework, we develop a weighted Jacobi iterative method that utilizes Gaussian process regression for parameter prediction and provide a corresponding convergence analysis. Moreover, the convergence conditions are designed to be compatible with other error bounds, enabling a more general analysis. Experimental results show that the parameters predicted based on Gaussian process regression significantly accelerate the convergence speed of Jacobi iterations.

</details>


### [37] [Comparison of Structure-Preserving Methods for the Cahn-Hilliard-Navier-Stokes Equations](https://arxiv.org/abs/2602.22861)
*Jimmy Kornelije Gunnarsson,Robert Klöfkorn*

Main category: math.NA

TL;DR: 开发了结构保持的间断Galerkin方法用于具有退化迁移率的Cahn-Hilliard-Navier-Stokes方程，通过参数化迁移率通量和边处理增强稳定性控制，证明了解的存在性和最优收敛率，同时保持质量守恒、能量耗散和离散最大值原理。


<details>
  <summary>Details</summary>
Motivation: 针对具有退化迁移率的Cahn-Hilliard-Navier-Stokes方程，需要开发能够保持物理结构特性的数值方法。现有方法在稳定性控制和计算效率方面存在改进空间，特别是在处理耦合系统和自适应网格时。

Method: 提出了SWIPD-L和SIPGD-L两种结构保持的间断Galerkin方法，采用参数化迁移率通量设计，通过边处理技术增强强制性和稳定性控制。方法证明了广义三线性形式的强制性，并保持了质量守恒、能量耗散和离散最大值原理。

Result: 证明了方法的强制性，展示了最优收敛率。与现有SIPG-L和SWIP-L方法比较确认了相似的稳定性。在hp自适应网格上对独立Cahn-Hilliard方程和耦合系统进行验证，显示在不损失精度的情况下显著节省计算成本。

Conclusion: 提出的结构保持间断Galerkin方法能够有效处理具有退化迁移率的Cahn-Hilliard-Navier-Stokes方程，在保持物理结构特性的同时提供良好的稳定性和计算效率，特别适用于自适应网格计算。

Abstract: We develop structure-preserving discontinuous Galerkin methods for the Cahn-Hilliard-Navier-Stokes equations with degenerate mobility. The proposed SWIPD-L and SIPGD-L methods incorporate parametrized mobility fluxes with edge-wise mobility treatments for enhanced coercivity-stability control. We prove coercivity for the generalized trilinear form and demonstrate optimal convergence rates while preserving mass conservation, energy dissipation, and the discrete maximum principle. Comparisons with existing SIPG-L and SWIP-L methods confirm similar stability. Validation on $hp$-adaptive meshes for both standalone Cahn-Hilliard and coupled systems shows significant computational savings without accuracy loss.

</details>


### [38] [A Reduced Magnetic Vector Potential Approach with Higher-Order Splines](https://arxiv.org/abs/2602.22997)
*Merle Backmeyer,Laura A. M. D'Angelo,Brahim Ramdane,Sebastian Schöps*

Main category: math.NA

TL;DR: 提出了一种基于高阶等几何分析方法的磁准静态涡流问题求解方案，通过Biot-Savart源场和有限元反应场的分解，避免了线圈网格划分，支持任意绕组路径，在缩减计算域内实现高阶场近似。


<details>
  <summary>Details</summary>
Motivation: 磁准静态涡流问题在电磁设备设计中具有重要意义，传统方法需要复杂的线圈网格划分，且难以处理任意绕组路径。现有方法在几何精度和计算效率方面存在局限，需要一种既能避免线圈网格划分又能实现高阶精度的新方法。

Method: 基于表面Biot-Savart评估方法，将磁准静态问题分解为Biot-Savart驱动的源场和有限元反应场。将简化磁矢量势框架推广到准静态区域，并引入一致的高阶样条离散化。该方法避免了线圈网格划分，支持任意绕组路径，在缩减计算域内实现高阶场近似。

Result: 建立了最优收敛速率，数值研究确定了实际恢复高阶精度所需的条件：包括包围界面的几何正则性、精确的核积分、以及源-反应耦合的兼容迹空间。方法在保持计算效率的同时实现了高阶精度。

Conclusion: 提出的高阶等几何方法成功解决了磁准静态涡流问题，通过源场-反应场分解避免了线圈网格划分，支持任意绕组路径，在缩减域内实现高阶近似。该方法为电磁设备设计提供了高效精确的计算工具。

Abstract: This work presents a high-order isogeometric formulation for magnetoquasistatic eddy-current problems based on a decomposition into Biot-Savart-driven source fields and finite-element reaction fields. Building upon a recently proposed surface-only Biot-Savart evaluation, we generalize the reduced magnetic vector potential framework to the quasistatic regime and introduce a consistent high-order spline discretization. The resulting method avoids coil meshing, supports arbitrary winding paths, and enables high-order field approximation within a reduced computational domain. Beyond establishing optimal convergence rates, the numerical investigation identifies the requirements necessary to recover high-order accuracy in practice, including geometric regularity of the enclosing interface, accurate kernel quadrature, and compatible trace spaces for the source-reaction coupling.

</details>


### [39] [Nearest Reversible Markov Chains with Sparsity Constraints: An Optimization Approach](https://arxiv.org/abs/2602.23059)
*Stefano Cipolla,Fabio Durastante,Miryam Gnazzo,Beatrice Meini*

Main category: math.NA

TL;DR: 该论文提出了一种将非可逆马尔可夫链近似为可逆链的矩阵邻近问题方法，特别关注稀疏转移矩阵情况，通过二次规划求解，为MCMC等领域提供理论框架。


<details>
  <summary>Details</summary>
Motivation: 可逆性是马尔可夫链的关键性质，对Metropolis-Hastings等MCMC算法至关重要。然而许多应用产生非可逆链，因此需要以最小修改将其近似为可逆链。

Method: 将任务表述为矩阵邻近问题，专注于稀疏转移矩阵的实际情况，将优化问题转化为二次规划问题进行求解。

Result: 数值实验证明了该方法的有效性，能够有效近似非可逆链为可逆链。

Conclusion: 该框架为在MCMC、计算化学和数据驱动建模中强制执行可逆性和稀疏模式提供了原则性方法。

Abstract: Reversibility is a key property of Markov chains, central to algorithms such as Metropolis-Hastings and other MCMC methods. Yet many applications yield non-reversible chains, motivating the problem of approximating them by reversible ones with minimal modification. We formulate this task as a matrix nearness problem and focus on the practically relevant case of sparse transition matrices. The resulting optimization problem is a quadratic programming problem, and numerical experiments illustrate the effectiveness of the approach. This framework provides a principled way to enforce reversibility and sparsity patterns in Markov chains with applications in MCMC, computational chemistry, and data-driven modeling.

</details>


### [40] [On the choice of viscous discontinuous Galerkin discretization for entropy correction artificial viscosity methods](https://arxiv.org/abs/2602.23210)
*Samuel Q. Van Fleet,Jesse Chan*

Main category: math.NA

TL;DR: ECAV是一种通过熵耗散修正项强制半离散熵不等式的方法，可作为极小粘性系数的数值粘性实现。本文分析LDG离散ECAV，证明其系数上界为O(h)，不产生限制性时间步条件，且保持接触间断，并与传统激波捕捉粘性方法比较。


<details>
  <summary>Details</summary>
Motivation: 研究熵修正人工粘性(ECAV)方法在局部间断Galerkin(LDG)离散下的性质，分析其时间步限制、接触间断保持能力，并与传统激波捕捉粘性方法进行比较。

Method: 采用局部间断Galerkin(LDG)方法离散熵修正人工粘性(ECAV)，通过理论分析证明ECAV系数的上界为O(h)，分析其接触间断保持特性，并与传统激波捕捉人工粘性方法进行对比。

Result: 证明ECAV系数具有O(h)上界，表明该方法不会产生限制性时间步条件；同时证明ECAV能够保持接触间断；与传统激波捕捉粘性方法相比，ECAV具有更好的性能表现。

Conclusion: ECAV在LDG离散下具有良好的性质：不产生限制性时间步条件、保持接触间断，相比传统激波捕捉粘性方法具有优势，是一种有效的数值方法。

Abstract: Entropy correction artificial viscosity (ECAV) is an approach for enforcing a semi-discrete entropy inequality through an entropy dissipative correction term. The resulting method can be implemented as an artificial viscosity with an extremely small viscosity coefficient. In this work, we analyze ECAV when the artificial viscosity is discretized using a local discontinuous Galerkin (LDG) method. We prove an $O(h)$ upper bound on the ECAV coefficient, indicating that ECAV does not result in a restrictive time-step condition. We additionally show that ECAV is contact preserving, and compare ECAV to traditional shock capturing artificial viscosity methods.

</details>
