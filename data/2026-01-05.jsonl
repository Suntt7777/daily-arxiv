{"id": "2601.00119", "categories": ["math.PR", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.00119", "abs": "https://arxiv.org/abs/2601.00119", "authors": ["Omer Angel", "Caelan Atamanchuk", "Anna Brandenberger", "Serte Donderwinkel", "Robin Khanfir"], "title": "The largest common subtree of two random trees", "comment": "45 pages, 7 figures", "summary": "We study the size and structure of the largest common subtree (LCS) between two independent Bienaymé trees conditioned to have size $n$. When the trees are critical with finite $2$nd and $(2+κ)$th moment respectively for some $κ>0$, we prove that the LCS has size of order $\\sqrt{n}$, and is approximated by the length of three paths meeting at a central node. Moreover, we show that the largest common subtree between two critical independent Bienaymé trees with size $n$ and finite second moments may be much larger than $\\sqrt{n}$, implying that our result is tight. We also pose a number of open questions and suggestions for future research."}
{"id": "2601.00176", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.00176", "abs": "https://arxiv.org/abs/2601.00176", "authors": ["Chuang Xu"], "title": "Exponential ergodicity of first order endotactic stochastic reaction systems", "comment": null, "summary": "Chemical reaction networks are a widely accepted modeling framework for diverse science phenomena stemming from all disciplines of science, such as biochemistry, ecology, epidemiology, social and political science. In this paper we prove that every first order endotactic stochastic mass-action reaction system (SMART) is essential (i.e., every state in the state space is within a closed communicating class of the underlying continuous time Markov chain model) and is exponentially ergodic. The proof is based on a recent result on first order endotactic reaction networks in a companion paper [C.X., First order endotactic reaction networks. arXiv:2409.01598v2]. Besides, we show that a stochastic reaction system (of possibly nonlinear propensities) dominated by a first order endotactic SMART is exponentially erogdic. To demonstrate the applicability of results, we provide various examples of higher order SMART, including e.g., (1) SMART with a first order endotactic asymptotic limit as well as, (2) joint of translations of first order endotactic SMART."}
{"id": "2601.00291", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.00291", "abs": "https://arxiv.org/abs/2601.00291", "authors": ["Alberto M. Campos", "Bernardo N. B. de Lima"], "title": "The probability of connection between two vertices cannot be monotone with the distance for Bernoulli Percolation on transitive graphs", "comment": "8 pgs, 3 figures", "summary": "A popular question in Bernoulli percolation models is if the probability of connection between two vertices in a transitive graph decays monotonically with the distance between these two vertices. For example, on the square lattice is an open question to prove that the probability of the origin being connected to the vertex $(0,n)$ is monotone in $n$. In this short note, we exhibit an example of a transitive graph in which the probability of connection between vertices does not necessarily decay as the distance of those vertices grows. We also define a critical point for percolation in $\\mathbb{Z}^d$, in which using a generalization of the percolation process it is possible to see the same phenomena happening in the embedding of $\\mathbb{Z}^d$ over $\\mathbb{R}^d$."}
{"id": "2601.00467", "categories": ["math.PR", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.00467", "abs": "https://arxiv.org/abs/2601.00467", "authors": ["Yeor Hafouta"], "title": "Effective geometric ergodicty for Markov chains in random environment", "comment": "8 pp", "summary": "In this short note we prove ``effective\" geometric ergodicity (i.e a Perron-Frobenius theorem) for Markov chains in random mixing dynamical environment satisfying a random non-uniform version of the Doeblin condition. Effectivity here means that all the random variables involved in the random exponential rates are integrable with arbitrarily large order. This compliments \\cite[Theorem 2.1]{Kifer 1996}, where ``non-effective\" geometric ergodicity was obtained. From a different perspective, our result is also motivated by egrodic theory, as it can be seen as an effective version of the ``spectral\" gap in the top Oseledets space in the Oseledets multiplicative ergodic theorem for the random Markov operator cocycle (when it applies). We also present applications of the effective ergodicity to rates in the (quenched) almost sure invariance principle (ASIP), exponential decay of correlations for Markovian skew products and for exponential tails for random mixing times. As a byproduct of the proof of the ASIP rates we also provide easy to verify sufficient conditions for the verification of the assumptions of \\cite[Theorem 2.4]{Kifer 1998}."}
{"id": "2601.00103", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.00103", "abs": "https://arxiv.org/abs/2601.00103", "authors": ["Ari Stern", "Enrico Zampa"], "title": "Finite element exterior calculus for time-dependent Hamiltonian partial differential equations", "comment": "42 pages, 4 figures", "summary": "The success of symplectic integrators for Hamiltonian ODEs has led to a decades-long program of research seeking analogously structure-preserving numerical methods for Hamiltonian PDEs. In this paper, we construct a large class of such methods by combining finite element exterior calculus (FEEC) for spatial semidiscretization with symplectic integrators for time discretization. The resulting methods satisfy a local multisymplectic conservation law in space and time, which generalizes the symplectic conservation law of Hamiltonian ODEs, and which carries finer information about Hamiltonian structure than other approaches based on global function spaces. We give particular attention to conforming FEEC methods and hybridizable discontinuous Galerkin (HDG) methods. The theory and methods are illustrated by application to the semilinear Hodge wave equation."}
{"id": "2601.00091", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.00091", "abs": "https://arxiv.org/abs/2601.00091", "authors": ["Manuel Sáenz", "Pragya Sur"], "title": "Characterizing Finite-Dimensional Posterior Marginals in High-Dimensional GLMs via Leave-One-Out", "comment": null, "summary": "We investigate Bayes posterior distributions in high-dimensional generalized linear models (GLMs) under the proportional asymptotics regime, where the number of features and samples diverge at a comparable rate. Specifically, we characterize the limiting behavior of finite-dimensional marginals of the posterior. We establish that the posterior does not contract in this setting. Yet, the finite-dimensional posterior marginals converge to Gaussian tilts of the prior, where the mean of the Gaussian depends on the true signal coordinates of interest. Notably, the effect of the prior survives even in the limit of large samples and dimensions. We further characterize the behavior of the posterior mean and demonstrate that the posterior mean can strictly outperform the maximum likelihood estimate in mean-squared error in natural examples. Importantly, our results hold regardless of the sparsity level of the underlying signal. On the technical front, we introduce leave-one-out strategies for studying these marginals that may be of independent interest for analyzing low-dimensional functionals of high-dimensional signals in other Bayesian inference problems."}
{"id": "2601.00265", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.00265", "abs": "https://arxiv.org/abs/2601.00265", "authors": ["Prem Talwai", "Rene Caldentey", "Avi Giloni", "Clifford Hurvich", "David Simchi-Levi", "Yichen Zhang"], "title": "Designing Information Delays in Supply Chains", "comment": null, "summary": "This paper studies how a downstream retailer in a decentralized two-tier supply chain can implicitly transmit demand information to an upstream supplier through the structure of its order stream in the absence of an explicit information-sharing mechanism. We distinguish our work from prior work by introducing the notion of information delay and by linking optimal implicit information sharing to the group delay of the retailer's ordering transfer function. We show that pure delay is strictly suboptimal, while fractional-delay mechanisms can reshape the order autocorrelation to improve supplier forecastability and reduce system-wide inventory costs. Using Hardy-space factorization, we develop a tractable family of invertible ARMA policies that approximates the theoretically optimal (but non-rational) limiting filter derived by Caldentey et al. (2025) and preserves its informational delay properties. This construction yields sharp guidance on how policy complexity, as measured by the degrees of the ARMA policies, impacts supply chain costs. We further extend the analysis to memory-constrained suppliers and characterize how the complexity of the retailer's policy should scale with the supplier's finite forecasting window, highlighting when, perhaps counterintuitively, increasing policy complexity can become counterproductive."}
{"id": "2601.00634", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.00634", "abs": "https://arxiv.org/abs/2601.00634", "authors": ["Esa Nummelin", "Elja Arjas"], "title": "Thermodynamic Formalism of Stochastic Equilibrium Economics", "comment": "43 pages; text compression could in principle be achieved (and be desirable!) by reducing the size of the lower margins on all pages. Technical help in this regard would be welcome!", "summary": "In economics, construction of perfect models in a way that would be comparable to the standards customary in physical sciences is generally not feasible. In particular, the observed value for an economic equilibrium may deviate significantly from its model-based a priori expected value. Mathematically, the a posteriori observed equilibrium may then represent a large deviation in the sense that it falls outside the region of validity of the Central Limit Theorem. With this as the motivating starting point, we propose a new approach to the theory of stochastic economic equilibrium. Drawing on recent developments in probability theory, we argue for the relevance of the theory of large deviations in stochastic equilibrium economics. Thereby the formalism of stochastic equilibrium economics becomes analogous to that of classical statistical mechanics, as the theory of large deviations forms also the mathematical basis of statistical mechanics. In consequence, thermodynamic concepts such as entropy, partition function and canonical probability can be introduced in a natural way to stochastic equilibrium economics. We focus here on the economic analogs of two fundamental principles, the Second Law of Thermodynamics and the Gibbs Conditioning Principle."}
{"id": "2601.00107", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.00107", "abs": "https://arxiv.org/abs/2601.00107", "authors": ["Deepyaman Chakraborty", "Ruben Harris", "Rupert Klein", "Guillermo Olicón-Méndez", "Sebastian Reich", "Claudia Schillings"], "title": "Affine Invariant Langevin Dynamics for rare-event sampling", "comment": null, "summary": "We introduce an affine invariant Langevin dynamics (ALDI) framework for the efficient estimation of rare events in nonlinear dynamical systems. Rare events are formulated as Bayesian inverse problems through a nonsmooth limit-state function whose zero level set characterises the event of interest. To overcome the nondifferentiability of this function, we propose a smooth approximation that preserves the failure set and yields a posterior distribution satisfying the small-noise limit. The resulting potential is sampled by ALDI, a (derivative-free) interacting particle system whose affine invariance allows it to adapt to the local anisotropy of the posterior.\n  We demonstrate the performance of the method across a hierarchy of benchmarks, namely two low-dimensional examples (an algebraic problem with convex geometry and a dynamical problem of saddle-type instability) and a point-vortex model for atmospheric blockings. In all cases, ALDI concentrates near the relevant near-critical sets and provides accurate proposal distributions for self-normalised importance sampling. The framework is computationally robust, potentially gradient-free, and well-suited for complex forward models with strong geometric anisotropy. These results highlight ALDI as a promising tool for rare-event estimation in unstable regimes of dynamical systems."}
{"id": "2601.00239", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.00239", "abs": "https://arxiv.org/abs/2601.00239", "authors": ["Ioannis Papastathopoulos", "Jennifer Wadsworth"], "title": "Geometric extremal graphical models and coefficients of extremal dependence on block graphs", "comment": "20 pages, 5 figures", "summary": "We introduce the concept of geometric extremal graphical models, which are defined through the gauge function of the limit set obtained from suitably scaled random vectors in light-tailed margins. For block graphs, we prove results relating to the propagation of various extremal dependence coefficients along the graph. A particular focus is placed on coefficients that link to the framework of conditional extreme value theory, which are especially interesting when variables do not all attain their most extreme values simultaneously. We also consider results related to the case when variables do exhibit joint extreme behaviour. Through the recent translation of the geometric approach for multivariate extremes to a statistical modelling framework, geometric extremal graphical models, and results relating to them, pave the way for an approach to modelling of high dimensional extremes with complex extremal dependence structures."}
{"id": "2601.00350", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.00350", "abs": "https://arxiv.org/abs/2601.00350", "authors": ["Liang Hong"], "title": "The true detection probability versus the subjective detection probability of a uniformly optimal search plan", "comment": null, "summary": "This article investigates the difference between the true detection probability and the subjective probability of a uniformly optimal search plan. Its main contributions are multi-fold. First, it provides a set of examples to show that, in terms of the true detection probability, the uniformly optimal search plan may or may not be optimal. Secondly, it establishes that the true detection probability of the uniformly optimal search plan based on a composite prior can be less than that of the composite uniformly search plan based on different priors. Next, it argues that an open problem is unsolvable. Finally, it shows that the true detection probability of the uniformly optimal search plan converges to one as the search time approaches infinity."}
{"id": "2601.00793", "categories": ["math.PR", "math-ph", "math.AT"], "pdf": "https://arxiv.org/pdf/2601.00793", "abs": "https://arxiv.org/abs/2601.00793", "authors": ["Benjamin Schweinhart", "Morgan Shuman"], "title": "Voronoi Percolation: Topological Stability and Giant Cycles", "comment": null, "summary": "We study the topological stability of Voronoi percolation in higher dimensions. We show that slightly increasing p allows a discretization that preserves increasing topological properties with high probability. This strengthens a theorem of Bollobás and Riordan and generalizes it to higher dimensions. As a consequence, we prove a sharp phase transition for the emergence of i-dimensional giant cycles in Voronoi percolation on the 2i-dimensional torus."}
{"id": "2601.00161", "categories": ["math.NA", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.00161", "abs": "https://arxiv.org/abs/2601.00161", "authors": ["Jiuyang Liang", "Libin Lu", "Shidong Jiang"], "title": "Fast Ewald Summation with Prolates for Charged Systems in the NPT Ensemble", "comment": "31 pages, 9 figures", "summary": "We present an NPT extension of Ewald summation with prolates (ESP), a spectrally accurate and scalable particle-mesh method for molecular dynamics simulations of periodic, charged systems. Building on the recently introduced ESP framework, this work focuses on rigorous and thermodynamically consistent pressure/stress evaluation in the isothermal--isobaric ensemble. ESP employs prolate spheroidal wave functions as both splitting and spreading kernels, reducing the Fourier grid size needed to reach a prescribed pressure accuracy compared with current widely used mesh-Ewald methods based on Gaussian splitting and B-spline spreading. We derive a unified pressure-tensor formulation applicable to isotropic, semi-isotropic, anisotropic, and fully flexible cells, and show that the long-range pressure can be evaluated with a single forward FFT followed by diagonal scaling, whereas force evaluation requires both forward and inverse transforms. We provide production implementations in LAMMPS and GROMACS and validate pressure and force accuracy on bulk water, LiTFSI ionic liquids, and a transmembrane system. Benchmarks on up to $3\\times 10^3$ CPU cores demonstrate strong scaling and reduced communication cost at matched accuracy, particularly for NPT pressure evaluation."}
{"id": "2601.00377", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.00377", "abs": "https://arxiv.org/abs/2601.00377", "authors": ["Sijia Xia", "Michael K. Ng", "Xiongjun Zhang"], "title": "Sparse Tucker Decomposition and Graph Regularization for High-Dimensional Time Series Forecasting", "comment": null, "summary": "Existing methods of vector autoregressive model for multivariate time series analysis make use of low-rank matrix approximation or Tucker decomposition to reduce the dimension of the over-parameterization issue. In this paper, we propose a sparse Tucker decomposition method with graph regularization for high-dimensional vector autoregressive time series. By stacking the time-series transition matrices into a third-order tensor, the sparse Tucker decomposition is employed to characterize important interactions within the transition third-order tensor and reduce the number of parameters. Moreover, the graph regularization is employed to measure the local consistency of the response, predictor and temporal factor matrices in the vector autoregressive model.The two proposed regularization techniques can be shown to more accurate parameters estimation. A non-asymptotic error bound of the estimator of the proposed method is established, which is lower than those of the existing matrix or tensor based methods. A proximal alternating linearized minimization algorithm is designed to solve the resulting model and its global convergence is established under very mild conditions. Extensive numerical experiments on synthetic data and real-world datasets are carried out to verify the superior performance of the proposed method over existing state-of-the-art methods."}
{"id": "2601.00375", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.00375", "abs": "https://arxiv.org/abs/2601.00375", "authors": ["Haibin Chen", "Hong Yan", "Guanglu Zhou"], "title": "Completely Positive Reformulations of Polynomial Optimization Problems with Linear Inequality Constraints", "comment": null, "summary": "Polynomial optimization encompasses a broad class of problems in which both the objective function and constraints are polynomial functions of the decision variables. In recent years, a substantial body of research has focused on reformulating polynomial optimization problems (POPs) as conic programs over the cone of completely positive tensors (CPTs). In this article, we propose several new completely positive reformulations for a class of POPs with linear inequality constraints. Our approach begins by lifting these problems into a novel convex optimization framework, wherein the variables are represented as combinations of symmetric rank-one tensors. Based on this lifted formulation, we present a general characterization of POPs with linear inequality constraints that can be reformulated as conic programs over the CPT cone. Additionally, we construct the dual formulations of the resulting completely positive programs. Under mild assumptions, we prove that these dual problems are strictly feasible and strong duality holds."}
{"id": "2601.00107", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.00107", "abs": "https://arxiv.org/abs/2601.00107", "authors": ["Deepyaman Chakraborty", "Ruben Harris", "Rupert Klein", "Guillermo Olicón-Méndez", "Sebastian Reich", "Claudia Schillings"], "title": "Affine Invariant Langevin Dynamics for rare-event sampling", "comment": null, "summary": "We introduce an affine invariant Langevin dynamics (ALDI) framework for the efficient estimation of rare events in nonlinear dynamical systems. Rare events are formulated as Bayesian inverse problems through a nonsmooth limit-state function whose zero level set characterises the event of interest. To overcome the nondifferentiability of this function, we propose a smooth approximation that preserves the failure set and yields a posterior distribution satisfying the small-noise limit. The resulting potential is sampled by ALDI, a (derivative-free) interacting particle system whose affine invariance allows it to adapt to the local anisotropy of the posterior.\n  We demonstrate the performance of the method across a hierarchy of benchmarks, namely two low-dimensional examples (an algebraic problem with convex geometry and a dynamical problem of saddle-type instability) and a point-vortex model for atmospheric blockings. In all cases, ALDI concentrates near the relevant near-critical sets and provides accurate proposal distributions for self-normalised importance sampling. The framework is computationally robust, potentially gradient-free, and well-suited for complex forward models with strong geometric anisotropy. These results highlight ALDI as a promising tool for rare-event estimation in unstable regimes of dynamical systems."}
{"id": "2601.00193", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.00193", "abs": "https://arxiv.org/abs/2601.00193", "authors": ["Lisen Ding", "Xiangyi Peng", "Dongling Wang"], "title": "Temporal Two-Grid Compact Difference Scheme for Benjamin-Bona-Mahony-Burgers Equation", "comment": null, "summary": "This paper proposes a temporal two-grid compact difference (TTCD) scheme for solving the Benjamin-Bona-Mahony-Burgers (BBMB) equation with initial and periodic boundary conditions. The method consists of three main steps: first, solving a nonlinear system on a coarse time grid of size $τ_c$; then obtaining a coarse approximation on the fine time grid of size $τ_f$ via linear Lagrange interpolation; and finally solving a linearized scheme on the fine grid to obtain the corrected solution. The TTCD scheme reduces computational cost without sacrificing accuracy. Moreover, using the energy method, we rigorously prove the conservation property, unique solvability, convergence, and stability of the proposed scheme. It is shown that the method achieves convergence of order $\\mathcal{O}(τ_c^2 + τ_f^2 + h^4)$ in the maximum norm, where $h$ is space step size. Finally, some numerical experiments are provided to demonstrate the effectiveness and feasibility of the proposed strategy."}
{"id": "2601.00507", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.00507", "abs": "https://arxiv.org/abs/2601.00507", "authors": ["Junhyung Park", "Fanny Yang", "Thomas Icard"], "title": "Counterfactual Spaces", "comment": null, "summary": "We mathematically axiomatise the stochastics of counterfactuals, by introducing two related frameworks, called counterfactual probability spaces and counterfactual causal spaces, which we collectively term counterfactual spaces. They are, respectively, probability and causal spaces whose underlying measurable spaces are products of world-specific measurable spaces. In contrast to more familiar accounts of counterfactuals founded on causal models, we do not view interventions as a necessary component of a theory of counterfactuals. As an alternative to Pearl's celebrated ladder of causation, we view counterfactuals and interventions are orthogonal concepts, respectively mathematised in counterfactual probability spaces and causal spaces. The two concepts are then combined to form counterfactual causal spaces. At the heart of our theory is the notion of shared information between the worlds, encoded completely within the probability measure and causal kernels, and whose extremes are characterised by independence and synchronisation of worlds. Compared to existing frameworks, counterfactual spaces enable the mathematical treatment of a strictly broader spectrum of counterfactuals."}
{"id": "2601.00449", "categories": ["math.OC", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.00449", "abs": "https://arxiv.org/abs/2601.00449", "authors": ["Jonas Christoffer Villumsen", "Yusuke Sugita"], "title": "Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks", "comment": "32 pages, 12 figures", "summary": "Advances in artificial intelligence (AI) and deep learning have raised concerns about its increasing energy consumption, while demand for deploying AI in mobile devices and machines at the edge is growing. Binary neural networks (BNNs) have recently gained attention as energy and memory efficient models suitable for resource constrained environments; however, training BNNs exactly is computationally challenging because of its discrete characteristics. Recent work proposing a framework for training BNNs based on quadratic unconstrained binary optimisation (QUBO) and progress in the design of Ising machines for solving QUBO problems suggest a potential path to efficiently optimising discrete neural networks. In this work, we extend existing QUBO models for training BNNs to accommodate arbitrary network topologies and propose two novel methods for regularisation. The first method maximises neuron margins biasing the training process toward parameter configurations that yield larger pre-activation magnitudes. The second method employs a dropout-inspired iterative scheme in which reduced subnetworks are trained and used to adjust linear penalties on network parameters. We apply the proposed QUBO formulation to a small binary image classification problem and conduct computational experiments on a GPU-based Ising machine. The numerical results indicate that the proposed regularisation terms modify training behaviour and yield improvements in classification accuracy on data not present in the training set."}
{"id": "2601.00301", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.00301", "abs": "https://arxiv.org/abs/2601.00301", "authors": ["Allal Guessab", "Federico Nudo"], "title": "Spectral Schur analysis of structured moment matrices for quadratic histopolation", "comment": null, "summary": "In this paper we study parameter-dependent structured moment matrices with a canonical block form arising from weighted quadratic histopolation on simplicial meshes. For a strictly positive density on a simplex, we construct compatible face densities and an orthogonal decomposition of the quadratic polynomial space into face and interior components, which induces a natural face-interior block structure. A reduced Schur complement is identified that fully characterizes enrichment and well-posedness and provides a sharp spectral stability result. We show that this quantity coincides with the square root of the smallest eigenvalue of a low-dimensional symmetric positive definite operator. This matrix-based viewpoint yields simple spectral criteria for the invertibility of local moment systems and motivates spectrally preferable choices of face and interior bases with improved conditioning. Using the resulting degrees of freedom together with density and scaling parameters as design variables, we formulate a small eigenvalue optimization problem aimed at improving stability and reducing the condition number of the global reconstruction system. Three-dimensional experiments on uniform and quasi-uniform simplicial meshes illustrate the predicted stability, conditioning, and convergence behaviour of the enriched quadratic reconstruction."}
{"id": "2601.00541", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.00541", "abs": "https://arxiv.org/abs/2601.00541", "authors": ["Falong Tan", "Shan Tang", "Lixing Zhu"], "title": "Asymptotic Distribution-Free Tests for Ultra-high Dimensional Parametric Regressions via Projected Empirical Processes and $p$-value Combination", "comment": null, "summary": "This paper develops a novel methodology for testing the goodness-of-fit of sparse parametric regression models based on projected empirical processes and p-value combination, where the covariate dimension may substantially exceed the sample size. In such ultra-high dimensional settings, traditional empirical process-based tests often fail due to the curse of dimensionality or their reliance on the asymptotic linearity and normality of parameter estimators--properties that may not hold under ultra-high dimensional scenarios. To overcome these challenges, we first extend the classic martingale transformation to ultra-high dimensional settings under mild conditions and construct a Cramer-von Mises type test based on a martingale-transformed, projected residual-marked empirical process for any projection on the unit sphere. The martingale transformation renders this projected test asymptotically distribution-free and enables us to derive its limiting distribution using only standard convergence rates of parameter estimators. While the projected test is consistent for almost all projections on the unit sphere under mild conditions, it may still suffer from power loss for specific projections. Therefore, we further employ powerful p-value combination procedures, such as the Cauchy combination, to aggregate p-values across multiple projections, thereby enhancing overall robustness. Furthermore, recognizing that empirical process-based tests excel at detecting low-frequency signals while local smoothing tests are generally superior for high-frequency alternatives, we propose a novel hybrid test that aggregates both approaches using Cauchy combination. The resulting hybrid test is powerful against both low-frequency and high-frequency alternatives. $\\cdots$"}
{"id": "2601.00476", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.00476", "abs": "https://arxiv.org/abs/2601.00476", "authors": ["Trivikram Satharasi", "Tochukwu E. Ogri", "Muzaffar Qureshi", "Kyle Volle", "Rushikesh Kamalapurkar"], "title": "Safe Adaptive Feedback Control via Barrier States", "comment": "Submission in review for IFAC conference", "summary": "This paper presents a safe feedback control framework for nonlinear control-affine systems with parametric uncertainty by leveraging adaptive dynamic programming (ADP) with barrier-state augmentation. The developed ADP-based controller enforces control invariance by optimizing a value function that explicitly penalizes the barrier state, thereby embedding safety directly into the Bellman structure. The near-optimal control policy computed using model-based reinforcement learning is combined with a concurrent learning estimator to identify the unknown parameters and guarantee uniform convergence without requiring persistency of excitation. Using a barrier-state Lyapunov function, we establish boundedness of the barrier dynamics and prove closed-loop stability and safety. Numerical simulations on an optimal obstacle-avoidance problem validate the effectiveness of the developed approach."}
{"id": "2601.00399", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.00399", "abs": "https://arxiv.org/abs/2601.00399", "authors": ["Chunmei Wang", "Shangyou Zhang"], "title": "A weak Galerkin least squares finite element method for linear convection equations in non-divergence form", "comment": "16 pages, 14 tables, 4 figures", "summary": "This article develops a weak Galerkin least-squares (WG--LS) finite element method for first-order linear convection equations in non-divergence form. The method is formulated using discontinuous finite element functions and does not require any coercivity assumption on the convection vector or reaction coefficient. The resulting discrete problem leads to a symmetric and positive definite linear system and is applicable to general polygonal and polyhedral meshes. Under minimal regularity assumptions on the coefficients, optimal-order error estimates are established for the WG--LS approximation in a suitable energy norm. Numerical experiments are presented to confirm the theoretical convergence results and to demonstrate the accuracy and efficiency of the proposed method."}
{"id": "2601.00632", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.00632", "abs": "https://arxiv.org/abs/2601.00632", "authors": ["Giacomo Borghi", "José A. Carrillo"], "title": "Variational inference via Gaussian interacting particles in the Bures-Wasserstein geometry", "comment": null, "summary": "Motivated by variational inference methods, we propose a zeroth-order algorithm for solving optimization problems in the space of Gaussian probability measures. The algorithm is based on an interacting system of Gaussian particles that stochastically explore the search space and self-organize around global minima via a consensus-based optimization (CBO) mechanism. Its construction relies on the Linearized Bures-Wasserstein (LBW) space, a novel parametrization of Gaussian measures we introduce for efficient computations. LBW is inspired by linearized optimal transport and preserves key geometric features while enabling computational tractability. We establish well-posedness and study the convergence properties of the particle dynamics via a mean-field approximation. Numerical experiments on variational inference tasks demonstrate the algorithm's robustness and superior performance with respect to gradient-based method in presence of non log-concave targets."}
{"id": "2601.00404", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.00404", "abs": "https://arxiv.org/abs/2601.00404", "authors": ["T. Chaumont-Frelet"], "title": "Guaranteed stability bounds for second-order PDE problems satisfying a Garding inequality", "comment": null, "summary": "We propose an algorithm to numerically determined whether a second-order linear PDE problem satisfying a Garding inequality is well-posed. This algorithm further provides a lower bound to the inf-sup constant of the weak formulation, which may in turn be used for a posteriori error estimation purposes. Our numerical lower bound is based on two discrete singular value problems involving a Lagrange finite element discretization coupled with an a posteriori error estimator based on flux reconstruction techniques. We show that if the finite element discretization is sufficiently rich, our lower bound underestimates the optimal constant only by a factor roughly equal to two."}
{"id": "2601.00732", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.00732", "abs": "https://arxiv.org/abs/2601.00732", "authors": ["Michalis Ramp", "Andreas Kasis", "Stelios Timotheou"], "title": "Stability of vehicular admission control schemes in urban traffic networks under modelling uncertainty", "comment": null, "summary": "Urban transportation networks face significant challenges due to traffic congestion, leading to adverse environmental and socioeconomic impacts. Vehicular admission control (VAC) strategies have emerged as a promising solution to alleviate congestion. By leveraging information and communication technologies, VAC strategies regulate vehicle entry into the network to optimize different traffic metrics of interest over space and time. Despite the significant development of VAC strategies, their stability at the presence of modelling uncertainty remains under-explored. This paper investigates the stability properties of a class of decentralized VAC schemes under modelling uncertainty. Specifically, we consider large-scale, heterogeneous urban traffic networks characterised by nonlinear dynamics and concave macroscopic fundamental diagrams with bounded uncertainty between flow, density, and speed. In this context, we examine a broad class of decentralized VAC dynamics, described by general nonlinear forms. Using passivity theory, we derive scalable, locally verifiable conditions on the design of VAC schemes, that enable stability guarantees in the presence of modelling uncertainty. Several examples are presented to illustrate the applicability of the proposed design framework. Our analytical results are validated through numerical simulations on a 6-region system, demonstrating their effectiveness and practical relevance."}
{"id": "2601.00672", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00672", "abs": "https://arxiv.org/abs/2601.00672", "authors": ["Seungchan Ko", "Jiyeon Kim", "Dongwook Shin"], "title": "Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs", "comment": null, "summary": "In this paper, we study the finite element operator network (FEONet), an operator-learning method for parametric problems, originally introduced in J. Y. Lee, S. Ko, and Y. Hong, Finite Element Operator Network for Solving Elliptic-Type Parametric PDEs, SIAM J. Sci. Comput., 47(2), C501-C528, 2025. FEONet realizes the parameter-to-solution map on a finite element space and admits a training procedure that does not require training data, while exhibiting high accuracy and robustness across a broad class of problems. However, its computational cost increases and accuracy may deteriorate as the number of elements grows, posing notable challenges for large-scale problems. In this paper, we propose a new sparse network architecture motivated by the structure of the finite elements to address this issue. Throughout extensive numerical experiments, we show that the proposed sparse network achieves substantial improvements in computational cost and efficiency while maintaining comparable accuracy. We also establish theoretical results demonstrating that the sparse architecture can approximate the target operator effectively and provide a stability analysis ensuring reliable training and prediction."}
{"id": "2601.00729", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.00729", "abs": "https://arxiv.org/abs/2601.00729", "authors": ["Mohamed El Guide", "Alaa El Ichi", "Khalide Jbilou", "Lothar Reichel", "Hessah Alqahtani"], "title": "A Unified Trace-Optimization Framework for Multidimensionality Reduction", "comment": null, "summary": "This paper presents a comprehensive overview of several multidimensional reduction methods focusing on Multidimensional Principal Component Analysis (MPCA), Multilinear Orthogonal Neighborhood Preserving Projection (MONPP), Multidimensional Locally Linear Embedding (MLLE), and Multidimensional Laplacian Eigenmaps (MLE). These techniques are formulated within a unified framework based on trace optimization, where the dimensionality reduction problem is expressed as maximization or minimization problems. In addition to the linear MPCA and MONPP approaches, kernel-based extensions of these methods also are presented. The latter methods make it possible to capture nonlinear relations between high-dimensional data. A comparative analysis highlights the theoretical foundations, assumptions, and computational efficiency of each method, as well as their practical applicability. The study provides insights and guidelines for selecting an appropriate dimensionality reduction technique suited to the application at hand."}
