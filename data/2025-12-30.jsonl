{"id": "2512.22162", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22162", "abs": "https://arxiv.org/abs/2512.22162", "authors": ["Vladimir Vovk"], "title": "Exchangeability and randomness for infinite and finite sequences", "comment": "15 pages, 1 figure", "summary": "Randomness (in the sense of being generated in an IID fashion) and exchangeability are standard assumptions in nonparametric statistics and machine learning, and relations between them have been a popular topic of research. This note draws the reader's attention to the fact that, while for infinite sequences of observations the two assumptions are almost indistinguishable, the difference between them becomes very significant for finite sequences of a given length."}
{"id": "2512.22403", "categories": ["math.ST", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.22403", "abs": "https://arxiv.org/abs/2512.22403", "authors": ["Chia-Yu Hsu", "Shubhanshu Shekhar"], "title": "Active Nonparametric Two-Sample Testing by Betting on Heterogeneous Data Sources", "comment": null, "summary": "We study the problem of active nonparametric sequential two-sample testing over multiple heterogeneous data sources. In each time slot, a decision-maker adaptively selects one of $K$ data sources and receives a paired sample generated from that source for testing. The goal is to decide as quickly as possible whether the pairs are generated from the same distribution or not. The gain achieved by such adaptive sampling (in terms of smaller expected stopping time or larger error exponents) has been well-characterized for parametric models via Chernoff's adaptive MLE selection rule [1]. However, analogous results are not known for the case of nonparametric problems, such as two-sample testing, where we place no restrictions on the distributions.\n  Our main contribution is a general active nonparametric testing procedure that combines an adaptive source-selecting strategy within the testing-by-betting framework of [2] that works under minimal distributional assumptions. In each time slot, our scheme proceeds by selecting a source according to a probability that mixes exploitation, favoring sources with the largest empirical distinguishability, and exploration via a vanishing greedy strategy. The (paired) observations so collected are then used to update the \"betting-wealth process\", which is a stochastic process guaranteed to be a nonnegative martingale under the null. The procedure stops and rejects the null when the wealth process exceeds an appropriate threshold; an event that is unlikely under the null. We show that our test controls the type-I error at a prespecified level-$α$ under the null, and establish its power-one property and a bound on its expected sample size under the alternative. Our results provide a precise characterization of the improvements achievable by a principled adaptive sampling strategy over its passive analog."}
{"id": "2512.22412", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.22412", "abs": "https://arxiv.org/abs/2512.22412", "authors": ["Yunhong Lyu", "Bouchra R. Nasri", "Bruno N. Rémillard"], "title": "Sequential change-point detection for generalized Ornstein-Uhlenbeck processes", "comment": null, "summary": "In this article, we study sequential change-point methods for discretely observed generalized Ornstein-Uhlenbeck processes with periodic drift. Two detection methods are proposed, and their respective performance is studied through numerical experiments for several choices of parameters."}
{"id": "2512.22557", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.22557", "abs": "https://arxiv.org/abs/2512.22557", "authors": ["Xiaoda Xu", "Jun Xian"], "title": "Sharp Non-Asymptotic Bounds for the Star Discrepancy of Double-Infinite Random Matrices via Optimal Covering Numbers", "comment": null, "summary": "We establish sharp non-asymptotic probabilistic bounds for the star discrepancy of double-infinite random matrices -- a canonical model for sequences of random point sets in high dimensions. By integrating the recently proved \\textbf{optimal covering numbers for axis-parallel boxes} (Gnewuch, 2024) into the dyadic chaining framework, we achieve \\textbf{explicitly computable constants} that improve upon all previously known bounds.\n  For dimension $d \\ge 3$, we prove that with high probability, \\[ D_N^d \\le \\sqrt{αA_d + βB \\frac{\\ln \\log_2 N}{d}} \\sqrt{\\frac{d}{N}}, \\] where $A_d$ is given by an explicit series and satisfies $A_3 \\le 745$, a \\textbf{14\\% improvement} over the previous best constant of 868 (Fiedler et al., 2023). For $d=2$, we obtain the currently smallest known constant $A_2 \\le 915$.\n  Our analysis reveals a \\textbf{precise trade-off} between the dimensional dependence and the logarithmic factor in $N$, highlighting how optimal covering estimates directly translate to tighter discrepancy bounds. These results immediately yield improved error guarantees for \\textbf{quasi-Monte Carlo integration, uncertainty quantification, and high-dimensional sampling}, and provide a new benchmark for the probabilistic analysis of geometric discrepancy.\n  \\textbf{Keywords:} Star discrepancy, double-infinite random matrices, covering numbers, dyadic chaining, high-dimensional integration, quasi-Monte Carlo, probabilistic bounds."}
{"id": "2512.22421", "categories": ["math.NA", "cs.LG", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.22421", "abs": "https://arxiv.org/abs/2512.22421", "authors": ["Zihan Lin", "QiZhi He"], "title": "Differentiable Inverse Modeling with Physics-Constrained Latent Diffusion for Heterogeneous Subsurface Parameter Fields", "comment": "33 pages, 16 figures", "summary": "We present a latent diffusion-based differentiable inversion method (LD-DIM) for PDE-constrained inverse problems involving high-dimensional spatially distributed coefficients. LD-DIM couples a pretrained latent diffusion prior with an end-to-end differentiable numerical solver to reconstruct unknown heterogeneous parameter fields in a low-dimensional nonlinear manifold, improving numerical conditioning and enabling stable gradient-based optimization under sparse observations. The proposed framework integrates a latent diffusion model (LDM), trained in a compact latent space, with a differentiable finite-volume discretization of the forward PDE. Sensitivities are propagated through the discretization using adjoint-based gradients combined with reverse-mode automatic differentiation. Inversion is performed directly in latent space, which implicitly suppresses ill-conditioned degrees of freedom while preserving dominant structural modes, including sharp material interfaces. The effectiveness of LD-DIM is demonstrated using a representative inverse problem for flow in porous media, where heterogeneous conductivity fields are reconstructed from spatially sparse hydraulic head measurements. Numerical experiments assess convergence behavior and reconstruction quality for both Gaussian random fields and bimaterial coefficient distributions. The results show that LD-DIM achieves consistently improved numerical stability and reconstruction accuracy of both parameter fields and corresponding PDE solutions compared with physics-informed neural networks (PINNs) and physics-embedded variational autoencoder (VAE) baselines, while maintaining sharp discontinuities and reducing sensitivity to initialization."}
{"id": "2512.22312", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.22312", "abs": "https://arxiv.org/abs/2512.22312", "authors": ["Debraj Das", "Soumendra Lahiri"], "title": "Necessary and sufficient conditions for high dimensional Central Limit Theorem under moment conditions", "comment": null, "summary": "High dimensional central limit theorems (the CLTs) have been extensively studied in recent years under a variety of sufficient moment conditions connecting the dimension growth rate with the tail decay rate. In this article, we investigate whether the existing moment conditions are also necessary under the independence of the components. We consider four exhaustive classes, viz. when underlying random variables (I) have all polynomial moments, (II) have some polynomial moment of order higher than two, (III) have only second moment but no polynomial moment higher than two exists, and (IV) have infinite second moment, but belong to the domain of attraction of normal distribution. We find the optimal growth rate of the dimension with respect to sample size in the high dimensional CLTs over hyper-rectangles. More precisely, we derive necessary and sufficient moment conditions for the validity of the the CLT over hyper-rectangles in each of the four regimes listed above, showing that the CLT may hold under much weaker conditions compared to those considered in the existing literature."}
{"id": "2512.22347", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22347", "abs": "https://arxiv.org/abs/2512.22347", "authors": ["Austin Cooper", "Sean Meyn"], "title": "Reinforcement Learning for Optimal Stopping in POMDPs with Application to Quickest Change Detection", "comment": "24 pages, 9 figures. To appear, IEEE Trans. Auto. Control", "summary": "The field of quickest change detection (QCD) focuses on the design and analysis of online algorithms that estimate the time at which a significant event occurs. In this paper, design and analysis are cast in a Bayesian framework, where QCD is formulated as an optimal stopping problem with partial observations. An approximately optimal detection algorithm is sought using techniques from reinforcement learning. The contributions of the paper are summarized as follows: (i) A Q-learning algorithm is proposed for the general partially observed optimal stopping problem. It is shown to converge under linear function approximation, given suitable assumptions on the basis functions. An example is provided to demonstrate that these assumptions are necessary to ensure algorithmic stability. (ii) Prior theory motivates a particular choice of features in applying Q-learning to QCD. It is shown that, in several scenarios and under ideal conditions, the resulting class of policies contains one that is approximately optimal. (iii) Numerical experiments show that Q-learning consistently produces policies that perform close to the best achievable within the chosen function class."}
{"id": "2512.22714", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22714", "abs": "https://arxiv.org/abs/2512.22714", "authors": ["Matey Neykov"], "title": "Polynomial-Time Near-Optimal Estimation over Certain Type-2 Convex Bodies", "comment": null, "summary": "We develop polynomial-time algorithms for near-optimal minimax mean estimation under $\\ell_2$-squared loss in a Gaussian sequence model under convex constraints. The parameter space is an origin-symmetric, type-2 convex body $K \\subset \\mathbb{R}^n$, and we assume additional regularity conditions: specifically, we assume $K$ is well-balanced, i.e., there exist known radii $r, R > 0$ such that $r B_2 \\subseteq K \\subseteq R B_2$, as well as oracle access to the Minkowski gauge of $K$. Under these and some further assumptions on $K$, our procedures achieve the minimax rate up to small factors, depending poly-logarithmically on the dimension, while remaining computationally efficient.\n  We further extend our methodology to the linear regression and robust heavy-tailed settings, establishing polynomial-time near-optimal estimators when the constraint set satisfies the regularity conditions above. To the best of our knowledge, these results provide the first general framework for attaining statistically near-optimal performance under such broad geometric constraints while preserving computational tractability."}
{"id": "2512.22567", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.22567", "abs": "https://arxiv.org/abs/2512.22567", "authors": ["Francesco Romor", "Federico Pichi", "Giovanni Stabile", "Gianluigi Rozza", "Christoph Schwab"], "title": "ROM for Viscous, Incompressible Flow in Polygons -- exponential $n$-width bounds and convergence rate", "comment": null, "summary": "We demonstrate exponential convergence of Reduced Order Model (ROM) approximations for mixed boundary value problems of the stationary, incompressible Navier-Stokes equations in plane, polygonal domains $Ω$. Admissible boundary conditions comprise mixed BCs, no-slip, slip and open boundary conditions, subject to corner-weighted analytic boundary data and volume forcing. The small data hypothesis is assumed to ensure existence of a unique weak solution in the sense of Leray-Hopf. Recent results on corner-weighted, analytic regularity of velocity and pressure fields in $Ω$, imply exponential convergence rates of so-called mixed $hp$-Finite Element Methods in $H^1(Ω)^2\\times L^2(Ω)$ on sequences of geometric partitions of $Ω$, with corner-refinement. Based on these exponential convergence rate bounds, we infer exponential bounds for the Kolmogorov $n$-widths of solution sets for analytic forcing and boundary data. This implies corresponding exponential convergence rates of POD Galerkin methods that are based on truth solutions which are obtained offline from low-order, divergence stable mixed Finite Element discretizations. Numerical experiments confirm the exponential rates and the theoretical results."}
{"id": "2512.22330", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.22330", "abs": "https://arxiv.org/abs/2512.22330", "authors": ["Raphaël Cerf"], "title": "Revisiting De Moivre-Laplace", "comment": null, "summary": "We revisit the proof of the de Moivre--Laplace theorem, which is the ancestor of the central limit theorem for the binomial distribution. Our goal is to provide a proof that can be reasonably presented to undergraduate students within a basic course of probability theory. We follow the strategies presented in two classical references, the books of Breiman and Feller, but we replace the arguments involving series expansions of the logarithm or the exponential by the basic inequality $\\exp(t)\\geq 1+t$. This way we avoid completely the use of uniform convergence and power series. We also avoid using Stirling's formula, instead we use the exact formula for the Wallis integral. As a by product of the proof, we also obtain a non-asymptotic inequality linking the binomial and the Gaussian distributions."}
{"id": "2512.22419", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22419", "abs": "https://arxiv.org/abs/2512.22419", "authors": ["Mohannad Alkhraijah", "Devon Sigler", "Daniel K. Molzahn"], "title": "A Decomposition Method for Solving Sensitivity-Based Distributed Optimal Power Flow", "comment": null, "summary": "Efficiently solving large-scale optimal power flow (OPF) problems is challenging due to the high dimensionality and interconnectivity of modern power systems. Decomposition methods offer a promising solution via partitioning large problems into smaller subproblems that can be solved in parallel, often with local information. These approaches reduce computational burden and improve flexibility by allowing agents to manage their local models. This article introduces a decomposition method that enables a distributed solution to OPF problems. The proposed method solves OPF problems with a sensitivity-based formulation using the alternating direction method of multipliers (ADMM) algorithm. We also propose a distributed method to compute system-wide sensitivities without sharing local parameters. This approach facilitates scalable optimization while satisfying global constraints and limiting data sharing. We demonstrate the effectiveness of the proposed approach using a large set of test systems and compare its performance against existing decomposition methods. The results show that the proposed method significantly outperforms the typical phase-angle formulation with a 14-times faster computation speed on average."}
{"id": "2512.22866", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.22866", "abs": "https://arxiv.org/abs/2512.22866", "authors": ["Afshin Yaghoubi", "Esmaile Khorram", "Omid Naghshineh Arjmand"], "title": "A Recursive Exponential-Gamma Mixture: a New Generalized of the Lindley Distribution", "comment": null, "summary": "The Lindley distribution was first introduced by Lindley in 1958 for Bayesian computations. Over the past years, various generalizations of this distribution have been proposed by different authors. The generalized Lindley distributions sometimes have many parameters, and although they show good flexibility, their statistical form becomes complicated. In this article, we propose a new and simple distribution determined by the recursive relation of the Lindley distribution and the Gamma distribution with specific weights. Subsequently, some statistical properties of this distribution are examined, and with real numerical examples, its superiority over the Lindley generalizations is demonstrated."}
{"id": "2512.22708", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.22708", "abs": "https://arxiv.org/abs/2512.22708", "authors": ["A. Durán", "N. Reguera"], "title": "A high-order method for the numerical approximation of fractional nonlinear Schrödinger equations", "comment": null, "summary": "In this paper, the periodic initial-value problem for the fractional nonlinear Schrödinger (fNLS) equation is discretized in space by a Fourier spectral Galerkin method and in time by diagonally implicit, high-order Runge-Kutta schemes, based on the composition with the implicit midpoint rule (IMR). Some properties and error estimates for the semidiscretization in space and for the full discretization are proved. The convergence results and the general performance of the scheme are illustrated with several numerical experiments."}
{"id": "2512.22554", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.22554", "abs": "https://arxiv.org/abs/2512.22554", "authors": ["Fatihcan M. Atay"], "title": "On the duality between consensus problems and Markov processes, with application to delay systems", "comment": null, "summary": "We consider consensus of multi-agent systems as a dual problem to Markov processes. Based on an exchange of relevant notions and results between the two fields, we present a uniform framework which admits the introduction and treatment of time delays in a common setting. We study both information propagation and information processing delays, and for each case derive conditions for reaching consensus and calculate the consensus value."}
{"id": "2512.22512", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.22512", "abs": "https://arxiv.org/abs/2512.22512", "authors": ["Xingwu Zeng", "Can Zhang"], "title": "Small-time approximate controllability for the nonlinear complex Ginzburg-Landau equation with bilinear control", "comment": "26 pages", "summary": "In this paper, we consider the bilinear approximate controllability for the complex Ginzburg-Landau (CGL) equation with a power-type nonlinearity of any integer degree on a torus of arbitrary space dimension. Under a saturation hypothesis on the control operator, we show the small-time global controllability of the CGL equation. The proof is obtained by developing a multiplicative version of a geometric control approach, introduced by Agrachev and Sarychev in \\cite{AS05,AS06}."}
{"id": "2512.23047", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.23047", "abs": "https://arxiv.org/abs/2512.23047", "authors": ["Sayantan Banerjee"], "title": "Bayesian Effective Dimension: A Mutual Information Perspective", "comment": null, "summary": "High-dimensional Bayesian procedures often exhibit behavior that is effectively low dimensional, even when the ambient parameter space is large or infinite-dimensional. This phenomenon underlies the success of shrinkage priors, regularization, and approximate Bayesian methods, yet it is typically described only informally through notions such as sparsity, intrinsic dimension, or degrees of freedom. In this paper we introduce the \\emph{Bayesian effective dimension}, a model- and prior-dependent quantity defined through the mutual information between parameters and data. This notion quantifies the expected information gain from prior to posterior and provides a coordinate-free measure of how many directions in parameter space are statistically learnable at a given sample size. In regular parametric models the effective dimension coincides with the usual parameter dimension, while in high-dimensional, ill-posed, or strongly regularized settings it can be substantially smaller. We develop basic properties of the effective dimension and present explicit calculations for Gaussian location models and linear models with general design, revealing close connections with spectral complexity and effective rank. These examples illustrate how shrinkage and regularization mechanisms directly control the growth of effective dimension. The framework offers a unifying perspective on dimension reduction in Bayesian inference and provides insight into uncertainty quantification and the behavior of approximate posterior distributions."}
{"id": "2512.22831", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.22831", "abs": "https://arxiv.org/abs/2512.22831", "authors": ["Endre Süli", "Dennis Trautwein"], "title": "Convergent numerical schemes for the viscoelastic Giesekus model in two dimensions", "comment": null, "summary": "In this work, we develop a class of stable and convergent numerical methods for the approximate solution of the viscoelastic Giesekus model in two space dimensions. The model couples the incompressible Navier--Stokes equations with an evolution equation for an additional stress tensor accounting for elastic effects. This coupled evolution equation is stated here in terms of the elastic deformation gradient and models transport and nonlinear relaxation effects. In the existing literature, numerical schemes for such models often suffer from accuracy limitations and convergence problems, usually due to the lack of rigorous existence results or inherent limitations of the discretization. Therefore, our main goal is to prove the (subsequence) convergence of the proposed numerical method to a large-data global weak solution in two dimensions, without relying on cut-offs or additional regularization. This also provides an alternative proof of the recent existence result by Bulíček et al.~(Nonlinearity, 2022). Finally, we verify the practicality of the proposed method through numerical experiments, including convergence studies and typical benchmark problems."}
{"id": "2512.22592", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.22592", "abs": "https://arxiv.org/abs/2512.22592", "authors": ["Vladimir Vatutin", "Elena Dyakonova"], "title": "Limit theorems for critical branching processes in an extremely unfavorable random environment", "comment": "26 pages", "summary": "Let $\\{Z_{m},m\\geq 0\\}$ be a critical branching process in random environment and $\\{S_{m},m\\geq 0\\}$ be its associated random walk. Assuming that the increments distribution of the associated random walk belongs without centering to the domain of attraction of an $α$-stable law we prove conditional limit theorems describing, as $n\\rightarrow \\infty $, the distribution the number of particles in the process $\\{Z_{m},0\\leq m\\leq n\\}$ given $Z_{n}>0$ and $S_{n}\\leq const$."}
{"id": "2512.22561", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22561", "abs": "https://arxiv.org/abs/2512.22561", "authors": ["N. Dinh", "M. A. Goberna", "D. H. Long", "M. Volle"], "title": "Robust generalized S-Procedure", "comment": "11 pages", "summary": "We introduce in this paper the so-called robust generalized S-procedure associated with a given robust optimization problem. We provide a primal characterization for the validity of this procedure as well as a dual characterization under the assumption that the decision space is locally convex. We also analyze an extension of the mentioned robust S-procedure that incorporates a right-hand side function."}
{"id": "2512.23069", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.23069", "abs": "https://arxiv.org/abs/2512.23069", "authors": ["Eyar Azar", "Michael J. Feldman", "Boaz Nadler"], "title": "Robustness of OLS to sample removals: Theoretical analysis and implications", "comment": null, "summary": "For learned models to be trustworthy, it is essential to verify their robustness to perturbations in the training data. Classical approaches involve uncertainty quantification via confidence intervals and bootstrap methods. In contrast, recent work proposes a more stringent form of robustness: stability to the removal of any subset of $k$ samples from the training set. In this paper, we present a theoretical study of this criterion for ordinary least squares (OLS). Our contributions are as follows: (1) Given $n$ i.i.d. training samples from a general misspecified model, we prove that with high probability, OLS is robust to the removal of any $k \\ll n $ samples. (2) For data of dimension $p$, OLS can withstand up to ${k\\ll \\sqrt{np}/\\log n}$ sample removals while remaining robust and achieving the same error rate as OLS applied to the full dataset. Conversely, if $k$ is proportional to $n$, OLS is provably non-robust. (3) We revisit prior analyses that found several econometric datasets to be highly non-robust to sample removals. While this appears to contradict our results in (1), we demonstrate that the sensitivity is due to either heavy-tailed responses or correlated samples. Empirically, this sensitivity is considerably attenuated by classical robust methods, such as linear regression with a Huber loss."}
{"id": "2512.23182", "categories": ["math.NA", "math.SP"], "pdf": "https://arxiv.org/pdf/2512.23182", "abs": "https://arxiv.org/abs/2512.23182", "authors": ["Xuefeng Liu", "Michael Plum"], "title": "A Two-Stage Finite Element Approach for High-precision Guaranteed Lower Eigenvalue Bounds", "comment": "45 pages, 9 figures", "summary": "Obtaining high-precision guaranteed lower eigenvalue bounds remains difficult, even though the standard high-order conforming finite element (FEM) easily yields extremely sharp upper bounds. Recently developed rigorous approaches using such as Crouzeix--Raviart or linear conforming elements do not extend well to high-order FEM. Some non-standard FEM approaches can provide sharp eigenvalue bounds but are technically involved. This persistent gap between accurate upper bounds and equally sharp rigorous lower bounds via standard high-order conforming FEMs makes the problem technically demanding and highly competitive. In this paper, we propose a new two-stage rigorous algorithm that closes this gap by employing high-order FEM on graded meshes and producing rigorous lower eigenvalue bounds as sharp as the corresponding high-order upper bounds, as demonstrated in our numerical examples. Numerical experiments for the Laplacian and Steklov eigenvalue problems on square and dumbbell domains show the accuracy and efficiency of the method, particularly on graded or highly nonuniform meshes. These results confirm that the proposed approach provides a practical and competitive solution to the long-standing difficulty of obtaining sharp, reliable lower eigenvalue bounds."}
{"id": "2512.22773", "categories": ["math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.22773", "abs": "https://arxiv.org/abs/2512.22773", "authors": ["Julia Gaudio", "Andrew Jin"], "title": "Exact Recovery in the Geometric SBM", "comment": "38 pages", "summary": "Community detection is the problem of identifying dense communities in networks. Motivated by transitive behavior in social networks (\"thy friend is my friend\"), an emerging line of work considers spatially-embedded networks, which inherently produce graphs containing many triangles. In this paper, we consider the problem of exact label recovery in the Geometric Stochastic Block Model (GSBM), a model proposed by Baccelli and Sankararaman as the spatially-embedded analogue of the well-studied Stochastic Block Model. Under mild technical assumptions, we completely characterize the information-theoretic threshold for exact recovery, generalizing the earlier work of Gaudio, Niu, and Wei."}
{"id": "2512.22642", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22642", "abs": "https://arxiv.org/abs/2512.22642", "authors": ["Anbang Liu", "Shaochong Lin", "Jingchuan Chen", "Peng Wu", "Zuojun Max Shen"], "title": "A Survey of Machine-Learning-Based Scheduling: From Solver-Centric to Data-Centric Paradigms", "comment": null, "summary": "Scheduling problems are a fundamental class of combinatorial optimization problems that underpin operational efficiency in manufacturing, logistics, and service systems. While operations research has traditionally developed solver-centric methods emphasizing model structure and optimality, recent advances in machine learning are reshaping scheduling into a data-centric discipline that learns from experience and adapts to dynamic environments. This paper provides a comprehensive and comparative review of this methodological transition. We first revisit classical optimization-based approaches and summarize how ML has been integrated within them to improve computational efficiency. We then review end-to-end learning approaches that generate scheduling solutions directly from data, highlighting how they shift decision-making from explicit optimization to learned inference. Adopting a systematic, method-oriented perspective, we compare these paradigms and their underlying learning algorithms in terms of principles, scalability, interpretability, and generalization. Finally, we discuss key research challenges and outline future directions along three interdependent dimensions, scalability, reliability, and universality, that together define a pathway toward adaptive, intelligent, and trustworthy scheduling systems for data-driven operations management."}
{"id": "2512.23308", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23308", "abs": "https://arxiv.org/abs/2512.23308", "authors": ["Jyotishka Datta", "Nicholas G. Polson", "Vadim Sokolov", "Daniel Zantedeschi"], "title": "Conformal Prediction = Bayes?", "comment": null, "summary": "Conformal prediction (CP) is widely presented as distribution-free predictive inference with finite-sample marginal coverage under exchangeability. We argue that CP is best understood as a rank-calibrated descendant of the Fisher-Dempster-Hill fiducial/direct-probability tradition rather than as Bayesian conditioning in disguise.\n  We establish four separations from coherent countably additive predictive semantics. First, canonical conformal constructions violate conditional extensionality: prediction sets can depend on the marginal design P(X) even when P(Y|X) is fixed. Second, any finitely additive sequential extension preserving rank calibration is nonconglomerable, implying countable Dutch-book vulnerabilities. Third, rank-calibrated updates cannot be realized as regular conditionals of any countably additive exchangeable law on Y^infty. Fourth, formalizing both paradigms as families of one-step predictive kernels, conformal and Bayesian kernels coincide only on a Baire-meagre subset of the space of predictive laws.\n  We further show that rank- and proxy-based reductions are generically Blackwell-deficient relative to full-data experiments, yielding positive Le Cam deficiency for suitable losses. Extending the analysis to prediction-powered inference (PPI) yields an analogous message: bias-corrected, proxy-rectified estimators can be valid as confidence devices while failing to define transportable belief states across stages, shifts, or adaptive selection. Together, the results sharpen a general limitation of wrappers: finite-sample calibration guarantees do not by themselves supply composable semantics for sequential updating or downstream decision-making."}
{"id": "2512.23238", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23238", "abs": "https://arxiv.org/abs/2512.23238", "authors": ["Tao Lin", "Yuanhui Lin", "Xu Zhang"], "title": "Frenet Immersed Finite Element Spaces on Triangular Meshes", "comment": null, "summary": "In this paper, we develop geometry-conforming immersed finite element (GC-IFE) spaces on triangular meshes for elliptic interface problems. These IFE spaces are constructed via a Frenet-Serret mapping that transforms the interface curve into a straight line, allowing the interface jump conditions to be imposed exactly. Extending the framework of [7,8] from rectangular to triangular meshes, we introduce three procedures for constructing high-degree Frenet-IFE spaces: an initial construction based on monomial bases, a generalized construction using orthogonal polynomials, and reconstruction methods aimed at improving the conditioning of the associated mass matrix. The optimal approximation capability of the proposed IFE spaces is demonstrated through numerical examples. We further incorporate these spaces into interior penalty discontinuous Galerkin methods for elliptic interface problems and observe optimal convergence rates in the $H^1$ and $L^2$ norms."}
{"id": "2512.22803", "categories": ["math.PR", "cs.DS", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.22803", "abs": "https://arxiv.org/abs/2512.22803", "authors": ["Dan Mikulincer", "Youngtak Sohn"], "title": "Fast mixing in Ising models with a negative spectral outlier via Gaussian approximation", "comment": "42 pages", "summary": "We study the mixing time of Glauber dynamics for Ising models in which the interaction matrix contains a single negative spectral outlier. This class includes the anti-ferromagnetic Curie-Weiss model, the anti-ferromagnetic Ising model on expander graphs, and the Sherrington-Kirkpatrick model with disorder of negative mean. Existing approaches to rapid mixing rely crucially on log-concavity or spectral width bounds and therefore can break down in the presence of a negative outlier.\n  To address this difficulty, we develop a new covariance approximation method based on Gaussian approximation. This method is implemented via an iterative application of Stein's method to quadratic tilts of sums of bounded random variables, which may be of independent interest. The resulting analysis provides an operator-norm control of the full correlation structure under arbitrary external fields. Combined with the localization schemes of Eldan and Chen, these estimates lead to a modified logarithmic Sobolev inequality and near-optimal mixing time bounds in regimes where spectral width bounds fail. As a complementary result, we prove exponential lower bounds on the mixing time for low temperature anti-ferromagnetic Ising models on sparse Erdös-Rényi graphs, based on the existence of gapped states as in the recent work of Sellke."}
{"id": "2512.22750", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22750", "abs": "https://arxiv.org/abs/2512.22750", "authors": ["Jiachen Jin", "Kangkang Deng", "Hongxia Wang"], "title": "A Single-loop Stochastic Riemannian ADMM for Nonsmooth Optimization", "comment": null, "summary": "We study a class of nonsmooth stochastic optimization problems on Riemannian manifolds. In this work, we propose MARS-ADMM, the first stochastic Riemannian alternating direction method of multipliers with provable near-optimal complexity guarantees. Our algorithm incorporates a momentum-based variance-reduced gradient estimator applied exclusively to the smooth component of the objective, together with carefully designed penalty parameter and dual stepsize updates. Unlike existing approaches that rely on computationally expensive double-loop frameworks, MARS-ADMM operates in a single-loop fashion and requires only a constant number of stochastic gradient evaluations per iteration. Under mild assumptions, we establish that MARS-ADMM achieves an iteration complexity of \\(\\tilde{\\mathcal{O}}(\\varepsilon^{-3})\\), which improves upon the previously best-known bound of \\(\\mathcal{O}(\\varepsilon^{-3.5})\\) for stochastic Riemannian operator-splitting methods. As a result, our analysis closes the theoretical complexity gap between stochastic Riemannian operator-splitting algorithms and stochastic methods for nonsmooth optimization with nonlinear constraints. Notably, the obtained complexity also matches the best-known bounds in deterministic nonsmooth Riemannian optimization, demonstrating that deterministic-level accuracy can be achieved using only constant-size stochastic samples."}
{"id": "2512.23425", "categories": ["math.ST", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23425", "abs": "https://arxiv.org/abs/2512.23425", "authors": ["William Kengne", "Modou Wade"], "title": "A general framework for deep learning", "comment": null, "summary": "This paper develops a general approach for deep learning for a setting that includes nonparametric regression and classification. We perform a framework from data that fulfills a generalized Bernstein-type inequality, including independent, $φ$-mixing, strongly mixing and $\\mathcal{C}$-mixing observations. Two estimators are proposed: a non-penalized deep neural network estimator (NPDNN) and a sparse-penalized deep neural network estimator (SPDNN). For each of these estimators, bounds of the expected excess risk on the class of Hölder smooth functions and composition Hölder functions are established. Applications to independent data, as well as to $φ$-mixing, strongly mixing, $\\mathcal{C}$-mixing processes are considered. For each of these examples, the upper bounds of the expected excess risk of the proposed NPDNN and SPDNN predictors are derived. It is shown that both the NPDNN and SPDNN estimators are minimax optimal (up to a logarithmic factor) in many classical settings."}
{"id": "2512.23357", "categories": ["math.NA", "math.CV"], "pdf": "https://arxiv.org/pdf/2512.23357", "abs": "https://arxiv.org/abs/2512.23357", "authors": ["Michael S. Ackermann", "Sean Reiter", "Lloyd N. Trefethen"], "title": "$L^2$ and $L^\\infty$ rational approximation", "comment": null, "summary": "Using recently developed algorithms, we compute and compare best $L^2$ and $L^\\infty$ rational approximations of analytic functions on the unit disk. Although there is some theory for these problems going back decades, this may be the first computational study. To compute the $L^2$ best approximations, we employ a new formulation of TF-IRKA in barycentric form."}
{"id": "2512.22836", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.22836", "abs": "https://arxiv.org/abs/2512.22836", "authors": ["Vitaliy Golomoziy"], "title": "Submartingale Condition for Weak Convergence for Semi-Markov Processes", "comment": null, "summary": "In this paper, we consider a modified version of a well-known submartingale condition fortheweak convergence of probabilitymeasures, adapted to the semi-Markov case. In this setting, it is convenient to work with an embedded Markov chain and the filtration generated by jump times. We demonstrate that a straightforward restatement of the classical result is not valid, and that an additional condition is required."}
{"id": "2512.22806", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22806", "abs": "https://arxiv.org/abs/2512.22806", "authors": ["Jorge I. Poveda", "Mahmoud Abdelgalil"], "title": "On Composite Foster Functions for a Class of Singularly Perturbed Stochastic Hybrid Inclusions", "comment": null, "summary": "We study sufficient conditions for stability and recurrence in a class of singularly perturbed stochastic hybrid dynamical systems. The systems considered combine multi-time-scale deterministic continuous-time dynamics, modeled by constrained differential inclusions, with discrete-time dynamics described by constrained difference inclusions subject to random disturbances. Under suitable regularity assumptions on the dynamics and causality of the associated solutions, we develop a family of composite nonsmooth Lagrange-Foster and Lyapunov-Foster functions that certify stability and recurrence properties by leveraging simpler functions related to the slow and fast subsystems. Stability is characterized with respect to compact sets, while recurrence is established for bounded open sets. The proposed framework is illustrated through several examples and applications, including the stability analysis of singularly perturbed switching systems with stochastic spontaneous mode transitions, feedback optimization problems with stochastically switching plants, and momentum-based feedback optimization algorithms with stochastic restarting."}
{"id": "2512.22773", "categories": ["math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.22773", "abs": "https://arxiv.org/abs/2512.22773", "authors": ["Julia Gaudio", "Andrew Jin"], "title": "Exact Recovery in the Geometric SBM", "comment": "38 pages", "summary": "Community detection is the problem of identifying dense communities in networks. Motivated by transitive behavior in social networks (\"thy friend is my friend\"), an emerging line of work considers spatially-embedded networks, which inherently produce graphs containing many triangles. In this paper, we consider the problem of exact label recovery in the Geometric Stochastic Block Model (GSBM), a model proposed by Baccelli and Sankararaman as the spatially-embedded analogue of the well-studied Stochastic Block Model. Under mild technical assumptions, we completely characterize the information-theoretic threshold for exact recovery, generalizing the earlier work of Gaudio, Niu, and Wei."}
{"id": "2512.23362", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.23362", "abs": "https://arxiv.org/abs/2512.23362", "authors": ["Duan-Peng Ling", "Wenlong Zhang"], "title": "A Data-Driven Approach to Solving First-Kind Fredholm Integral Equations and Their Convergence Analysis", "comment": null, "summary": "We investigate the statistical recovery of solutions to first-kind Fredholm integral equations with discrete, scattered, and noisy pointwise measurements. Assuming the forward operator's range belongs to the Sobolev space of order $m$, which implies algebraic singular-value decay $s_j\\le Cj^{-m}$, we derive optimal upper bounds for the reconstruction error in the weak topology under an a priori choice of the regularization parameter. For bounded-variance noise, we establish mean-square error rates that explicitly quantify the dependence on sample size $n$, noise level $σ$, and smoothness index $m$; under sub-Gaussian noise, we strengthen these to exponential concentration bounds. The analysis yields an explicit a priori and a posteriori rule for the regularization parameter. Numerical experiments validate the theoretical results and demonstrate the efficiency of our practical parameter choice."}
{"id": "2512.22844", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.22844", "abs": "https://arxiv.org/abs/2512.22844", "authors": ["Panqiu Xia", "Jiayu Zheng"], "title": "Discrete Feynman-Kac approximation for parabolic Anderson model using random walks", "comment": "30 pages, 1 figure", "summary": "In this paper, we introduce a natively positive approximation method based on the Feynman-Kac representation using random walks, to approximate the solution to the one-dimensional parabolic Anderson model of Skorokhod type, with either a flat or a Dirac delta initial condition. Assuming the driving noise is a fractional Brownian sheet with Hurst parameters $H \\geq \\frac{1}{2}$ and $H_* \\geq \\frac{1}{2}$ in time and space, respectively, we also provide an error analysis of the proposed method. The error in $L^p (Ω)$ norm is of order \\[ O \\big(h^{\\frac{1}{2}[(2H + H_* - 1) \\wedge 1] - ε}\\big), \\] where $h > 0$ is the step size in time (resp. $\\sqrt{h}$ in space), and $ε> 0$ can be chosen arbitrarily small. This error order matches the Hölder continuity of the solution in time with a correction order $ε$, making it `almost' optimal. Furthermore, these results provide a quantitative framework for convergence of the partition function of directed polymers in Gaussian environments to the parabolic Anderson model."}
{"id": "2512.22817", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22817", "abs": "https://arxiv.org/abs/2512.22817", "authors": ["Sedi Bartz", "Heinz H. Bauschke", "Yuan Gao"], "title": "Baillon-Bruck-Reich revisited: divergent-series parameters and strong convergence in the linear case", "comment": "5 pages, 0 figures", "summary": "The Krasnoselskii-Mann iteration is an important algorithm in optimization and variational analysis for finding fixed points of nonexpansive mappings. In the general case, it produces a sequence converging \\emph{weakly} to a fixed point provided the parameter sequence satisfies a divergent-series condition.\n  In this paper, we show that \\emph{strong} convergence holds provided the underlying nonexpansive mapping is \\emph{linear}. This improves on a celebrated result by Baillon, Bruck, and Reich from 1978, where the parameter sequence was assumed to be constant as well as on recent work where the parameters were bounded away from $0$ and $1$."}
{"id": "2512.23643", "categories": ["math.NA", "cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23643", "abs": "https://arxiv.org/abs/2512.23643", "authors": ["Konstantin Yakovlev", "Nikita Puchkin"], "title": "Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks", "comment": "38 pages", "summary": "We present a theory for simultaneous approximation of the score function and its derivatives, enabling the handling of data distributions with low-dimensional structure and unbounded support. Our approximation error bounds match those in the literature while relying on assumptions that relax the usual bounded support requirement. Crucially, our bounds are free from the curse of dimensionality. Moreover, we establish approximation guarantees for derivatives of any prescribed order, extending beyond the commonly considered first-order setting."}
{"id": "2512.23363", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23363", "abs": "https://arxiv.org/abs/2512.23363", "authors": ["Tommaso Taddei", "Xuejun Xu", "Lei Zhang"], "title": "High-order implicit Runge-Kutta time integrators for component-based model reduction of FSI problems", "comment": null, "summary": "We propose a model order reduction framework for incompressible fluid-structure interaction (FSI) problems based on high-order implicit Runge-Kutta (IRK) methods. We consider separate reduced spaces for fluid velocity, fluid pressure and solid displacement; we enrich the velocity space with supremizer modes to ensure the inf-sup stability of the fluid subproblem; we consider bubble-port decomposition of fluid velocity and solid displacement to satisfy the kinematic conditions at the fluid structure interface. We resort to Galerkin projection to define the semi-discrete reduced-order model and we consider a Radau-IIA IRK method for time integration: the resulting algebraic system is solved using static condensation of the interface degrees of freedom. The reduced-order model preserves a semi-discrete energy balance inherited from the full-order model, and avoids the need for additional interface enrichment. Numerical experiments demonstrate that the proposed combination of high-order IRK schemes with bubble-port decoupling of velocity and displacement degrees of freedom yields stable and accurate reduced-order model for long-time integration of strongly-coupled parametric FSI problems."}
{"id": "2512.22935", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.22935", "abs": "https://arxiv.org/abs/2512.22935", "authors": ["René L. Schilling", "Jian Wang", "Bingyao Wu", "Jie-Xiang Zhu"], "title": "Convergence rates for the $p$-Wasserstein distance of the empirical measures of an ergodic Markov process", "comment": "25 pages", "summary": "Let $X:=(X_t)_{t\\geq 0}$ be an ergodic Markov process on $\\real^d$, and $p>0$. We derive upper bounds of the $p$-Wasserstein distance between the invariant measure and the empirical measures of the Markov process $X$. For this we assume, e.g.\\ that the transition semigroup of $X$ is exponentially contractive in terms of the $1$-Wasserstein distance, or that the iterated Poincaré inequality holds together with certain moment conditions on the invariant measure. Typical examples include diffusions and underdamped Langevin dynamics."}
{"id": "2512.22909", "categories": ["math.OC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.22909", "abs": "https://arxiv.org/abs/2512.22909", "authors": ["Zhaosong Lu", "Sanyou Mei"], "title": "A first-order method for nonconvex-strongly-concave constrained minimax optimization", "comment": "Accepted by Optimization Methods and Software", "summary": "In this paper we study a nonconvex-strongly-concave constrained minimax problem. Specifically, we propose a first-order augmented Lagrangian method for solving it, whose subproblems are nonconvex-strongly-concave unconstrained minimax problems and suitably solved by a first-order method developed in this paper that leverages the strong concavity structure. Under suitable assumptions, the proposed method achieves an \\emph{operation complexity} of $O(\\varepsilon^{-3.5}\\log\\varepsilon^{-1})$, measured in terms of its fundamental operations, for finding an $\\varepsilon$-KKT solution of the constrained minimax problem, which improves the previous best-known operation complexity by a factor of $\\varepsilon^{-0.5}$."}
{"id": "2512.23476", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23476", "abs": "https://arxiv.org/abs/2512.23476", "authors": ["Laura Weidensager"], "title": "Sensitivity Analysis on the Sphere and a Spherical ANOVA Decomposition", "comment": null, "summary": "We establish sensitivity analysis on the sphere. We present formulas that allow us to decompose a function $f\\colon \\mathbb S^d\\rightarrow \\mathbb R$ into a sum of terms $f_{\\boldsymbol u,\\boldsymbol ξ}$. The index $\\boldsymbol u$ is a subset of $\\{1,2,\\ldots,d+1\\}$, where each term $f_{\\boldsymbol u,\\boldsymbol ξ}$ depends only on the variables with indices in $\\boldsymbol u$. In contrast to the classical analysis of variance (ANOVA) decomposition, we additionally use the decomposition of a function into functions with different parity, which adds the additional parameter $\\boldsymbol ξ$. The natural geometry on the sphere naturally leads to the dependencies between the input variables. Using certain orthogonal basis functions for the function approximation, we are able to model high-dimensional functions with low-dimensional variable interactions."}
{"id": "2512.23164", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.23164", "abs": "https://arxiv.org/abs/2512.23164", "authors": ["Min Wang"], "title": "Infinite divisibility of $α$-Cauchy and related variables", "comment": "14 pages", "summary": "We study the infinite divisibility of the $α$-Cauchy variable $\\mathcal{C}_α$, $α> 1$. The distribution of $\\mathcal{C}_2$ is the well-known Cauchy distribution, which is infinitely divisible and even stable. But when $α\\neq 2$, there is no known result on the infinite divisibility of $\\mathcal{C}_α$. In this paper, we prove that $\\mathcal{C}_α$ is infinitely divisible if $1 < α\\leq 6/5$, and we give some sufficient conditions for $|\\mathcal{C}_α|^p, \\, p\\in \\mathbb{R},$ to be infinitely divisible, which partially answers the open questions raised by Yano, Yano and Yor in 2009. In the proofs, a class of positive random variables having moments of Gamma type plays an important role, and we investigate the conditions for their existence."}
{"id": "2512.22961", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22961", "abs": "https://arxiv.org/abs/2512.22961", "authors": ["Mathieu Laurière", "Mehdi Talbi"], "title": "Deep Learning for the Multiple Optimal Stopping Problem", "comment": null, "summary": "This paper presents a novel deep learning framework for solving multiple optimal stopping problems in high dimensions. While deep learning has recently shown promise for single stopping problems, the multiple exercise case involves complex recursive dependencies that remain challenging. We address this by combining the Dynamic Programming Principle with neural network approximation of the value function. Unlike policy-search methods, our algorithm explicitly learns the value surface. We first consider the discrete-time problem and analyze neural network training error. We then turn to continuous problems and analyze the additional error due to the discretization of the underlying stochastic processes. Numerical experiments on high-dimensional American basket options and nonlinear utility maximization demonstrate that our method provides an efficient and scalable method for the multiple optimal stopping problem."}
{"id": "2512.23540", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23540", "abs": "https://arxiv.org/abs/2512.23540", "authors": ["Mehdi Hamzehnejad", "Abbas Salemi"], "title": "Error Estimates for Gauss--Christoffel Quadrature under Reduced Regularity Conditions", "comment": "14 pages, 3 tables", "summary": "Gauss--Christoffel quadrature is a fundamental method for numerical integration, and its convergence analysis is closely related to the decay of Chebyshev expansion coefficients. Classical estimates, including those due to Trefethen, are based on weighted bounded variation assumptions involving the singular weight $(1-x^{2})^{-1/2}$, which may be too restrictive for functions with limited regularity at the endpoints.\n  In this paper, we establish a new error bound for Gauss--Christoffel quadrature under weakened regularity assumptions. The analysis relies on a new identity for higher-order derivatives of Chebyshev polynomials. As a consequence, we obtain an improved decay estimate for Chebyshev coefficients, where the classical weighted condition \\[ V_{r}=\\int_{-1}^{1}\\frac{|f^{(r+1)}(x)|}{\\sqrt{1-x^{2}}}\\,dx \\] is replaced by the weaker condition \\[ U_{r}=\\int_{-1}^{1}|f^{(r+1)}(x)|\\,dx. \\]\n  This result leads to a corresponding error estimate for the Gauss--Christoffel quadrature rule, which is less restrictive than previous bounds. The approach is also extended to the Gauss--Gegenbauer case. Numerical experiments are provided to illustrate the theoretical results."}
{"id": "2512.23179", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.23179", "abs": "https://arxiv.org/abs/2512.23179", "authors": ["Min Wang"], "title": "An example of a non-log-concave distribution where the difference has a log-concave density", "comment": "2 pages", "summary": "By the Prékopa-Leindler inequality, the difference $X-X'$ has a log-concave density provided that $X$ has a log-concave density and $X, X'$ are independent and identically distributed. We prove that the opposite direction does not always hold true by giving an explicit example."}
{"id": "2512.22986", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22986", "abs": "https://arxiv.org/abs/2512.22986", "authors": ["Siyi Wang", "Zifan Wang", "Karl H. Johansson"], "title": "Risk-Averse Learning with Varying Risk Levels", "comment": null, "summary": "In safety-critical decision-making, the environment may evolve over time, and the learner adjusts its risk level accordingly. This work investigates risk-averse online optimization in dynamic environments with varying risk levels, employing Conditional Value-at-Risk (CVaR) as the risk measure. To capture the dynamics of the environment and risk levels, we employ the function variation metric and introduce a novel risk-level variation metric. Two information settings are considered: a first-order scenario, where the learner observes both function values and their gradients; and a zeroth-order scenario, where only function evaluations are available. For both cases, we develop risk-averse learning algorithms with a limited sampling budget and analyze their dynamic regret bounds in terms of function variation, risk-level variation, and the total number of samples. The regret analysis demonstrates the adaptability of the algorithms in non-stationary and risk-sensitive settings. Finally, numerical experiments are presented to demonstrate the efficacy of the methods."}
{"id": "2512.23580", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23580", "abs": "https://arxiv.org/abs/2512.23580", "authors": ["Zhirui Tang", "Julian Koellermeier", "Emil Løvbak", "Giovanni Samaey"], "title": "Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications", "comment": "Section 5.6 of this article builds upon the numerical results presented in arXiv:2509.11883 and these articles contain some textual overlap", "summary": "In plasma edge simulations, the behavior of neutral particles is often described by a Boltzmann--BGK equation. Solving this kinetic equation and estimating the moments of its solution are essential tasks, typically carried out using Monte Carlo (MC) methods. However, for large-sized reactors, like ITER and DEMO, high collision rates lead to a substantial computational cost. To accelerate the calculation, an asymptotic-preserving kinetic-diffusion Monte Carlo (KDMC) simulation method (Mortier et al., SIAM J. Sci. Comput., 2022) and a corresponding fluid estimation technique (Mortier et al., Contrib. Plasma Phys., 2022) have recently been proposed. In this work, we present a comprehensive analysis of the convergence of KDMC combined with the associated fluid estimation. The analysis consists of proving theoretical upper bounds for both KDMC and the fluid estimation, and numerical verifications of these bounds. In addition, we compare the analyzed algorithm with a purely fluid-based method using the fully kinetic MC method as a reference. The algorithm consistently achieves lower error than the fluid-based method, and even one order of magnitude lower in a fusion-relevant test case. Moreover, the algorithm exhibits a significant speedup compared to the reference kinetic MC method. Overall, our analysis confirms the effectiveness of KDMC with the associated fluid estimation in nuclear fusion applications."}
{"id": "2512.23195", "categories": ["math.PR", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23195", "abs": "https://arxiv.org/abs/2512.23195", "authors": ["Shuta Nakajima"], "title": "Uniqueness of Replica-symmetric Saddle Point for Ising Perceptron", "comment": "21 pages. Even though the proof is entirely analytic, we independently perform numerical checks (see https://github.com/njimaMath/research_public/blob/main/perceptronFixed/numerics/numerics_report.pdf)", "summary": "We study the replica-symmetric saddle point equations for the Ising perceptron with Gaussian disorder and margin $κ\\ge 0$. We prove that for each $κ\\ge 0$ there is a critical capacity $α_c(κ)=\\frac{2}{π\\,\\mathbb E[(κ-Z)_+^2]}$, where $Z$ is a standard normal and $(x)_+=\\max\\{x,0\\}$, such that the saddle point equation has a unique solution for $α\\in(0,α_c(κ))$ and has no solution when $α\\ge α_c(κ)$. When $α\\uparrow α_c(κ)$ and $κ>0$, the replica-symmetric free energy at this solution diverges to $-\\infty$. In the zero-margin case $κ=0$, Ding and Sun obtained a conditional uniqueness result, with one step verified numerically. Our argument gives a fully analytic proof without computer assistance. We used GPT-5 to help develop intermediate proof steps and to perform sanity-check computations."}
{"id": "2512.23115", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23115", "abs": "https://arxiv.org/abs/2512.23115", "authors": ["Eilon Solan", "Avraham Tabbach", "Chang Zhao"], "title": "The Design of Optimal Dependency and Rewards", "comment": null, "summary": "We analyze a two-period principal-agent model in which the principal faces a budget constraint, and the agent's private costs of performing tasks across the two periods may be correlated. We examine the optimal design of the reward scheme and the cost correlation structure. Our findings reveal that when the budget is low, the optimal reward scheme employs \\textit{sufficient performance targeting}, rewarding the agent's first performance. Conversely, when the principal's budget is high, the focus shifts to \\textit{sustained performance targeting}, compensating the agent's second performance. Introducing a negative cost correlation proves particularly beneficial in both scenarios: it increases the likelihood of the agent performing at least once under low budgets and balances the agent's total costs to facilitate consistent performance under high budgets. However, the optimal cost correlation structure can be more elaborate, especially for intermediate budget levels. Our results offer valuable insights for real-world applications, such as research funding allocation."}
{"id": "2512.23621", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23621", "abs": "https://arxiv.org/abs/2512.23621", "authors": ["Luxuan Yang", "Fei Lu", "Ting Gao", "Wei Wei", "Jinqiao Duan"], "title": "Learning Lévy density via adaptive RKHS regression with bi-level optimization", "comment": null, "summary": "We propose a nonparametric method to learn the Lévy density from probability density data governed by a nonlocal Fokker-Planck equation. We recast the problem as identifying the kernel in a nonlocal integral operator from discrete data, which leads to an ill-posed inverse problem. To regularize it, we construct an adaptive reproducing kernel Hilbert space (RKHS) whose kernel is built directly from the data. Under standard source and spectral decay conditions, we show that the reconstruction error decays in the mesh size at a near optimal rate. Importantly, we develop a generalized singular value decomposition (GSVD)-based bilevel optimization algorithm to choose the regularization parameter, leading to efficient and robust computation of the regularized estimator. Numerical experiments for several Lévy densities, drift fields and data types (PDE-based densities and sample ensemble-based KDE reconstructions) demonstrate that our bilevel RKHS method outperforms classical L-curve and generalized cross-validation strategies and that the adaptive RKHS norm is more accurate and robust than $L^2_ρ$- and $\\ell^2$-based regularization."}
{"id": "2512.23266", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.23266", "abs": "https://arxiv.org/abs/2512.23266", "authors": ["Elie Aïdékon", "Yueyun Hu"], "title": "Average-weight percolation on the complete graph", "comment": null, "summary": "Attach to each edge of the complete graph on $n$ vertices, i.i.d. exponential random variables with mean $n$. Aldous [1] proved that the longest path with average weight below $p$ undergoes a phase transition at $p=\\frac{1}{e}$: it is $o(n)$ when $p<\\frac{1}{e}$ and of order $n$ if $p>\\frac1e$. Later, Ding [4] revealed a finer phase transition around $\\frac{1}{e}$: there exist $c'>c>0$ such that the length of the longest path is of order $\\ln^3 n$ if $ p \\le \\frac{1}{e}+\\frac{c}{\\ln^2 n}$ and is polynomial if $p\\ge \\frac{1}{e}+\\frac{c'}{\\ln^2 n}$. We identify the location of this phase transition and obtain sharp asymptotics of the length near criticality. The proof uses an exploration mechanism mimicking a branching random walk with selection introduced by Brunet and Derrida [3]."}
{"id": "2512.23134", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23134", "abs": "https://arxiv.org/abs/2512.23134", "authors": ["Lang Yu", "Nanjing Huang"], "title": "Difference-of-Convex Elastic Net for Compressed Sensing", "comment": null, "summary": "This work proposes a novel and unified sparse recovery framework, termed the difference of convex Elastic Net (DCEN). This framework effectively balances strong sparsity promotion with solution stability, and is particularly suitable for high-dimensional variable selection involving highly correlated features. Built upon a difference-of-convex (DC) structure, DCEN employs two continuously tunable parameters to unify classical and state-of-the-art models--including Lasso, Elastic Net, Ridge, and $\\ell_1-α\\ell_2$--as special cases. Theoretically, sufficient conditions for exact and stable recovery are established under the restricted isometry property (RIP), and a closed-form expression of the DCEN regularization proximal operator is derived. Moreover, two efficient optimization algorithms are developed based on the DC algorithm (DCA) and the alternating direction method of multipliers (ADMM). Within the Kurdyka-Lojasiewicz (KL) framework, the global convergence of DCA and its linear convergence rate are rigorously established. Furthermore, DCEN is extended to image reconstruction by incorporating total variation (TV) regularization, yielding the DCEN-TV model, which is efficiently solved via the Split Bregman method. Numerical experiments demonstrate that DCEN consistently outperforms state-of-the-art methods in sparse signal recovery, high-dimensional variable selection under strong collinearity, and Magnetic Resonance Imaging (MRI) image reconstruction, achieving superior recovery accuracy and robustness."}
{"id": "2512.23643", "categories": ["math.NA", "cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23643", "abs": "https://arxiv.org/abs/2512.23643", "authors": ["Konstantin Yakovlev", "Nikita Puchkin"], "title": "Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks", "comment": "38 pages", "summary": "We present a theory for simultaneous approximation of the score function and its derivatives, enabling the handling of data distributions with low-dimensional structure and unbounded support. Our approximation error bounds match those in the literature while relying on assumptions that relax the usual bounded support requirement. Crucially, our bounds are free from the curse of dimensionality. Moreover, we establish approximation guarantees for derivatives of any prescribed order, extending beyond the commonly considered first-order setting."}
{"id": "2512.23288", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.23288", "abs": "https://arxiv.org/abs/2512.23288", "authors": ["Jiagang Ren", "Hua Zhang"], "title": "Bismut-Elworthy-Li Formulae for Forward-Backward SDEs with Jumps and Applications", "comment": "49 pages", "summary": "Under nondegeneracy assumptions on the diffusion coefficients, we establish the derivative formulae of Bismut-Elworthy-Li's type for forward-backward stochastic differential equations with respect to Poisson random measure using the lent particle method created by Bouleau and Denis, which is not given before. Applying this formula, the existence and uniqueness of a solution of nonlocal quasi-linear integral partial differential equations, which are differentiable with respect to the space variable, are obtained, even if the initial datum and coefficients of this equation are not."}
{"id": "2512.23150", "categories": ["math.OC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23150", "abs": "https://arxiv.org/abs/2512.23150", "authors": ["Vítor A. Barbosa", "Rafael A. Melo"], "title": "Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan", "comment": null, "summary": "We consider the strongly NP-hard single-machine coupled task scheduling problem with exact delays to minimize the makespan. In this problem, a set of jobs has to be scheduled, each composed of two tasks interspersed by an exact delay. Given that no preemption is allowed, the goal consists of minimizing the completion time of the last scheduled task. We model the problem using constraint programming (CP) and propose a biased random-key genetic algorithm (BRKGA). Our CP model applies well-established global constraints. Our BRKGA combines some successful components in the literature: an initial solution generator, periodical restarts and shakes, and a local search algorithm. Furthermore, the BRKGA's decoder is focused on efficiency rather than optimality, which accelerates the solution space exploration. Computational experiments on a benchmark set containing instances with up to 100 jobs (200 tasks) indicate that the proposed BRKGA can efficiently explore the problem solution space, providing high-quality approximate solutions within low computational times. It can also provide better solutions than the CP model under the same computational settings, i.e., three minutes of time limit and a single thread. The CP model, when offered a longer running time of 3600 seconds and multiple threads, significantly improved the results, reaching the current best-known solution for 90.56% of these instances. Finally, our experiments highlight the importance of the shake and local search components in the BRKGA, whose combination significantly improves the results of a standard BRKGA."}
{"id": "2512.23648", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23648", "abs": "https://arxiv.org/abs/2512.23648", "authors": ["Simone Minniti", "Jens Visbech", "Claes Eskilsson", "Nicola Parolini", "Allan Peter Engsig-Karup"], "title": "A High-Order Spectral Element Solver for Steady-State Free Surface Flows", "comment": "23 pages, 17 figures", "summary": "We present a spectral element solver for the steady incompressible Navier-Stokes equations subject to a free surface. Utilizing the kinematic behaviour of the free surface boundary, an iterative pseudo-time procedure is proposed to determine the a priori unknown free surface profile. The numerical model is implemented in the open-source finite element framework Firedrake, which enables the use of a high-order polynomial basis on unstructured meshes through weak formulations. Additionally, the curvature of the free surface and submerged bodies is incorporated through curvilinear elements obtained via transfinite linear blending, which conserves the high-order convergent properties of the overall scheme. The model is applied to several benchmark cases in two spatial dimensions. Initially, it addresses fixed-domain problems, including the lid-driven cavity flow and flows around bodies such as a cylinder and a NACA airfoil. Subsequently, with the presence of a free surface, it is extended to determine the flow around a bathymetry bump and a submerged NACA airfoil. The results confirm the high-order accuracy of the model through convergence studies and demonstrate a substantial speed-up over low-order numerical schemes."}
{"id": "2512.23309", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.23309", "abs": "https://arxiv.org/abs/2512.23309", "authors": ["Chang Liu", "Dejun Luo"], "title": "Structure preservation and emergent dissipation in stochastic wave equations with transport noise", "comment": "27 pages", "summary": "We study nonlinear wave equations perturbed by transport noise acting either on the displacement or on the velocity. Such noise models random advection and, under suitable scaling of space covariance, may generate an effective dissipative term. We establish well-posedness in both cases and analyse the associated scaling limits. When the noise acts on the displacement, the system preserves its original structure and converges to the deterministic nonlinear wave equation, whereas if it acts on the velocity, the rescaled dynamics produce an additional Laplacian damping term, leading to a stochastic derivation of a Westervelt-type acoustic model."}
{"id": "2512.23166", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23166", "abs": "https://arxiv.org/abs/2512.23166", "authors": ["Frank E. Curtis", "Xiaoyi Qu", "Daniel P. Robinson"], "title": "A Proximal-Gradient Method for Solving Regularized Optimization Problems with General Constraints", "comment": "1 figure", "summary": "We propose, analyze, and test a proximal-gradient method for solving regularized optimization problems with general constraints. The method employs a decomposition strategy to compute trial steps and uses a merit function to determine step acceptance or rejection. Under various assumptions, we establish a worst-case iteration complexity result, prove that limit points are first-order KKT points, and show that manifold identification and active-set identification properties hold. Preliminary numerical experiments on a subset of the CUTEst test problems and sparse canonical correlation analysis problems demonstrate the promising performance of our approach."}
{"id": "2512.22909", "categories": ["math.OC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.22909", "abs": "https://arxiv.org/abs/2512.22909", "authors": ["Zhaosong Lu", "Sanyou Mei"], "title": "A first-order method for nonconvex-strongly-concave constrained minimax optimization", "comment": "Accepted by Optimization Methods and Software", "summary": "In this paper we study a nonconvex-strongly-concave constrained minimax problem. Specifically, we propose a first-order augmented Lagrangian method for solving it, whose subproblems are nonconvex-strongly-concave unconstrained minimax problems and suitably solved by a first-order method developed in this paper that leverages the strong concavity structure. Under suitable assumptions, the proposed method achieves an \\emph{operation complexity} of $O(\\varepsilon^{-3.5}\\log\\varepsilon^{-1})$, measured in terms of its fundamental operations, for finding an $\\varepsilon$-KKT solution of the constrained minimax problem, which improves the previous best-known operation complexity by a factor of $\\varepsilon^{-0.5}$."}
{"id": "2512.23334", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.23334", "abs": "https://arxiv.org/abs/2512.23334", "authors": ["Xiaoda Xu", "Jun Xian"], "title": "On a Class of Partitions with Lower Expected Star Discrepancy and Its Upper Bound than Jittered Sampling", "comment": null, "summary": "We investigate the expected star discrepancy under a newly designed class of convex equivolume partition models. The main contributions are two-fold. First, we establish a strong partition principle for the star discrepancy, showing that our newly designed partitions yield stratified sampling point sets with lower expected star discrepancy than both classical jittered sampling and simple random sampling. Specifically, we prove that $\\mathbb{E}(D^{*}_{N}(Z))\\leq\\mathbb{E}(D^{*}_{N}(Y))<\\mathbb{E}(D^{*}_{N}(X))$, where $X$, $Y$, and $Z$ represent simple random sampling, jittered sampling, and our new partition sampling, respectively. Second, we derive explicit upper bounds for the expected star discrepancy under our partition models, which improve upon existing bounds for jittered sampling. Our results resolve Open Question 2 posed in Kiderlen and Pausinger (2021) regarding the strong partition principle for star discrepancy."}
{"id": "2512.23178", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23178", "abs": "https://arxiv.org/abs/2512.23178", "authors": ["Zijian Liu"], "title": "Clipped Gradient Methods for Nonsmooth Convex Optimization under Heavy-Tailed Noise: A Refined Analysis", "comment": "Part of this work is in submission", "summary": "Optimization under heavy-tailed noise has become popular recently, since it better fits many modern machine learning tasks, as captured by empirical observations. Concretely, instead of a finite second moment on gradient noise, a bounded ${\\frak p}$-th moment where ${\\frak p}\\in(1,2]$ has been recognized to be more realistic (say being upper bounded by $σ_{\\frak l}^{\\frak p}$ for some $σ_{\\frak l}\\ge0$). A simple yet effective operation, gradient clipping, is known to handle this new challenge successfully. Specifically, Clipped Stochastic Gradient Descent (Clipped SGD) guarantees a high-probability rate ${\\cal O}(σ_{\\frak l}\\ln(1/δ)T^{1/{\\frak p}-1})$ (resp. ${\\cal O}(σ_{\\frak l}^2\\ln^2(1/δ)T^{2/{\\frak p}-2})$) for nonsmooth convex (resp. strongly convex) problems, where $δ\\in(0,1]$ is the failure probability and $T\\in\\mathbb{N}$ is the time horizon. In this work, we provide a refined analysis for Clipped SGD and offer two faster rates, ${\\cal O}(σ_{\\frak l}d_{\\rm eff}^{-1/2{\\frak p}}\\ln^{1-1/{\\frak p}}(1/δ)T^{1/{\\frak p}-1})$ and ${\\cal O}(σ_{\\frak l}^2d_{\\rm eff}^{-1/{\\frak p}}\\ln^{2-2/{\\frak p}}(1/δ)T^{2/{\\frak p}-2})$, than the aforementioned best results, where $d_{\\rm eff}\\ge1$ is a quantity we call the $\\textit{generalized effective dimension}$. Our analysis improves upon the existing approach on two sides: better utilization of Freedman's inequality and finer bounds for clipping error under heavy-tailed noise. In addition, we extend the refined analysis to convergence in expectation and obtain new rates that break the known lower bounds. Lastly, to complement the study, we establish new lower bounds for both high-probability and in-expectation convergence. Notably, the in-expectation lower bounds match our new upper bounds, indicating the optimality of our refined analysis for convergence in expectation."}
{"id": "2512.23346", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.23346", "abs": "https://arxiv.org/abs/2512.23346", "authors": ["Bingru Zhao", "Mingshang Hu"], "title": "Backward Stochastic Volterra integral equations driven by G-Brownian motion", "comment": null, "summary": "In this paper, we study the Backward stochastic Volterra integral equation driven by G-Brownian motion (G-BSVIE). By adopting a different backward iteration method, we construct the approximating sequences on each local interval. With the help of G-stochastic analysis techniques and the monotone convergence theorem, the existence, uniqueness, and continuity of the solution over the entire interval are established. Moreover, we derive the comparison theorem."}
{"id": "2512.23188", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23188", "abs": "https://arxiv.org/abs/2512.23188", "authors": ["Huaning Liu", "Junke Yang", "Soren L. Larsen", "Pamela P. Martinez", "Gokce Dayanikli"], "title": "Incorporating Authority Perception, Economic Status, and Behavioral Response in Infectious Disease Control", "comment": null, "summary": "We introduce a multi-population mean field game framework to examine how economic status and authority perception shape vaccination and social distancing decisions under different epidemic control policies. We carried out a survey to inform our model and stratify the population into six groups based on income and perception of authority, capturing behavioral heterogeneity. Individuals adjust their socialization and vaccination levels to optimize objectives such as minimizing treatment costs, complying with social-distancing guidelines if they are authority-followers, or reducing losses from decreased social interactions if they are authority-indifferents, alongside economic costs. Public health authorities influence behavior through social-distancing guidelines and vaccination costs. We characterize the Nash equilibrium via a forward-backward differential equation system, provide its mathematical analysis, and develop a numerical algorithm to solve it. Our findings reveal a trade-off between social-distancing and vaccination decisions. Under stricter guidelines that target both susceptible and infected individuals, followers reduce both socialization and vaccination levels, while indifferents increase socialization due to followers' preventative measures. Adaptive guidelines targeting infected individuals effectively reduce infections and narrow the gap between low- and high-income groups, even when susceptible individuals socialize more and vaccinate less. Lower vaccination costs incentivize vaccination among low-income groups, but their impact on disease spread is smaller than when they are coupled with social-distancing guidelines. Trust-building emerges as a critical factor in epidemic mitigation, underscoring the importance of data-informed, game-theoretical models that aim to understand complex human responses to mitigation policies."}
{"id": "2512.23673", "categories": ["math.PR", "math.FA"], "pdf": "https://arxiv.org/pdf/2512.23673", "abs": "https://arxiv.org/abs/2512.23673", "authors": ["Rafał Meller"], "title": "Spectral norm of matrices with independent entries up to polyloglog", "comment": null, "summary": "In this paper, we study the expectation of the operator norm of the random matrix (a_{ij} X_{ij}) for i,j <= n, under the assumption that the random variables (X_{ij}) are independent, symmetric and satisfy the moment growth condition ||X_{ij}||{2p} <= C ||X_{ij}||{p} for every p >= 1. We derive an upper bound expressed in terms of quantities that can be explicitly computed in many cases. This bound implies a two-sided estimate, up to a factor given by a power of an iterated logarithm. This factor is considerably smaller than the natural scale of the problem. Our result thus provides positive evidence supporting a conjecture formulated by Rafal Latala and Jan Swiatkowski."}
{"id": "2512.23203", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23203", "abs": "https://arxiv.org/abs/2512.23203", "authors": ["Shuo Shi", "Juan Zhang"], "title": "Output feedback stabilization of linear port-Hamiltonian descriptor systems", "comment": "20 pages", "summary": "This paper presents a structure-preserving method for the stabilization of linear port-Hamiltonian (pH) descriptor systems via output feedback. The stabilization problem is NP-hard for general descriptor systems. Existing approaches often rely on explicit knowledge of the structure-defining matrix $Q$, which is difficult to determine in practice. When $Q$ is unknown, we derive necessary and sufficient conditions under which proportional output feedback ensures that the closed-loop system is regular, impulse-free, asymptotically stable, and retains the port-Hamiltonian structure. These conditions also allow any positive definite matrix to serve as the feedback matrix. The framework is further extended to proportional and derivative output feedback, enabling the assignment of a desired dynamical order. The proposed method thus generalizes existing stabilization results from the special case $Q = I$ to systems with an unknown $Q$, offering a systematic method to structure-preserving stabilization of pH descriptor systems."}
{"id": "2512.23317", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23317", "abs": "https://arxiv.org/abs/2512.23317", "authors": ["Kansei Ushiyama", "Shun Sato", "Takayasu Matsuo"], "title": "Essential Convergence Rates of Continuous-Time Models for Optimization Methods", "comment": null, "summary": "Designing and analyzing optimization methods via continuous-time models expressed as ordinary differential equations (ODEs) is a promising approach for its intuitiveness and simplicity. A key concern, however, is that the convergence rates of such models can be arbitrarily modified by time rescaling, rendering the task of seeking ODEs with ``fast'' convergence meaningless. To eliminate this ambiguity of the rates, we introduce the notion of the essential convergence rate. We justify this notion by proving that, under appropriate assumptions on discretization, no method obtained by discretizing an ODE can achieve a faster rate than its essential convergence rate."}
{"id": "2512.23339", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.23339", "abs": "https://arxiv.org/abs/2512.23339", "authors": ["Subrata Majumdar", "Debanjit Mondal"], "title": "Small-time global controllability of a class of bilinear fourth-order parabolic equations", "comment": "29 pages, Comments are welcome!", "summary": "In this work, we investigate the small-time global controllability properties of a class of fourth-order nonlinear parabolic equations driven by a bilinear control posed on the one-dimensional torus. The controls depend only on time and act through a prescribed family of spatial profiles. Our first result establishes the small-time global approximate controllability of the system using three scalar controls, between states that share the same sign. This property is obtained by adapting the geometric control approach to the fourth-order setting, using a finite family of frequency-localized controls. We then study the small-time global exact controllability to non-zero constant states for the concerned system. This second result is achieved by analyzing the null controllability of an appropriate linearized fourth-order system and by deducing the controllability of the nonlinear bilinear model through a fixed-point argument together with the small-time global approximate control property."}
{"id": "2512.23527", "categories": ["math.OC", "cs.DM", "cs.IT", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.23527", "abs": "https://arxiv.org/abs/2512.23527", "authors": ["Barbara Fiedorowicz", "Amitabh Basu"], "title": "Identifying faulty edges in resistive electrical networks", "comment": null, "summary": "Given a resistive electrical network, we would like to determine whether all the resistances (edges) in the network are working, and if not, identify which edge (or edges) are faulty. To make this determination, we are allowed to measure the effective resistance between certain pairs of nodes (which can be done by measuring the amount of current when one unit of voltage difference is applied at the chosen pair of nodes). The goal is to determine which edge, if any, is not working in the network using the smallest number of measurements. We prove rigorous upper and lower bounds on this optimal number of measurements for different classes of graphs. These bounds are tight for several of these classes showing that our measurement strategies are optimal."}
{"id": "2512.23695", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23695", "abs": "https://arxiv.org/abs/2512.23695", "authors": ["Egor Makarenkov"], "title": "A dimension reduction procedure for the selection of Two-spring lattice-spring topologies with minimal fabrication cost and required weighted force-resistance performance", "comment": "8 pages, 5 figures", "summary": "Starting from a problem in elastoplasticity, we consider an optimization problem $C(c_1,c_2)=c_1+c_2\\to \\min$ under constraints $F_R^k(c_1,c_2)=a\\cdot F^k(c_1,c_2)+b\\cdot R^k(c_1,c_2)\\ge 1$ and $F^k(c_1,c_2)\\ge 1$, where both $F^k$ and $R^k$ non-linear, $a,b$ are constants, and $i\\in\\{1,2\\}$ is an index. For each $(a,b)$ we determine which of the two values of $i\\in\\{1,2\\}$ leads to the smaller minimum of the optimization problem. This way we obtain an interesting curve bounding the region where $k=1$ outperforms $k=2$."}
