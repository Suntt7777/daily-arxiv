{"id": "2601.20970", "categories": ["math.OC", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20970", "abs": "https://arxiv.org/abs/2601.20970", "authors": ["Gabriel Ponte", "Marcia Fampa", "Jon Lee"], "title": "The augmented NLP bound for maximum-entropy remote sampling", "comment": null, "summary": "The maximum-entropy remote sampling problem (MERSP) is to select a subset of s random variables from a set of n random variables, so as to maximize the information concerning a set of target random variables that are not directly observable. We assume throughout that the set of all of these random variables follows a joint Gaussian distribution, and that we have the covariance matrix available. Finally, we measure information using Shannon's differential entropy.\n  The main approach for exact solution of moderate-sized instances of MERSP has been branch-and-bound, and so previous work concentrated on upper bounds. Prior to our work, there were two upper-bounding methods for MERSP: the so-called NLP bound and the spectral bound, both introduced 25 years ago. We are able now to establish domination results between these two upper bounds. We propose an ``augmented NLP bound'' based on a subtle convex relaxation. We provide theoretical guarantees, giving sufficient conditions under which the augmented NLP bound strictly dominates the ordinary NLP bound. In addition, the augmented NLP formulation allows us to derive upper bounds for rank-deficient covariance matrices when they satisfy a technical condition. This is in contrast to the earlier work on the ordinary NLP bound that worked with only positive definite covariance matrices. Finally, we introduce a novel and very effective diagonal-scaling technique for MERSP, employing a positive vector of parameters. Numerical experiments on benchmark instances demonstrate the effectiveness of our approaches in advancing the state of the art for calculating upper bounds on MERSP."}
{"id": "2601.20973", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.20973", "abs": "https://arxiv.org/abs/2601.20973", "authors": ["Asaf Cohen", "Ruolan He", "Yuqiong Wang"], "title": "Thompson Sampling Algorithm for Stochastic Games", "comment": null, "summary": "We study a stochastic differential game with $N$ competitive players in a linear-quadratic framework with ergodic cost, where $d$-dimensional diffusion processes govern the state dynamics with an unknown common drift (matrix). Assuming a Gaussian prior on the drift, we use filtering techniques to update its posterior estimates. Based on these estimates, we propose a Thompson-sampling-based algorithm with dynamic episode lengths to approximate strategies. We show that the Bayesian regret for each player has an error bound of order $O(\\sqrt{T\\log(T)})$, where $T$ is the time-horizon, independent of the number of players. This implies that average regret per unit time goes to zero. Finally, we prove that the algorithm results in a Nash equilibrium."}
{"id": "2601.20977", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.20977", "abs": "https://arxiv.org/abs/2601.20977", "authors": ["Paulo Michel F. Yamagishi", "Marcia Fampa", "Jon Lee"], "title": "The dual-path fixing strategy and its application to the set-covering problem", "comment": null, "summary": "We introduce the dual-path fixing strategy to exploit dual algorithms for solving relaxations of mixed-integer nonlinear-optimization problems. Such dual algorithms are naturally applied in the context of branch-and-bound, and eventual impact on the success of branch-and-bound is our strong motivation. Our fixing strategy aims to be more powerful than the common strategy of fixing variables based on a single dual-feasible solution (e.g., standard reduced-cost fixing for mixed-integer linear optimization), but to be much faster than ``strong fixing'', essentially requiring no more time than that of the dual algorithm that we exploit. We have successfully tested our ideas on mixed-integer linear-optimization set-covering instances from the literature, in the context of the dual-simplex method applied to the continuous relaxations."}
{"id": "2601.21166", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21166", "abs": "https://arxiv.org/abs/2601.21166", "authors": ["Taha El Bakkali", "Rayane Bouftini", "Qiuyi Zhang", "Omar Saadi"], "title": "Noisy Pairwise-Comparison Random Search for Smooth Nonconvex Optimization", "comment": null, "summary": "We consider minimizing high-dimensional smooth nonconvex objectives using only noisy pairwise comparisons. Unlike classical zeroth-order methods limited by the ambient dimension $d$, we propose Noisy-Comparison Random Search (NCRS), a direct-search method that exploits random line search to adapt to the intrinsic dimension $k \\le d$. We establish novel non-convex convergence guarantees for approximate stationarity: under a uniform-margin oracle, NCRS attains $ε$-stationarity with complexity $\\mathcal{O}(k/(p^{2}ε^{2}))$, explicitly replacing ambient dependence with the intrinsic dimension. Furthermore, we introduce a general tie-aware noise model where comparison quality degrades near ties; for this setting, we prove that a majority-vote variant of NCRS achieves $ε$-stationarity with complexity $\\mathcal{O}(k^{2}/ε^{4})$."}
{"id": "2601.21019", "categories": ["math.ST", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21019", "abs": "https://arxiv.org/abs/2601.21019", "authors": ["Markus Holzleitner", "Sergiy Pereverzyev", "Sergei V. Pereverzyev", "Vaibhav Silmana", "S. Sivananthan"], "title": "Towards regularized learning from functional data with covariate shift", "comment": "38 pages", "summary": "This paper investigates a general regularization framework for unsupervised domain adaptation in vector-valued regression under the covariate shift assumption, utilizing vector-valued reproducing kernel Hilbert spaces (vRKHS). Covariate shift occurs when the input distributions of the training and test data differ, introducing significant challenges for reliable learning. By restricting the hypothesis space, we develop a practical operator learning algorithm capable of handling functional outputs. We establish optimal convergence rates for the proposed framework under a general source condition, providing a theoretical foundation for regularized learning in this setting. We also propose an aggregation-based approach that forms a linear combination of estimators corresponding to different regularization parameters and different kernels. The proposed approach addresses the challenge of selecting appropriate tuning parameters, which is crucial for constructing a good estimator, and we provide a theoretical justification for its effectiveness. Furthermore, we illustrate the proposed method on a real-world face image dataset, demonstrating robustness and effectiveness in mitigating distributional discrepancies under covariate shift."}
{"id": "2601.20978", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.20978", "abs": "https://arxiv.org/abs/2601.20978", "authors": ["Omid Khosravi", "Mehdi Tatari"], "title": "Solution of Advection Equation with Discontinuous Initial and Boundary Conditions via Physics-Informed Neural Networks", "comment": null, "summary": "In this paper, we investigate several techniques for modeling the one-dimensional advection equation for a specific class of problems with discontinuous initial and boundary conditions using physics-informed neural networks (PINNs). To mitigate the spectral bias phenomenon, we employ a Fourier feature mapping layer as the input representation, adopt a two-stage training strategy in which the Fourier feature parameters and the neural network weights are optimized sequentially, and incorporate adaptive loss weighting. To further enhance the approximation accuracy, a median filter is applied to the spatial data, and the predicted solution is constrained through a bounded linear mapping. Moreover, for certain nonlinear problems, we introduce a modified loss function inspired by the upwind numerical scheme to alleviate the excessive smoothing of discontinuous solutions typically observed in neural network approximations."}
{"id": "2601.21023", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.21023", "abs": "https://arxiv.org/abs/2601.21023", "authors": ["Fei Cao", "Roberto Cortez"], "title": "The fractal geometry of opinion formation", "comment": "30 pages, 3 figures", "summary": "In this manuscript, we introduce and study a variant of the agent-based opinion dynamics proposed in a recent work [8], within the framework of an interacting multi-agent system, where agents are assumed to interact with each other and update their opinions after each pairwise encounter. Specifically, our opinion model involves a large crowd of $N$ indistinguishable agents, each characterized by an opinion value ranging within the interval $[-1,1]$. At each update time, two agents are picked uniformly at random and the opinion of one agent will either shift by a proportion $μ_+ \\in (0,1]$ towards $+1$, or by a proportion $μ_- \\in (0,1]$ towards $-1$, with probabilities depending on the other agent's opinion. We rigorously derive the mean-field limit PDE that governs the large-population limit of the agent-based model and present several quantitative results demonstrating convergence to the unique equilibrium distribution. Remarkably, for a suitable choice of model parameters, the long-term equilibrium opinion profile displays a striking self-similar structure that generalizes the celebrated Bernoulli convolution, a topic extensively studied in the context of fractal geometry [23,44]. These findings also enhance our understanding of the opinion fragmentation phenomenon and may provide valuable insights for the development of more sophisticated models in future research."}
{"id": "2601.21243", "categories": ["math.OC", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21243", "abs": "https://arxiv.org/abs/2601.21243", "authors": ["Amir Ali Farzin", "Yuen-Man Pun", "Philipp Braun", "Tyler Summers", "Iman Shames"], "title": "Solving the Offline and Online Min-Max Problem of Non-smooth Submodular-Concave Functions: A Zeroth-Order Approach", "comment": null, "summary": "We consider max-min and min-max problems with objective functions that are possibly non-smooth, submodular with respect to the minimiser and concave with respect to the maximiser. We investigate the performance of a zeroth-order method applied to this problem. The method is based on the subgradient of the Lovász extension of the objective function with respect to the minimiser and based on Gaussian smoothing to estimate the smoothed function gradient with respect to the maximiser. In expectation sense, we prove the convergence of the algorithm to an $ε$-saddle point in the offline case. Moreover, we show that, in the expectation sense, in the online setting, the algorithm achieves $O(\\sqrt{N\\bar{P}_N})$ online duality gap, where $N$ is the number of iterations and $\\bar{P}_N$ is the path length of the sequence of optimal decisions. The complexity analysis and hyperparameter selection are presented for all the cases. The theoretical results are illustrated via numerical examples."}
{"id": "2601.21131", "categories": ["math.ST", "cs.IT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21131", "abs": "https://arxiv.org/abs/2601.21131", "authors": ["Qiyang Han"], "title": "Thompson sampling: Precise arm-pull dynamics and adaptive inference", "comment": null, "summary": "Adaptive sampling schemes are well known to create complex dependence that may invalidate conventional inference methods. A recent line of work shows that this need not be the case for UCB-type algorithms in multi-armed bandits. A central emerging theme is a `stability' property with asymptotically deterministic arm-pull counts in these algorithms, making inference as easy as in the i.i.d. setting.\n  In this paper, we study the precise arm-pull dynamics in another canonical class of Thompson-sampling type algorithms. We show that the phenomenology is qualitatively different: the arm-pull count is asymptotically deterministic if and only if the arm is suboptimal or is the unique optimal arm; otherwise it converges in distribution to the unique invariant law of an SDE. This dichotomy uncovers a unifying principle behind many existing (in)stability results: an arm is stable if and only if its interaction with statistical noise is asymptotically negligible.\n  As an application, we show that normalized arm means obey the same dichotomy, with Gaussian limits for stable arms and a semi-universal, non-Gaussian limit for unstable arms. This not only enables the construction of confidence intervals for the unknown mean rewards despite non-normality, but also reveals the potential of developing tractable inference procedures beyond the stable regime.\n  The proofs rely on two new approaches. For suboptimal arms, we develop an `inverse process' approach that characterizes the inverse of the arm-pull count process via a Stieltjes integral. For optimal arms, we adopt a reparametrization of the arm-pull and noise processes that reduces the singularity in the natural SDE to proving the uniqueness of the invariant law of another SDE. We prove the latter by a set of analytic tools, including the parabolic Hörmander condition and the Stroock-Varadhan support theorem."}
{"id": "2601.21018", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21018", "abs": "https://arxiv.org/abs/2601.21018", "authors": ["Barbara Kaltenbacher", "William Rundell"], "title": "Identification of space-dependent coefficients in two competing terms of a nonlinear subdiffusion equation", "comment": null, "summary": "We consider a (sub)diffusion equation with a nonlinearity of the form $pf(u)-qu$, where $p$ and $q$ are space dependent functions. Prominent examples are the Fisher-KPP, the Frank-Kamenetskii-Zeldovich and the Allen-Cahn equations. We devise a fixed point scheme for reconstructing the spatially varying coefficients from interior observations a) at final time under two different excitations b) at two different time instances under a single excitation. Convergence of the scheme as well as local uniqueness of these coefficients is proven. Numerical experiments illustrate the performance of the reconstruction scheme."}
{"id": "2601.21054", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.21054", "abs": "https://arxiv.org/abs/2601.21054", "authors": ["Rami Atar", "Leonid Mytnik", "Gershon Wolansky"], "title": "Trimmed branching random walk and a free obstacle problem", "comment": null, "summary": "Consider $N$ particles performing random walks on the $ε$-grid $(εZ)^d$, $ε>0$ with branching and density-dependent selection: When one of the particles branches, a particle is removed from the most populated site. The walks are assumed to be asymptotic, as $ε\\to0$, to diffusion processes of the form \\[ dX_i(t)=b(X_i(t))dt+\\sqrt{2}dW_i(t), \\] for $b$ a given vector field. Denoting $L^*=Δ-\\nabla\\cdot(b\\,\\cdot)$, the hydrodynamic limit, as $N\\to\\infty$ followed by $ε\\to0$, is characterized in terms of a parabolic free obstacle problem \\[ \\partial_t u=L^*u+u-β\\] where $β$ is a measure on $R^d\\times[0,\\infty)$ supported on $\\{(x,t):u(x,t)=|u(\\cdot,t)|_\\infty\\}$. Here, the unknowns are $u$, the mass density, and $β$, the removal measure, for which $t\\mapstoβ(R^d\\times[0,t])$ is prescribed. This is analogous to the well-understood relation between particle systems with spatial selection and free boundary problems, but the techniques require quite different ideas. The key ingredients of the proof include PDE uniqueness for continuous densities and a uniform-in-$ε$ estimate on modulus of continuity of prelimit densities. The work gives rise to open problems such as ``flat top'' versus ``sharp top'' solutions, which are discussed based on concrete examples."}
{"id": "2601.21333", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21333", "abs": "https://arxiv.org/abs/2601.21333", "authors": ["Pinxi Gong", "Lexiao Lai", "Jianhao Ma"], "title": "Certifying optimality in nonconvex robust PCA", "comment": null, "summary": "Robust principal component analysis seeks to recover a low-rank matrix from fully observed data with sparse corruptions. A scalable approach fits a low-rank factorization by minimizing the sum of entrywise absolute residuals, leading to a nonsmooth and nonconvex objective. Under standard incoherence conditions and a random model for the corruption support, we study factorizations of the ground-truth rank-$r$ matrix with both factors of rank $r$. With high probability, every such factorization is a Clarke critical point. We also characterize the local geometry: when the factorization rank equals $r$, these solutions are sharp local minima; when it exceeds $r$, they are strict saddle points."}
{"id": "2601.21818", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.21818", "abs": "https://arxiv.org/abs/2601.21818", "authors": ["Cecilie Olesen Recke", "Sarah Lumpp", "Nataliia Kushnerchuk", "Janike Oldekop", "Jiayi Li", "Jane Ivy Coons", "Elina Robeva"], "title": "Identifiability in Graphical Discrete Lyapunov Models", "comment": "29 pages, 18 pages of appendix", "summary": "In this paper, we study discrete Lyapunov models, which consist of steady-state distributions of first-order vector autoregressive models. The parameter matrix of such a model encodes a directed graph whose vertices correspond to the components of the random vector. This combinatorial framework naturally allows for cycles in the graph structure. We focus on the fundamental problem of identifying the entries of the parameter matrix. In contrast to the classical setting, we assume non-Gaussian error terms, which allows us to use the higher-order cumulants of the model. In this setup, we show generic identifiability for directed acyclic graphs with self-loops at each vertex and show how to express the parameters as a rational function of the cumulants. Furthermore, we establish local identifiability for all directed graphs containing self loops at each vertex and no isolated vertices. Finally, we provide first results on the defining equations of the models, showing model equivalence for certain graphs and paving the way towards structure learning."}
{"id": "2601.21080", "categories": ["math.NA", "cs.LG", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.21080", "abs": "https://arxiv.org/abs/2601.21080", "authors": ["Lizuo Liu", "Lu Zhang", "Anne Gelb"], "title": "Parametric Hyperbolic Conservation Laws: A Unified Framework for Conservation, Entropy Stability, and Hyperbolicity", "comment": "arXiv admin note: text overlap with arXiv:2507.01795", "summary": "We propose a parametric hyperbolic conservation law (SymCLaw) for learning hyperbolic systems directly from data while ensuring conservation, entropy stability, and hyperbolicity by design. Unlike existing approaches that typically enforce only conservation or rely on prior knowledge of the governing equations, our method parameterizes the flux functions in a form that guarantees real eigenvalues and complete eigenvectors of the flux Jacobian, thereby preserving hyperbolicity. At the same time, we embed entropy-stable design principles by jointly learning a convex entropy function and its associated flux potential, ensuring entropy dissipation and the selection of physically admissible weak solutions. A corresponding entropy-stable numerical flux scheme provides compatibility with standard discretizations, allowing seamless integration into classical solvers. Numerical experiments on benchmark problems, including Burgers, shallow water, Euler, and KPP equations, demonstrate that SymCLaw generalizes to unseen initial conditions, maintains stability under noisy training data, and achieves accurate long-time predictions, highlighting its potential as a principled foundation for data-driven modeling of hyperbolic conservation laws."}
{"id": "2601.21079", "categories": ["math.PR", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2601.21079", "abs": "https://arxiv.org/abs/2601.21079", "authors": ["Maximillian Newman"], "title": "The quenched structured coalescent for diploid population models on finite graphs with large migrations and uneven offspring distributions", "comment": "41 pages, 2 figures", "summary": "In this work we describe a new model for the evolution of a diploid structured population backwards in time that allows for large migrations and uneven offspring distributions. The model generalizes both the mean-field model of Birkner et al. [\\textit{Electron. J. Probab.} 23: 1-44 (2018)] and the haploid structured model of Möhle [\\textit{Theor. Popul. Biol.} 2024 Apr:156:103-116]. We show convergence, with mild conditions on the joint distribution of offspring frequencies and migrations, of gene genealogies conditional on the pedigree to a time-inhomogeneous coalescent process driven by a Poisson point process $Ψ$ that records the timing and scale of large migrations and uneven offspring distributions. This quenched scaling limit demonstrates a significant difference in the predictions of the classical annealed theory of structured coalescent processes. In particular, the annealed and quenched scaling limits coincide if and only if these large migrations and uneven offspring distributions are absent. The proof proceeds by the method of moments and utilizes coupling techniques from the theory of random walks in random environments. Several examples are given and their quenched scaling limits established."}
{"id": "2601.21355", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21355", "abs": "https://arxiv.org/abs/2601.21355", "authors": ["Rongxing Du", "Hoi-To Wai"], "title": "Decentralized Learning with Dynamically Refined Edge Weights: A Data-Dependent Framework", "comment": "4 pages(without appendix)", "summary": "This paper aims to accelerate decentralized optimization by strategically designing the edge weights used in the agent-to-agent message exchanges. We propose a Dynamic Directed Decentralized Gradient (D3GD) framework and show that the proposed data-dependent framework is a practical alternative to the classical directed DGD (Di-DGD) algorithm for learning on directed graphs. To obtain a strategy for edge weights refinement, we derive a design function inspired by the cost-to-go function in a new convergence analysis for Di-DGD. This results in a data-dependent dynamical design for the edge weights. A fully decentralized version of D3GD is developed such that each agent refines its communication strategy using only neighbor's information. Numerical experiments show that D3GD accelerates convergence towards stationary solution by 30-40\\% over Di-DGD, and learns edge weights that adapt to data similarity."}
{"id": "2601.21931", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.21931", "abs": "https://arxiv.org/abs/2601.21931", "authors": ["Karel Devriendt", "Ignacio Echave-Sustaeta Rodríguez", "Frank Röttger"], "title": "Extremal conditional independence for Hüsler-Reiss distributions via modular functions", "comment": "16 pages, 3 figures", "summary": "We study extremal conditional independence for Hüsler-Reiss distributions, which is a parametric subclass of multivariate Pareto distributions. As the main contribution, we introduce two set functions, i.e.~functions which assign a value to the distribution and each of its marginals, and show that extremal conditional independence statements can be characterized by modularity relations for these functions. For the first function, we make use of the close connection between Hüsler-Reiss and Gaussian models to introduce a multiinformation-inspired measure $m^{\\text{HR}}$ for Hüsler-Reiss distributions. For the second function, we consider an invariant $σ^2$ that is naturally associated to the Hüsler-Reiss parameterization and establish the second modularity criterion under additional positivity constraints. Together, these results provide new tools for describing extremal dependence structures in high-dimensional extreme value statistics. In addition, we study the geometry of a bounded subset of Hüsler-Reiss parameters and its relation with the Gaussian elliptope."}
{"id": "2601.21241", "categories": ["math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.21241", "abs": "https://arxiv.org/abs/2601.21241", "authors": ["Simone Chiocchetti", "Giovanni Russo"], "title": "An efficient implicit scheme for the multimaterial Euler equations in Lagrangian coordinates", "comment": null, "summary": "Stratified fluids composed of a sequence of alternate layers show interesting macroscopic properties, which may be quite different from those of the individual constituent fluids. On a macroscopic scale, such systems can be considered a sort of fluid metamaterial. In many cases each fluid layer can be described by Euler equations following the stiffened gas equation of state. The computation of detailed numerical solutions of such stratified material poses several challenges, first and foremost the issue of artificial smearing of material parameters across interface boundaries. Lagrangian schemes completely eliminate this issue, but at the cost of rather stringent time step restrictions. In this work we introduce an implicit numerical method for the multimaterial Euler equations in Lagrangian coordinates. The implicit discretization is aimed at bypassing the prohibitive time step restrictions present in flows with stratified media, where one of the materials is particularly dense, or rigid (or both). This is the case for flows of water-air mixtures, air-granular media, or similar high density ratio systems. We will present the novel discretisation approach, which makes extensive use of the remarkable structure of the governing equations in Lagrangian coordinates to find the solution by means of a single implicit discrete wave equation for the pressure field, yielding a symmetric positive definite structure and thus a particularly efficient algorithm. Additionally, we will introduce simple filtering strategies for counteracting the emergence of pressure or density oscillations typically encountered in multimaterial flows, and will present results concerning the robustness, accuracy, and performance of the proposed method, including applications to stratified media with high density and stiffness ratios."}
{"id": "2601.21412", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.21412", "abs": "https://arxiv.org/abs/2601.21412", "authors": ["Alexei Borodin", "Alexey Bufetov"], "title": "Leaders in multi-type TASEP", "comment": "24 pages", "summary": "We study the totally asymmetric simple exclusion process (TASEP) on $\\mathbb{Z}$ with step initial condition, in which all particles have distinct types. Our main object of interest is the type of the rightmost particle -- the leader -- at large time $t$. We prove a central limit theorem for this random variable. Somewhat unexpectedly, the problem is closely connected to certain observables of voter and coalescing processes on $\\mathbb{Z}$; we therefore derive their asymptotics as well. We also analyze the large-time behavior of a few other related observables, including certain multi-particle ones."}
{"id": "2601.21487", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21487", "abs": "https://arxiv.org/abs/2601.21487", "authors": ["Kaiwei Yang", "Lexiao Lai"], "title": "Manifold constrained steepest descent", "comment": "23 pages, 7 figures, and 5 tables", "summary": "Norm-constrained linear minimization oracle (LMO)-based optimizers such as spectral gradient descent and Muon are attractive in large-scale learning, but extending them to manifold-constrained problems is nontrivial and often leads to nested-loop schemes that solve tangent-space subproblems iteratively. We propose \\emph{Manifold Constrained Steepest Descent} (MCSD), a single-loop framework for optimization over manifolds that selects a norm-induced steepest-descent direction via an LMO applied to the Riemannian gradient, and then returns to the manifold via projection. Under standard smoothness assumptions, we establish convergence guarantees for MCSD and a stochastic momentum variant. We further introduce \\emph{SPEL}, the spectral-norm specialization of MCSD on the Stiefel manifold, which admits scalable implementations via fast matrix sign computations. Experiments on PCA, orthogonality-constrained CNNs, and manifold-constrained LLM adapter tuning demonstrate improved stability and competitive performance relative to standard Riemannian baselines and existing manifold-aware LMO methods."}
{"id": "2601.21368", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21368", "abs": "https://arxiv.org/abs/2601.21368", "authors": ["Peng Yang", "Zhimin Zhang"], "title": "Natural superconvergence points for splines", "comment": "27 pages, 3 figures, 3 tables", "summary": "This paper develops a unified theory of natural superconvergence points for polynomial spline approximations to second-order elliptic problems. Beginning with the one-dimensional case, we establish that when a point $x_0$ is a local symmetric center of the partition, the numerical error $(u-u_h)^{(s)}(x_0)$ exhibits superconvergence whenever the polynomial degree $k$ and the derivative order $s$ share the same parity. In particular, for the smoothest spline (B-spline) solution, the abundance of superconvergence points allows us to construct asymptotic expansion of the error within the element that fully characterize all superconvergence points, for both function values and derivatives. The theoretical framework is then extended to higher-dimensional settings on simplicial and tensor-product meshes, and the essential conclusions are preserved, with one-dimensional derivatives generalized to mixed derivatives. Numerical experiments demonstrate that superconvergence persists even in extremely localized symmetric regions, revealing that superconvergence points are both readily attainable and follow systematic distribution patterns."}
{"id": "2601.21489", "categories": ["math.PR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.21489", "abs": "https://arxiv.org/abs/2601.21489", "authors": ["Ali Khalesi", "Rawad Bitar"], "title": "Fundamental Limits of Decentralized Self-Regulating Random Walks", "comment": null, "summary": "Self-regulating random walks (SRRWs) are decentralized token-passing processes on a graph allowing nodes to locally \\emph{fork}, \\emph{terminate}, or \\emph{pass} tokens based only on a return-time \\emph{age} statistic. We study SRRWs on a finite connected graph under a lazy reversible walk, with exogenous \\emph{trap} deletions summarized by the absorption pressure $Λ_{\\mathrm{del}}=\\sum_{u\\in\\mathcal P_{\\mathrm{trap}}}ζ(u)π(u)$ and a global per-visit fork cap $q$. Using exponential envelopes for return-time tails, we build graph-dependent Laplace envelopes that universally bound the stationary fork intensity of any age-based policy, leading to an effective triggering age $A_{\\mathrm{eff}}$. A mixing-based block drift analysis then yields controller-agnostic stability limits: any policy that avoids extinction and explosion must satisfy a \\emph{viability} inequality (births can overcome $Λ_{\\mathrm{del}}$ at low population) and a \\emph{safety} inequality (trap deletions plus deliberate terminations dominate births at high population). Under corridor-wise versions of these conditions, we obtain positive recurrence of the population to a finite corridor."}
{"id": "2601.21606", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21606", "abs": "https://arxiv.org/abs/2601.21606", "authors": ["Amine Othmane", "Philipp Schmitz", "Karl Worthmann", "Kathrin Flaßkamp"], "title": "A data-based image representation for continuous-time LTI systems", "comment": null, "summary": "We derive a numerically stable method to obtain an image representation of an unknown linear system only from data, leveraging a continuous-time version of Willems et al.'s fundamental lemma. We propose a data-based representation that, unlike previous approaches, avoids solving differential-algebraic equations and uses derivatives approximated by algebraic differentiators. Our image-based formulation significantly reduces the complexity of the data-driven representation by eliminating redundant degrees of freedom and thus reducing the number of unknown quantities to be identified. Simulation results confirm the effectiveness of the proposed approach, even in the presence of severe measurement disturbances."}
{"id": "2601.21388", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21388", "abs": "https://arxiv.org/abs/2601.21388", "authors": ["Mingyi Wang", "Dongling Wang"], "title": "Higher-Order Finite Difference Methods for the Tempered Fractional Laplacian", "comment": null, "summary": "This paper presents a general framework of high-order finite difference (HFD) schemes for the tempered fractional Laplacian (TFL) based on new generating functions obtained from the discrete symbols. Specifically, for sufficiently smooth functions, the resulting discretizations achieve high-order convergence with orders $p=4, 6, 8$. The discrete operators lead to Toeplitz stiffness matrices, allowing efficient matrix-vector multiplications via fast algorithms. Building on these approximations, HFD methods are formulated for solving TFL equations, and their stability and convergence are rigorously analyzed. Numerical simulations confirm the effectiveness of the proposed methods, showing excellent agreement with the theoretical predictions."}
{"id": "2601.21535", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.21535", "abs": "https://arxiv.org/abs/2601.21535", "authors": ["Giacomo Greco", "Domenico Marinucci"], "title": "Sparsity for isotropic spherical random fields", "comment": "23 pages, 5 figures", "summary": "We introduce a simple representation for isotropic spherical random fields and we discuss how it allows to discuss different notions of sparsity under isotropy. We also show how a suitable construction of sparse fields can mimic well the angular power spectrum and the polyspectra of some popular non-Gaussian fields, at the same time allowing for computationally efficient simulation algorithms. Using related ideas we also show how it is possible to obtain sparse approximations of spherical random fields which preserve isotropy, thus addressing an issue which has been raised in the Cosmological literature."}
{"id": "2601.21705", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21705", "abs": "https://arxiv.org/abs/2601.21705", "authors": ["Andi Bodnariu", "Nils Engler", "Neofytos Rodosthenous"], "title": "Outrunning the Omega Clock: A Singular Control Problem for Dividend Optimisation with Ruin and Time-in-Distress Default", "comment": null, "summary": "This paper extends the classical dividend problem by incorporating a novel, path-dependent mechanism of firm default. In the traditional framework, ruin occurs when the surplus process first reaches zero. In contrast, default in our model may also arise when the surplus spends an excessive amount of time below a distress threshold, even without ever hitting zero. This occupation-time-based default criterion captures financial distress more realistically, as prolonged periods of low liquidity or capitalisation may trigger regulatory intervention or operational failure. The resulting optimisation problem is formulated as a new singular stochastic control problem with discontinuous state-dependent discounting and killing. We provide a complete analytical solution via a bespoke sequential guess-and-verify method and identify three distinct classes of optimal dividend strategies corresponding to different parameter regimes of the dual-ruin structure. Notably, for certain distress thresholds, the optimal policy features disconnected action and inaction regions. We further show that, unlike in the classical dividend problem, higher effective discounting induced by occupation time below a distress level can lead to delayed, rather than earlier, dividend payments."}
{"id": "2601.21428", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21428", "abs": "https://arxiv.org/abs/2601.21428", "authors": ["Yoshihito Kazashi", "Fabio Nobile", "Fabio Zoccolan"], "title": "Numerical Methods for Dynamical Low-Rank Approximations of Stochastic Differential Equations -- Part I: Time discretization", "comment": "49 pages, 67 figures", "summary": "In this work (Part I), we study three time-discretization procedures of the Dynamical Low-Rank Approximation (DLRA) of high-dimensional stochastic differential equations (SDEs). Specifically, we consider the Dynamically Orthogonal (DO) method for DLRA proposed and analyzed in arXiv:2308.11581v4, which consists of a linear combination of products between deterministic orthonormal modes and stochastic modes, both time-dependent. The first strategy we consider for numerical time-integration is very standard, consisting in a forward discretization in time of both deterministic and stochastic components. Its convergence is proven subject to a time-step restriction dependent on the smallest singular value of the Gram matrix associated to the stochastic modes. Under the same condition on the time-step, this smallest singular value is shown to be always positive, provided that the SDE under study is driven by a non-degenerate noise. The second and the third algorithms, on the other hand, are staggered ones, in which we alternately update the deterministic and the stochastic modes in half steps. These approaches are shown to be more stable than the first one and allow us to obtain convergence results without the aforementioned restriction on the time-step. Computational experiments support theoretical results. In this work we do not consider the discretization in probability, which will be the topic of Part II."}
{"id": "2601.21539", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.21539", "abs": "https://arxiv.org/abs/2601.21539", "authors": ["Lucia Celli"], "title": "Wide neural networks with general weights: convergence rate and explicit dependence on the hyper-parameters", "comment": "105 pages", "summary": "Using Stein's method techniques introduced by Chatterjee (2008) and further extended by Kasprzak and Peccati (2022) and by Lachièze-Rey and Peccati (2017), we derive novel quantitative bounds on the convergence in distribution of feed-forward fully connected neural networks (with Lipschitz activation functions) towards Gaussian processes, as the hidden layer width $n$ tends to infinity. We consider networks initialized with independent and identically distributed (i.i.d.) weights possessing sufficiently many finite moments, and i.i.d. Gaussian biases independent of the weights. Specifically, when the network is evaluated at a single input, we obtain convergence rates of order $O(n^{-1/2})$ in both total variation and Wasserstein distances. When evaluated at a general finite collection of inputs, we establish bounds of the same order in terms of the convex distance. All bounds are given in explicit and computable form. As a consequence of our estimates, we also deduce a novel convergence result in the regime where the depth of the neural network increases simultaneously with the width $n$, up to order $O\\big((\\log_2 n)^{1/3}\\big)$. To the best of our knowledge, this is the first CLT in the infinite width/depth limit holding for general (nonlinear) Lipschitz activation functions and non-Gaussian weight distributions. Our analysis yields several results of independent interest, including: (i) an explicit lower bound on the determinant of the limiting covariance matrix and (ii) new advances in Stein's method, both for the one-dimensional Stein's equation associated with the square of a Lipschitz function and for the multivariate Stein's equation associated with the tensor product of a Lipschitz function with itself."}
{"id": "2601.21710", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21710", "abs": "https://arxiv.org/abs/2601.21710", "authors": ["Yuan Zhang", "Yutong Han", "Yuanqing Xia", "Aming Li"], "title": "On Diagonalizable Systems with Random Structure", "comment": null, "summary": "Diagonalizability plays an important role in the analysis and design of multivariable systems. A structured matrix is called structurally diagonalizable if almost all of its numerical realizations, obtained by assigning real values to its free entries, are diagonalizable. Structural diagonalizability is useful for the verification and optimization of various structural system properties. In this paper, we study the asymptotic probability distribution of structural diagonalizability for structured systems whose system matrices are represented by directed Erdős-Rényi random graphs. Leveraging a recently established graph-theoretic characterization of structural diagonalizability, we analyze the distribution of structurally diagonalizable graphs under different edge-density regimes. For dense graphs, we prove that the system is almost always structurally diagonalizable. For graphs of medium density, we derive tight upper and lower bounds on the asymptotic probability of structural diagonalizability. For extremely sparse graphs, we show that this probability approaches 0. The theoretical results are validated through extensive numerical simulations with varying numbers of vertices and connection probabilities."}
{"id": "2601.21635", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21635", "abs": "https://arxiv.org/abs/2601.21635", "authors": ["Giovanni Taraschi", "Maicon Ribeiro Correa"], "title": "Numerical analysis of a locking-free primal hybrid method for linear elasticity with $H(\\mathrm{div})$-conforming stress recovery", "comment": null, "summary": "In this work, we study a primal hybrid finite element method for the approximation of linear elasticity problems, posed in terms of displacement, an auxiliary pressure field, and a Lagrange multiplier related to the traction. We develop a general analysis for the existence and uniqueness of the solution for the discrete problem, which is applied to the construction of stable approximation spaces on triangular and quadrilateral meshes. The use of these spaces lead to optimal convergence orders, resulting in a locking-free method capable of providing robust approximations for nearly incompressible problems. Finally, we propose a strategy for recovering the stress field from the hybrid solution by solving element-wise sub-problems. The resulting stress approximation is $H(\\mathrm{div})$-conforming, locally equilibrated, weakly symmetric, and robust to locking."}
{"id": "2601.21717", "categories": ["math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21717", "abs": "https://arxiv.org/abs/2601.21717", "authors": ["Shogo Nakakita"], "title": "On sample complexity for covariance estimation via the unadjusted Langevin algorithm", "comment": "21 pages, comments welcome!", "summary": "We establish sample complexity guarantees for estimating the covariance matrix of strongly log-concave smooth distributions using the unadjusted Langevin algorithm (ULA). We quantitatively compare our complexity estimates on single-chain ULA with embarrassingly parallel ULA and derive that the sample complexity of the single-chain approach is smaller than that of embarrassingly parallel ULA by a logarithmic factor in the dimension and the reciprocal of the prescribed precision, with the difference arising from effective bias reduction through burn-in. The key technical contribution is a concentration bound for the sample covariance matrix around its expectation, derived via a log-Sobolev inequality for the joint distribution of ULA iterates."}
{"id": "2601.21748", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21748", "abs": "https://arxiv.org/abs/2601.21748", "authors": ["Lin Li", "Jiongmin Yong"], "title": "Stochastic Optimal Linear Quadratic Controls with A Recursive Cost Functional", "comment": "27 pages", "summary": "This paper is concerned with a stochastic linear quadratic (LQ, for short) control problem with a recursive cost functional. It involves BSDEs in $L^1$ whose well-posedness is a subtle issue. A suitable framework has been adopted so that the corresponding LQ problem is correctly formulated. Open-loop and closed-loop solvability of such an LQ problem have been investigated and characterized by the solvability of an FBSDE and that of Riccati differential equation."}
{"id": "2601.21668", "categories": ["math.NA", "physics.comp-ph", "physics.flu-dyn", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2601.21668", "abs": "https://arxiv.org/abs/2601.21668", "authors": ["Philipp Krah", "Zetao Lin", "R. -Paul Wilhelm", "Fabio Bacchini", "Jean-Christophe Nave", "Virginie Grandgirard", "Kai Schneider"], "title": "A Hybrid semi-Lagrangian Flow Mapping Approach for Vlasov Systems: Combining Iterative and Compositional Flow Maps", "comment": "Preprint", "summary": "We propose a hybrid semi-Lagrangian scheme for the Vlasov--Poisson equation that combines the Numerical Flow Iteration (NuFI) method with the Characteristic Mapping Method (CMM). Both approaches exploit the semi-group property of the underlying diffeomorphic flow, enabling the reconstruction of solutions through flow maps that trace characteristics back to their initial positions. NuFI builds this flow map iteratively, preserving symplectic structure and conserving invariants, but its computational cost scales quadratically with time. Its advantage lies in a compact, low-dimensional representation depending only on the electric field. In contrast, CMM achieves low computational costs when remapping by composing the global flow map from explicitly stored submaps. The proposed hybrid method merges these strengths: NuFi is employed for accurate and conservative local time stepping, while CMM efficiently propagates the solution through submap composition. This approach reduces storage requirements, maintains accuracy, and improves structural properties. Numerical experiments demonstrate the effectiveness of the scheme and highlight the trade-offs between memory usage and computational cost. We benchmark against a semi-Lagrangian predictor-corrector scheme used in modern gyrokinetic codes, evaluating accuracy and conservation properties."}
{"id": "2601.21762", "categories": ["math.PR", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.21762", "abs": "https://arxiv.org/abs/2601.21762", "authors": ["Xue-Mei Li", "Szymon Sobczak"], "title": "Navier-Stokes with a fractional transport noise as a limit of multi-scale dynamics", "comment": "32 pages", "summary": "We define a bona fide rough path solution for the Navier-Stokes equation with an additional rough transport term, and show that the SPDE on the three-dimensional torus driven by a fractional Brownian motion on $H^σ$ has solutions characterised as the effective limits of a slow/fast system. We further show that this rough path solution is equivalent to the widely used incremental notion of solution (the unbounded rough driver formulation), demonstrating broader applicability to other nonlinear SPDEs."}
{"id": "2601.21836", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21836", "abs": "https://arxiv.org/abs/2601.21836", "authors": ["Marco Rando", "Samuel Vaiter"], "title": "ZOBA: An Efficient Single-loop Zeroth-order Bilevel Optimization Algorithm", "comment": "79 pages, 5 figures, 5 tables", "summary": "Bilevel optimization problems consist of minimizing a value function whose evaluation depends on the solution of an inner optimization problem. These problems are typically tackled using first-order methods that require computing the gradient of the value function ({\\it the hypergradient}). In several practical settings, however, first-order information is unavailable ({\\it zeroth-order setting}), rendering these methods inapplicable. Finite-difference methods provide an alternative by approximating hypergradients using function evaluations along a set of directions. Nevertheless, such surrogates are notoriously expensive, and existing finite-difference bilevel methods rely on two-loop algorithms that are poorly parallelizable. In this work, we propose ZOBA, the first finite-difference single-loop algorithm for bilevel optimization. Our method leverages finite-difference hypergradient approximations based on delayed information to eliminate the need for nested loops. We analyze the proposed algorithm and establish convergence rates in the non-convex setting, achieving a complexity of $\\mathcal{O}(p(d + p)^2\\varepsilon^{-2})$, where $p$ and $d$ denote the dimension of inner and outer spaces respectively, which is better than prior approaches based on Hessian approximation. We further introduce and analyze HF-ZOBA, a Hessian-free variant that yields additional complexity improvements. Finally, we corroborate our findings with numerical experiments on synthetic functions and a real-world black-box task in adversarial machine learning. Our results show that our methods achieve accuracy comparable to state-of-the-art techniques while requiring less computation time."}
{"id": "2601.21707", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21707", "abs": "https://arxiv.org/abs/2601.21707", "authors": ["Tamás Dózsa", "Andrea Angino", "Zoltán Szabó", "József Bokor", "Matthias Voigt"], "title": "Adaptive Kernel Methods", "comment": "Submitted to IEEE Transactions on Neural Networks and Learning Systems for review", "summary": "Kernel methods approximate nonlinear maps in a data-driven manner by projecting the target map onto a finite-dimensional Hilbert space called the solution space. Traditionally, this space is a subspace of a fixed ambient reproducing kernel Hilbert space (RKHS), determined solely by the chosen kernel and the dataset, whose elements identify the basis elements. Consequently, the projection operator underlying the kernel method depends on the loss function, the dataset, and the choice of ambient RKHS. In this study, we consider kernel methods whose solution spaces also depend on learnable parameters that are independent of the dataset. The resulting methods can be viewed as variable projection operators that depend on the loss function, the dataset, and the new learnable parameters instead of a fixed RKHS. This work has two main contributions. First, we propose an efficient approximation of kernels associated with infinite-dimensional RKHSs, commonly used to reduce the solution-space dimension for large datasets. Second, we construct fixed-dimensional, parameter-dependent solution spaces that enable highly efficient kernel models suitable for large-scale problems without the need to approximate kernels of infinite-dimensional RKHSs. Our novel family of adaptive kernel methods generalizes earlier approaches, including Random Fourier Features, and we demonstrate their effectiveness through several numerical experiments."}
{"id": "2601.21763", "categories": ["math.PR", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.21763", "abs": "https://arxiv.org/abs/2601.21763", "authors": ["Shuigen Liu", "Xin T. Tong"], "title": "Spectral Gap of Metropolis Algorithms for Non-smooth Distributions under Isoperimetry", "comment": null, "summary": "Metropolis algorithms are classical tools for sampling from target distributions, with broad applications in statistics and scientific computing. Their convergence speed is governed by the spectral gap of the associated Markov operator. Recently, Andrieu et al. (2024) derived the first explicit bounds for the spectral gap of Random-Walk Metropolis when the target distribution is smooth and strongly log-concave. However, existing literature rarely discuss non-smooth targets. In this work, we derive explicit spectral gap bounds for the Random-Walk Metropolis and Metropolis-adjusted Langevin algorithms over a broad class of non-smooth distributions. Moreover, combining our analysis with a recent result in Goyal et al. (2025), we extend these bounds to targets satisfying a Poincare or log-Sobolev inequality, beyond the strongly log-concave setting. Our theoretical results are further supported by numerical experiments."}
{"id": "2601.21858", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21858", "abs": "https://arxiv.org/abs/2601.21858", "authors": ["Jie Liu", "Hailun Zhang", "Jiheng Zhang"], "title": "When to Match: A Cost-Balancing Principle for Dynamic Markets", "comment": null, "summary": "Matching platforms, from ridesharing to food delivery to competitive gaming, face a fundamental operational dilemma: match agents immediately to minimize waiting costs, or delay to exploit the efficiency gains of thicker markets. Yet computing optimal policies is generally intractable, sophisticated algorithms often rely on restrictive distributional assumptions, and common heuristics lack worst-case performance guarantees. We formulate a versatile framework for multi-sided matching with general state-dependent cost structures and non-stationary arrival dynamics. Central to our approach is a cost-balancing principle: match when accumulated waiting cost reaches a calibrated proportion of instantaneous matching cost. This equilibrium condition emerges from fluid-limit analysis and motivates a simple, adaptive Cost-Balancing (CB) algorithm requiring no distributional assumptions. We prove that CB achieves a competitive ratio of $(1+\\sqrtΓ)$ under adversarial arrivals, where $Γ$ quantifies economies of scale, guaranteeing cost within a constant factor of the offline optimum. In contrast, standard greedy and threshold policies can incur unbounded costs in adversarial scenarios. We further establish a universal lower bound of $(\\sqrt{5}+1)/2$ (the golden ratio), quantifying the fundamental price of uncertainty in online matching. Experiments on game matchmaking and real-world food delivery data demonstrate practical effectiveness, with CB consistently outperforming industry-standard heuristics."}
{"id": "2601.21736", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21736", "abs": "https://arxiv.org/abs/2601.21736", "authors": ["Michael Hinze", "Christian Kahle", "Michael Stahl"], "title": "A reduced basis method for parabolic PDEs based on a space-time least squares formulation", "comment": null, "summary": "In this work, we present a POD-greedy reduced basis method for parabolic partial differential equations (PDEs), based on the least squares space-time formulation proposed in [Hinze, Kahle, Stahl, A least-squares space-time approach for parabolic equations, 2023, arXiv:2305.03402] that assumes only minimal regularity. We extend this approach to the parameter-dependent case. The corresponding variational formulation then is based on a parameter-dependent, symmetric, uniformly coercive, and continuous bilinear form. We apply the reduced basis method to this formulation, following the well-developed techniques for parameterized coercive problems, as seen e.g. in reduced basis methods for parameterized elliptic PDEs. We present an offline-online decomposition and provide certification with absolute and relative error bounds. The performance of the method is demonstrated using selected numerical examples."}
{"id": "2601.21867", "categories": ["math.PR", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21867", "abs": "https://arxiv.org/abs/2601.21867", "authors": ["David Treeby", "Edward Wang"], "title": "Escaping the unit ball", "comment": "11 pages, 2 figures", "summary": "We prove that among all unit-speed paths, a straight line minimises the expected escape time from a ball in $\\mathbf{R}^n$, solving the min-mean variant of Bellman's Lost in a Forest problem for ball-shaped forests. The proof uses the Kneser--Poulsen conjecture in the plane, together with results on polygonal chain straightening in higher dimensions. Moreover, we calculate this minimal escape time by deriving the expected linear distance to the boundary of a ball in $n$ dimensions."}
{"id": "2601.21860", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21860", "abs": "https://arxiv.org/abs/2601.21860", "authors": ["Nicole Tianjiao Yang"], "title": "Pathwise Learning of Stochastic Dynamical Systems with Partial Observations", "comment": null, "summary": "The reconstruction and inference of stochastic dynamical systems from data is a fundamental task in inverse problems and statistical learning. While surrogate modeling advances computational methods to approximate these dynamics, standard approaches typically require high-fidelity training data. In many practical settings, the data are indirectly observed through noisy and nonlinear measurement. The challenge lies not only in approximating the coefficients of the SDEs, but in simultaneously inferring the posterior updates given the observations. In this work, we present a neural path estimation approach to solve stochastic dynamical systems based on variational inference. We first derive a stochastic control problem that solve filtering posterior path measure corresponding to a pathwise Zakai equation. We then construct a generative model that maps the prior path measure to posterior measure through the controlled diffusion and the associated Randon-Nykodym derivative. Through an amortization of sample paths of the observation process, the control is learned by an embedding of the noisy observation paths. Thus, we learn the unknown prior SDE and the control can recover the conditional path measure given the observation sample paths and we learn an associated SDE which induces the same path measure. In the end, we perform experiments on nonlinear dynamical systems, demonstrating the model's ability to learn multimodal, chaotic, or high dimensional systems."}
{"id": "2601.21764", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21764", "abs": "https://arxiv.org/abs/2601.21764", "authors": ["Olivier Bokanowski", "Carlos Esteve-Yagüe", "Richard Tsai"], "title": "Solving Hamilton-Jacobi equations by minimizing residuals of monotone discretizations", "comment": "29 pages, 5 figures", "summary": "We derive sufficient conditions under which residual minimization yields well-posed discrete solutions for nonlinear equations defined by monotone finite--difference discretizations. Our analysis is motivated by the challenge of solving fully nonlinear Hamilton--Jacobi (HJ) equations in high dimensions by means of a Neural Network, which is trained by minimizing residuals arising from monotone discretizations of the Hamiltonian. While classical theory ensures that consistency and monotonicity imply convergence to the viscosity solution, treating these discrete systems as optimization problems introduces new analytical hurdles: solvability and the uniqueness of local minima do not follow from monotonicity alone.\n  By establishing the well--posedness of these optimization--based solvers, our framework enables the adaptation of Level Set Methods to high--dimensional settings, unlocking new capabilities in applications such as high--dimensional segmentation and interface tracking. Finally, we observe that these arguments extend almost directly to degenerate elliptic or parabolic PDEs on graphs equipped with monotone graph Laplacians."}
{"id": "2601.22056", "categories": ["math.PR", "math.AP", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.22056", "abs": "https://arxiv.org/abs/2601.22056", "authors": ["Benjamin Gess", "Rishabh S. Gvalani", "Adrian Martini"], "title": "Ergodicity for SPDEs driven by divergence-free transport noise", "comment": null, "summary": "We study the ergodic behaviour of the McKean-Vlasov equations driven by common, divergence-free transport noise. In particular, we show that in dimension $d\\geq 2$, if the noise is mixing and sufficiently strong it can enforce the uniqueness of invariant probability measures, even if the deterministic part of equation has multiple steady states."}
{"id": "2601.21917", "categories": ["math.OC", "cs.CC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21917", "abs": "https://arxiv.org/abs/2601.21917", "authors": ["Amir Ali Ahmadi", "Georgina Hall"], "title": "On Approximate Computation of Critical Points", "comment": null, "summary": "We show that computing even very coarse approximations of critical points is intractable for simple classes of nonconvex functions. More concretely, we prove that if there exists a polynomial-time algorithm that takes as input a polynomial in $n$ variables of constant degree (as low as three) and outputs a point whose gradient has Euclidean norm at most $2^n$ whenever the polynomial has a critical point, then P=NP. The algorithm is permitted to return an arbitrary point when no critical point exists. We also prove hardness results for approximate computation of critical points under additional structural assumptions, including settings in which existence and uniqueness of a critical point are guaranteed, the function is lower bounded, and approximation is measured in terms of distance to a critical point. Overall, our results stand in contrast to the commonly-held belief that, in nonconvex optimization, approximate computation of critical points is a tractable task."}
{"id": "2601.21799", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21799", "abs": "https://arxiv.org/abs/2601.21799", "authors": ["Daniel Kressner", "Peter Oehme"], "title": "A novel Krylov subspace method for approximating Fréchet derivatives of large-scale matrix functions", "comment": "15 pages, 13 figures, 2 tables", "summary": "We present a novel Krylov subspace method for approximating $L_f(A, E) \\vc{b}$, the matrix-vector product of the Fréchet derivative $L_f(A, E)$ of a large-scale matrix function $f(A)$ in direction $E$, a task that arises naturally in the sensitivity analysis of quantities involving matrix functions, such as centrality measures for networks. It also arises in the context of gradient-based methods for optimization problems that feature matrix functions, e.g., when fitting an evolution equation to an observed solution trajectory. In principle, the well-known identity \\[\n  f\\left( \\begin{bmatrix}\n  A & E \\\\ 0 & A\n  \\end{bmatrix} \\right) \\begin{bmatrix}\n  0 \\\\ \\vc{b}\n  \\end{bmatrix} = \\begin{bmatrix}\n  L_f(A, E) \\vc{b} \\\\ f(A) \\vc{b}\n  \\end{bmatrix}, \\] allows one to directly apply any standard Krylov subspace method, such as the Arnoldi algorithm, to address this task. However, this comes with the major disadvantage that the involved block triangular matrix has unfavorable spectral properties, which impede the convergence analysis and, to a certain extent, also the observed convergence. To avoid these difficulties, we propose a novel modification of the Arnoldi algorithm that aims at better preserving the block triangular structure. In turn, this allows one to bound the convergence of the modified method by the best polynomial approximation of the derivative $f^\\prime$ on the numerical range of $A$. Several numerical experiments illustrate our findings."}
{"id": "2601.22102", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2601.22102", "abs": "https://arxiv.org/abs/2601.22102", "authors": ["Ernesto M. Greco", "Daniela Morale"], "title": "Integrability properties and stochastic McKean-Vlasov dynamics with singular Lennard-Jones drift: a mesoscale regularization", "comment": null, "summary": "We study the convergence of the empirical measure of moderately interacting particle systems subject to singular forces derived by Lennard-Jones potential. Although the classical Lennard-Jones force is widely used in molecular dynamics, analytical results are not available. We consider a Lennard-Jones potential with free parameters in the McKean-Vlasov framework and proceed with a regularization at the mesoscale letting the particles interact moderately. We prove the well-posedness of the McKean-Vlasov SDE involving such singular kernels and the convergence of the empirical measure towards the solution of the McKean-Vlasov Fokker-Planck PDE, by means of a semigroup approach. We derive both the range of parameters characterizing the aggregation and repulsive force and the mesoscale order for which the convergence is achieved, by obtaining the right integrability regularity of the drift."}
{"id": "2601.21990", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21990", "abs": "https://arxiv.org/abs/2601.21990", "authors": ["Nicolas Blin", "Stefano Gualandi", "Christopher Maes", "Andrea Lodi", "Bartolomeo Stellato"], "title": "Batched First-Order Methods for Parallel LP Solving in MIP", "comment": "15 pages, 4 figures, 4 tables", "summary": "We present a batched first-order method for solving multiple linear programs in parallel on GPUs. Our approach extends the primal-dual hybrid gradient algorithm to efficiently solve batches of related linear programming problems that arise in mixed-integer programming techniques such as strong branching and bound tightening. By leveraging matrix-matrix operations instead of repeated matrix-vector operations, we obtain significant computational advantages on GPU architectures. We demonstrate the effectiveness of our approach on various case studies and identify the problem sizes where first-order methods outperform traditional simplex-based solvers depending on the computational environment one can use. This is a significant step for the design and development of integer programming algorithms tightly exploiting GPU capabilities where we argue that some specific operations should be allocated to GPUs and performed in full instead of using light-weight heuristic approaches on CPUs."}
{"id": "2601.21874", "categories": ["math.NA", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21874", "abs": "https://arxiv.org/abs/2601.21874", "authors": ["Bin Gao", "Renfeng Peng", "Ya-xiang Yuan"], "title": "Quotient geometry of tensor ring decomposition", "comment": "22 pages, 8 figures, 1 table", "summary": "Differential geometries derived from tensor decompositions have been extensively studied and provided the foundations for a variety of efficient numerical methods. Despite the practical success of the tensor ring (TR) decomposition, its intrinsic geometry remains less understood, primarily due to the underlying ring structure and the resulting nontrivial gauge invariance. We establish the quotient geometry of TR decomposition by imposing full-rank conditions on all unfolding matrices of the core tensors and capturing the gauge invariance. Additionally, the results can be extended to the uniform TR decomposition, where all core tensors are identical. Numerical experiments validate the developed geometries via tensor ring completion tasks."}
{"id": "2601.22142", "categories": ["math.PR", "math-ph", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.22142", "abs": "https://arxiv.org/abs/2601.22142", "authors": ["Scott Armstrong", "Ahmed Bou-Rabee", "Tuomo Kuusi"], "title": "Superdiffusion and anomalous regularization in self-similar random incompressible flows", "comment": "155 pages, announcement at https://www.scottnarmstrong.com/2026/01/superdiffusivity-anomalous-regularization/", "summary": "We study the long-time behavior of a particle in $\\mathbb{R}^d$, $d \\geq 2$, subject to molecular diffusion and advection by a random incompressible flow. The velocity field is the divergence of a stationary random stream matrix $\\mathbf{k} $ with positive Hurst exponent $γ> 0$, so the resulting random environment is multiscale and self-similar. In the perturbative regime $γ\\ll 1$, we prove quenched power-law superdiffusion: for a typical realization of the environment, the displacement variance at time $t$ grows like $t^{2/(2-γ)}$, the scaling predicted by renormalization group heuristics. We also identify the leading prefactor up to a random (quenched) relative error of order $γ^{\\frac12}\\left| \\log γ\\right|^3$. The proof implements a Wilsonian renormalization group scheme at the level of the infinitesimal generator $\\nabla \\cdot (νI_d + \\mathbf{k} ) \\nabla$, based on a self-similar induction across scales. We demonstrate that the coarse-grained generator is well-approximated, at each scale $r$, by a constant-coefficient Laplacian with effective diffusivity growing like $r^γ$. This approximation is inherently scale-local: reflecting the multifractal nature of the environment, the relative error does not decay with the scale, but remains of order $γ^{\\frac12}\\left| \\log γ\\right|^2$. We also prove anomalous regularization under the quenched law: for almost every realization of the drift, solutions of the associated elliptic equation are Hölder continuous with exponent $1 - Cγ^{\\frac12}$ and satisfy estimates which are uniform in the molecular diffusivity $ν$ and the scale."}
{"id": "2601.22038", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22038", "abs": "https://arxiv.org/abs/2601.22038", "authors": ["Vitalii Aksenov", "Martin Eigel", "Mathias Oster"], "title": "Anderson Mixing in Bures Wasserstein Space of Gaussian Measures", "comment": null, "summary": "Various statistical tasks, including sampling or computing Wasserstein barycenters, can be reformulated as fixed-point problems for operators on probability distributions.\n  Accelerating standard fixed-point iteration schemes provides a promising novel approach to the design of efficient numerical methods for these problems.\n  The Wasserstein geometry on the space of probability measures, although not precisely Riemannian, allows us to define various useful Riemannian notions, such as tangent spaces, exponential maps and parallel transport, motivating the adaptation of Riemannian numerical methods.\n  We demonstrate this by developing and implementing the Riemannian Anderson Mixing (RAM) method for Gaussian distributions.\n  The method reuses the history of the residuals and improves the iteration complexity, and we argue that the additional costs, compared to Picard method, are negligible.\n  We show that certain open balls in the Bures-Wasserstein manifold satisfy the requirements for convergence of RAM.\n  The numerical experiments show a significant acceleration compared to a Picard iteration, and performance on par with Riemannian Gradient Descent and Conjugate Gradient methods."}
{"id": "2601.21019", "categories": ["math.ST", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21019", "abs": "https://arxiv.org/abs/2601.21019", "authors": ["Markus Holzleitner", "Sergiy Pereverzyev", "Sergei V. Pereverzyev", "Vaibhav Silmana", "S. Sivananthan"], "title": "Towards regularized learning from functional data with covariate shift", "comment": "38 pages", "summary": "This paper investigates a general regularization framework for unsupervised domain adaptation in vector-valued regression under the covariate shift assumption, utilizing vector-valued reproducing kernel Hilbert spaces (vRKHS). Covariate shift occurs when the input distributions of the training and test data differ, introducing significant challenges for reliable learning. By restricting the hypothesis space, we develop a practical operator learning algorithm capable of handling functional outputs. We establish optimal convergence rates for the proposed framework under a general source condition, providing a theoretical foundation for regularized learning in this setting. We also propose an aggregation-based approach that forms a linear combination of estimators corresponding to different regularization parameters and different kernels. The proposed approach addresses the challenge of selecting appropriate tuning parameters, which is crucial for constructing a good estimator, and we provide a theoretical justification for its effectiveness. Furthermore, we illustrate the proposed method on a real-world face image dataset, demonstrating robustness and effectiveness in mitigating distributional discrepancies under covariate shift."}
{"id": "2601.22080", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22080", "abs": "https://arxiv.org/abs/2601.22080", "authors": ["Shuaicheng Tong", "Michael A. Boateng", "Mathieu Tanneau", "Pascal Van Hentenryck"], "title": "Volt/VAR Optimization in Transmission Networks with Discrete-Control Devices", "comment": null, "summary": "Voltage (Volt) and reactive-power (VAR) control in transmission networks is critical for reliability and increasingly needs fast, implementable decisions. This paper presents a transmission Volt/VAR Optimization (VVO) framework that co-optimizes discrete control of on-load tap-changing transformers (OLTCs) and capacitor banks (CBs) with AC power flow (ACPF) physics to improve voltage stability and minimize VAR generation. The framework follows a relax-round-resolve pipeline: a continuous relaxation proposes targets, a rounding step selects feasible discrete settings, and a final solve enforces AC power flow physics. Extensive experiments on IEEE, PEGASE, and RTE systems show consistent improvements in voltage and VAR quality metrics with modest generator redispatch while preserving economic operation and achieving compatible runtimes with real-time transmission operations."}
{"id": "2601.21243", "categories": ["math.OC", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21243", "abs": "https://arxiv.org/abs/2601.21243", "authors": ["Amir Ali Farzin", "Yuen-Man Pun", "Philipp Braun", "Tyler Summers", "Iman Shames"], "title": "Solving the Offline and Online Min-Max Problem of Non-smooth Submodular-Concave Functions: A Zeroth-Order Approach", "comment": null, "summary": "We consider max-min and min-max problems with objective functions that are possibly non-smooth, submodular with respect to the minimiser and concave with respect to the maximiser. We investigate the performance of a zeroth-order method applied to this problem. The method is based on the subgradient of the Lovász extension of the objective function with respect to the minimiser and based on Gaussian smoothing to estimate the smoothed function gradient with respect to the maximiser. In expectation sense, we prove the convergence of the algorithm to an $ε$-saddle point in the offline case. Moreover, we show that, in the expectation sense, in the online setting, the algorithm achieves $O(\\sqrt{N\\bar{P}_N})$ online duality gap, where $N$ is the number of iterations and $\\bar{P}_N$ is the path length of the sequence of optimal decisions. The complexity analysis and hyperparameter selection are presented for all the cases. The theoretical results are illustrated via numerical examples."}
{"id": "2601.22126", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22126", "abs": "https://arxiv.org/abs/2601.22126", "authors": ["David Huckleberry Gutman", "George Lobo"], "title": "An Invitation to Higher-Order Riemannian Optimization: Optimal and Implementable Methods", "comment": null, "summary": "This paper presents the first optimal-rate $p$-th order methods with $p\\geq 1$ for finding first and second-order stationary points of non-convex smooth objective functions over Riemannian manifolds. In contrast to the geodesically convex setting, we definitively establish that the optimal oracle complexity of non-convex optimization over manifolds matches that over Euclidean space. In parallel with the complexity analysis, we introduce a general framework for systematically studying higher-order regularity on Riemannian manifolds that characterizes its joint dependence on the objective function and the chosen retraction. To the best of our knowledge, this framework constitutes the first known application in optimization of pullback connections and the Sasaki metric to the study of retraction-based pullbacks of the objective function. We provide clean derivative bounds based on a new covariant Faà di Bruno formula derived within our framework. For $p=3$, our methods are fully implementable via a new Krylov-based framework for minimizing quartically regularized cubic polynomials. This is the first Krylov method for this class of polynomials and may be of independent interest beyond Riemannian optimization."}
{"id": "2601.21917", "categories": ["math.OC", "cs.CC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21917", "abs": "https://arxiv.org/abs/2601.21917", "authors": ["Amir Ali Ahmadi", "Georgina Hall"], "title": "On Approximate Computation of Critical Points", "comment": null, "summary": "We show that computing even very coarse approximations of critical points is intractable for simple classes of nonconvex functions. More concretely, we prove that if there exists a polynomial-time algorithm that takes as input a polynomial in $n$ variables of constant degree (as low as three) and outputs a point whose gradient has Euclidean norm at most $2^n$ whenever the polynomial has a critical point, then P=NP. The algorithm is permitted to return an arbitrary point when no critical point exists. We also prove hardness results for approximate computation of critical points under additional structural assumptions, including settings in which existence and uniqueness of a critical point are guaranteed, the function is lower bounded, and approximation is measured in terms of distance to a critical point. Overall, our results stand in contrast to the commonly-held belief that, in nonconvex optimization, approximate computation of critical points is a tractable task."}
{"id": "2601.21764", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21764", "abs": "https://arxiv.org/abs/2601.21764", "authors": ["Olivier Bokanowski", "Carlos Esteve-Yagüe", "Richard Tsai"], "title": "Solving Hamilton-Jacobi equations by minimizing residuals of monotone discretizations", "comment": "29 pages, 5 figures", "summary": "We derive sufficient conditions under which residual minimization yields well-posed discrete solutions for nonlinear equations defined by monotone finite--difference discretizations. Our analysis is motivated by the challenge of solving fully nonlinear Hamilton--Jacobi (HJ) equations in high dimensions by means of a Neural Network, which is trained by minimizing residuals arising from monotone discretizations of the Hamiltonian. While classical theory ensures that consistency and monotonicity imply convergence to the viscosity solution, treating these discrete systems as optimization problems introduces new analytical hurdles: solvability and the uniqueness of local minima do not follow from monotonicity alone.\n  By establishing the well--posedness of these optimization--based solvers, our framework enables the adaptation of Level Set Methods to high--dimensional settings, unlocking new capabilities in applications such as high--dimensional segmentation and interface tracking. Finally, we observe that these arguments extend almost directly to degenerate elliptic or parabolic PDEs on graphs equipped with monotone graph Laplacians."}
{"id": "2601.21867", "categories": ["math.PR", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21867", "abs": "https://arxiv.org/abs/2601.21867", "authors": ["David Treeby", "Edward Wang"], "title": "Escaping the unit ball", "comment": "11 pages, 2 figures", "summary": "We prove that among all unit-speed paths, a straight line minimises the expected escape time from a ball in $\\mathbf{R}^n$, solving the min-mean variant of Bellman's Lost in a Forest problem for ball-shaped forests. The proof uses the Kneser--Poulsen conjecture in the plane, together with results on polygonal chain straightening in higher dimensions. Moreover, we calculate this minimal escape time by deriving the expected linear distance to the boundary of a ball in $n$ dimensions."}
{"id": "2601.21874", "categories": ["math.NA", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21874", "abs": "https://arxiv.org/abs/2601.21874", "authors": ["Bin Gao", "Renfeng Peng", "Ya-xiang Yuan"], "title": "Quotient geometry of tensor ring decomposition", "comment": "22 pages, 8 figures, 1 table", "summary": "Differential geometries derived from tensor decompositions have been extensively studied and provided the foundations for a variety of efficient numerical methods. Despite the practical success of the tensor ring (TR) decomposition, its intrinsic geometry remains less understood, primarily due to the underlying ring structure and the resulting nontrivial gauge invariance. We establish the quotient geometry of TR decomposition by imposing full-rank conditions on all unfolding matrices of the core tensors and capturing the gauge invariance. Additionally, the results can be extended to the uniform TR decomposition, where all core tensors are identical. Numerical experiments validate the developed geometries via tensor ring completion tasks."}
