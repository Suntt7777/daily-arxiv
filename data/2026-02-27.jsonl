{"id": "2602.22369", "categories": ["math.ST", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.22369", "abs": "https://arxiv.org/abs/2602.22369", "authors": ["Ruixiao Wang", "Xiaohong Chen", "Sinho Chewi"], "title": "Sampling from Constrained Gibbs Measures: with Applications to High-Dimensional Bayesian Inference", "comment": null, "summary": "This paper considers a non-standard problem of generating samples from a low-temperature Gibbs distribution with \\emph{constrained} support, when some of the coordinates of the mode lie on the boundary. These coordinates are referred to as the non-regular part of the model. We show that in a ``pre-asymptotic'' regime in which the limiting Laplace approximation is not yet valid, the low-temperature Gibbs distribution concentrates on a neighborhood of its mode. Within this region, the distribution is a bounded perturbation of a product measure: a strongly log-concave distribution in the regular part and a one-dimensional exponential-type distribution in each coordinate of the non-regular part. Leveraging this structure, we provide a non-asymptotic sampling guarantee by analyzing the spectral gap of Langevin dynamics. Key examples of low-temperature Gibbs distributions include Bayesian posteriors, and we demonstrate our results on three canonical examples: a high-dimensional logistic regression model, a Poisson linear model, and a Gaussian mixture model."}
{"id": "2602.22929", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.22929", "abs": "https://arxiv.org/abs/2602.22929", "authors": ["Marc Taberner-Ortiz", "Manfred Denker"], "title": "Remarks on stationary GARCH processes under heavy tail distributions", "comment": null, "summary": "Let $(X_n)_{n\\in \\mathbb Z}$ be a GARCH process with $E(X_0^4)<\\infty$, and let $μ_n$ denote the distribution of $\\frac 1{\\sqrt n}\\sum_{i=1}^n [X_i^2-\\mathbb E(X_0^2)]$. We derive a numerical approximation of $μ_n$ when $x_1,...,x_n$ are observed. This yields the derivation of confidence intervals for $μ= E(X_0^2)$ and we investigate the accuracy of these confidence intervals in comparison with standard ones based on normal approximation. Moreover, when the innovation process has heavy tail distribution, we improve the method using a new resampling method."}
{"id": "2602.22954", "categories": ["math.ST", "cs.CE", "eess.SP", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.22954", "abs": "https://arxiv.org/abs/2602.22954", "authors": ["L. Martino", "V. Elvira"], "title": "Effective sample size approximations as entropy measures", "comment": null, "summary": "In this work, we analyze alternative effective sample size (ESS) metrics for importance sampling algorithms, and discuss a possible extended range of applications. We show the relationship between the ESS expressions used in the literature and two entropy families, the Rényi and Tsallis entropy. The Rényi entropy is connected to the Huggins-Roy's ESS family introduced in \\cite{Huggins15}. We prove that that all the ESS functions included in the Huggins-Roy's family fulfill all the desirable theoretical conditions. We analyzed and remark the connections with several other fields, such as the Hill numbers introduced in ecology, the Gini inequality coefficient employed in economics, and the Gini impurity index used mainly in machine learning, to name a few.\n  Finally, by numerical simulations, we study the performance of different ESS expressions contained in the previous ESS families in terms of approximation of the theoretical ESS definition, and show the application of ESS formulas in a variable selection problem."}
{"id": "2602.23021", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.23021", "abs": "https://arxiv.org/abs/2602.23021", "authors": ["Steffen Grønneberg", "Nils Lid Hjort"], "title": "On the errors committed by sequences of estimator functionals", "comment": "27 pages, 1 figure. Statistical Research Report, Department of Mathematics, University of Oslo, from March 2010, now arXiv'd February 2026. The paper is published, essentially in this form, in Mathematical Methods of Statistics, 2012, vol. 20, pages 327-346, at this url: link.springer.com/article/10.3103/S106653071104003X", "summary": "Consider a sequence of estimators $\\hat θ_n$ which converges almost surely to $θ_0$ as the sample size $n$ tends to infinity. Under weak smoothness conditions, we identify the asymptotic limit of the last time $\\hat θ_n$ is further than $\\eps$ away from $θ_0$ when $\\eps \\rightarrow 0^+$. These limits lead to the construction of sequentially fixed width confidence regions for which we find analytic approximations. The smoothness conditions we impose is that $\\hat θ_n$ is to be close to a Hadamard-differentiable functional of the empirical distribution, an assumption valid for a large class of widely used statistical estimators. Similar results were derived in Hjort and Fenstad (1992, Annals of Statistics) for the case of Euclidean parameter spaces; part of the present contribution is to lift these results to situations involving parameter functionals. The apparatus we develop is also used to derive appropriate limit distributions of other quantities related to the far tail of an almost surely convergent sequence of estimators, like the number of times the estimator is more than $\\eps$ away from its target. We illustrate our results by giving a new sequential simultaneous confidence set for the cumulative hazard function based on the Nelson--Aalen estimator and investigate a problem in stochastic programming related to computational complexity."}
{"id": "2602.22390", "categories": ["math.NA", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.22390", "abs": "https://arxiv.org/abs/2602.22390", "authors": ["Siu Wun Cheung", "Youngsoo Choi", "Jean-Luc Fattebert", "Jonas Kaufman", "Daniel Osei-Kuffuor"], "title": "A Reduced Order Model approach for First-Principles Molecular Dynamics Computations", "comment": null, "summary": "To leverage the redundancy between the electronic structure computed at each step of first-principles molecular dynamics, we present a data-driven modeling framework for Kohn-Sham Density Functional Theory that bypasses the explicit optimization of electronic wavefunctions. We sample a priori representative atomic configurations and construct a low-dimensional basis that efficiently approximates the electronic structure subspace. Subsequently, we employ this reduced basis in a direct solver for the electronic single particle density matrix, thereby enabling the efficient determination of ground state without iterative wavefunction optimization. We demonstrate the efficacy of our approach in a Born-Oppenheimer molecular dynamics of a water molecule, showing that the resulting simulations accurately reproduce key structural properties, such as bond lengths and bond angle, obtained from full first-principles molecular dynamics. This work highlights the potential of data-driven approaches to develop efficient electronic structure solvers for first-principles simulations."}
{"id": "2602.22342", "categories": ["math.PR", "math.FA", "math.MG"], "pdf": "https://arxiv.org/pdf/2602.22342", "abs": "https://arxiv.org/abs/2602.22342", "authors": ["Antoine Song"], "title": "Sum of Gaussian vectors and large sets", "comment": null, "summary": "We show that for some constant $κ>0$, any centered $κ$-subgaussian random variable is equal to the sum of three standard Gaussian random variables, confirming a conjecture of M. Talagrand. We also prove that given $Λ\\geq 1$, any centered random vector $X$ in $\\mathbb{R}^n$ such that $\\|X\\|\\leq Λ$ almost surely and $\\|\\mathrm{Cov}(X)\\|\\leq {Λ^2 }{e^{-Λ^2}}$ is equal to the sum of a universal number of standard Gaussian random vectors. In particular, a centered random vector is subgaussian if and only if it is a finite sum of Gaussian random vectors. We apply these results to settle the permutation invariant case of M. Talagrand's convexity problem, and to give optimal estimates on the largest ellipsoid contained in a sum of large sets in Gaussian spaces."}
{"id": "2602.22421", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22421", "abs": "https://arxiv.org/abs/2602.22421", "authors": ["Donghao Zhu", "Hanzhang Qin", "Ching-pei Lee", "Yuki Saito", "Takahiro Kawashima", "Kenji Fukumizu"], "title": "Huge-Scale Assortment Optimization with Customer Choice: A Parallel Primal-Dual Approach", "comment": null, "summary": "We study huge-scale assortment optimization problems to maximize expected revenue under customer choice, addressing a fundamental challenge in industries such as transportation, retail, and healthcare. The choice-based linear programming (CBLP) formulation provides a powerful framework for optimizing sales allocations across customer segments, yet traditional approaches often fail to solve CBLPs of huge scale (involving millions of customer choices) due to the lack of algorithmic designs that exploit problem structure. To overcome this computational bottleneck, we propose a first-order primal-dual method, SPFOM, which requires only a small computational cost per iteration, achieves a provably near-optimal convergence rate, and can be readily extended to parallel computing environments. Computational experiments demonstrate the computational and practical superiority of SPFOM over state-of-the-art solvers for large-scale linear programs. The framework is extended to a multi-period assortment optimization setting with inventory constraints, where SPFOM estimates global shadow prices that enhance classical bid-price control policies compared with benchmark methods such as market segment decomposition. Numerical experiments and a case study using real-world data from the ZOZOTOWN platform validate the practical effectiveness of SPFOM, highlighting its advantages in improving revenue performance while maintaining balanced inventory levels."}
{"id": "2602.23023", "categories": ["math.ST", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23023", "abs": "https://arxiv.org/abs/2602.23023", "authors": ["Alexandra Carpentier", "Nicolas Verzelen"], "title": "Low-degree Lower bounds for clustering in moderate dimension", "comment": null, "summary": "We study the fundamental problem of clustering $n$ points into $K$ groups drawn from a mixture of isotropic Gaussians in $\\mathbb{R}^d$. Specifically, we investigate the requisite minimal distance $Δ$ between mean vectors to partially recover the underlying partition. While the minimax-optimal threshold for $Δ$ is well-established, a significant gap exists between this information-theoretic limit and the performance of known polynomial-time procedures. Although this gap was recently characterized in the high-dimensional regime ($n \\leq dK$), it remains largely unexplored in the moderate-dimensional regime ($n \\geq dK$). In this manuscript, we address this regime by establishing a new low-degree polynomial lower bound for the moderate-dimensional case when $d \\geq K$. We show that while the difficulty of clustering for $n \\leq dK$ is primarily driven by dimension reduction and spectral methods, the moderate-dimensional regime involves more delicate phenomena leading to a \"non-parametric rate\". We provide a novel non-spectral algorithm matching this rate, shedding new light on the computational limits of the clustering problem in moderate dimension."}
{"id": "2602.22679", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.22679", "abs": "https://arxiv.org/abs/2602.22679", "authors": ["Tiantian Sun", "Juan Zhang"], "title": "Error Analysis of Parameter Prediction via Gaussian Process Regression and Its Application to Weighted Jacobi Iteration", "comment": null, "summary": "In this paper, we introduce a novel theoretical framework for Gaussian process regression error analysis, leveraging a function-space decomposition. Based on this framework, we develop a weighted Jacobi iterative method that utilizes Gaussian process regression for parameter prediction and provide a corresponding convergence analysis. Moreover, the convergence conditions are designed to be compatible with other error bounds, enabling a more general analysis. Experimental results show that the parameters predicted based on Gaussian process regression significantly accelerate the convergence speed of Jacobi iterations."}
{"id": "2602.22348", "categories": ["math.PR", "math-ph", "math.FA", "math.SP"], "pdf": "https://arxiv.org/pdf/2602.22348", "abs": "https://arxiv.org/abs/2602.22348", "authors": ["Hubert Balsam", "Kamil Kaleta", "Mariusz Olszewski", "Katarzyna Pietruska-Pałuba"], "title": "IDS for subordinate Brownian motions in Poisson random environment on nested fractals", "comment": "27 pages", "summary": "We establish the Lifshitz singularity of the integrated density of states (IDS) for random Schrödinger operators \\[ H^ω = φ(-\\mathcal{L}) + V^ω \\] on planar unbounded nested fractals with the Good Labeling Property. Here, $\\mathcal{L}$ is the Laplacian on the fractal, $φ$ is an operator monotone function with mild regularity, and $V^ω$ is a Poissonian random potential with a sufficiently regular profile. The main novelty of our work lies in showing that the study of $V^ω$ can be effectively reduced to the analysis of certain alloy-type potential, where the sites are no longer lattice points as in the classical $\\mathbb{Z}^d$ case, but fractal complexes. This observation enables us to apply an approach, new in the setting of Poissonian random fields, which allows us to treat a broad class of Bernstein functions $φ$. In particular, it covers the case $φ(λ)=(λ+m^{d_w/\\vartheta})^{\\vartheta/d_w}-m$, $\\vartheta \\in (0,d_w)$, $m>0$, corresponding to relativistic models, which were previously unattainable on fractals by known methods."}
{"id": "2602.22458", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22458", "abs": "https://arxiv.org/abs/2602.22458", "authors": ["Dario Dennstädt"], "title": "Model Predictive Control for output tracking with prescribed performance", "comment": "PhD thesis", "summary": "Model Predictive Control (MPC) offers a versatile framework for constraint handling and multi-objective optimisation, yet practical application faces challenges regarding initial and recursive feasibility, robustness against model mismatches, and sampled-data constraints. This thesis develops a novel MPC framework for a class of non-linear continuous-time systems governed by functional differential equations. It targets output tracking within prescribed error bounds while systematically overcoming these challenges.\n  First, we introduce funnel MPC, an algorithm eliminating reliance on terminal conditions or restrictive long prediction horizons. Utilising funnel penalty functions -- state costs penalising tracking error deviations from time-varying boundaries -- this framework ensures feasibility while rigorously enforcing tracking performance guarantees.\n  Next, we unify funnel MPC with model-free funnel feedback into a hybrid architecture. This synergises model-based optimisation with adaptive feedback compensation, achieving prescribed tracking performance despite structural model-plant mismatches, unmodelled dynamics, and unknown disturbances.\n  To further enhance predictive accuracy, we integrate a data-driven learning framework that iteratively refines the model using system measurements, improving long-term performance without compromising robustness.\n  Finally, we formalise the transition to sampled-data implementations. We derive explicit bounds on sampling rates and control effort to guarantee stability under piecewise constant control signals, a critical step for digital hardware deployment.\n  By addressing feasibility, robustness, learning, and sampling, this thesis establishes a cohesive framework for output tracking within prescribed bounds, paving the way for future advances in learning-enhanced and robust MPC."}
{"id": "2602.23073", "categories": ["math.ST", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23073", "abs": "https://arxiv.org/abs/2602.23073", "authors": ["Yaacov Pariente", "Vadim Indelman"], "title": "Accelerated Online Risk-Averse Policy Evaluation in POMDPs with Theoretical Guarantees and Novel CVaR Bounds", "comment": null, "summary": "Risk-averse decision-making under uncertainty in partially observable domains is a central challenge in artificial intelligence and is essential for developing reliable autonomous agents. The formal framework for such problems is the partially observable Markov decision process (POMDP), where risk sensitivity is introduced through a risk measure applied to the value function, with Conditional Value-at-Risk (CVaR) being a particularly significant criterion. However, solving POMDPs is computationally intractable in general, and approximate methods rely on computationally expensive simulations of future agent trajectories. This work introduces a theoretical framework for accelerating CVaR value function evaluation in POMDPs with formal performance guarantees. We derive new bounds on the CVaR of a random variable X using an auxiliary random variable Y, under assumptions relating their cumulative distribution and density functions; these bounds yield interpretable concentration inequalities and converge as the distributional discrepancy vanishes. Building on this, we establish upper and lower bounds on the CVaR value function computable from a simplified belief-MDP, accommodating general simplifications of the transition dynamics. We develop estimators for these bounds within a particle-belief MDP framework with probabilistic guarantees, and employ them for acceleration via action elimination: actions whose bounds indicate suboptimality under the simplified model are safely discarded while ensuring consistency with the original POMDP. Empirical evaluation across multiple POMDP domains confirms that the bounds reliably separate safe from dangerous policies while achieving substantial computational speedups under the simplified model."}
{"id": "2602.22861", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.22861", "abs": "https://arxiv.org/abs/2602.22861", "authors": ["Jimmy Kornelije Gunnarsson", "Robert Klöfkorn"], "title": "Comparison of Structure-Preserving Methods for the Cahn-Hilliard-Navier-Stokes Equations", "comment": "12 pages, 4 figures, submitted as proceeding contributions ENUMATH 2025", "summary": "We develop structure-preserving discontinuous Galerkin methods for the Cahn-Hilliard-Navier-Stokes equations with degenerate mobility. The proposed SWIPD-L and SIPGD-L methods incorporate parametrized mobility fluxes with edge-wise mobility treatments for enhanced coercivity-stability control. We prove coercivity for the generalized trilinear form and demonstrate optimal convergence rates while preserving mass conservation, energy dissipation, and the discrete maximum principle. Comparisons with existing SIPG-L and SWIP-L methods confirm similar stability. Validation on $hp$-adaptive meshes for both standalone Cahn-Hilliard and coupled systems shows significant computational savings without accuracy loss."}
{"id": "2602.22509", "categories": ["math.PR", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.22509", "abs": "https://arxiv.org/abs/2602.22509", "authors": ["Simon Gabriel", "Tommaso Rosati"], "title": "Fluctuations in the weakly coupled 4D Anderson Hamiltonian", "comment": "102 pages", "summary": "We study the weak coupling limit of the Anderson Hamiltonian in the critical dimension $d=4$. In a perturbative sense, we prove Gaussian fluctuations about the Green's function of the Laplacian. The fluctuations are described by an explicit effective variance, up to a critical value of the coupling constant at which we expect a phase transition in the structure of the fluctuations. The proof is based on a combinatorial analysis of Feynman diagrams, and on a detailed study of the BPHZ renormalisation of the model. We characterise the limiting distribution in terms of primitive blow-ups, and prove that no Laplacian renormalisation is present. Our approach seems applicable to a broad class of equations."}
{"id": "2602.22551", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22551", "abs": "https://arxiv.org/abs/2602.22551", "authors": ["Rick S. H. Willemsen", "Tenindra Abeywickrama", "Ramu Anandakrishnan"], "title": "A Fast and Practical Column Generation Approach for Identifying Carcinogenic Multi-Hit Gene Combinations", "comment": null, "summary": "Cancer is often driven by specific combinations of an estimated two to nine gene mutations, known as multi-hit combinations. Identifying these combinations is critical for understanding carcinogenesis and designing targeted therapies. We formalise this challenge as the Multi-Hit Cancer Driver Set Cover Problem (MHCDSCP), a binary classification problem that selects gene combinations to maximise coverage of tumor samples while minimising coverage of normal samples. Existing approaches typically rely on exhaustive search and supercomputing infrastructure. In this paper, we present constraint programming and mixed integer programming formulations of the MHCDSCP. Evaluated on real-world cancer genomics data, our methods achieve performance comparable to state-of-the-art methods while running on a single commodity CPU in under a minute. Furthermore, we introduce a column generation heuristic capable of solving small instances to optimality. These results suggest that solving the MHCDSCP is less computationally intensive than previously believed, thereby opening research directions for exploring modelling assumptions."}
{"id": "2602.22997", "categories": ["math.NA", "cs.CE"], "pdf": "https://arxiv.org/pdf/2602.22997", "abs": "https://arxiv.org/abs/2602.22997", "authors": ["Merle Backmeyer", "Laura A. M. D'Angelo", "Brahim Ramdane", "Sebastian Schöps"], "title": "A Reduced Magnetic Vector Potential Approach with Higher-Order Splines", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This work presents a high-order isogeometric formulation for magnetoquasistatic eddy-current problems based on a decomposition into Biot-Savart-driven source fields and finite-element reaction fields. Building upon a recently proposed surface-only Biot-Savart evaluation, we generalize the reduced magnetic vector potential framework to the quasistatic regime and introduce a consistent high-order spline discretization. The resulting method avoids coil meshing, supports arbitrary winding paths, and enables high-order field approximation within a reduced computational domain. Beyond establishing optimal convergence rates, the numerical investigation identifies the requirements necessary to recover high-order accuracy in practice, including geometric regularity of the enclosing interface, accurate kernel quadrature, and compatible trace spaces for the source-reaction coupling."}
{"id": "2602.22602", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.22602", "abs": "https://arxiv.org/abs/2602.22602", "authors": ["Erhan Bayraktar", "Xihao He", "Xiang Yu", "Fengyi Yuan"], "title": "Mean-field games with rough common noise: the compactification approach", "comment": null, "summary": "We study mean-field game (MFG) problems with rough common noise where the representative state dynamics is governed by a controlled rough stochastic differential equation driven by an idiosyncratic Brownian motion and a deterministic rough path noise affecting the whole population. Within this new framework, we introduce a canonical weak formulation based on relaxed controls and rough martingale problems. We prove the existence of a pathwise mean-field equilibrium in this context by developing new technical tools for compactification to accommodate rough integration, which deviate substantially from classical compactification arguments in the literature. Finally, we discuss the relationship between the pathwise problem and the classical MFG problem with randomized Brownian common noise: conditioning yields the pathwise problem almost surely; and conversely, under a suitable causality/measurable-selection requirement, pathwise mean-field equilibria can be aggregated to produce randomized mean-field equilibria in the classical problem."}
{"id": "2602.22553", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22553", "abs": "https://arxiv.org/abs/2602.22553", "authors": ["Cédric Josz", "Wenqing Ouyang"], "title": "Computing Kurdyka-Łojasiewicz exponents via composition and symmetry", "comment": "59 pages", "summary": "We devise calculus rules for the Kurdyka-Łojasiewicz (KL) exponent using the rank theorem and Lie group actions. They apply to a wide class of composite and invariant functions, and are particularly suitable for handling nonisolated local minima. Notably, smoothness plays no role, eschewing gradient and Hessian computations. This provides a unified framework for establishing linear convergence of various algorithms in matrix factorization, $\\ell_1$-matrix factorization, matrix sensing, and linear neural networks."}
{"id": "2602.23059", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.23059", "abs": "https://arxiv.org/abs/2602.23059", "authors": ["Stefano Cipolla", "Fabio Durastante", "Miryam Gnazzo", "Beatrice Meini"], "title": "Nearest Reversible Markov Chains with Sparsity Constraints: An Optimization Approach", "comment": null, "summary": "Reversibility is a key property of Markov chains, central to algorithms such as Metropolis-Hastings and other MCMC methods. Yet many applications yield non-reversible chains, motivating the problem of approximating them by reversible ones with minimal modification. We formulate this task as a matrix nearness problem and focus on the practically relevant case of sparse transition matrices. The resulting optimization problem is a quadratic programming problem, and numerical experiments illustrate the effectiveness of the approach. This framework provides a principled way to enforce reversibility and sparsity patterns in Markov chains with applications in MCMC, computational chemistry, and data-driven modeling."}
{"id": "2602.22783", "categories": ["math.PR", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.22783", "abs": "https://arxiv.org/abs/2602.22783", "authors": ["Daniela Bertacchi", "Elena Montanaro", "Fabio Zucca"], "title": "Branching random walks with ageing", "comment": null, "summary": "Branching processes are models used to describe populations that reproduce and die over time. In the classical setting, an individual's reproductive capacity remains constant throughout its lifetime. However, in real-world situations, reproductive capacity typically undergoes ageing - that is, after reaching a peak, it decreases over time. In this work, we study the influence of ageing on the behaviour of the process and how modifying its parameters, along with reproduction rates, affects the destiny of the process."}
{"id": "2602.22573", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22573", "abs": "https://arxiv.org/abs/2602.22573", "authors": ["Kuang Bai", "Wei Yao", "Jane J. Ye", "Jin Zhang"], "title": "Directional first order approach for a class of bilevel programs", "comment": "25 pages", "summary": "In this paper, we study a class of bilevel optimization program (BP), where the feasible set of the lower level program is independent of the upper level variable. For bilevel programs it is known that the first order approach requires the convexity of the lower level program while reformulations involving the value function results in difficult optimization problems. In this paper we propose a directional first order approach which does not require the convexity of the lower level program. First, under some reasonable assumptions, we show that the lower level program can be equivalently characterized by its first order condition over a directional neighborhood. Next, for the resulting single level optimization problem, under common constraint qualifications, we establish directional necessary optimality conditions. Finally, an example of BP with nonconvex lower level program is given, where we demonstrate the failure of the classical first order approach and derive necessary optimality conditions using its directional counterpart."}
{"id": "2602.23081", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.23081", "abs": "https://arxiv.org/abs/2602.23081", "authors": ["Thomas Schillinger"], "title": "A Hyperbolic Transport Model for Passenger Flow on Tram Networks", "comment": "34 pages, 14 figures, 3 tables", "summary": "We introduce a modeling framework for an urban tram network based on a hyperbolic partial differential equation describing the transport of passengers along the network, coupled with a family of stochastic processes representing passenger boarding. Solutions are considered in a measure-valued sense. The system is further extended and subjected to uncertainties such as delays and service interruptions through a numerical study. Its robustness is assessed using appropriate risk measures."}
{"id": "2602.22885", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.22885", "abs": "https://arxiv.org/abs/2602.22885", "authors": ["Piotr Śniady"], "title": "Pfaffian point processes for coalescing particles via checkerboard duality", "comment": "13 pages, 2 figures", "summary": "Coalescing particles on a line merge when they meet. When every site is initially occupied, only finitely many particles survive at any positive time, and their positions form a Pfaffian point process: all correlation functions are determined by pairwise quantities arranged in antisymmetric matrices. Previous proofs of this structure relied on analytic methods specific to time-homogeneous dynamics. We identify the checkerboard duality as the structural reason for the Pfaffian: on a discrete planar graph, binary random choices create two complementary non-crossing forests, one tracing ancestral lineages backward and the other carrying the coalescing particles forward as domain boundaries. This duality converts the absence of particles in an interval into coalescence of ancestral lineages at its endpoints. A cancellative labeling then converts coalescence into annihilation, for which a companion paper provides a Pfaffian formula. The resulting empty-interval formula holds for any discrete graph with the checkerboard structure and arbitrary inhomogeneous edge probabilities, requiring no symmetry or specific distributions. This covers settings beyond existing methods, including totally asymmetric dynamics and position-dependent transition rules, and yields an explicit Pfaffian point process in each setting. For Brownian motion, the formula recovers the known Pfaffian point process and the empty-interval probabilities previously derived by PDE methods."}
{"id": "2602.22577", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.22577", "abs": "https://arxiv.org/abs/2602.22577", "authors": ["Yuto Watanabe", "Yang Zheng"], "title": "Gradient Dominance in the Linear Quadratic Regulator: A Unified Analysis for Continuous-Time and Discrete-Time Systems", "comment": "28 pages, 4 figures", "summary": "Despite its nonconvexity, policy optimization for the Linear Quadratic Regulator (LQR) admits a favorable structural property known as gradient dominance, which facilitates linear convergence of policy gradient methods to the globally optimal gain. While gradient dominance has been extensively studied, continuous-time and discrete-time LQRs have largely been analyzed separately, relying on slightly different assumptions, proof strategies, and resulting guarantees. In this paper, we present a unified gradient dominance property for both continuous-time and discrete-time LQRs under mild stabilizability and detectability assumptions. Our analysis is based on a convex reformulation derived from a common Lyapunov inequality representation and a unified change-of-variables procedure. This convex-lifting perspective yields a single proof framework applicable to both time models. The unified treatment clarifies how differences between continuous-time and discrete-time dynamics influence theoretical guarantees and reveals a deeper structural symmetry between the two formulations. Numerical examples illustrate and support the theoretical findings."}
{"id": "2602.23210", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.23210", "abs": "https://arxiv.org/abs/2602.23210", "authors": ["Samuel Q. Van Fleet", "Jesse Chan"], "title": "On the choice of viscous discontinuous Galerkin discretization for entropy correction artificial viscosity methods", "comment": null, "summary": "Entropy correction artificial viscosity (ECAV) is an approach for enforcing a semi-discrete entropy inequality through an entropy dissipative correction term. The resulting method can be implemented as an artificial viscosity with an extremely small viscosity coefficient. In this work, we analyze ECAV when the artificial viscosity is discretized using a local discontinuous Galerkin (LDG) method. We prove an $O(h)$ upper bound on the ECAV coefficient, indicating that ECAV does not result in a restrictive time-step condition. We additionally show that ECAV is contact preserving, and compare ECAV to traditional shock capturing artificial viscosity methods."}
{"id": "2602.23049", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.23049", "abs": "https://arxiv.org/abs/2602.23049", "authors": ["Lorenzo Facciaroni", "Costantino Ricciuti", "Enrico Scalas"], "title": "Non-Markovian chains with long-range dependence and their scaling limits", "comment": "1 Figure", "summary": "There is a well-established theory linking certain semi-Markov chains and continuous-time random walks to time-fractional equations and anomalous diffusion. In this work, we go beyond the semi-Markov framework by considering some non-Markovian chains, which exhibit long-memory behaviour, due to stochastic dependence among their waiting times. Particular attention is devoted to the so-called para-Markov chains. Their waiting times share the same marginal distributions as those of the above mentioned semi-Markov chains, but they are dependent; their joint distribution is of Schur-constant type and is closely related to complete Bernstein functions and De Finetti's theorems. A second model that we focus on is given by time-changed Markov chains, where the random time is the inverse of an increasing stable process. This generalizes well-known semi-Markov models available in the literature, which typically focus solely on the inverse of the Levy stable subordinator. The above mentioned models are unified by a general theory of time change of Markov chains."}
{"id": "2602.22589", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22589", "abs": "https://arxiv.org/abs/2602.22589", "authors": ["Daniel Yamin", "Willem-Jan van Hoeve", "Ted K. Ralphs"], "title": "Dantzig-Wolfe and Arc-Flow Reformulations: A Systematic Comparison", "comment": null, "summary": "Dantzig-Wolfe reformulation is a widely used technique for obtaining stronger relaxations in the context of branch-and-bound methods for solving integer optimization problems. Arc-Flow reformulations are a lesser known technique related to dynamic programming that has experienced a resurgence as result of the recent popularization of decision diagrams as a tool for solving integer programs. Although these two reformulation techniques arose independently, the recently proposed solution paradigm known as column elimination has revealed that they are in fact closely connected. Building on a unified formulation and notation, this study clarifies the theoretical connections and computational trade-offs between these two reformulations.\n  We first revisit the known fact that the LP relaxations of these two reformulations yield the same dual bound. We then dig deeper, establishing conditions under which valid inequalities in the original, Dantzig-Wolfe, or Arc-Flow spaces can be translated across reformulations without loss of strength, and reinterpreting iterative strengthening methods, such as decremental state-space relaxation and column elimination, through the lens of cutting planes. To assess the potential impact of these insights empirically, we benchmark both reformulations under identical conditions on the vehicle routing problem with time windows using state-of-the-art column- and cut-generation techniques. The results identify clear contrasts: the Arc-Flow reformulation benefits from faster convergence and performs best when subproblems are highly relaxed or low-dimensional, whereas the Dantzig-Wolfe reformulation is more efficient when the master problem remains compact. Overall, our study provides a unified perspective and practical guidelines for choosing between Dantzig-Wolfe and Arc-Flow reformulations in large-scale integer optimization."}
{"id": "2602.23112", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.23112", "abs": "https://arxiv.org/abs/2602.23112", "authors": ["Qingwu Gao", "Dimitrios G. Konstantinides", "Charalampos D. Passalidis", "Yuebao Wang", "Hui Xu"], "title": "Asymptotics of randomly weighted sums without moment conditions of random weights", "comment": null, "summary": "In the paper, under a suitable condition, we study the asymptotics of randomly weighted sums and randomly weighted stopped sums with upper tail asymptotically independent increments, where no moment condition is made on random weights, and we provide an example to show the suitable condition is necessary in some sense. To this end, we firstly consider the uniform asymptotics of the corresponding weighted sums with a large convergence range than the existing results. Then, using the above results, we obtain an asymptotic estimation of the finite-time and random-time ruin probabilities in a discrete-time risk model. In the case of regular variation increments, a more explicit estimation is given by an extended Breiman's theorem. Finally, through some examples we illustrate that the conditions of the above results are relaxed and clear, and that there exist random variables are upper tail asymptotically independent rather than tail asymptotically independent."}
{"id": "2602.22608", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22608", "abs": "https://arxiv.org/abs/2602.22608", "authors": ["Benjamin Grimmer", "Ning Liu"], "title": "Lower Bounds for Linear Minimization Oracle Methods Optimizing over Strongly Convex Sets", "comment": "17 pages", "summary": "We consider the oracle complexity of constrained convex optimization given access to a Linear Minimization Oracle (LMO) for the constraint set and a gradient oracle for the $L$-smooth, strongly convex objective. This model includes Frank-Wolfe methods and their many variants. Over the problem class of strongly convex constraint sets $S$, our main result proves that no such deterministic method can guarantee a final objective gap less than $\\varepsilon$ in fewer than $Ω(\\sqrt{L\\, \\mathrm{diam}(S)^2/\\varepsilon})$ iterations. Our lower bound matches, up to constants, the accelerated Frank-Wolfe theory of Garber and Hazan (2015). Together, these establish this as the optimal complexity for deterministic LMO methods over strongly convex constraint sets. Second, we consider optimization over $β$-smooth sets, finding that in the modestly smooth regime of $β=Ω(1/\\sqrt{\\varepsilon})$, no complexity improvement for span-based LMO methods is possible against either compact convex sets or strongly convex sets."}
{"id": "2602.23124", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.23124", "abs": "https://arxiv.org/abs/2602.23124", "authors": ["Istvan Berkes", "Ioannis Karatzas", "Walter Schachermayer"], "title": "Necessary and Sufficient Conditions for the Lacunary/Hereditary Laws of Large Numbers", "comment": null, "summary": "The celebrated theorem of Komlos asserts that L1-boundedness is sufficient for a given sequence of functions to contain a subsequence along which (in a \"lacunary\" manner), and along whose every further subsequence (\"hereditarily\"), a strong law of large numbers holds. We identify here slightly weaker, Egorov-type conditions, as not only sufficient in this context, but necessary as well. Necessary and sufficient conditions are developed also for the lacunary/hereditary version of the weak law of large numbers for general sequences, as well as for the weak law of large numbers in the context of exchangeable sequences, both long-open questions."}
{"id": "2602.22640", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22640", "abs": "https://arxiv.org/abs/2602.22640", "authors": ["Xintong Wang", "Liang Chen", "Yu-Hong Dai"], "title": "Efficient exact sequential lifting algorithm for binary knapsack set", "comment": null, "summary": "Lifting is a crucial technique in mixed integer programming (MIP) for generating strong valid inequalities, which serve as cutting planes to improve the branch-and-cut algorithm. We first propose an exact sequential lifting algorithm for the binary knapsack set, which employs the dominance list structure to remove redundant storage and computation in the dynamic programming (DP) array. This structure preserves scale invariance and effectively handles constraints with non-integer coefficients. Then, a reduction method is developed for the lifting procedure under some conditions, further enhancing computational efficiency. Finally, numerical experiments demonstrate that the proposed algorithm outperforms DP with arrays in terms of both efficiency and stability, particularly for large-scale and large-capacity instances. Moreover, it enables exact sequential lifting for binary knapsack sets with non-integer weights and large capacities, making it directly applicable in modern MIP solvers."}
{"id": "2602.23137", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.23137", "abs": "https://arxiv.org/abs/2602.23137", "authors": ["Raluca M. Balan", "William D. Stephenson"], "title": "Gaussian fluctuations for hyperbolic Anderson model with Lévy colored noise", "comment": "45 pages", "summary": "In this article, we study the asymptotic behaviour of the spatial integral $F_R(t)$ of the solution to the hyperbolic Anderson model in dimension $d=1$, driven by the Lévy colored noise introduced in Balan and Jiménez (2026). We assume that the spatial coloration kernel of the noise is either integrable on $\\mathbb{R}$, or is the Riesz kernel of order $α\\in (0,1)$, and the Lévy measure of the noise has finite moments of order $p$ and $2p$ for some $p \\in (1,2]$. By applying a recent result of Trauthwein (2025), we prove that $F_R(t)/\\sqrt{{\\rm Var}\\big(F_R(t)\\big)}$ converges to the standard normal distribution as $R \\to \\infty$, and we give an estimate for the rate of this convergence in the Fortet-Mourier distance, the 1-Wasserstein distance, or the Kolmogorov distance. We also provide the corresponding functional limit result."}
{"id": "2602.22670", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22670", "abs": "https://arxiv.org/abs/2602.22670", "authors": ["Zichong Ou", "Jie Lu"], "title": "Robust Distributed Nonconvex Optimization Enabling Communication Acceleration and Privacy Protection", "comment": "8 pages, 2 figures, accepted by ACC2026", "summary": "This paper addresses a distributed nonconvex optimization problem over multi-agent networks, where each agent exchanges its local information solely with its neighbors. Given that most existing distributed nonconvex optimization algorithms are susceptible to information leakage during inter agent communications, we propose a Robust Proximal Primal dual algorithm, referred to as RPP, to enhance the security of information transmission. In contrast to many existing approaches that directly transmit local variables throughout the network, we introduce carefully designed random noises to obfuscate sensitive local information. This not only preserves privacy but also demonstrates the noise robustness of our proposed algorithm. We establish a sublinear rate at which RPP converges to a stationary solution. Moreover, by incorporating Chebyshev acceleration, an accelerated variant of RPP is developed and achieves the optimal communication complexity bound for the algorithms that allow for exchanging local deci sions at each iteration. The superior convergence performance of RPP is validated through a few numerical experiments, which also indicate that, within an appropriate range, the introduced perturbations do not impede the convergence speed of RPP."}
{"id": "2602.23149", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.23149", "abs": "https://arxiv.org/abs/2602.23149", "authors": ["Isabella Alvarenga", "Daniel Valesin"], "title": "Interface for variants of the contact process", "comment": null, "summary": "We study two one-dimensional variants of the contact process: the contact-and-barrier process, where the population evolves in a region delimited by a randomly moving barrier, and the multitype contact process, in which two species compete for space. The contact-and-barrier process is started with the barrier at the origin and all sites to its right occupied, while the multitype contact process is started from the Heaviside configuration with species 1 to the left of the origin and species 2 to the right. We prove that both models exhibit tight interfaces and that, after centring by an appropriate deterministic speed, the interface position satisfies a central limit theorem. Our analysis relies on a renewal-time method based on a novel construction called patchwork construction, in which the processes are built by concatenating space-time evolutions over successive time intervals of random length, providing a more convenient framework for defining the renewal times that drive the proofs."}
{"id": "2602.22741", "categories": ["math.OC", "math.LO", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.22741", "abs": "https://arxiv.org/abs/2602.22741", "authors": ["Morenikeji Neri", "Nicholas Pischke", "Thomas Powell"], "title": "Generalized fluctuation bounds for stochastic algorithms in the presence of compactness", "comment": "52 pages", "summary": "We provide a convergence result for sequences of random variables taking values in a metric space that satisfy a stochastic quasi-Fejér monotonicity condition, in the context of a (local) compactness assumption. Our result is quantitative in that we derive an explicit and effective construction which, in terms of only a few moduli representing quantitative witnesses to key properties of the sequence of random variables and the underlying metric space involved, provides a metastable rate of pointwise convergence, a type of generalized fluctuation bound. That quantitative result in particular relies on the development of a finitary theory of martingales, culminating in a fully finitary Robbins-Siegmund theorem. We outline how this result particularises to the circumstances of the seminal work of Combettes and Pesquet on stochastic quasi-Fejér monotone sequences in separable Hilbert spaces, and we provide an initial application by illustrating how these results can be used to provide a metastable rate of pointwise convergence for a stochastic Krasnoselskii-Mann scheme solving a stochastic common fixed point problem for nonexpansive maps over proper Hadamard spaces. This work is set in the context of recent applications of the logic-based methodology of proof mining to probability theory, and represents its most sophisticated case study to date."}
{"id": "2602.23326", "categories": ["math.PR", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.23326", "abs": "https://arxiv.org/abs/2602.23326", "authors": ["Andrea Montanari"], "title": "Spin Glass Concepts in Computer Science, Statistics, and Learning", "comment": "33 pages; 2 pdf figures", "summary": "Spin glass theory studies the structure of sublevel sets and minima (or near-minima) of certain classes of random functions in high dimension. Near-minima of random functions also play an important role in high-dimensional statistics and statistical learning, where minimizing the empirical risk (which is a random function of the model parameters) is the method of choice for learning a statistical model from noisy data. Finally, near-minima of random functions are obviously central to average-case analysis of optimization algorithms. Computer science, statistics, and machine learning naturally lead to questions that are traditionally not addressed within physics and mathematical physics. I will try to explain how ideas from spin glass theory have seeded recent developments in these fields.\n  (This article was written on the occasion of the 2024 Abel Prize to Michel Talagrand.)"}
{"id": "2602.22888", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22888", "abs": "https://arxiv.org/abs/2602.22888", "authors": ["Chun-Chi Lin", "Yang-Kai Lue", "Dung The Tran"], "title": "Existence of Quantum Splines via Fourth-Order Gradient Flows", "comment": null, "summary": "We establish a rigorous existence theory for the quantum splines introduced by Brody, Holm, and Meier in Physical Review Letters (2012). These curves arise as solutions of a variational problem on the unitary group describing optimally controlled quantum evolutions. By formulating the problem within a geometric gradient flow framework for Riemannian spline interpolation, we construct a well-posed fourth order evolution whose asymptotic limits realize the desired quantum splines. The analysis requires adapting the variational structure to boundary conditions dictated by the physical model, which are not directly amenable to the setting in our recently developed framework for gradient flows of Riemannian spline interpolation. We show that, despite these difficulties, the modified system admits a rigorous analytical treatment, yielding both existence and a constructive procedure for generating quantum splines. Our results provide a mathematical foundation for the variational description of smooth quantum control trajectories and clarify the analytical structure underlying their formation."}
{"id": "2602.22369", "categories": ["math.ST", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.22369", "abs": "https://arxiv.org/abs/2602.22369", "authors": ["Ruixiao Wang", "Xiaohong Chen", "Sinho Chewi"], "title": "Sampling from Constrained Gibbs Measures: with Applications to High-Dimensional Bayesian Inference", "comment": null, "summary": "This paper considers a non-standard problem of generating samples from a low-temperature Gibbs distribution with \\emph{constrained} support, when some of the coordinates of the mode lie on the boundary. These coordinates are referred to as the non-regular part of the model. We show that in a ``pre-asymptotic'' regime in which the limiting Laplace approximation is not yet valid, the low-temperature Gibbs distribution concentrates on a neighborhood of its mode. Within this region, the distribution is a bounded perturbation of a product measure: a strongly log-concave distribution in the regular part and a one-dimensional exponential-type distribution in each coordinate of the non-regular part. Leveraging this structure, we provide a non-asymptotic sampling guarantee by analyzing the spectral gap of Langevin dynamics. Key examples of low-temperature Gibbs distributions include Bayesian posteriors, and we demonstrate our results on three canonical examples: a high-dimensional logistic regression model, a Poisson linear model, and a Gaussian mixture model."}
{"id": "2602.23076", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.23076", "abs": "https://arxiv.org/abs/2602.23076", "authors": ["Anthony Palmieri", "Francesco Rinaldi", "Saverio Salzo", "Sara Venturini"], "title": "Iteration Complexity of Frank-Wolfe and Its Variants for Bilevel Optimization", "comment": "23 pages, 2 figures", "summary": "We study Frank-Wolfe (FW) methods for constrained bilevel optimization when the lower-level problem is solved only approximately, yielding biased and inexact hypergradients. We analyze inexact variants of vanilla FW as well as away-step and pairwise FW, and provide convergence rates in the nonconvex setting under gradient errors. By combining these results with recent bounds on hypergradient errors from iterative and approximate implicit differentiation, we derive overall iteration complexity guarantees for bilevel FW. Experiments on two real-world applications validate the theory and demonstrate practical effectiveness."}
{"id": "2602.22741", "categories": ["math.OC", "math.LO", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.22741", "abs": "https://arxiv.org/abs/2602.22741", "authors": ["Morenikeji Neri", "Nicholas Pischke", "Thomas Powell"], "title": "Generalized fluctuation bounds for stochastic algorithms in the presence of compactness", "comment": "52 pages", "summary": "We provide a convergence result for sequences of random variables taking values in a metric space that satisfy a stochastic quasi-Fejér monotonicity condition, in the context of a (local) compactness assumption. Our result is quantitative in that we derive an explicit and effective construction which, in terms of only a few moduli representing quantitative witnesses to key properties of the sequence of random variables and the underlying metric space involved, provides a metastable rate of pointwise convergence, a type of generalized fluctuation bound. That quantitative result in particular relies on the development of a finitary theory of martingales, culminating in a fully finitary Robbins-Siegmund theorem. We outline how this result particularises to the circumstances of the seminal work of Combettes and Pesquet on stochastic quasi-Fejér monotone sequences in separable Hilbert spaces, and we provide an initial application by illustrating how these results can be used to provide a metastable rate of pointwise convergence for a stochastic Krasnoselskii-Mann scheme solving a stochastic common fixed point problem for nonexpansive maps over proper Hadamard spaces. This work is set in the context of recent applications of the logic-based methodology of proof mining to probability theory, and represents its most sophisticated case study to date."}
{"id": "2602.23145", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.23145", "abs": "https://arxiv.org/abs/2602.23145", "authors": ["Juan Guillermo Garrido", "Pedro Pérez-Aros", "Mathias Staudigl"], "title": "Stochastic Differential Inclusions driven by Maximal Monotone Operators with empty interiors", "comment": null, "summary": "This paper studies the long-time behavior of stochastic differential inclusions driven by maximal monotone operators, motivated by continuous-time models of first-order optimization methods under noisy or approximate operator information. We first address well-posedness and show that existence and uniqueness can be established without the customary requirement that the operator's domain has nonempty interior, by adopting an appropriate notion of solution. We then analyze asymptotic properties of the resulting stochastic dynamics, extending convergence guarantees beyond previously studied settings that rely on smooth potentials, full-domain subdifferentials, or Lipschitz monotone operators. In addition, we consider a Tikhonov-type regularization of the stochastic inclusion and prove corresponding well-posedness and long-time convergence results."}
{"id": "2602.22929", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.22929", "abs": "https://arxiv.org/abs/2602.22929", "authors": ["Marc Taberner-Ortiz", "Manfred Denker"], "title": "Remarks on stationary GARCH processes under heavy tail distributions", "comment": null, "summary": "Let $(X_n)_{n\\in \\mathbb Z}$ be a GARCH process with $E(X_0^4)<\\infty$, and let $μ_n$ denote the distribution of $\\frac 1{\\sqrt n}\\sum_{i=1}^n [X_i^2-\\mathbb E(X_0^2)]$. We derive a numerical approximation of $μ_n$ when $x_1,...,x_n$ are observed. This yields the derivation of confidence intervals for $μ= E(X_0^2)$ and we investigate the accuracy of these confidence intervals in comparison with standard ones based on normal approximation. Moreover, when the innovation process has heavy tail distribution, we improve the method using a new resampling method."}
{"id": "2602.23157", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.23157", "abs": "https://arxiv.org/abs/2602.23157", "authors": ["Kaijing Lyu", "Umberto Biccari", "Jun-Min Wang"], "title": "Operator learning for prescribed-time stabilization of reaction-diffusion systems", "comment": null, "summary": "This paper addresses boundary prescribed-time stabilization of a one-dimensional heat equation with spatially and temporally varying coefficients. In contrast to asymptotic or exponential stabilization, prescribed-time stabilization ensures convergence to equilibrium within a user-defined time that is independent of the initial condition, a property that is particularly attractive in applications with stringent transient performance requirements. The backstepping design for this problem requires solving, at each time instant, a two-dimensional time-dependent kernel Partial Differential Equation (PDE) whose solution continuously varies with the plant coefficients. The repeated numerical solution of this parabolic kernel PDE results in a prohibitive computational burden, thereby limiting real-time applicability. To overcome this limitation, we propose a neural-operator-based approximation of the mapping from the time-varying system coefficient to the corresponding backstepping kernel. The operator is trained offline using representative solutions of the kernel PDE and subsequently deployed online to generate the required time-varying kernels in real time. We establish, via Lyapunov analysis, that the resulting neural-operator-based controller preserves prescribed-time stability provided that the operator approximation error satisfies an explicit bound. Furthermore, we investigate a direct approximation of the full feedback law mapping the plant parameter functions and state measurements to the boundary control input. For this setting, we prove semiglobal practical prescribed-time stability of the closed-loop system. Numerical experiments demonstrate that the proposed approach reduces the computational cost of kernel generation by several orders of magnitude, thereby enabling real-time prescribed-time stabilization for heat equations with spatially and temporally varying coefficients."}
{"id": "2602.23023", "categories": ["math.ST", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23023", "abs": "https://arxiv.org/abs/2602.23023", "authors": ["Alexandra Carpentier", "Nicolas Verzelen"], "title": "Low-degree Lower bounds for clustering in moderate dimension", "comment": null, "summary": "We study the fundamental problem of clustering $n$ points into $K$ groups drawn from a mixture of isotropic Gaussians in $\\mathbb{R}^d$. Specifically, we investigate the requisite minimal distance $Δ$ between mean vectors to partially recover the underlying partition. While the minimax-optimal threshold for $Δ$ is well-established, a significant gap exists between this information-theoretic limit and the performance of known polynomial-time procedures. Although this gap was recently characterized in the high-dimensional regime ($n \\leq dK$), it remains largely unexplored in the moderate-dimensional regime ($n \\geq dK$). In this manuscript, we address this regime by establishing a new low-degree polynomial lower bound for the moderate-dimensional case when $d \\geq K$. We show that while the difficulty of clustering for $n \\leq dK$ is primarily driven by dimension reduction and spectral methods, the moderate-dimensional regime involves more delicate phenomena leading to a \"non-parametric rate\". We provide a novel non-spectral algorithm matching this rate, shedding new light on the computational limits of the clustering problem in moderate dimension."}
{"id": "2602.23180", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.23180", "abs": "https://arxiv.org/abs/2602.23180", "authors": ["Marek Tyburec", "Michael Stingl", "Shenyuan Ma"], "title": "Hierarchy of bounds in free orthotropic material optimization: From convex relaxations to Hashin-Shtrikman via sequential global programming", "comment": "50 pages, 15 figures", "summary": "We study free orthotropic material optimization for two-dimensional plane-stress compliance minimization with two well-ordered isotropic phases, motivated by the gap between tensors admissible in classical free-material optimization and tensors realizable by composites. To reduce this gap, we construct a hierarchy of realizability-aware admissible sets induced by zeroth-order, Voigt, and Hashin--Shtrikman (HS) energy bounds, moving from convex relaxations to a tighter nonconvex model. In the convex zeroth-order and Voigt settings, the Voigt set is strictly tighter for intermediate volume fractions and coincides with the zeroth-order set at pure-phase endpoints, and the Voigt model reduces to an isotropic variable-thickness-sheet formulation. In the single-loadcase continuum zeroth-order problem, at least one optimal solution can be chosen orthotropic. For HS constraints, we rewrite the bound as a Voigt term minus a nonnegative correction, clarifying strict tightening for interior volume fractions and local nonconvexity. We further prove that the convex hull of the HS feasible set equals the Voigt set and derive reduced formulations via active-constraint analysis and explicit elementwise volume characterization, including reductions specialized to orthotropic effective tensors. In the single-loadcase continuum setting, the HS relaxation is tight with the Allaire--Kohn relaxed problem, attained in the relaxation sense by sequential laminates, whereas in generic multi-loadcase settings it provides a lower bound on optimal compliance over general microstructures. The resulting nonconvex orthotropic HS problem is solved by sequential global programming, and numerical results confirm the predicted compliance hierarchy and show close agreement with finite-rank laminate references."}
{"id": "2602.23260", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.23260", "abs": "https://arxiv.org/abs/2602.23260", "authors": ["Mehdi Karimi", "Levent Tuncel"], "title": "Efficient Interior-Point Methods for Hyperbolic Programming via Straight-Line Programs", "comment": "30 pages, 7 Tables, 3 figures", "summary": "Hyperbolic (HB) programming generalizes many popular convex optimization problems, including semidefinite and second-order cone programming. Despite substantial theoretical progress on HB programming, efficient computational tools for solving large-scale hyperbolic programs remain limited. This paper presents DDS 3.0, a new release of the Domain-Driven Solver, which provides an efficient interior-point implementation tailored for hyperbolic programming. A key innovation lies in a new straight-line program (SLP) representation that enables compact representation and efficient computation of hyperbolic polynomials, their gradients, and Hessians. The SLP structure significantly reduces computational cost, allowing the Hessian to be computed in the same asymptotic complexity as the gradient through a batched reverse-over-forward differentiation scheme. We further introduce an improved corrector step for the primal-dual interior-point method, enhancing stability and convergence on convex sets where only the primal self-concordant barrier is efficiently computable. We create a comprehensive benchmark library beyond the elementary symmetric polynomials, using several different techniques. Numerical experiments demonstrate substantial performance gains of DDS 3.0 compared to first-order Frank-Wolfe algorithm, homotopy method, and SDP software utilizing SDP relaxations."}
{"id": "2602.23323", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.23323", "abs": "https://arxiv.org/abs/2602.23323", "authors": ["Claire Walton", "Isaac Kaminer", "Qi Gong", "Abram H. Clark", "Theodoros Tsatsanifos"], "title": "Modeling Large-Scale Adversarial Swarm Engagements using Optimal Control", "comment": "arXiv admin note: substantial text overlap with arXiv:2108.02311. substantial text overlap with arXiv:2108.02311", "summary": "We investigate the optimal control of large-scale autonomous systems under explicitly adversarial conditions, incorporating the probabilistic destruction of agents over time. In many such systems, adversarial interactions arise as different agents or groups compete against one another. A crucial yet often overlooked factor in existing theoretical and modeling frameworks is the random attrition of agents during operation. Effective modeling and control strategies must therefore account for both agent attrition and spatial dynamics.\n  Given the inherently random nature of agent survival, directly solving this problem is challenging. To address this, we propose and evaluate three approximate numerical modeling approaches in which agent survival probabilities decrease deterministically over time based on their relative positions. We apply these schemes to a scenario where agents defend a high-value unit against an attacking swarm. Our results demonstrate that these models can effectively capture the dynamics of such interactions, provided that attrition and spatial positioning are tightly integrated. These findings are relevant to a broad range of adversarial autonomy scenarios where both agent positioning and survival probabilities play a critical role."}
