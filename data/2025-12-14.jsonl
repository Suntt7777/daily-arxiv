{"id": "2512.10049", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.10049", "abs": "https://arxiv.org/abs/2512.10049", "authors": ["Jocelyn Nembe"], "title": "Adaptive Nonparametric Estimation via Kernel Transport on Group Orbits: Oracle Inequalities and Minimax Rates", "comment": null, "summary": "We develop a unified framework for nonparametric functional estimation based on kernel transport along orbits of discrete group actions, which we term \\emph{Twin Spaces}. Given a base kernel $K$ and a group $G = \\langle\\varphi\\rangle$ acting isometrically on the input space $E$, we construct a hierarchy of transported kernels $\\{K_j\\}_{j\\geq 0}$ and a penalized model selection scheme satisfying a Kraft inequality. Our main contributions are threefold: (i) we establish non-asymptotic oracle inequalities for the penalized twin-kernel estimator with explicit constants; (ii) we introduce novel twin-regularity classes that capture smoothness along group orbits and prove that our estimator adapts to these classes; (iii) we show that the framework recovers classical minimax-optimal rates in the Euclidean setting while enabling improved rates when the target function exhibits orbital structure. The effective dimension $d_{\\mathrm{eff}}$ governing the rates is characterized in terms of the quotient $G/L$, where $L$ is the subgroup preserving the base operation. Connections to wavelet methods, geometric quantization, and adaptive computation are discussed."}
{"id": "2512.10068", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.10068", "abs": "https://arxiv.org/abs/2512.10068", "authors": ["Jocelyn Nembé"], "title": "TwinKernel Estimation for Point Process Intensity Functions: Adaptive Nonparametric Methods via Orbital Regularity", "comment": null, "summary": "We develop TwinKernel methods for nonparametric estimation of intensity functions of point processes. Building on the general TwinKernel framework and combining it with martingale techniques for counting processes, we construct estimators that adapt to orbital regularity of the intensity function. Given a point process $N$ with intensity $λ$ and a cyclic group $G = \\langle\\varphi\\rangle$ acting on the time/space domain, we transport kernels along group orbits to create a hierarchy of smoothed Nelson-Aalen type estimators. Our main results establish: (i) uniform consistency via martingale concentration inequalities; (ii) optimal convergence rates for intensities in twin-Hölder classes, with rates depending on the effective dimension $d_{\\mathrm{eff}}$; (iii) adaptation to unknown smoothness through penalized model selection; (iv) automatic boundary bias correction via local polynomial extensions in twin coordinates; (v) minimax lower bounds showing rate optimality. We apply the methodology to hazard rate estimation under random censoring, where periodicity or other orbital structure in the hazard may arise from circadian rhythms, seasonal effects, or treatment schedules. Martingale central limit theorems yield asymptotic confidence bands. Simulation studies demonstrate 3--7$\\times$ improvements over classical kernel hazard estimators when the intensity exhibits orbital regularity."}
{"id": "2512.10075", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.10075", "abs": "https://arxiv.org/abs/2512.10075", "authors": ["Jocelyn Nembé"], "title": "Concentration of Measure under Diffeomorphism Groups: A Universal Framework with Optimal Coordinate Selection", "comment": null, "summary": "We establish a universal framework for concentration inequalities based on invariance under diffeomorphism groups. Given a probability measure $μ$ on a space $E$ and a diffeomorphism $ψ: E \\to F$, concentration properties transfer covariantly: if the pushforward $ψ_*μ$ concentrates, so does $μ$ in the pullback geometry. This reveals that classical concentration inequalities -- Hoeffding, Bernstein, Talagrand, Gaussian isoperimetry -- are manifestations of a single principle of \\emph{geometric invariance}. The choice of coordinate system $ψ$ becomes a free parameter that can be optimized. We prove that for any distribution class $\\Pc$, there exists an optimal diffeomorphism $ψ^*$ minimizing the concentration constant, and we characterize $ψ^*$ in terms of the Fisher-Rao geometry of $\\Pc$. We establish \\emph{strict improvement theorems}: for heavy-tailed or multiplicative data, the optimal $ψ$ yields exponentially tighter bounds than the identity. We develop the full theory including transportation-cost inequalities, isoperimetric profiles, and functional inequalities, all parametrized by the diffeomorphism group $\\Diff(E)$. Connections to information geometry (Amari's $α$-connections), optimal transport with general costs, and Riemannian concentration are established. Applications to robust statistics, multiplicative models, and high-dimensional inference demonstrate that coordinate optimization can improve statistical efficiency by orders of magnitude."}
{"id": "2512.10220", "categories": ["math.ST", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.10220", "abs": "https://arxiv.org/abs/2512.10220", "authors": ["Mark Sellke", "Steven Yin"], "title": "On Learning-Curve Monotonicity for Maximum Likelihood Estimators", "comment": "24 pages", "summary": "The property of learning-curve monotonicity, highlighted in a recent series of work by Loog, Mey and Viering, describes algorithms which only improve in average performance given more data, for any underlying data distribution within a given family. We establish the first nontrivial monotonicity guarantees for the maximum likelihood estimator in a variety of well-specified parametric settings. For sequential prediction with log loss, we show monotonicity (in fact complete monotonicity) of the forward KL divergence for Gaussian vectors with unknown covariance and either known or unknown mean, as well as for Gamma variables with unknown scale parameter. The Gaussian setting was explicitly highlighted as open in the aforementioned works, even in dimension 1. Finally we observe that for reverse KL divergence, a folklore trick yields monotonicity for very general exponential families.\n  All results in this paper were derived by variants of GPT-5.2 Pro. Humans did not provide any proof strategies or intermediate arguments, but only prompted the model to continue developing additional results, and verified and transcribed its proofs."}
{"id": "2512.09967", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.09967", "abs": "https://arxiv.org/abs/2512.09967", "authors": ["Maryam Babaei", "Peter Rucz", "Manfred Kaltenbacher", "Stefan Schoder"], "title": "Hybrid Finite Element and Least Squares Support Vector Regression Method for solving Partial Differential Equations with Legendre Polynomial Kernels", "comment": null, "summary": "A hybrid computational approach that integrates the finite element method (FEM) with least squares support vector regression (LSSVR) is introduced to solve partial differential equations. The method combines FEM's ability to provide the nodal solutions and LSSVR with higher-order Legendre polynomial kernels to deliver a closed-form analytical solution for interpolation between the nodes. The hybrid approach implements element-wise enhancement (super-resolution) of a given numerical solution, resulting in high resolution accuracy, while maintaining consistency with FEM nodal values at element boundaries. It can adapt any low-order FEM code to obtain high-order resolution by leveraging localized kernel refinement and parallel computation without additional implementation overhead. Therefore, effective inference/post-processing of the obtained super-resolved solution is possible. Evaluation results show that the hybrid FEM-LSSVR approach can achieve significantly higher accuracy compared to the base FEM solution. Comparable accuracy is a achieved when comparing the hybrid solution with a standalone FEM result with the same polynomial basis function order. The convergence studies were conducted for four elliptic boundary value problems to demonstrate the method's ability, accuracy, and reliability. Finally, the algorithm can be directly used as a plug-and-play method for super-resolving low-order numerical solvers and for super-resolution of expensive/under-resolved experimental data."}
{"id": "2512.10012", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10012", "abs": "https://arxiv.org/abs/2512.10012", "authors": ["Mattes Mollenhauer", "Christian Fiedler"], "title": "Fuk-Nagaev inequality in smooth Banach spaces: Optimum bounds for distributions of heavy-tailed martingales", "comment": null, "summary": "We derive a Fuk-Nagaev inequality for the maxima of norms of martingale sequences in smooth Banach spaces which allow for a finite number of higher conditional moments. The bound is obtained by combining an optimization approach for a Chernoff bound due to Rio (2017) with a classical bound for moment generating functions of smooth Banach space norms by Pinelis (1994). Our result improves comparable infinite-dimensional bounds in the literature by removing unnecessary centering terms and giving precise constants. As an application, we propose a McDiarmid-type bound for vector-valued functions which allow for a uniform bound on their conditional higher moments."}
{"id": "2512.09968", "categories": ["math.OC", "math.LO"], "pdf": "https://arxiv.org/pdf/2512.09968", "abs": "https://arxiv.org/abs/2512.09968", "authors": ["Paulo Firmino", "Laurentiu Leustean"], "title": "Quantitative results on a generalized viscosity approximation method", "comment": null, "summary": "In this paper, we study, in a nonlinear setting, the asymptotic behaviour of a generalized viscosity approximation method associated with a countable family of nonexpansive mappings satisfying resolvent-like conditions. We apply proof mining methods to obtain quantitative results on asymptotic regularity in W-hyperbolic spaces and rates of metastability in CAT(0) spaces."}
{"id": "2512.10488", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.10488", "abs": "https://arxiv.org/abs/2512.10488", "authors": ["Natalia Stepanova", "Marie Turcicova", "Xiang Zhao"], "title": "Adaptive almost full recovery in sparse nonparametric models", "comment": "34 pages, 1 figure", "summary": "We observe an unknown function of $d$ variables $f(\\boldsymbol{t})$, $\\boldsymbol{t} \\in[0,1]^d$, in the Gaussian white noise model of intensity $\\varepsilon>0$. We assume that the function $f$ is regular and that it is a sum of $k$-variate functions, where $k$ varies from $1$ to $s$ ($1\\leq s\\leq d$). These functions are unknown to us and only a few of them are nonzero. In this article, we address the problem of identifying the nonzero function components of $f$ almost fully in the case when $d=d_\\varepsilon\\to \\infty$ as $\\varepsilon\\to 0$ and $s$ is either fixed or $s=s_\\varepsilon\\to \\infty$, $s=o(d)$ as $\\varepsilon\\to 0$. This may be viewed as a variable selection problem. We derive the conditions when almost full variable selection in the model at hand is possible and provide a selection procedure that achieves this type of selection. The procedure is adaptive to the level of sparsity described by the sparsity index $β\\in(0,1)$. We also derive conditions that make almost full variable selection in the model of our interest impossible. In view of these conditions, the proposed selector is seen to perform asymptotically optimal. The theoretical findings are illustrated numerically."}
{"id": "2512.10027", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10027", "abs": "https://arxiv.org/abs/2512.10027", "authors": ["Yassin Bahid", "Eduardo Corona", "Nancy Rodriguez"], "title": "A Mass Preserving Numerical Scheme for Kinetic Equations that Model Social Phenomena", "comment": null, "summary": "In recent years, kinetic equations have been used to model many social phenomena. A key feature of these models is that transition rate kernels involve Dirac delta functions, which capture sudden, discontinuous state changes. Here, we study kinetic equations with transition rates of the form $$ T(x,y,u) = δ_{φ(x,y) - u}. $$ We establish the global existence and uniqueness of solutions for these systems and introduce a fully deterministic scheme, the \\emph{Mass Preserving Collocation Method}, which enables efficient, high fidelity simulation of models with multiple subsystems. We validate the accuracy, efficiency, and consistency of the solver on models with up to five subsystems, and compare its performance against two state-of-the-art agent-based methods: Tau-leaping and hybrid methods. Our scheme resolves subsystem distributions captured by these stochastic approaches while preserving mass numerically, requiring significantly less computational time and resources, and avoiding variability and hyperparameter tuning characteristic of these methods."}
{"id": "2512.10057", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.10057", "abs": "https://arxiv.org/abs/2512.10057", "authors": ["Jiahao Jiang"], "title": "Towards a Mathematical Theory of Adaptive Memory: From Time-Varying to Responsive Fractional Brownian Motion", "comment": "108 pages, 0 figures. Submitted to arXiv", "summary": "This work develops a comprehensive mathematical theory for a class of stochastic processes whose local regularity adapts dynamically in response to their own state. We first introduce and rigorously analyze a time-varying fractional Brownian motion (TV-fBm) with a deterministic, Hölder-continuous Hurst exponent function. Key properties are established, including its exact variance scaling law, precise local increment asymptotics, local non-determinism, large deviation asymptotics for its increments, and a covariance structure that admits a closed-form hypergeometric representation. We then define a novel class of processes termed Responsive Fractional Brownian Motion (RfBm). Here,the Hurst exponent is governed by a Lipschitz-Hölder response function depending on the process state itself, creating an intrinsic feedback mechanism between state and memory. We establish the well-posedness of this definition, prove pathwise Hölder regularity of the induced instantaneous scaling exponent, and analyze associated cumulative memory processes along with their asymptotic convergence. The mathematical structure of RfBm naturally gives rise to a continuous-time, pathwise attention mechanism. We show that its kernel induces a well-defined attention weight distribution, derive fundamental bounds for these weights, and quantify the stability of attentional allocation through residence measures and volatility functionals. This work develops a stochastic-process-theoretic framework for concepts central to adaptive memory and content-sensitive information processing, offering a mathematically grounded perspective that may complement existing empirical approaches."}
{"id": "2512.10255", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.10255", "abs": "https://arxiv.org/abs/2512.10255", "authors": ["Jianting Pan", "Ming Yan"], "title": "Fast projection onto the top-k-sum constraint", "comment": "29 pages", "summary": "This paper develops an efficient algorithm for computing the Euclidean projection onto the top-k-sum constraint, a key operation in financial risk management and matrix optimization problems. Existing projection methods rely on sorting and therefore incur an initial O(nlogn) complexity, which limits their scalability in high-dimensional settings. To address this difficulty, we revisit the Karush-Kuhn-Tucker (KKT) conditions of the projection problem and introduce relaxed conditions that remain sufficient for characterizing the solution. These conditions lead to a simple geometric interpretation: finding the solutions is equivalent to locating the intersection of two monotone piecewise linear functions. Building on this insight, we propose an iterative and highly efficient algorithm that searches directly for the intersection point and completely avoids all sorting procedures. We prove that the algorithm converges globally and reaches the exact solution in a finite number of iterations. Extensive numerical experiments further demonstrate that the proposed algorithm substantially outperforms existing algorithms and exhibits empirical O(n) complexity across a broad range of problem instances."}
{"id": "2512.10502", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.10502", "abs": "https://arxiv.org/abs/2512.10502", "authors": ["Faranak Goodarzi", "Somayeh Ghafouri"], "title": "Measures of inaccuracy based on Varextropy", "comment": null, "summary": "Recently, varextropy has been introduced as a new dispersion index and a measure of information. In this article, we derive the generating function of extropy and present its infinite series representation. Furthermore, we propose new variability measures: the inaccuracy and weighted inaccuracy measures between two random variables based on varextropy and we investigate their properties. We also obtain lower bounds for the inaccuracy measure and compare them with each other. In addition, we introduce a discrimination measure based on varextropy and employ it both for comparing probability distributions and for assessing the goodness of fit of distributions to data and we compare this measure with the dispersion index derived from the Kullback-Leibler divergence given in Balakrishnan et al. (2022)."}
{"id": "2512.10059", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.10059", "abs": "https://arxiv.org/abs/2512.10059", "authors": ["Rasmus Vikhamar-Sandberg", "Michal Repisky"], "title": "Efficient Boys function evaluation using minimax approximation", "comment": null, "summary": "We present an algorithm for efficient evaluation of Boys functions $F_0,\\dots,F_{k_\\mathrm{max}}$ tailored to modern computing architectures, in particular graphical processing units (GPUs), where maximum throughput is high and data movement is costly. The method combines rational minimax approximations with upward and downward recurrence relations. The non-negative real axis is partitioned into three regions, $[0,\\infty\\rangle = A\\cup B\\cup C$, where regions $A$ and $B$ are treated using rational minimax approximations and region $C$ by an asymptotic approximation. This formulation avoids lookup tables and irregular memory access, making it well suited hardware with high maximum throughput and low latency. The rational minimax coefficients are generated using the rational Remez algorithm. For a target maximum absolute error of $\\varepsilon_\\mathrm{tol} = 5\\cdot10^{-14}$, the corresponding approximation regions and coefficients for Boys functions $F_0,\\dots,F_{32}$ are provided in the appendix."}
{"id": "2512.10085", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10085", "abs": "https://arxiv.org/abs/2512.10085", "authors": ["Miguel Abadi"], "title": "Large Deviation inequalities for sums of positive correlated variables with clustering", "comment": "21 pages", "summary": "Large deviation inequalities for ergodic sums is an important subject since the seminal contribution of Bernstein for independent random variables with finite variances, followed by the Chernoff method and the Hoefding result for independent bounded variables. Very few results appears in the literature for the non independent case. Here we consider the, barely treated in the literature, case of positively correlated Bernoulli variables. This case represents the appearance in clusters of a certain fixed phenomena in the overlying stochastic process. Under a very mild condition we prove several upper deviation inequalities. The results follow by a spectral decomposition of an appropriated recursive operator. We illustrate with examples."}
{"id": "2512.10270", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10270", "abs": "https://arxiv.org/abs/2512.10270", "authors": ["Yicheng Lin", "Bingxian Wu", "Nan Bai", "Yunxiao Ren", "Zhisheng Duan"], "title": "Optimality Deviation using the Koopman Operator", "comment": null, "summary": "This paper investigates the impact of approximation error in data-driven optimal control problem of nonlinear systems while using the Koopman operator. While the Koopman operator enables a simplified representation of nonlinear dynamics through a lifted state space, the presence of approximation error inevitably leads to deviations in the computed optimal controller and the resulting value function. We derive explicit upper bounds for these optimality deviations, which characterize the worst-case effect of approximation error. Supported by numerical examples, these theoretical findings provide a quantitative foundation for improving the robustness of data-driven optimal controller design."}
{"id": "2512.10546", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.10546", "abs": "https://arxiv.org/abs/2512.10546", "authors": ["Alexis Derumigny", "Miltiadis Galanis", "Wieger Schipper", "Aad van der Vaart"], "title": "Bootstrapping not under the null?", "comment": "60 pages, 13 figures", "summary": "We propose a bootstrap testing framework for a general class of hypothesis tests, which allows resampling under the null hypothesis as well as other forms of bootstrapping. We identify combinations of resampling schemes and bootstrap statistics for which the resulting tests are asymptotically exact and consistent against fixed alternatives. We show that in these cases the limiting local power functions are the same for the different resampling schemes. We also show that certain naive bootstrap schemes do not work. To demonstrate its versatility, we apply the framework to several examples: independence tests, tests on the coefficients in linear regression models, goodness-of-fit tests for general parametric models and for semi-parametric copula models. Simulation results confirm the asymptotic results and suggest that in smaller samples non-traditional bootstrap schemes may have advantages. This bootstrap-based hypothesis testing framework is implemented in the R package BootstrapTests."}
{"id": "2512.10083", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10083", "abs": "https://arxiv.org/abs/2512.10083", "authors": ["Patrick Henning", "Laura Huynh", "Daniel Peterseim"], "title": "Metric-driven numerical methods", "comment": null, "summary": "In this paper, we explore the concept of metric-driven numerical methods as a powerful tool for solving various types of multiscale partial differential equations. Our focus is on computing constrained minimizers of functionals - or, equivalently, by considering the associated Euler-Lagrange equations - the solution of a class of eigenvalue problems that may involve nonlinearities in the eigenfunctions. We introduce metric-driven methods for such problems via Riemannian gradient techniques, leveraging the idea that gradients can be represented in different metrics (so-called Sobolev gradients) to accelerate convergence. We show that the choice of metric not only leads to specific metric-driven iterative schemes, but also induces approximation spaces with enhanced properties, particularly in low-regularity regimes or when the solution exhibits heterogeneous multiscale features. In fact, we recover a well-known class of multiscale spaces based on the Localized Orthogonal Decomposition (LOD), now derived from a new perspective. Alongside a discussion of the metric-driven approach for a model problem, we also demonstrate its application to simulating the ground states of spin-orbit-coupled Bose-Einstein condensates."}
{"id": "2512.10142", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.10142", "abs": "https://arxiv.org/abs/2512.10142", "authors": ["S. C. Park"], "title": "Conformal Invariance of the FK-Ising Model on Lorentz-Maximal S-Embeddings", "comment": "14 pages, 1 figure", "summary": "We show on non-flat but critical s-embeddings the celebrated convergence of the interface curves of the critical FK Ising model to an $\\operatorname{SLE}_{16/3}$ curve, using discrete complex analytic techniques first used in arXiv:0708.0039, arXiv:1312.0533 and subsequently extended to more lattice settings including isoradial graphs arXiv:0910.2045, circle packings arXiv:1712.08736, and flat s-embeddings arXiv:2006.14559. In our setting, the s-embedding approximates a maximal surface in the Minkowski space $\\mathbb R^{2,1}$, an `exact' criticality condition identified in arXiv:2006.14559, which is stronger than the percolation-theoretic `near-critical' setup studied in, e.g., arXiv:2309.08470. The proof relies on a careful discretisation of the Laplace-Beltrami operator on the s-embedding, which is crucial in identifying the limit of the martingale observable."}
{"id": "2512.10325", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10325", "abs": "https://arxiv.org/abs/2512.10325", "authors": ["Francesco Alemanno"], "title": "Residual subspace evolution strategies for nonlinear inverse problems", "comment": null, "summary": "Nonlinear inverse problems often feature noisy, non-differentiable, or expensive residual evaluations that make Jacobian-based solvers unreliable. Popular derivative-free optimizers such as natural evolution strategies (NES) or Powell's NEWUOA still assume smoothness or expend many evaluations to maintain stability. Ensemble Kalman inversion (EKI) relies on empirical covariances that require preconditioning and scale poorly with residual dimension.\n  We introduce residual subspace evolution strategies (RSES), a derivative-free solver that samples Gaussian probes around the current iterate, builds a residual-only surrogate from their differences, and recombines the probes through a least-squares solve yielding an optimal update without forming Jacobians or covariances. Each iteration costs $k+1$ residual evaluations, where $k \\ll n$ for $n$-dimensional problems, with $O(k^3)$ linear algebra overhead.\n  Benchmarks on calibration, regression, and deconvolution problems demonstrate consistent misfit reduction in both deterministic and stochastic settings. RSES matches or surpasses xNES and NEWUOA while staying competitive with EKI under matched evaluation budgets, particularly when smoothness or covariance assumptions fail."}
{"id": "2512.10825", "categories": ["math.ST", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.10825", "abs": "https://arxiv.org/abs/2512.10825", "authors": ["Thabo Samakhoana", "Benjamin Grimmer"], "title": "An Elementary Proof of the Near Optimality of LogSumExp Smoothing", "comment": "10 pages", "summary": "We consider the design of smoothings of the (coordinate-wise) max function in $\\mathbb{R}^d$ in the infinity norm. The LogSumExp function $f(x)=\\ln(\\sum^d_i\\exp(x_i))$ provides a classical smoothing, differing from the max function in value by at most $\\ln(d)$. We provide an elementary construction of a lower bound, establishing that every overestimating smoothing of the max function must differ by at least $\\sim 0.8145\\ln(d)$. Hence, LogSumExp is optimal up to constant factors. However, in small dimensions, we provide stronger, exactly optimal smoothings attaining our lower bound, showing that the entropy-based LogSumExp approach to smoothing is not exactly optimal."}
{"id": "2512.10122", "categories": ["math.NA", "math.SP"], "pdf": "https://arxiv.org/pdf/2512.10122", "abs": "https://arxiv.org/abs/2512.10122", "authors": ["Hannah Potgieter", "Razvan C. Fetecau", "Steven J. Ruuth"], "title": "Numerical approximation of the first $p$-Laplace eigenpair", "comment": null, "summary": "We approximate the first Dirichlet eigenpair of the $p$-Laplace operator for $2 \\leq p < \\infty$ on both Euclidean and surface domains. We emphasize large $p$ values and discuss how the $p \\to \\infty$ limit connects to the underlying geometry of our domain. Working with large $p$ values introduces significant numerical challenges. We present a surface finite element numerical scheme that combines a Newton inverse-power iteration with a new domain rescaling strategy, which enables stable computations for large $p$. Numerical experiments in $1$D, planar domains, and surfaces embedded in $\\mathbb{R}^3$ demonstrate the accuracy and robustness of our approach and show convergence towards the $p \\to \\infty$ limiting behavior."}
{"id": "2512.10171", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10171", "abs": "https://arxiv.org/abs/2512.10171", "authors": ["Gustavo O. Carvalho", "Fábio P. Machado", "J. Hermenegildo R. González"], "title": "The Frog Model on $\\mathbb{Z}$ with General Random Survival Parameter", "comment": "20 pages", "summary": "We study the frog model on $\\mathbb{Z}$ with particle-wise random geometric lifetimes: each particle has a survival parameter $π\\in(0,1)$ sampled i.i.d., whose density near $1$ satisfies $f_π(u)\\sim (1-u)^{β-1}L\\big((1-u)^{-1}\\big)$ with $β>0$, and $L$ slowly varying. This strictly extends the $\\mathrm{Beta}(α,β)$ case. Let $η$ denote the common law of the i.i.d.\\ initial number of particles $\\{η_x\\}_{x\\in\\mathbb{Z}}$. Using a percolation comparison and sharp one-particle displacement tails, we obtain a universal threshold at $β=\\tfrac12$. If $β>\\tfrac12$ and $E(η)<\\infty$, extinction occurs almost surely. If $β<\\tfrac12$ and $\\mathbb{P}(η=0)<1$, survival has positive probability. At the boundary $β=\\tfrac12$ we give sharp criteria: extinction if $E(η)<\\infty$ and $8\\,\\limsup_{n\\to\\infty}L(n^2)<1/E(η)$; survival if $\\mathbb{P}(η=0)<1$ and $\\sqrt{2}\\,\\liminf_{n\\to\\infty}L(n^2)>1/E(η)$. These results recover the Carvalho-Machado threshold for Beta laws and show that only the exponent $β$ governs the phase transition, while $L$ impacts the critical regime."}
{"id": "2512.10366", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.10366", "abs": "https://arxiv.org/abs/2512.10366", "authors": ["Minh N. Dao", "Hung M. Phan", "Matthew K. Tam", "Thang D. Truong"], "title": "Primal-dual splitting for structured composite monotone inclusions with or without cocoercivity", "comment": null, "summary": "In this paper, we propose a primal-dual splitting algorithm for a broad class of structured composite monotone inclusions that involve finitely many set-valued operators, compositions of set-valued operators with bounded linear operators, and single-valued operators possibly without cocoercivity. The proposed algorithm is not only a unification for several contemporary algorithms but also a blueprint to generate new algorithms with graph-based structures. Our approach reduces dimensionality compared with the standard product space technique, which typically reformulates the original problem as the sum of two maximally monotone operators in order to apply splitting methods. It accommodates different cocoercive or Lipschitz constants as well as different resolvent parameters, and yields a larger allowable step-size range than in product space reformulations. We demonstrate the practicality of the approach by a numerical experiment on the decentralized fused lasso problem."}
{"id": "2512.10192", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10192", "abs": "https://arxiv.org/abs/2512.10192", "authors": ["Stefano Bonetti", "Michele Botti", "Patrick Vega"], "title": "A robust fully-mixed finite element method with skew-symmetry penalization for low-frequency poroelasticity", "comment": "19 pages", "summary": "In this work, we present and analyze a fully-mixed finite element scheme for the dynamic poroelasticity problem in the low-frequency regime. We write the problem as a four-field, first-order, hyperbolic system of equations where the symmetry constraint on the stress field is imposed via penalization. This strategy is equivalent to adding a perturbation to the saddle point system arising when the stress symmetry is weakly-imposed. The coupling of solid and fluid phases is discretized by means of stable mixed elements in space and implicit time advancing schemes. The presented stability analysis is fully robust with respect to meaningful cases of degenerate model parameters. Numerical tests validate the convergence and robustness and assess the performances of the method for the simulation of wave propagation phenomena in porous materials."}
{"id": "2512.10199", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10199", "abs": "https://arxiv.org/abs/2512.10199", "authors": ["Samuel G. G. Johnston", "Rohan Shiatis"], "title": "Explicit correlation functions for the six-vertex model in the free-fermion regime", "comment": "27 pages", "summary": "In this article, we show that, in the free-fermion regime of the six-vertex model, all $k$-point correlation functions of vertex types admit a determinantal representation: \\begin{align*} \\mathbb{P}\\Bigg( \\bigcap_{p=1}^k \\{ \\text{vertex at } v^p \\text{ has type } t_p \\} \\Bigg) = \\left( \\prod_{p=1}^k a_{t_p} \\right)\n  \\det\\big[ L(x^i,y^j) \\big]_{i,j=1}^{2k}, \\end{align*} where $t_1,\\ldots,t_k \\in \\{1,\\ldots,6\\}$ label the six possible vertex types, and $\\{a_t : 1 \\leq t \\leq 6\\}$ are the corresponding six-vertex weights. For each $1 \\leq p \\leq k$, the four points $x^{2p-1}, x^{2p}, y^{2p-1}, y^{2p} \\in (\\mathbb{Z}/2)^2$ are $t_p$-dependent choices among the midpoints of the edges incident to $v^p$. The correlation kernel $L$ has the contour integral representation \\begin{align*} L(x,y) = \\oint_{|w_1|=1} \\oint_{|w_2|=1}\n  \\frac{dw_1}{2πi\\, w_1}\\,\n  \\frac{dw_2}{2πi\\, w_2}\\,\n  w_1^{\\,y_1 - x_1}\\, w_2^{\\,y_2 - x_2}\\,\n  h\\big(c(x),c(y);w_1,w_2\\big), \\end{align*} where $h\\big(c(x),c(y);w_1,w_2\\big)$ is a simple rational function of $(w_1,w_2)$ that depends on $x$ and $y$ only through their orientations $c(x)$ and $c(y)$. Our proof is fully self-contained: we construct a determinantal point process on $\\mathbb{Z}^2$ and identify the six-vertex model as its pushforward under an explicit mapping."}
{"id": "2512.10507", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.10507", "abs": "https://arxiv.org/abs/2512.10507", "authors": ["Dominik Kuzinowicz", "Paweł Lichocki", "Gioni Mexi", "Marc E. Pfetsch", "Sebastian Pokutta", "Max Zimmer"], "title": "Objective Coefficient Rounding and Almost Symmetries in Binary Programs", "comment": "8 pages, 2 pages references, 3 tables", "summary": "This article investigates the interplay of rounding objective coefficients in binary programs and almost symmetries. Empirically, reducing the number of significant bits through rounding often leads to instances that are easier to solve. One reason can be that the amount of symmetries increases, which enables solvers to be more effective when they are exploited. This can signify that the original instance contains 'almost symmetries'. Furthermore, solving the rounded problems provides approximations to the original objective values. We empirically investigate these relations on instances of the capacitated facility location problem, the knapsack problem and a diverse collection of additional instances, using the solvers SCIP and CP-SAT. For all investigated problem classes, we show empirically that this yields faster algorithms with guaranteed solution quality. The influence of symmetry depends on the instance type and solver."}
{"id": "2512.10204", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10204", "abs": "https://arxiv.org/abs/2512.10204", "authors": ["Weimin Han"], "title": "Variational-hemivariational inequalities: A brief survey on mathematical theory and numerical analysis", "comment": null, "summary": "Variational-hemivariational inequalities are an area full of interesting and challenging mathematical problems. The area can be viewed as a natural extension of that of variational inequalities. Variational-hemivariational inequalities are valuable for application problems from physical sciences and engineering that involve non-smooth and even set-valued relations, monotone or non-monotone, among physical quantities. In the recent years, there has been substantial growth of research interest in modeling, well-posedness analysis, development of numerical methods and numerical algorithms of variational-hemivariational inequalities. This survey paper is devoted to a brief account of well-posedness and numerical analysis results for variational-hemivariational inequalities. The theoretical results are presented for a family of abstract stationary variational-hemivariational inequalities and the main idea is explained for an accessible proof of existence and uniqueness. To better appreciate the distinguished feature of variational-hemivariational inequalities, for comparison, three mechanical problems are introduced leading to a variational equation, a variational inequality, and a variational-hemivariational inequality, respectively. The paper also comments on mixed variational-hemivariational inequalities, with examples from applications in fluid mechanics, and on results concerning the numerical solution of other types (nonstationary, history dependent) of variational-hemivariational inequalities."}
{"id": "2512.10311", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10311", "abs": "https://arxiv.org/abs/2512.10311", "authors": ["Huijie Qiao"], "title": "Large deviation principles for fully coupled multiscale multivalued stochastic systems", "comment": "29 pages", "summary": "This study focuses on large deviation principles for fully coupled multiscale multivalued stochastic systems, in which the slow component is governed by a multivalued stochastic differential equation and the fast component is described by a general stochastic differential equation. First, we establish the large deviation principle for the slow component at any fixed time by leveraging viscosity solutions of second-order Hamilton-Jacobi-Bellman equations involving multivalued operators. Subsequently, we illustrate the theoretical results through a concrete example."}
{"id": "2512.10641", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10641", "abs": "https://arxiv.org/abs/2512.10641", "authors": ["CéEdric Join", "Emmanuel Delaveau", "Michel Fliess"], "title": "Linear Quadratic Regulators: A New Look", "comment": null, "summary": "Linear time-invariant control systems can be considered as finitely generated modules over the commutative principal ideal ring $\\mathbb{R}[\\frac{d}{dt}]$ of linear differential operators with respect to the time derivative. The Kalman controllability in this algebraic language is translated as the freeness of the system module. Linear quadratic regulators rely on quadratic Lagrangians, or cost functions. Any flat output, i.e., any basis of the corresponding free module leads to an open-loop control strategy via an Euler-Lagrange equation, which becomes here a linear ordinary differential equation with constant coefficients. In this approach, the two-point boundary value problem, including the control variables, becomes tractable. It yields notions of optimal time horizon, optimal parameter design and optimal rest-to-rest trajectories. The loop is closed via an intelligent controller derived from model-free control, which is known to exhibit excellent performance concerning model mismatches and disturbances."}
{"id": "2512.10260", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10260", "abs": "https://arxiv.org/abs/2512.10260", "authors": ["Qiao Hu", "Bo Zhang", "Haiwen Zhang"], "title": "Convergence analysis of contrast source inversion type methods for acoustic inverse medium scattering problems", "comment": null, "summary": "The contrast source inversion (CSI) method and the subspace-based optimization method (SOM) are first proposed in 1997 and 2009, respectively, and subsequently modified. The two methods and their variants share several properties and thus are called the CSI-type methods. The CSI-type methods are efficient and popular methods for solving inverse medium scattering problems, but their rigorous convergence remains an open problem. In this paper, we propose two iteratively regularized CSI-type (IRCSI-type) methods with a novel $\\ell_1$ proximal term as the iteratively regularized term: the iteratively regularized CSI (IRCSI) method and the iteratively regularized SOM (IRSOM) method, which have a similar computation complexity to the original CSI and SOM methods, respectively, and prove their global convergence under natural and weak conditions on the original objective function. To the best of our knowledge, this is the first convergence result for iterative methods of solving nonlinear inverse scattering problems with a fixed frequency. The convergence and performance of the two IRCSI-type algorithms are illustrated by numerical experiments."}
{"id": "2512.10460", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10460", "abs": "https://arxiv.org/abs/2512.10460", "authors": ["Baptiste Bergeot", "Nils Berglund", "Israa Zogheib"], "title": "The dynamic saddle-node bifurcation with noise on the slow variable", "comment": "37 pages, 8 figures", "summary": "In this work, we analyse the effect of adding Gaussian white noise to the slow variable of a slow--fast system passing through a saddle--node (or fold) bifurcation. This problem is mainly motivated by applications to non-equilibrium energy sinks. While the effect of adding noise to the fast variable, which is important for noise-induced tipping, has been previously analysed in detail, the case where the slow variable is perturbed by noise has not been considered before. Our main result is that the noise increases the slow variable on average. We compute the effect of the noise, to lowest order, on the expectation and variance of the slow variable after the bifurcation. The contribution of the noise can be explicitly expressed in terms of Airy functions. We also provide numerical simulations, which show that the expansion to lowest order matches the observations for fairly large values of the noise intensity."}
{"id": "2512.10654", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.10654", "abs": "https://arxiv.org/abs/2512.10654", "authors": ["Sabrina Bonandin", "Konstantin Riedl", "Sara Veneruso"], "title": "Strong Global Convergence of the Consensus-Based Optimization Algorithm", "comment": null, "summary": "Consensus-based optimization (CBO) is a multi-agent metaheuristic derivative-free optimization algorithm that has proven to be capable of globally minimizing nonconvex nonsmooth functions across a diverse range of applications while being amenable to theoretical analysis. The method leverages an interplay between exploration of the energy landscape of the objective function through a system of interacting particles subject to stochasticity and exploitation of the particles' positions through the computation of a global consensus about the location of the minimizer based on the Laplace principle. In this paper, we prove strong mean square convergence of the practical numerical time-discrete CBO algorithm to the global minimizer for a rich class of objective functions. For CBO with both isotropic and anisotropic diffusion, our convergence result features conditions on the choice of the hyperparameters as well as explicit rates of convergence in the time discretization step size $Δt$ and the number of particles $N$. By interpreting the time-discrete algorithm at the continuous-time level through a system of stochastic differential equations (SDEs), our proof strategy combines traditional finite-time convergence theory for numerical methods applied to SDEs with careful considerations due to the fact that the CBO coefficients do not satisfy a global Lipschitz condition. To accomodate the latter, we adopt a recently proposed generalization of Sznitman's classical argument, which allows to discard an event of small probability, controllable through fine moment estimates for the particle systems."}
{"id": "2512.10330", "categories": ["math.NA", "math.FA"], "pdf": "https://arxiv.org/pdf/2512.10330", "abs": "https://arxiv.org/abs/2512.10330", "authors": ["V. N. Kolokoltsov", "E. L. Shishkina"], "title": "Matrix approach to the fractional calculus", "comment": null, "summary": "In this paper, we introduce the new construction of fractional derivatives and integrals with respect to a function, based on a matrix approach. We believe that this is a powerful tool in both analytical and numerical calculations. We begin with the differential operator with respect to a function that generates a semigroup. By discretizing this operator, we obtain a matrix approximation. Importantly, this discretization provides not only an approximating operator but also an approximating semigroup. This point motivates our approach, as we then apply Balakrishnan's representations of fractional powers of operators, which are based on semigroups. Using estimates of the semigroup norm and the norm of the difference between the operator and its matrix approximation, we derive the convergence rate for the approximation of the fractional power of operators with the fractional power of correspondings matrix operators. In addition, an explicit formula for calculating an arbitrary power of a two-band matrix is obtained, which is indispensable in the numerical solution of fractional differential and integral equations."}
{"id": "2512.10536", "categories": ["math.PR", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.10536", "abs": "https://arxiv.org/abs/2512.10536", "authors": ["Rui Bai", "Chunrong Feng", "Huaizhong Zhao"], "title": "Large deviations for invariant measure of stochastic Allen-Cahn equation with inhomogeneous boundary conditions and multiplicative noise", "comment": "33 pages", "summary": "We prove the validity of a small noise large deviation principle for the family of invariant measures $\\{μ_ε\\}_{ε>0} $ associated to the one dimensional stochastic Allen-Cahn equation with inhomogeneous Dirichlet boundary conditions, perturbed by unbounded multiplicative noise. The main difficulty is that the system is not strongly dissipative. Using L. Simon's convergence theorem, we show that the dynamics of the noiseless system converge in large time to the minimizer of the Ginzburg-Landau energy functional, which is unique due to the boundary condition. We obtain an estimate of the invariant measure on the bounded set in the Sobolev space $W^{k^\\star,p^\\star} $, where $k^\\star p^\\star>1$, and $p^\\star$ is large. As a corollary of the main result, we show that $μ_ε$ concentrates around the unique minimizer with such boundary conditions exponentially fast when $ε$ is sufficiently small."}
{"id": "2512.10826", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.10826", "abs": "https://arxiv.org/abs/2512.10826", "authors": ["Chenglong Bao", "Yancheng Yuan", "Shulan Zhu"], "title": "On the Convergence Analysis of an Inexact Preconditioned Stochastic Model-Based Algorithm", "comment": null, "summary": "This paper focuses on investigating an inexact stochastic model-based optimization algorithm that integrates preconditioning techniques for solving stochastic composite optimization problems. The proposed framework unifies and extends the fixed-metric stochastic model-based algorithm to its preconditioned and inexact variants. Convergence guarantees are established under mild assumptions for both weakly convex and convex settings, without requiring smoothness or global Lipschitz continuity of the objective function. By assuming a local Lipschitz condition, we derive nonasymptotic and asymptotic convergence rates measured by the gradient of the Moreau envelope. Furthermore, convergence rates in terms of the distance to the optimal solution set are obtained under an additional quadratic growth condition on the objective function. Numerical experiment results demonstrate the theoretical findings for the proposed algorithm."}
{"id": "2512.10473", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10473", "abs": "https://arxiv.org/abs/2512.10473", "authors": ["Mejdi Azaïez", "Yayu Guo", "Carlos Núñez Fernández", "Samuele Rubino", "Chuanju Xu"], "title": "Second order reduced model via incremental projection for Navier Stokes", "comment": null, "summary": "The numerical simulation of incompressible flows is challenging due to the tight coupling of velocity and pressure. Projection methods offer an effective solution by decoupling these variables, making them suitable for large-scale computations. This work focuses on reduced-order modeling using incremental projection schemes for the Stokes equations. We present both semi-discrete and fully discrete formulations, employing BDF2 in time and finite elements in space. A proper orthogonal decomposition (POD) approach is adopted to construct a reduced-order model for the Stokes problem. The method enables explicit computation of reduced velocity and pressure while preserving accuracy. We provide a detailed stability analysis and derive error estimates, showing second-order convergence in time. Numerical experiments are conducted to validate the theoretical results and demonstrate computational efficiency."}
{"id": "2512.10550", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.10550", "abs": "https://arxiv.org/abs/2512.10550", "authors": ["Márton Balázs", "Ruby Bestwick", "Artem Borisov", "Elnur Emrah", "Jessica Jay"], "title": "Local convergence in $t$-PNG", "comment": "21 pages, 6 figures; comments welcome", "summary": "We prove local convergence of the $t$-PNG model with zero boundary to the stationary $t$-PNG model, confirming a recent conjecture of Drillick and Lin (2024). The stationary $t$-PNG model is the one with both left and bottom boundaries of Poisson nucleations with rate parameters $\\frac{1}{λ(1-t)}$ and $λ$, respectively, for some $λ>0$. In the proof, we consider the trajectories of certain second class particles via a basic monotone coupling of three $t$-PNG processes, and adapt microscopic concavity ideas used in particle models (e.g., Balázs and Seppäläinen (2009)), as well as blocking measure bounds like in Ferrari, Kipnis and Saada (1991)."}
{"id": "2512.10831", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.10831", "abs": "https://arxiv.org/abs/2512.10831", "authors": ["Roman Chertovskih", "Nikolay Pogodaev", "Maxim Staritsyn", "A. Pedro Aguiar"], "title": "Indirect methods in optimal control on Banach spaces", "comment": null, "summary": "This work focuses on indirect descent methods for optimal control problems governed by nonlinear ordinary differential equations in Banach spaces, viewed as abstract models of distributed dynamics. As a reference line, we revisit the classical schemes, rooted in Pontryagin's maximum principle, and highlight their sensitivity to local convexity and lack of monotone convergence. We then develop an alternative method based on exact cost-increment formulas and finite-difference probes of the terminal cost. We show that our method exhibits stable monotone convergence in numerical analysis of an Amari-type neural field control problem."}
{"id": "2512.10560", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10560", "abs": "https://arxiv.org/abs/2512.10560", "authors": ["Guoyu Zhang", "Ziming Dong", "Baoli Yin", "Yang Liu", "Hong Li"], "title": "Analysis of discrete energy-decay preserving schemes for Maxwell's equations in Cole-Cole dispersive medium", "comment": null, "summary": "This work investigates the design and analysis of energy-decay preserving numerical schemes for Maxwell's equations in a Cole-Cole (C-C) dispersive medium. A continuous energy-decay law is first established for the C-C model through a modified energy functional. Subsequently, a novel \\(θ\\)-scheme is proposed for temporal discretization, which is rigorously proven to preserve a discrete energy dissipation property under the condition \\(θ\\in [\\fracα{2}, \\frac{1}{2}]\\). The temporal convergence rate of the scheme is shown to be first-order for \\(θ\\neq 0.5\\) and second-order for \\(θ= 0.5\\). Extensive numerical experiments validate the theoretical findings, including convergence tests and energy-decay comparisons. The proposed SFTR-\\(θ\\) scheme demonstrates superior performance in maintaining monotonic energy decay compared to an alternative 2nd-order fractional backward difference formula, particularly in long-time simulations, highlighting its robustness and physical fidelity."}
{"id": "2512.10625", "categories": ["math.PR", "math-ph", "math.CA"], "pdf": "https://arxiv.org/pdf/2512.10625", "abs": "https://arxiv.org/abs/2512.10625", "authors": ["Michael Voit"], "title": "Bessel and Dunkl processes with drift", "comment": null, "summary": "For some discrete parameters $k\\ge0$, multivariate (Dunkl-)Bessel processes on Weyl chambers $C$ associated with root systems appear as projections of Brownian motions without drift on Euclidean spaces $V$, and the associated transition densities can be described in terms of multivariate Bessel functions; the most prominent examples are Dyson Brownian motions. The projections of Brownian motions on $V$ with drifts are also Feller diffusions on $C$, and their transition densities and their generators can be again described via these Bessel functions. These processes are called Bessel processes with drifts. In this paper we construct these Bessel processes processes with drift for arbitrary root systems and parameters $k\\ge 0$. Moreover, this construction works also for Dunkl processes. We study some features of these processes with drift like their radial parts, a Girsanov theorem, moments and associated martingales, strong laws of large numbers, and central limit theorems."}
{"id": "2512.10851", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10851", "abs": "https://arxiv.org/abs/2512.10851", "authors": ["Alexey Iskakov", "Igor Yadykin"], "title": "Spectral Decompositions of Controllability Gramian and Its Inverse based on System Eigenvalues in Companion Form", "comment": null, "summary": "Controllability and observability Gramians, along with their inverses, are widely used to solve various problems in control theory. This paper proposes spectral decompositions of the controllability Gramian and its inverse based on system eigenvalues for a continuous LTI dynamical system in the controllability canonical (companion) form. The Gramian and its inverse are represented as sums of Hermitian matrices, each corresponding to individual system eigenvalues or their pairwise combinations. These decompositions are obtained for the solutions of both algebraic and differential Lyapunov and Riccati equations with arbitrary initial conditions, allowing for the estimation of system spectral properties over an arbitrary time interval and their prediction at future moments. The derived decompositions are also generalized to the case of multiple eigenvalues in the dynamics matrix spectrum, enabling a closed-form estimation of the effects of resonant interactions with the system's eigenmodes. The spectral components are interpreted as measurable quantities in the minimum energy control problem. Therefore, they are unambiguously defined and can quantitatively characterize the influence of individual eigenmodes and associated system devices on controllability, observability, and the asymptotic dynamics of perturbation energy. The additional information obtained from these decompositions can improve the accuracy of algorithms in solving various practical problems, such as stability analysis, minimum energy control, structural design, tuning regulators, optimal placement of actuators and sensors, network analysis, and model order reduction."}
{"id": "2512.10716", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10716", "abs": "https://arxiv.org/abs/2512.10716", "authors": ["Juan Barajas-Calonge", "Mauricio A. Sepulveda Cortes", "Nicolas Torres", "Luis Miguel Villada"], "title": "Dynamically consistent finite volume scheme for a bimonomeric simplified model with inflammation processes for Alzheimer's disease", "comment": null, "summary": "A model of progression of Alzheimer's disease (AD) incorporating the interactions of A$β$-monomers, oligomers, microglial cells and interleukins with neurons is considered. The resulting convection-diffusion-reaction system consists of four partial differential equations (PDEs) and one ordinary differential equation (ODE). We develop a finite volume (FV) scheme for this system, together with non-negativity and a priori bounds for the discrete solution, so that we establish the existence of a discrete solution to the FV scheme. It is shown that the scheme converges to an admissible weak solution of the model. The reaction terms of the system are discretized using a semi-implicit strategy that coincides with a nonstandard discretization of the spatially homogeneous (SH) model. This construction enables us to prove that the FV scheme is dynamically consistent with respect to the spatially homogeneous version of the model. Finally, numerical experiments are presented to illustrate the model and to assess the behavior of the FV scheme."}
{"id": "2512.10686", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10686", "abs": "https://arxiv.org/abs/2512.10686", "authors": ["Raphaël Lachièze-Rey"], "title": "Maximal rigidity of random measure and uniqueness pairs: stealthy processes, quasicrystals and periodicity", "comment": null, "summary": "This article investigates the phenomenon of maximal rigidity in spatial processes, where perfect interpolation of the process is possible from partial information, specifically, from its restriction to a strict subdomain, often resulting in a trivial tail $σ$algebra. A classical example known since the 1930's is that a time series is fully determined by its values on the negative integers if its spectrum has a gap, or at least a sufficiently deep zero. We extend such results to higher dimensions and continuous settings by establishing a connection with the concept of uniqueness pairs, rooted in the uncertainty principle of harmonic analysis. We present several other manifestations of this principle, unify and strengthen seemingly unrelated results across different models: quasicrystals and stealthy processes are shown to be maximally rigid on cones, and discrete integer-valued processes are necessarily periodic when they have a simply connected spectrum. Finally, we identify a surprising class of continuous fields with seemingly standard behavior, such as linear variance and finite dependency range, that undergo a phase transition: they are perfectly interpolable on B(0, $ρ$) for $ρ$ ___ 2 $π$ but exhibit no rigidity for $ρ$ > 2."}
{"id": "2512.10906", "categories": ["math.OC", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10906", "abs": "https://arxiv.org/abs/2512.10906", "authors": ["Feras Al Taha", "Eilyan Bitar"], "title": "Distributionally Robust Regret Optimal Control Under Moment-Based Ambiguity Sets", "comment": "21 pages, 2 figures", "summary": "In this paper, we consider a class of finite-horizon, linear-quadratic stochastic control problems, where the probability distribution governing the noise process is unknown but assumed to belong to an ambiguity set consisting of all distributions whose mean and covariance lie within norm balls centered at given nominal values. To address the distributional ambiguity, we explore the design of causal affine control policies to minimize the worst-case expected regret over all distributions in the given ambiguity set. The resulting minimax optimal control problem is shown to admit an equivalent reformulation as a tractable convex program that corresponds to a regularized version of the nominal linear-quadratic stochastic control problem. While this convex program can be recast as a semidefinite program, semidefinite programs are typically solved using primal-dual interior point methods that scale poorly with the problem size in practice. To address this limitation, we propose a scalable dual projected subgradient method to compute optimal controllers to an arbitrary accuracy. Numerical experiments are presented to benchmark the proposed method against state-of-the-art data-driven and distributionally robust control design approaches."}
{"id": "2512.10718", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10718", "abs": "https://arxiv.org/abs/2512.10718", "authors": ["Sabia Asghar", "Duncan den Bakker", "Etelvina Javierre", "Qiyao Peng", "Fred J. Vermolen"], "title": "A Stabilized Finite Element Method for Morpho-Visco-Poroelastic Model", "comment": null, "summary": "We propose a mathematical model that combines elastic, viscous and porous effects with growth or shrinkage due to microstructural changes. This phenomenon is important in tissue or tumor growth, as well as in dermal contraction. Although existence results of the solution to the problem are not given, the current study assesses stability of the equilibria for both the continuous and semi-discrete versions of the model. Furthermore, a numerical condition for monotonicity of the numerical solution is described, as well as a way to stabilize the numerical solution so that spurious oscillations are avoided. The derived stabilization result is confirmed by computer simulations. In order to have a more quantitative picture, the total variation has been evaluated as a function of the stabilization parameter."}
{"id": "2512.10754", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10754", "abs": "https://arxiv.org/abs/2512.10754", "authors": ["Aditya Guha Roy", "Yuval Peres", "Shuo Qin", "Junchi Zuo"], "title": "How reactive gambling can backfire: ruin probability is increasing in $p$, Hölder continuous in initial fortune", "comment": null, "summary": "A gambler with an initial fortune $x$ starts by betting a dollar, then doubles the bet after every win and halves the bet after every loss. Let $p\\in (0,1)$ be the probability of winning for each round. We show that the gambler survives with positive probability if and only if $p < 1/2$ and $x > 2$. Moreover, the ruin probability is increasing and real-analytic in $p$, but a singular, Hölder continuous function of $x$."}
{"id": "2512.10825", "categories": ["math.ST", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.10825", "abs": "https://arxiv.org/abs/2512.10825", "authors": ["Thabo Samakhoana", "Benjamin Grimmer"], "title": "An Elementary Proof of the Near Optimality of LogSumExp Smoothing", "comment": "10 pages", "summary": "We consider the design of smoothings of the (coordinate-wise) max function in $\\mathbb{R}^d$ in the infinity norm. The LogSumExp function $f(x)=\\ln(\\sum^d_i\\exp(x_i))$ provides a classical smoothing, differing from the max function in value by at most $\\ln(d)$. We provide an elementary construction of a lower bound, establishing that every overestimating smoothing of the max function must differ by at least $\\sim 0.8145\\ln(d)$. Hence, LogSumExp is optimal up to constant factors. However, in small dimensions, we provide stronger, exactly optimal smoothings attaining our lower bound, showing that the entropy-based LogSumExp approach to smoothing is not exactly optimal."}
{"id": "2512.10792", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.10792", "abs": "https://arxiv.org/abs/2512.10792", "authors": ["Paolo Botta", "Piermario Vitullo", "Thomas Ventimiglia", "Andreas Linninger", "Paolo Zunino"], "title": "Physics-Informed Learning of Microvascular Flow Models using Graph Neural Networks", "comment": "28 pages, 8 figures", "summary": "The simulation of microcirculatory blood flow in realistic vascular architectures poses significant challenges due to the multiscale nature of the problem and the topological complexity of capillary networks. In this work, we propose a novel deep learning-based reduced-order modeling strategy, leveraging Graph Neural Networks (GNNs) trained on synthetic microvascular graphs to approximate hemodynamic quantities on anatomically realistic domains. Our method combines algorithms for synthetic vascular generation with a physics-informed training procedure that integrates graph topological information and local flow dynamics. To ensure the physical reliability of the learned surrogates, we incorporate a physics-informed loss functional derived from the governing equations, allowing enforcement of mass conservation and rheological constraints. The resulting GNN architecture demonstrates robust generalization capabilities across diverse network configurations. The GNN formulation is validated on benchmark problems with linear and nonlinear rheology, showing accurate pressure and velocity field reconstruction with substantial computational gains over full-order solvers. The methodology showcases significant generalization capabilities with respect to vascular complexity, as highlighted by tests on data from the mouse cerebral cortex. This work establishes a new class of graph-based surrogate models for microvascular flow, grounded in physical laws and equipped with inductive biases that mirror mass conservation and rheological models, opening new directions for real-time inference in vascular modeling and biomedical applications."}
{"id": "2512.10761", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.10761", "abs": "https://arxiv.org/abs/2512.10761", "authors": ["Ruibo Kou"], "title": "Special times for the point set process of the Brownian Net", "comment": null, "summary": "It is known that the point set process of the Brownian net is almost surely locally finite for all deterministic time, and there are random times that break this locally finiteness property. It is shown in this paper that the set of such random times has Hausdorff dimension 1/2 almost surely."}
{"id": "2512.10831", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.10831", "abs": "https://arxiv.org/abs/2512.10831", "authors": ["Roman Chertovskih", "Nikolay Pogodaev", "Maxim Staritsyn", "A. Pedro Aguiar"], "title": "Indirect methods in optimal control on Banach spaces", "comment": null, "summary": "This work focuses on indirect descent methods for optimal control problems governed by nonlinear ordinary differential equations in Banach spaces, viewed as abstract models of distributed dynamics. As a reference line, we revisit the classical schemes, rooted in Pontryagin's maximum principle, and highlight their sensitivity to local convexity and lack of monotone convergence. We then develop an alternative method based on exact cost-increment formulas and finite-difference probes of the terminal cost. We show that our method exhibits stable monotone convergence in numerical analysis of an Amari-type neural field control problem."}
{"id": "2512.10848", "categories": ["math.PR", "cs.DS", "math.FA"], "pdf": "https://arxiv.org/pdf/2512.10848", "abs": "https://arxiv.org/abs/2512.10848", "authors": ["Yunbum Kook", "Santosh S. Vempala"], "title": "The Localization Method for High-Dimensional Inequalities", "comment": "Working draft; comments welcome!", "summary": "We survey the localization method for proving inequalities in high dimension, pioneered by Lovász and Simonovits (1993), and its stochastic extension developed by Eldan (2012). The method has found applications in a surprising wide variety of settings, ranging from its original motivation in isoperimetric inequalities to optimization, concentration of measure, and bounding the mixing rate of Markov chains. At heart, the method converts a given instance of an inequality (for a set or distribution in high dimension) into a highly structured instance, often just one-dimensional."}
{"id": "2512.10933", "categories": ["math.PR", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.10933", "abs": "https://arxiv.org/abs/2512.10933", "authors": ["Pierre-François Rodriguez", "Wen Zhang"], "title": "Anomalous scaling law for the two-dimensional Gaussian free field", "comment": "33 pages", "summary": "We consider the Gaussian free field $\\varphi$ on $\\mathbb{Z}^2$ at large spatial scales $N$ and give sharp bounds on the probability $θ(a,N)$ that the radius of a finite cluster in the excursion set $\\{\\varphi \\geq a\\}$ on the corresponding metric graph is macroscopic. We prove a scaling law for this probability, by which $θ(a,N)$ transitions from fractional logarithmic decay for near-critical parameters $(a,N)$ to polynomial decay in the off-critical regime. The transition occurs across a certain scaling window determined by a correlation length scale $ξ$, which is such that $θ(a,N) \\sim θ(0,ξ)(\\tfrac{N}ξ)^{-τ}$ for typical heights $a$ as $N/ξ$ diverges, with an explicit exponent $τ$ that we identify in the process. This is in stark contrast with recent results from arXiv:2101.02200 and arXiv:2312.10030 in dimension three, where similar observables are shown to follow regular scaling laws, with polynomial decay at and near criticality, and rapid decay in ${N}/ξ$ away from it."}
