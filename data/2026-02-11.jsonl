{"id": "2602.09219", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.09219", "abs": "https://arxiv.org/abs/2602.09219", "authors": ["Remo Kretschmann", "Han Cheng Lie"], "title": "Goodness-of-fit testing for nonlinear inverse problems with random observations", "comment": "44 pages", "summary": "This work is concerned with nonparametric goodness-of-fit testing in the context of nonlinear inverse problems with random observations. Bayesian posterior distributions based upon a Gaussian process prior distribution are proven to contract at a certain rate uniformly over a set of true parameters. The corresponding posterior mean is shown to converge uniformly at the posterior contraction rate in the sense of satisfying a concentration inequality. Distinguishability for bounded alternatives separated from a composite null hypothesis at the posterior contraction rate is established using infimum plug-in tests based on the posterior mean and also on maximum a posteriori estimators. The results are applied to a class of inverse problems governed by ordinary differential equation initial value problems that is widely used in pharmacokinetics. For this class, uniform posterior contraction rates are proven and then used to establish distinguishability."}
{"id": "2602.09240", "categories": ["math.ST", "cs.IT", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.09240", "abs": "https://arxiv.org/abs/2602.09240", "authors": ["Yihan Zhang", "Hong Chang Ji", "Ramji Venkataramanan", "Marco Mondelli"], "title": "Optimal Estimation in Orthogonally Invariant Generalized Linear Models: Spectral Initialization and Approximate Message Passing", "comment": null, "summary": "We consider the problem of parameter estimation from a generalized linear model with a random design matrix that is orthogonally invariant in law. Such a model allows the design have an arbitrary distribution of singular values and only assumes that its singular vectors are generic. It is a vast generalization of the i.i.d. Gaussian design typically considered in the theoretical literature, and is motivated by the fact that real data often have a complex correlation structure so that methods relying on i.i.d. assumptions can be highly suboptimal. Building on the paradigm of spectrally-initialized iterative optimization, this paper proposes optimal spectral estimators and combines them with an approximate message passing (AMP) algorithm, establishing rigorous performance guarantees for these two algorithmic steps. Both the spectral initialization and the subsequent AMP meet existing conjectures on the fundamental limits to estimation -- the former on the optimal sample complexity for efficient weak recovery, and the latter on the optimal errors. Numerical experiments suggest the effectiveness of our methods and accuracy of our theory beyond orthogonally invariant data."}
{"id": "2602.09356", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.09356", "abs": "https://arxiv.org/abs/2602.09356", "authors": ["Dimitri Konen", "Gilles Stupfler"], "title": "Regularized geometric quantiles and universal linear distribution functionals", "comment": null, "summary": "Geometric quantiles are popular location functionals to build rank-based statistical procedures in multivariate settings. They are obtained through the minimization of a non-smooth convex objective function. As a result, the singularity of the directional derivatives leads to numerical instabilities and poor sample properties as well as surprising `phase transitions' from empirical to population distributions. To solve these issues, we introduce a regularized version of geometric distribution functions and quantiles that are provably close to the usual geometric concepts and share their qualitative properties, both in the empirical and continuous case, while allowing for a much broader applicability of asymptotic results without any moment condition. We also show that any linear assignment of probability measures (such as the univariate distribution function), that is also translation- and orthogonal-equivariant, necessarily coincides with one of our regularized geometric distribution functions."}
{"id": "2602.09619", "categories": ["math.ST", "math.AG"], "pdf": "https://arxiv.org/pdf/2602.09619", "abs": "https://arxiv.org/abs/2602.09619", "authors": ["Dario Gasbarra", "Kaie Kubjas", "Sangita Kulathinal", "Nataliia Kushnerchuk", "Fatemeh Mohammadi", "Etienne Sebag"], "title": "Discrete-time, discrete-state multistate Markov models from the perspective of algebraic statistics", "comment": null, "summary": "We study discrete-time, discrete-state multistate Markov models from the perspective of algebraic statistics. These models are widely studied in event history analysis, and are characterized by the state space, the initial distribution and the transition probabilities. A finite path under the multistate Markov model is a particular set of states occupied at finite time instances $\\{1, \\dots, n\\}$. The main goal of this paper is to establish a bridge between event history analysis and algebraic statistics. The joint probabilities of finite paths in these models have a natural monomial parametrization in terms of the initial distribution and the transition probabilities. We study the polynomial relations among joint path probabilities. When the statistical constraints on the parameters are disregarded, nonhomogeneous multistate Markov models of arbitrary order can be viewed as slices of decomposable hierarchical models. This yields a complete description of their vanishing ideals as toric ideals generated by explicit families of binomials. Moreover, the variety of this vanishing ideal equals the nonhomogeneous multistate Markov model on the probability simplex. In contrast, homogeneous multistate Markov models exhibit different algebraic behavior, as time homogeneity imposes additional polynomial relations, leading to vanishing ideals that are strictly larger than in the nonhomogeneous case. We also derive families of binomial relations that vanish on homogeneous multistate Markov models. We investigate maximum likelihood estimation from statistical and algebraic perspectives. For nonhomogeneous models, classical and algebraic formulas agree; in the homogeneous case, the algebraic approach is more complex. Lastly, we provide data applications where we demonstrate the statistical theory to obtain the maximum likelihood estimates of the parameters under specific multistate Markov models."}
{"id": "2602.09342", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.09342", "abs": "https://arxiv.org/abs/2602.09342", "authors": ["Kohki Iba"], "title": "Hitting Probabilities of Finite Points for One-Dimensional Lévy Processes", "comment": "14 pages", "summary": "For a one-dimensional Lévy process, we derive an explicit formula for the probability of first hitting a specified point among a fixed finite set. Moreover, using this formula, we obtain an explicit expression for each entry of the $Q$-matrix of the trace process on the finite set. These formulas involve solely the renormalized zero resolvent."}
{"id": "2602.09055", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09055", "abs": "https://arxiv.org/abs/2602.09055", "authors": ["Sijia Li", "Lei Lin", "Junliang Lv"], "title": "An adaptive perfectly matched layer finite element method for acoustic-elastic interaction in periodic structures", "comment": "29 pages, 12 figures", "summary": "This paper considers the scattering of a time-harmonic acoustic plane wave by an elastic body with an unbounded periodic surface. The original problem can be confined to the analysis of the fields in one periodic cell. With the help of the perfectly matched layer (PML) technique, we can truncate the unbounded physical domain into a bounded computational domain. By respectively constructing the equivalent transparent boundary conditions of acoustic and elastic waves simultaneously, the well-posedness and exponential convergence of the solution to the associated truncated PML problem are established. The finite element method is applied to solve the PML problem of acoustic-elastic interaction. To address the singularity caused by the non-smooth surface of the elastic body, we establish a residual-type a posteriori error estimate and develop an adaptive PML finite element algorithm. Several numerical examples are presented to demonstrate the effectiveness of the proposed adaptive algorithm."}
{"id": "2602.09133", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09133", "abs": "https://arxiv.org/abs/2602.09133", "authors": ["Luke Fina", "Christopher Petersen"], "title": "Uniting Iteration Limits for Mixed-Integer Quadratic MPC", "comment": "Submitted to IEEE TCST", "summary": "Iteration limited model predictive control (MPC) can stabilize a feedback control system under sufficient conditions; this work explores combining a low iteration limit MPC with a high iteration limit MPC for mixed-integer quadratic programs (MIQPs) where the suboptimality is due to solver iteration limits. To combine the two MPCs a hybrid systems controller is developed that ``unites'' two MIQP-MPC solvers where the iteration limits of interest are the branch-and-bound and quadratic programming iteration limits. Asymptotic stability and robustness of the hybrid feedback control system are theoretically derived. Then an interpretable branch-and-bound algorithm and implementable uniting controller algorithm are developed. Finally, the developed algorithms and varying iteration limits are empirically evaluated in simulation for the switching thruster and minimum thrust spacecraft rendezvous problems."}
{"id": "2602.09762", "categories": ["math.ST", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.09762", "abs": "https://arxiv.org/abs/2602.09762", "authors": ["Kensuke Aishima"], "title": "Asymptotic analysis of the Gaussian kernel matrix for partially noisy data in high dimensions", "comment": null, "summary": "The Gaussian kernel is one of the most important kernels, applicable to many research fields, including scientific computing and data science. In this paper, we present asymptotic analysis of the Gaussian kernel matrix in high dimension under a statistical model of noisy data. The main result is a nice combination of Karoui's asymptotic analysis with procedures of constrained low rank matrix approximations. More specifically, Karouli clarified an important asymptotic structure of the Gaussian kernel matrix, leading to strong consistency of the eigenvectors, though the eigenvalues are inconsistent. This paper focuses on the above results and presents a consistent estimator with the use of the smallest eigenvalue, whenever the target kernel matrix tends to low rank in the asymptotic regime. Importantly, asymptotic analysis is given under a statistical model representing partial noise. Although a naive estimator is inconsistent, applying an optimization method for low rank approximations with constraints, we overcome the difficulty caused by the inconsistency, resulting in a new estimator with strong consistency in rank deficient cases."}
{"id": "2602.09547", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.09547", "abs": "https://arxiv.org/abs/2602.09547", "authors": ["Benjamin Gess", "Daniel Heydecker"], "title": "The Porous Medium Equation: Multiscale Integrability in Large Deviations", "comment": null, "summary": "We consider a zero-range process $η^N_t(x)$ with superlinear local jump rate, which in a hydrodynamic-small particle rescaling converges to the porous medium equation $\\partial_t u=\\frac12Δu^α, α>1$. As a main result we obtain a large deviation principle in any scaling regime of vanishing particle size $χ_N\\to 0$. The key challenge is to develop uniform integrability estimate on the nonlinearity $(η^N(x))^α$ in a situation where neither pathwise regularity nor Dirichlet-form based regularity is readily available. We resolve this by introducing a novel multiscale argument exploiting the appearance of pathwise regularity across scales."}
{"id": "2602.09057", "categories": ["math.NA", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.09057", "abs": "https://arxiv.org/abs/2602.09057", "authors": ["Zhipeng Chang", "Wenrui Hao", "Nian Liu"], "title": "SVD-Preconditioned Gradient Descent Method for Solving Nonlinear Least Squares Problems", "comment": null, "summary": "This paper introduces a novel optimization algorithm designed for nonlinear least-squares problems. The method is derived by preconditioning the gradient descent direction using the Singular Value Decomposition (SVD) of the Jacobian. This SVD-based preconditioner is then integrated with the first- and second-moment adaptive learning rate mechanism of the Adam optimizer. We establish the local linear convergence of the proposed method under standard regularity assumptions and prove global convergence for a modified version of the algorithm under suitable conditions. The effectiveness of the approach is demonstrated experimentally across a range of tasks, including function approximation, partial differential equation (PDE) solving, and image classification on the CIFAR-10 dataset. Results show that the proposed method consistently outperforms standard Adam, achieving faster convergence and lower error in both regression and classification settings."}
{"id": "2602.09212", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09212", "abs": "https://arxiv.org/abs/2602.09212", "authors": ["Mamadou Niang", "Mamadou Pathe LY", "Abdoul Aziz Ndiaye", "Abdoul Aziz Ndiaye", "Mamadou Abdoul Diop"], "title": "Controllability of nonautonomous measure driven integrodifferential evolution equations with nonlocal conditions", "comment": "22 pages", "summary": "This research delves into the exact controllability of semilinear measure-driven integrodifferential systems in nonlocal settings. We provide sufficient controllability requirements using the measure of noncompactness and the Mönch fixed point theorem without making any assumptions about how compact the evolution system is in relation to the linear part of the measure system. Here, we obtain results that both generalize and improve upon many prior findings."}
{"id": "2602.09833", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.09833", "abs": "https://arxiv.org/abs/2602.09833", "authors": ["Hancheng Bi", "Bernhard Schmitzer", "Thilo D. Stier"], "title": "Density estimation from batched broken random samples", "comment": "18 pages, 4 figures", "summary": "The broken random sample problem was first introduced by DeGroot, Feder, and Gole (1971, Ann. Math. Statist.): in each observation (batch), a random sample of $M$ i.i.d. point pairs $ ((X_i,Y_i))_{i=1}^M$ is drawn from a joint distribution with density $p(x,y)$, but we can observe only the unordered multisets $(X_i)_{i=1}^M$ and $(Y_i)_{i=1}^M$ separately; that is, the pairing information is lost. For large $M$, inferring $p$ from a single observation has been shown to be essentially impossible. In this paper, we propose a parametric method based on a pseudo-log-likelihood to estimate $p$ from $N$ i.i.d. broken sample batches, and we prove a fast convergence rate in $N$ for our estimator that is uniform in $M$, under mild assumptions."}
{"id": "2602.09643", "categories": ["math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.09643", "abs": "https://arxiv.org/abs/2602.09643", "authors": ["Nils Lid Hjort"], "title": "A simple proof of the discreteness of Dirichlet processes", "comment": "Based on pages 18-19 in N.L. Hjort's graduate thesis, 1976", "summary": "That Dirichlet processes are discrete with probability 1 is demonstrated once more. And yes, these two pages spent fifty years in Norwegian."}
{"id": "2602.09198", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09198", "abs": "https://arxiv.org/abs/2602.09198", "authors": ["Mauro Bonafini", "Davide Torlo", "Elena Gaburro"], "title": "Stability analysis of Arbitrary-Lagrangian-Eulerian ADER-DG methods on classical and degenerate spacetime geometries", "comment": "21 pages, 8 figures", "summary": "In this paper, we present a thorough von Neumann stability analysis of explicit and implicit Arbitrary-Lagrangian-Eulerian (ALE) ADER discontinuous Galerkin (DG) methods on classical and degenerate spacetime geometries for hyperbolic equations. First, we rigorously study the CFL stability conditions for the explicit ADER-DG method, confirming results widely used in the literature while specifying their limitations. Moreover, we highlight under which conditions on the mesh velocity the ALE methods, constrained to a given CFL, are actually stable. Next, we extend the stability study to ADER-DG in the presence of degenerate spacetime elements, with zero size at the beginning and the end of the time step, but with a non zero spacetime volume. This kind of elements has been introduced in a series of articles on direct ALE methods by Gaburro et al. to connect via spacetime control volumes regenerated Voronoi tessellations after a topology change. Here, we imitate this behavior in 1d by fictitiously inserting degenerate elements in between two cells. Then, we show that over this degenerate spacetime geometry, both for the explicit and implicit ADER-DG, the CFL stability constraints remain the same as those for classical geometries, laying the theoretical foundations for their use in the context of ALE methods."}
{"id": "2602.09285", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09285", "abs": "https://arxiv.org/abs/2602.09285", "authors": ["Alen Alexanderian", "Steven Maio"], "title": "Submodularity of the expected information gain in infinite-dimensional linear inverse problems", "comment": "14 Pages", "summary": "We consider infinite-dimensional linear Gaussian Bayesian inverse problems with uncorrelated sensor data, and focus on the problem of finding sensor placements that maximize the expected information gain (EIG). This study is motivated by optimal sensor placement for linear inverse problems constrained by partial differential equations (PDEs). We consider measurement models where each sensor collects a single-snapshot measurement. This covers sensor placement for inverse problems governed by linear steady PDEs or evolution equations with final-in-time observations. It is well-known that in the finite-dimensional (discretized) formulations of such inverse problems, EIG is a monotone submodular function. This also entails a theoretical guarantee for greedy sensor placement in the discretized setting. We extend the result on submodularity of the EIG to the infinite-dimensional setting, proving that the approximation guarantee of greedy sensor placement remains valid in the infinite-dimensional limit. We also discuss computational considerations and present strategies that exploit problem structure and submodularity to yield an efficient implementation of the greedy procedure."}
{"id": "2602.09959", "categories": ["math.ST", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.09959", "abs": "https://arxiv.org/abs/2602.09959", "authors": ["Hugo Latourelle-Vigeant", "Theodor Misiakiewicz"], "title": "Statistical-Computational Trade-offs in Learning Multi-Index Models via Harmonic Analysis", "comment": "91 pages", "summary": "We study the problem of learning multi-index models (MIMs), where the label depends on the input $\\boldsymbol{x} \\in \\mathbb{R}^d$ only through an unknown $\\mathsf{s}$-dimensional projection $\\boldsymbol{W}_*^\\mathsf{T} \\boldsymbol{x} \\in \\mathbb{R}^\\mathsf{s}$. Exploiting the equivariance of this problem under the orthogonal group $\\mathcal{O}_d$, we obtain a sharp harmonic-analytic characterization of the learning complexity for MIMs with spherically symmetric inputs -- which refines and generalizes previous Gaussian-specific analyses. Specifically, we derive statistical and computational complexity lower bounds within the Statistical Query (SQ) and Low-Degree Polynomial (LDP) frameworks. These bounds decompose naturally across spherical harmonic subspaces. Guided by this decomposition, we construct a family of spectral algorithms based on harmonic tensor unfolding that sequentially recover the latent directions and (nearly) achieve these SQ and LDP lower bounds. Depending on the choice of harmonic degree sequence, these estimators can realize a broad range of trade-offs between sample and runtime complexity. From a technical standpoint, our results build on the semisimple decomposition of the $\\mathcal{O}_d$-action on $L^2 (\\mathbb{S}^{d-1})$ and the intertwining isomorphism between spherical harmonics and traceless symmetric tensors."}
{"id": "2602.09659", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.09659", "abs": "https://arxiv.org/abs/2602.09659", "authors": ["Illia Donhauzer"], "title": "Asymptotics of multifractal products of spherical random fields", "comment": null, "summary": "The paper studies multifractal random measures on the sphere $\\mathbb{S}^d$ constructed via multifractal products of random fields. It presents new limit theorems for multifractal products of spherical fields and conditions for the non-degeneracy of the limiting measure. The multifractal properties of the limiting measure are investigated, and its Rényi function is derived. Compared to earlier results on multifractal products of spherical fields, the obtained limit theorems hold under general mixing conditions, enabling the consideration of multifractal products of fields from a broad class and the construction of random measures with flexible multifractal properties."}
{"id": "2602.09265", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09265", "abs": "https://arxiv.org/abs/2602.09265", "authors": ["Thomas Führer", "Gregor Gantner", "Norbert Heuer"], "title": "Boundary elements for clamped Kirchhoff--Love plates", "comment": null, "summary": "We present a Galerkin boundary element method for clamped Kirchhoff--Love plates with piecewise smooth boundary. It is a direct method based on the representation formula and requires the inversion of the single-layer operator and an application of the double-layer operator to the Dirichlet data. We present trace approximation spaces of arbitrary order, required for both the Dirichlet data and the unknown Neumann trace. Our boundary element method is quasi-optimal with respect to the natural trace norm\n  and achieves optimal convergence order under minimal regularity assumptions. We provide explicit representations of both boundary integral operators and discuss the implementation of the appearing integrals. Numerical experiments for smooth and non-smooth domains confirm predicted convergence rates."}
{"id": "2602.09527", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09527", "abs": "https://arxiv.org/abs/2602.09527", "authors": ["Evangelos Papoutsellis", "Zeljko Kereta", "Kostas Papafitsoros"], "title": "Split, Skip and Play: Variance-Reduced ProxSkip for Tomography Reconstruction is Extremely Fast", "comment": null, "summary": "Many modern iterative solvers for large-scale tomographic reconstruction incur two major computational costs per iteration: expensive forward/adjoint projections to update the data fidelity term and costly proximal computations for the regulariser, often done via inner iterations. This paper studies for the first time the application of methods that couple randomised skipping of the proximal with variance-reduced subset-based optimisation of data-fit term, to simultaneously reduce both costs in challenging tomographic reconstruction tasks. We provide a series of experiments using both synthetic and real data, demonstrating striking speed-ups of the order 5x--20x compared to the non-skipped counterparts which have been so far the standard approach for efficiently solving these problems. Our work lays the groundwork for broader adoption of these methods in inverse problems."}
{"id": "2602.10055", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.10055", "abs": "https://arxiv.org/abs/2602.10055", "authors": ["Mingao Yuan"], "title": "The weak law of large numbers for the friendship paradox index", "comment": null, "summary": "The friendship paradox index is a network summary statistic used to quantify the friendship paradox, which describes the tendency for an individual's friends to have more friends than the individual. In this paper, we utilize Markov's inequality to derive the weak law of large numbers for the friendship paradox index in a random geometric graph, a widely-used model for networks with spatial dependence and geometry. For uniform random geometric graph, where the nodes are uniformly distributed in a space, the friendship paradox index is asymptotically equal to $1/4$. On the contrary, in nonuniform random geometric graphs, the nonuniform node distribution leads to distinct limiting properties for the index. In the relatively sparse regime, the friendship paradox index is still asymptotically equal to $1/4$, the same as in the uniform case. In the intermediate sparse regime, however, the index converges in probability to $1/4$ plus a constant that is explicitly dependent on the node distribution. Finally, in the relatively dense case, the index diverges to infinity as the graph size increases. Our results highlight the sharp contrast between the uniform case and its nonuniform counterpart."}
{"id": "2602.09676", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.09676", "abs": "https://arxiv.org/abs/2602.09676", "authors": ["Michel Mandjes", "Daniël Rutgers", "Werner Scheinhardt"], "title": "Exact analysis of transient behavior of finite-capacity MAP-driven queues", "comment": null, "summary": "This paper studies the workload distribution of a finite-capacity queue driven by a spectrally one-sided Markov additive process (MAP). Our main result provides the Laplace-Stieltjes transform of the workload at an exponentially distributed time, thereby uniquely characterizing its transient distribution. The proposed approach combines several decompositions with established fluctuation-theoretic results for spectrally one-sided Lévy processes. For the special case of Markov-modulated compound Poisson input, we additionally derive results for the idle time and the cumulative amount of lost work. We conclude this paper with a series of numerical experiments."}
{"id": "2602.09505", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09505", "abs": "https://arxiv.org/abs/2602.09505", "authors": ["Martin Sæbye Carøe", "Mirza Karamehmedović", "Pierre Maréchal"], "title": "Interpolating between Tikhonov regularization and spectral cutoff", "comment": null, "summary": "Regularizing a linear ill-posed operator equation can be achieved by manipulating the spectrum of the operator's pseudo-inverse. Tikhonov regularization and spectral cutoff are well-known techniques within this category. This paper introduces an interpolating formula that defines a one-parameter family of regularizations, where Tikhonov and spectral cutoff methods are represented as limiting cases. By adjusting the interpolating parameter taking into account the specific operator equation under consideration, it is possible to mitigate the limitations associated with both Tikhonov and spectral cutoff regularizations. The proposed approach is demonstrated through numerical simulations in the fields of signal and image processing."}
{"id": "2602.09560", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09560", "abs": "https://arxiv.org/abs/2602.09560", "authors": ["Nguyen Nang Thieu", "Nguyen Dong Yen"], "title": "Optimization Problems with Nearly Convex Objective Functions and Nearly Convex Constraint Sets", "comment": null, "summary": "To every nearly convex optimization problem, that is a minimization problem with a nearly convex objective function and a nearly convex constraint set, we associate a uniquely defined convex optimization problem with a lower semicontinuous objective function and a closed constraint set. Interesting relationships between the original nearly convex problem and the associated convex problem are established. Optimality conditions in the form of Fermat's rules are obtained for both problems. We then get a Lagrange multiplier rule for a nearly convex optimization problem under a geometrical constraint and functional constraints from the Kuhn-Tucker conditions for the associated convex optimization problem. The obtained results are illustrated by concrete examples."}
{"id": "2602.10103", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.10103", "abs": "https://arxiv.org/abs/2602.10103", "authors": ["Frédéric Ouimet"], "title": "Minimax properties of gamma kernel density estimators under $L^p$ loss and $β$-Hölder smoothness of the target", "comment": "32 pages, 3 figures", "summary": "This paper considers the asymptotic behavior in $β$-Hölder spaces, and under $L^p$ loss, of the gamma kernel density estimator introduced by Chen [Ann. Inst. Statist. Math. 52 (2000), 471-480] for the analysis of nonnegative data, when the target's support is assumed to be upper bounded. It is shown that this estimator can achieve the minimax rate asymptotically for a suitable choice of bandwidth whenever $(p,β)\\in [1,3)\\times(0,2]$ or $(p,β)\\in [3,4)\\times ((p-3)/(p-2),2]$. It is also shown that this estimator cannot be minimax when either $p\\in [4,\\infty)$ or $β\\in (2,\\infty)$."}
{"id": "2602.09859", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.09859", "abs": "https://arxiv.org/abs/2602.09859", "authors": ["Duncan Dauvergne", "Oliver Scott Pankratz"], "title": "Geodesic networks and the disjointness gap in the directed landscape", "comment": "52 pages, 9 figures", "summary": "The directed landscape is a random directed metric on the plane that arises as the scaling limit of metric models in the KPZ universality class. For a pair of points p, q, the disjointness gap G(p; q) measures the shortfall when we optimize length over pairs of disjoint paths from p to q versus optimizing over all pairs of paths. Any spatial marginal of G is simply the gap between the top two lines in an Airy line ensemble. In this paper, we show that when the start and end time are fixed, the disjointness gap fully encodes the set of exceptional geodesic networks. The correspondence uses simple features of the disjointness gap, e.g. zeroes, local minima. We give a similar correspondence relating semi-infinite geodesic networks to a Busemann gap function. The proofs are deterministic given a list of soft properties related to the coalescent geometry of the directed landscape."}
{"id": "2602.09539", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09539", "abs": "https://arxiv.org/abs/2602.09539", "authors": ["Susana Lopez-Moreno", "June-Ho Lee", "Taehyeong Kim"], "title": "Tensor CUR Decomposition under the Linear-Map-Based Tensor-Tensor Multiplication", "comment": "6 pages, 1 figure, 2 tables", "summary": "The factorization of three-dimensional data continues to gain attention due to its relevance in representing and compressing large-scale datasets. The linear-map-based tensor-tensor multiplication is a matrix-mimetic operation that extends the notion of matrix multiplication to higher order tensors, and which is a generalization of the T-product. Under this framework, we introduce the tensor CUR decomposition, show its performance in video foreground-background separation for different linear maps and compare it to a robust matrix CUR decomposition, another tensor approximation and the slice-based singular value decomposition (SS-SVD). We also provide a theoretical analysis of our tensor CUR decomposition, extending classical matrix results to establish exactness conditions and perturbation bounds."}
{"id": "2602.09671", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09671", "abs": "https://arxiv.org/abs/2602.09671", "authors": ["Yongchun Bi", "Jun Zheng", "Guchuan Zhu"], "title": "Input-to-state stabilization of an ODE cascaded with a parabolic equation involving Dirichlet-Robin boundary disturbances", "comment": null, "summary": "This paper focuses on the input-to-state stabilization problem for an ordinary differential equation (ODE) cascaded by parabolic partial differential equation (PDE) in the presence of Dirichlet-Robin boundary disturbances, as well as in-domain disturbances. For the cascaded system with a Dirichlet pointwise interconnection, the ODE takes the value of a Robin boundary condition at the ODE-PDE interface as its direct input, and the PDE is driven by a Dirichlet boundary input at the opposite end. We first employ the backstepping method to design a boundary controller and to decouple the cascaded system. This decoupling facilitates independent stability analysis of the PDE and ODE systems sequentially. Then, to address the challenges posed by Dirichlet boundary disturbances to the application of the classical Lyapunov method, we utilize the generalized Lyapunov method to establish the ISS in the max-norm for the cascaded system involving Dirichlet boundary disturbances and two other types of disturbances. The obtained result indicates that even in the presence of different types of disturbances, ISS analysis can still be conducted within the framework of Lyapunov stability theory. For the well-posedness of the target system, it is conducted by using the technique of lifting and the semigroup method. Finally, numerical simulations are conducted to illustrate the effectiveness of the proposed control scheme and ISS properties for a cascaded system with different disturbances."}
{"id": "2602.09643", "categories": ["math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.09643", "abs": "https://arxiv.org/abs/2602.09643", "authors": ["Nils Lid Hjort"], "title": "A simple proof of the discreteness of Dirichlet processes", "comment": "Based on pages 18-19 in N.L. Hjort's graduate thesis, 1976", "summary": "That Dirichlet processes are discrete with probability 1 is demonstrated once more. And yes, these two pages spent fifty years in Norwegian."}
{"id": "2602.09922", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2602.09922", "abs": "https://arxiv.org/abs/2602.09922", "authors": ["Alexander Kalinin"], "title": "Stochastic Volterra equations with random functional coefficients in Banach spaces", "comment": null, "summary": "We derive unique Banach-valued solutions to stochastic Volterra equations with random coefficients that may depend on pure chance and involve singular kernels. In particular, for controlled and distribution-dependent coefficients these solutions become strong, as a measurability analysis of the Wasserstein metric confirms. The presented novel approach is based on the proof that a stochastic Volterra integral admits a progressively measurable modification in a weak sense and on sharp moment estimates for non-negative product measurable processes."}
{"id": "2602.09626", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09626", "abs": "https://arxiv.org/abs/2602.09626", "authors": ["Daniele A. Di Pietro", "Jerome Droniou", "Vito Patierno"], "title": "A Reynolds- and Hartmann-semirobust hybrid method for magnetohydrodynamics", "comment": null, "summary": "We propose and analyze a new method for the unsteady incompressible magnetohydrodynamics equations on convex domains with hybrid approximations of both vector-valued and scalar-valued fields. The proposed method is convection-semirobust, meaning that, for sufficiently smooth solutions, one can derive a priori estimates for the velocity and the magnetic field that do not depend on the inverse of the diffusion coefficients. This is achieved while at the same time providing relevant additional features, namely an improved order of convergence for the (asymptotic) diffusion-dominated regime, a small stencil (owing to the absence of inter-element penalty terms), and the possibility to significantly reduce the size of the algebraic problems through static condensation. The theoretical results are confirmed by a complete panel of numerical experiments."}
{"id": "2602.09679", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09679", "abs": "https://arxiv.org/abs/2602.09679", "authors": ["Chang Qin", "Yikun Li", "Ru Qian", "Jiayi Kang", "Yao Mao"], "title": "Real time filtering algorithms", "comment": "31 pages", "summary": "This paper presents a systematic review of recent advances in nonlinear filtering algorithms, structured into three principal categories: Kalman-type methods, Monte Carlo methods, and the Yau-Yau algorithm. For each category, we provide a comprehensive synthesis of theoretical developments, algorithmic variants, and practical applications that have emerged in recent years. Importantly, this review addresses both continuous-time and discrete-time system formulations, offering a unified review of filtering methodologies across different frameworks. Furthermore, our analysis reveals the transformative influence of artificial intelligence breakthroughs on the entire nonlinear filtering field, particularly in areas such as learning-based filters, neural network-augmented algorithms, and data-driven approaches."}
{"id": "2602.09240", "categories": ["math.ST", "cs.IT", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.09240", "abs": "https://arxiv.org/abs/2602.09240", "authors": ["Yihan Zhang", "Hong Chang Ji", "Ramji Venkataramanan", "Marco Mondelli"], "title": "Optimal Estimation in Orthogonally Invariant Generalized Linear Models: Spectral Initialization and Approximate Message Passing", "comment": null, "summary": "We consider the problem of parameter estimation from a generalized linear model with a random design matrix that is orthogonally invariant in law. Such a model allows the design have an arbitrary distribution of singular values and only assumes that its singular vectors are generic. It is a vast generalization of the i.i.d. Gaussian design typically considered in the theoretical literature, and is motivated by the fact that real data often have a complex correlation structure so that methods relying on i.i.d. assumptions can be highly suboptimal. Building on the paradigm of spectrally-initialized iterative optimization, this paper proposes optimal spectral estimators and combines them with an approximate message passing (AMP) algorithm, establishing rigorous performance guarantees for these two algorithmic steps. Both the spectral initialization and the subsequent AMP meet existing conjectures on the fundamental limits to estimation -- the former on the optimal sample complexity for efficient weak recovery, and the latter on the optimal errors. Numerical experiments suggest the effectiveness of our methods and accuracy of our theory beyond orthogonally invariant data."}
{"id": "2602.09650", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09650", "abs": "https://arxiv.org/abs/2602.09650", "authors": ["Majid Rajabzadeh", "Moein Khalighi"], "title": "LDG method for solving spatial and temporal fractional nonlinear convection-diffusion equations", "comment": null, "summary": "This paper focuses on a nonlinear convection-diffusion equation with space and time-fractional Laplacian operators of orders $1<β<2$ and $0<α\\leq1$, respectively. We develop local discontinuous Galerkin methods, including Legendre basis functions, for a solution to this class of fractional diffusion problem, and prove stability and optimal order of convergence $O(h^{k+1}+(Δt)^{1+\\frac{p}{2}}+p^2)$. This technique turns the equation into a system of first-order equations and approximates the solution by selecting the appropriate basis functions. Regarding accuracy and stability, the basis functions greatly improve the method. According to the numerical results, the proposed scheme performs efficiently and accurately in various conditions and meets the optimal order of convergence."}
{"id": "2602.09748", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09748", "abs": "https://arxiv.org/abs/2602.09748", "authors": ["Daan Otto", "Jannis Kurtz", "Dick den Hertog", "Ilker Birbil"], "title": "Linear Model Extraction via Factual and Counterfactual Queries", "comment": null, "summary": "In model extraction attacks, the goal is to reveal the parameters of a black-box machine learning model by querying the model for a selected set of data points. Due to an increasing demand for explanations, this may involve counterfactual queries besides the typically considered factual queries. In this work, we consider linear models and three types of queries: factual, counterfactual, and robust counterfactual. First, for an arbitrary set of queries, we derive novel mathematical formulations for the classification regions for which the decision of the unknown model is known, without recovering any of the model parameters. Second, we derive bounds on the number of queries needed to extract the model's parameters for (robust) counterfactual queries under arbitrary norm-based distances. We show that the full model can be recovered using just a single counterfactual query when differentiable distance measures are employed. In contrast, when using polyhedral distances for instance, the number of required queries grows linearly with the dimension of the data space. For robust counterfactuals, the latter number of queries doubles. Consequently, the applied distance function and robustness of counterfactuals have a significant impact on the model's security."}
{"id": "2602.09854", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.09854", "abs": "https://arxiv.org/abs/2602.09854", "authors": ["Xinjie Dai", "Diancong Jin", "Jiaoyang Xu"], "title": "Asymptotic error distribution for tamed Euler method with coupled monotonicity condition", "comment": null, "summary": "This paper establishes the asymptotic error distribution of the tamed Euler method for stochastic differential equations (SDEs) with a coupled monotonicity condition, that is, the limit distribution of the corresponding normalized error process. Specifically, for SDEs driven by multiplicative noise, we first propose a tamed Euler method parameterized by $α\\in (0, 1]$ and establish that its strong convergence rate is $α\\wedge\\frac{1}{2}$. Notably, $α$ can take arbitrary positive values by adjusting the regularization coefficient without altering the strong convergence rate. We then derive the asymptotic error distribution for this tamed Euler method. Further, we infer from the limit equation that among the tamed Euler method of strong order $\\frac{1}{2}$, the one with $α= \\frac{1}{2}$ yields the largest mean-square error after a long time, while those of $α>\\frac{1}{2}$ share a unified asymptotic error distribution. In addition, our analysis is also extended to SDEs with additive noise and similar conclusions are obtained. Additional treatments are required to accommodate super-linearly growing coefficients, a feature that distinguishes our analysis on the asymptotic error distribution from established results."}
{"id": "2602.09729", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.09729", "abs": "https://arxiv.org/abs/2602.09729", "authors": ["Chaoyi Cai", "Qiqin Cheng", "Di Wu", "Jianxian Qiu"], "title": "Beyond Free-Stream Preservation: Transport Polynomial Exactness for Moving-Mesh Methods under Arbitrary Mesh Motion", "comment": null, "summary": "High-order moving-mesh methods can effectively reduce numerical diffusion, but their formal accuracy typically relies on the regularity of the mesh velocity. This dependency creates a fundamental conflict in the numerical solution of hyperbolic conservation laws, where solution-driven adaptation may induce nonsmooth mesh motion, thereby degrading convergence order. We introduce \\emph{transport polynomial exactness} (TPE($k$)), a mesh-motion-independent criterion that generalizes classical free-stream preservation (TPE(0)) to the exact advection of degree-$k$ polynomials. We show that the classical geometric conservation law (GCL) is insufficient to ensure TPE($k$) for $k \\ge 1$ due to mismatches in higher-order geometric moments. To resolve this, we propose \\emph{evolved geometric moments} (EGMs), obtained by solving auxiliary transport equations discretized compatibly with the physical variables. We rigorously prove that second-degree EGMs evolved via the third-order strong stability preserving Runge--Kutta (SSPRK3) method coincide with the exact geometric moments. This exactness arises from a \\emph{superconvergence} mechanism wherein SSPRK3 reduces to Simpson's rule for EGM evolution. Leveraging this result, we construct a third-order conservative finite-volume rezoning moving-mesh scheme. The scheme satisfies the TPE(2) property for \\emph{arbitrary mesh motion} and \\emph{any pseudo-time step size}, thereby naturally accommodating spatiotemporally discontinuous mesh velocity. Crucially, this \\emph{breaks the efficiency bottleneck} in the conventional advection-based remapping step and reduces the required pseudo-time levels from $\\mathcal{O}(h^{-1})$ to $\\mathcal{O}(1)$ under bounded but discontinuous mesh velocity. Numerical experiments verify exact quadratic transport and stable third-order convergence under extreme mesh deformation, demonstrating substantial efficiency gains."}
{"id": "2602.09840", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09840", "abs": "https://arxiv.org/abs/2602.09840", "authors": ["Hongye Wang", "Chang He", "Bo Jiang"], "title": "Adaptive Single-Loop Methods for Stochastic Minimax Optimization on Riemannian Manifolds", "comment": null, "summary": "Stochastic minimax optimization on Riemannian manifolds has recently attracted significant attention due to its broad range of applications, such as robust training of neural networks and robust maximum likelihood estimation. Existing optimization methods for these problems typically require selecting stepsizes based on prior knowledge of specific problem parameters, such as Lipschitz-type constants and (geodesic) strong concavity constants. Unfortunately, these parameters are often unknown in practice. To overcome this issue, we develop single-loop adaptive methods that automatically adjust stepsizes using cumulative Riemannian (stochastic) gradient norms. We first propose a deterministic single-loop Riemannian adaptive gradient descent ascent method and show that it attains an $ε$-stationary point within $O(ε^{-2})$ iterations. This deterministic method is of independent interest and lays the foundation for our subsequent stochastic method. In particular, we propose the Riemannian stochastic adaptive gradient descent ascent method, which finds an $ε$-stationary point in $O(ε^{-6})$ iterations. Under additional second-order smoothness, this iteration complexity is further improved to $O(ε^{-4})$, which even outperforms the corresponding complexity result in Euclidean space. Some numerical experiments on real-world applications are conducted, including the regularized robust maximum likelihood estimation problem, and the robust training of neural networks with orthonormal weights. The results are encouraging and demonstrate the effectiveness of adaptivity in practice."}
{"id": "2602.10103", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.10103", "abs": "https://arxiv.org/abs/2602.10103", "authors": ["Frédéric Ouimet"], "title": "Minimax properties of gamma kernel density estimators under $L^p$ loss and $β$-Hölder smoothness of the target", "comment": "32 pages, 3 figures", "summary": "This paper considers the asymptotic behavior in $β$-Hölder spaces, and under $L^p$ loss, of the gamma kernel density estimator introduced by Chen [Ann. Inst. Statist. Math. 52 (2000), 471-480] for the analysis of nonnegative data, when the target's support is assumed to be upper bounded. It is shown that this estimator can achieve the minimax rate asymptotically for a suitable choice of bandwidth whenever $(p,β)\\in [1,3)\\times(0,2]$ or $(p,β)\\in [3,4)\\times ((p-3)/(p-2),2]$. It is also shown that this estimator cannot be minimax when either $p\\in [4,\\infty)$ or $β\\in (2,\\infty)$."}
{"id": "2602.09854", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.09854", "abs": "https://arxiv.org/abs/2602.09854", "authors": ["Xinjie Dai", "Diancong Jin", "Jiaoyang Xu"], "title": "Asymptotic error distribution for tamed Euler method with coupled monotonicity condition", "comment": null, "summary": "This paper establishes the asymptotic error distribution of the tamed Euler method for stochastic differential equations (SDEs) with a coupled monotonicity condition, that is, the limit distribution of the corresponding normalized error process. Specifically, for SDEs driven by multiplicative noise, we first propose a tamed Euler method parameterized by $α\\in (0, 1]$ and establish that its strong convergence rate is $α\\wedge\\frac{1}{2}$. Notably, $α$ can take arbitrary positive values by adjusting the regularization coefficient without altering the strong convergence rate. We then derive the asymptotic error distribution for this tamed Euler method. Further, we infer from the limit equation that among the tamed Euler method of strong order $\\frac{1}{2}$, the one with $α= \\frac{1}{2}$ yields the largest mean-square error after a long time, while those of $α>\\frac{1}{2}$ share a unified asymptotic error distribution. In addition, our analysis is also extended to SDEs with additive noise and similar conclusions are obtained. Additional treatments are required to accommodate super-linearly growing coefficients, a feature that distinguishes our analysis on the asymptotic error distribution from established results."}
{"id": "2602.09842", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09842", "abs": "https://arxiv.org/abs/2602.09842", "authors": ["Fabian Schaipp", "Robert M. Gower", "Adrien Taylor"], "title": "Step-Size Stability in Stochastic Optimization: A Theoretical Perspective", "comment": null, "summary": "We present a theoretical analysis of stochastic optimization methods in terms of their sensitivity with respect to the step size. We identify a key quantity that, for each method, describes how the performance degrades as the step size becomes too large. For convex problems, we show that this quantity directly impacts the suboptimality bound of the method. Most importantly, our analysis provides direct theoretical evidence that adaptive step-size methods, such as SPS or NGN, are more robust than SGD. This allows us to quantify the advantage of these adaptive methods beyond empirical evaluation. Finally, we show through experiments that our theoretical bound qualitatively mirrors the actual performance as a function of the step size, even for nonconvex problems."}
{"id": "2602.09762", "categories": ["math.ST", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.09762", "abs": "https://arxiv.org/abs/2602.09762", "authors": ["Kensuke Aishima"], "title": "Asymptotic analysis of the Gaussian kernel matrix for partially noisy data in high dimensions", "comment": null, "summary": "The Gaussian kernel is one of the most important kernels, applicable to many research fields, including scientific computing and data science. In this paper, we present asymptotic analysis of the Gaussian kernel matrix in high dimension under a statistical model of noisy data. The main result is a nice combination of Karoui's asymptotic analysis with procedures of constrained low rank matrix approximations. More specifically, Karouli clarified an important asymptotic structure of the Gaussian kernel matrix, leading to strong consistency of the eigenvectors, though the eigenvalues are inconsistent. This paper focuses on the above results and presents a consistent estimator with the use of the smallest eigenvalue, whenever the target kernel matrix tends to low rank in the asymptotic regime. Importantly, asymptotic analysis is given under a statistical model representing partial noise. Although a naive estimator is inconsistent, applying an optimization method for low rank approximations with constraints, we overcome the difficulty caused by the inconsistency, resulting in a new estimator with strong consistency in rank deficient cases."}
{"id": "2602.09926", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09926", "abs": "https://arxiv.org/abs/2602.09926", "authors": ["Fielbaum Andrés", "Cominetti Roberto", "Correa José"], "title": "The Increasing Gap Dynamics in a General Spatial Matching Model", "comment": null, "summary": "We study a representation of a problem that appears in numerous transport systems: $N$ servers distributed over a given space (e.g., cars on an urban network), receive random requests from arriving users who get assigned to the closest server, after which this server is replaced by a new one at a random location. We show that this creates a negative feedback loop, which we call \\textit{Increasing Gap Dynamics} (IGD): when a server is assigned a spatial gap forms, which is more likely to attract new users that further widen the gap. The simplest version of our model is a one-dimensional circle, for which we derive analytical results showing that the system converges to an inefficient equilibrium, worse than both balanced and fully random distributions of servers. We prove that an optimal assignment policy always matches the user to one of its two neighbouring servers so that long gaps tend to widen. Hence, the IGD persists even when assigning optimally rather than greedily. In two dimensions, the appearance of the IGD is illustrated through simulations on a square region. Finally, simulations of a proper ride-hailing system using real data from Manhattan confirms that the IGD arises and that it is responsible for the appearance of the well-known Wild Goose Chase."}
{"id": "2602.09928", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.09928", "abs": "https://arxiv.org/abs/2602.09928", "authors": ["Giannis Delimpaltadakis", "Pol Mestres", "Jorge Cortés", "W. P. M. H. Heemels"], "title": "Safe Feedback Optimization through Control Barrier Functions", "comment": null, "summary": "Feedback optimization refers to a class of methods that steer a control system to a steady state that solves an optimization problem. Despite tremendous progress on the topic, an important problem remains open: enforcing state constraints at all times. The difficulty in addressing it lies on mediating between the safety enforcement and the closed-loop stability, and ensuring the equivalence between closed-loop equilibria and the optimization problem's critical points. In this work, we present a feedback-optimization method that enforces state constraints at all times employing high-order control-barrier functions. We provide several results on the proposed controller dynamics, including well-posedness, safety guarantees, equivalence between equilibria and critical points, and local and global (in certain convex cases) asymptotic stability of optima. Various simulations illustrate our results."}
{"id": "2602.09996", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.09996", "abs": "https://arxiv.org/abs/2602.09996", "authors": ["Timo Berthold", "Fritz Geis"], "title": "Learning to Choose Branching Rules for Nonconvex MINLPs", "comment": null, "summary": "Outer-approximation-based branch-and-bound is a common algorithmic framework for solving MINLPs (mixed-integer nonlinear programs) to global optimality, with branching variable selection critically influencing overall performance. In modern global MINLP solvers, it is unclear whether branching on fractional integer variables should be prioritized over spatial branching on variables, potentially continuous, that show constraint violations, with different solvers following different defaults. We address this question using a data-driven approach. Based on a test set of hundreds of heterogeneous public and industrial MINLP instances, we train linear and random forest regression models to predict the relative speedup of the FICO(R) Xpress Global solver when using a branching rule that always prioritizes variables with violated integralities versus a mixed rule, allowing for early spatial branches.\n  We introduce a practical evaluation methodology that measures the effect of the learned model directly in terms of the shifted geometric mean runtime. Using only four features derived from strong branching and the nonlinear structure, our linear regression model achieves an 8-9% reduction in geometric-mean solving time for the Xpress solver, with over 10% improvement on hard instances. We also analyze a random regression forest model. Experiments across solver versions show that a model trained on Xpress 9.6 still yields significant improvements on Xpress 9.8 without retraining.\n  Our results demonstrate how regression models can successfully guide the branching-rule selection and improve the performance of a state-of-the-art commercial MINLP solver."}
{"id": "2602.10022", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.10022", "abs": "https://arxiv.org/abs/2602.10022", "authors": ["Julien Hermant"], "title": "Acceleration for Polyak-Łojasiewicz Functions with a Gradient Aiming Condition", "comment": null, "summary": "It is known that when minimizing smooth Polyak-Łojasiewicz (PL) functions, momentum algorithms cannot significantly improve the convergence bound of gradient descent, contrasting with the acceleration phenomenon occurring in the strongly convex case. To bridge this gap, the literature has proposed strongly quasar-convex functions as an intermediate non-convex class, for which accelerated bounds have been suggested to persist. We show that this is not true in general: the additional structure of strong quasar-convexity does not suffice to guaranty better worst-case bounds for momentum compared to gradient descent. As an alternative, we study PL functions under an aiming condition that measures how well the descent direction points toward a minimizer. This perspective clarifies the geometric ingredient enabling provable acceleration by momentum when minimizing PL functions."}
{"id": "2602.09057", "categories": ["math.NA", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.09057", "abs": "https://arxiv.org/abs/2602.09057", "authors": ["Zhipeng Chang", "Wenrui Hao", "Nian Liu"], "title": "SVD-Preconditioned Gradient Descent Method for Solving Nonlinear Least Squares Problems", "comment": null, "summary": "This paper introduces a novel optimization algorithm designed for nonlinear least-squares problems. The method is derived by preconditioning the gradient descent direction using the Singular Value Decomposition (SVD) of the Jacobian. This SVD-based preconditioner is then integrated with the first- and second-moment adaptive learning rate mechanism of the Adam optimizer. We establish the local linear convergence of the proposed method under standard regularity assumptions and prove global convergence for a modified version of the algorithm under suitable conditions. The effectiveness of the approach is demonstrated experimentally across a range of tasks, including function approximation, partial differential equation (PDE) solving, and image classification on the CIFAR-10 dataset. Results show that the proposed method consistently outperforms standard Adam, achieving faster convergence and lower error in both regression and classification settings."}
