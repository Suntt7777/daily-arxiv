{"id": "2512.13863", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.13863", "abs": "https://arxiv.org/abs/2512.13863", "authors": ["Alex L. Wang"], "title": "Optimal Subgradient Methods for Lipschitz Convex Optimization with Error Bounds", "comment": null, "summary": "We study the iteration complexity of Lipschitz convex optimization problems satisfying a general error bound. We show that for this class of problems, subgradient descent with either Polyak stepsizes or decaying stepsizes achieves minimax optimal convergence guarantees for decreasing distance-to-optimality. The main contribution is a novel lower-bounding argument that produces hard functions simultaneously satisfying zero-chain conditions and global error bounds."}
{"id": "2512.13920", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.13920", "abs": "https://arxiv.org/abs/2512.13920", "authors": ["Haoyuan Cai", "Sulaiman A. Alghunaim", "Ali H. Sayed"], "title": "DAMA: A Unified Accelerated Approach for Decentralized Nonconvex Minimax Optimization-Part I: Algorithm Development and Results", "comment": null, "summary": "In this work and its accompanying Part II [1], we develop an accelerated algorithmic framework, DAMA (Decentralized Accelerated Minimax Approach), for nonconvex Polyak-Lojasiewicz minimax optimization over decentralized multi-agent networks. Our approach integrates online and offline stochastic minimax algorithms with various decentralized learning strategies, yielding a versatile framework with broader flexibility than existing methods. Our unification is threefold: (i) we propose a unified decentralized learning strategy for minimax optimization that subsumes existing bias-correction techniques, such as gradient tracking, while introducing new variants that achieve tighter network-dependent bounds; (ii) we introduce a probabilistic gradient estimator, GRACE (Gradient Acceleration Estimator), which unifies momentum-based methods and loopless variance-reduction techniques for constructing accelerated gradients within DAMA, and is broadly applicable to general stochastic optimization problems; and (iii) we develop a unified analytical framework that establishes a general performance bound for DAMA, achieving state-of-the-art results with the best-known sample complexity. To the best of our knowledge, DAMA is the first framework to achieve a multi-level unification of decentralized learning strategies and accelerated gradient techniques. This work focuses on algorithm development and the main results, while Part II provides the theoretical analysis that substantiates these results and presents empirical validation across diverse network topologies using synthetic and real-world datasets."}
{"id": "2512.13923", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.13923", "abs": "https://arxiv.org/abs/2512.13923", "authors": ["Haoyuan Cai", "Sulaiman A. Alghunaim", "Ali H. Sayed"], "title": "DAMA: A Unified Accelerated Approach for Decentralized Nonconvex Minimax Optimization-Part II: Convergence and Performance Analyses", "comment": null, "summary": "In Part I of this work [1], we developed an accelerated algorithmic framework, DAMA (Decentralized Accelerated Minimax Approach), for nonconvex Polyak-Lojasiewicz (PL) minimax optimization over decentralized multi-agent networks. To further enhance convergence in online and offline scenarios, Part I of this work [1] also proposed a novel accelerated gradient estimator, namely, GRACE (GRadient ACceleration Estimator), which unifies several momentum-based methods (e.g., STORM) and loopless variance-reduction techniques (e.g., PAGE, Loopless SARAH), thereby enabling accelerated gradient updates within DAMA. Part I reported a unified performance bound for DAMA and refined guarantees for specific algorithmic instances, demonstrating the superior performance of several new variants on sparsely connected networks. In this Part II, we focus on the convergence and performance bounds that substantiate the main results presented in Part I [1]. In particular, we establish a unified performance bound for DAMA using the transformed recursion derived in Part I and subsequently refine this bound for its various special cases."}
{"id": "2512.13964", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.13964", "abs": "https://arxiv.org/abs/2512.13964", "authors": ["Lillian Makhoul", "Emily Speakman"], "title": "Volume Formulae for the Convex Hull of the Graph of a Trilinear Monomial: A Complete Characterization for General Box Domains", "comment": null, "summary": "Solving difficult mixed-integer nonlinear programs via spatial branch-and-bound requires effective convex outer-approximations of nonconvex sets. In this framework, complex problem formulations are decomposed into simpler library functions, whose relaxations are then composed to build relaxations of the overall problem. The trilinear monomial serves as one such fundamental library function, appearing frequently as a building block across diverse applications. By definition, its convex hull provides the tightest possible relaxation and thus serves as a benchmark for evaluating alternatives. Mixed volume techniques have yielded a parameterized volume formula for the convex hull of the graph of a trilinear monomial; however, existing results only address the case where all six bounds of the box domain are nonnegative. This restriction represents a notable gap in the literature, as variables with mixed-sign domains arise naturally in practice. In this work, we close the gap by extending to the general case via an exhaustive case analysis. We demonstrate that removing the nonnegative domain assumption alters the underlying structure of the convex hull polytope, leading to six distinct volume formulae that together characterize all possible parameter configurations."}
{"id": "2512.13928", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.13928", "abs": "https://arxiv.org/abs/2512.13928", "authors": ["Jakub Ślęzak"], "title": "Codifference as a measure of dispersion and dependence for mixture models", "comment": "23 pages, 4 figures", "summary": "Codifference is a commonly used measure of dependence for stable vectors and processes for which covariance is infinite. However, we argue that it can also be used for other heavy-tail distributions and it provides useful information for other non-Gaussian distributions as well, no matter the tails. Motivated by this, we analyse codifference using as little assumptions as possible about the studied model. It leads us to propose its natural domain and three natural variants of it. Using the wide class of variable scale mixture distributions we argue that the codifference can be interpreted as the measure of bulk properties which ignores the tails much more than the covariance. It can also detect forms of non-linear memory which covariance cannot. Finally, we show the asymptotic distribution of its estimator."}
{"id": "2512.13829", "categories": ["math.PR", "math.DS", "math.FA", "math.GR"], "pdf": "https://arxiv.org/pdf/2512.13829", "abs": "https://arxiv.org/abs/2512.13829", "authors": ["Nicolas Monod"], "title": "Conditional means, vector pricings, amenability and fixed points in cones", "comment": null, "summary": "We study a generalization of conditional probability for arbitrary ordered vector spaces. A related problem is that of assigning a numerical value to one vector relative to another.\n  We characterize the groups for which these generalized probabilities can be stationary, respectively invariant. This leads to a new criterion for amenability and for fixed points in cones."}
{"id": "2512.13740", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.13740", "abs": "https://arxiv.org/abs/2512.13740", "authors": ["Álvaro Fernández Corral", "Yahya Saleh"], "title": "Enhancing polynomial approximation of continuous functions by composition with homeomorphisms", "comment": null, "summary": "We enhance the approximation capabilities of algebraic polynomials by composing them with homeomorphisms. This composition yields families of functions that remain dense in the space of continuous functions, while enabling more accurate approximations. For univariate continuous functions exhibiting a finite number of local extrema, we prove that there exist a polynomial of finite degree and a homeomorphism whose composition approximates the target function to arbitrary accuracy. The construction is especially relevant for multivariate approximation problems, where standard numerical methods often suffer from the curse of dimensionality. To support our theoretical results, we investigate both regression tasks and the construction of molecular potential-energy surfaces, parametrizing the underlying homeomorphism using invertible neural networks. The numerical experiments show strong agreement with our theoretical analysis."}
{"id": "2512.14124", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.14124", "abs": "https://arxiv.org/abs/2512.14124", "authors": ["Boris S. Mordukhovich", "Peipei Tang", "Chengjing Wang"], "title": "Complete Characterizations of Well-Posedness in Parametric Composite Optimization", "comment": null, "summary": "This paper provides complete characterization of well-posedness for Karush-Kuhn-Tucker (KKT) systems associated with general problems of perturbed composite optimization. Leveraging the property of parabolic regularity for composite models, we show that the second-order subderivative of the cost function reduces to the novel second-order variational function playing a crucial role in the subsequent analysis. This foundational result implies that the strong second-order sufficient condition (SSOSC) introduced in this work for the general class of composite optimization problems naturally extends the classical second-order sufficient condition in nonlinear programming. Then we obtain several equivalent characterizations of the second-order qualification condition (SOQC) and highlight its equivalence to the constraint nondegeneracy condition under the $\\mathcal{C}^{2}$-cone reducibility assumption. These insights lead us to multiple equivalent conditions for the major Lipschitz-like/Aubin property of KKT systems, including the SOQC combined with the new second-order subdifferential condition and the SOQC combined with tilt stability of local minimizers. Furthermore, under $\\mathcal{C}^{2}$-cone reducibility, we prove that the Lipschitz-like property of the reference KKT system is equivalent to its strong regularity. Finally, we demonstrate that the Lipschitz-like property is equivalent to the nonsingularity of the generalized Jacobian associated with the KKT system under a certain verifiable assumption. These results provide a unified and rigorous framework for analyzing stability and sensitivity of solutions to composite optimization problems, as well as for the design and justification of numerical algorithms."}
{"id": "2512.14062", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.14062", "abs": "https://arxiv.org/abs/2512.14062", "authors": ["Matjaž Omladič", "Martin Vuk", "Aljaž Zalar"], "title": "Extreme Mass Distributions For K-Increasing Quasi-Copulas", "comment": "15 pages, 1 figure", "summary": "The rating of quasi-copula problems in the dependence modeling community has recently risen in spite of the lack of probability interpretation of quasi-copulas. The trendsetting paper J.J. Arias-Garcia, R. Mesiar, and B. De Baets, The unwalked path between quasi-copulas and copulas: Stepping stones in higher dimensions, Internat. J. of Approx. Reasoning, 80 (2017) 89--99, proposes the k-increasing property for some k {\\le} d as a property of d-variate quasi-copulas that would shed some light on what is in-between. This hierarchy of classes extends the bivariate notion of supermodularity property. The same authors propose a number of open problems in the continuation of this paper (Fuzzy Sets and Systems 393 (2020), 1--28). Their Open problem 5 asks for the extreme values of the mass distributions associated with multivariate quasi-copulas and was recently solved by the authors of this paper (Fuzzy Sets and Systems 527 (2026) 109698). The main goal of the present paper is to solve the maximal-volume problem (in absolute value) within each of the previously mentioned subclasses. By formulating and solving suitably simplified primal and dual linear programs, we derive the exact maximal negative and positive masses together with the corresponding extremal boxes."}
{"id": "2512.14021", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.14021", "abs": "https://arxiv.org/abs/2512.14021", "authors": ["Witold M. Bednorz", "Rafał M. Łochowski"], "title": "Concentration of the truncated variation of fractional Brownian motions of any Hurst index, their $1/H$-variations and local times", "comment": null, "summary": "We obtain bounds for probabilities of deviations of the truncated variation functional of fractional Brownian motions (fBm) of any Hurst index $H \\in (0,1)$ from their expected values. Obtained bounds are optimal for large values of deviations up to multiplicative constants depending on the parameter $H$ only. As an application, we give tight bounds for tails of $1/H$-variations of fBm along Lebesgue partitions and establish the a.s. weak convergence (in $L^1$) of normalized numbers of strip crossings by the trajectories of fBm to their local times for any Hurst parameter $H \\in (0,1)$."}
{"id": "2512.13963", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.13963", "abs": "https://arxiv.org/abs/2512.13963", "authors": ["Quincy Huhn", "Jean Ragusa", "Youngsoo Choi"], "title": "Offline Maximizing Minimally Invasive Proper Orthogonal Decomposition for Reduced Order Modeling of $S_n$ Radiation Transport", "comment": null, "summary": "Deterministic solutions to the Sn transport equation can be computationally expensive to calculate. Reduced Order Models (ROMs) provide an efficient means of approximating the Full Order Model (FOM) solution. We propose a novel approach for constructing ROMs of the Sn radiation transport equation, Offline Maximizing Minimally Invasive (OMMI) Proper Orthogonal Decomposition (POD). POD uses snapshot data to build a reduced basis, which is then used to project the FOM. Minimally Invasive POD leverages the sweep infrastructure within deterministic Sn transport solvers to construct the reduced linear system, even though the FOM linear system is never directly assembled. OMMI-POD extends Minimally Invasive POD by performing transport sweeps offline, thereby maximizing the potential speedup. It achieves this by generating a library of reduced systems from a training set, which is then interpolated in the online stage to provide a rapid approximate solution to the Sn transport equation. The model's performance is evaluated on a multigroup 2-D test problem, demonstrating low error and a 1600-fold speedup over the full order model."}
{"id": "2512.14226", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.14226", "abs": "https://arxiv.org/abs/2512.14226", "authors": ["Yixin Tan", "Fang Feng", "Shengfeng Zhu"], "title": "Shape design with phase field methods for structural hemivariational inequalities in contact problems", "comment": null, "summary": "We develop mathematical models for shape design and topology optimization in structural contact problems involving friction between elastic and rigid bodies. The governing mechanical constraint is a nonlinear, non-smooth, and non-convex hemivariational inequality, which provides a more general and realistic description of frictional contact forces than standard variational inequalities, but is also more challenging due to its non-convexity. For energy-type shape functionals, the Eulerian derivative of the hemivariational inequality is derived through rigorous shape sensitivity analysis. The rationality of a regularization approach is justified by asymptotic analysis, and this method is further applied to handle the non-smoothness of general shape functionals in the sensitivity framework. Based on these theoretical results, a numerical boundary variational method is proposed for shape optimization. For topology optimization, three phase-field algorithms are developed: a gradient-flow phase-field method, a phase-field method with second-order regularization of the cost functional, and a phase-field method coupled with topological derivatives. To the best of our knowledge, these approaches are new for shape design in hemivariational inequalities. Various numerical experiments confirm the accuracy and effectiveness of the proposed shape and topology optimization algorithms."}
{"id": "2512.14337", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.14337", "abs": "https://arxiv.org/abs/2512.14337", "authors": ["T. Tony Cai", "Abhinav Chakraborty", "Lasse Vuursteen"], "title": "The Cost of Adaptation under Differential Privacy: Optimal Adaptive Federated Density Estimation", "comment": "Main article is 24 pages, 1 figure, 26 page supplement", "summary": "Privacy-preserving data analysis has become a central challenge in modern statistics. At the same time, a long-standing goal in statistics is the development of adaptive procedures -- methods that achieve near-optimal performance across diverse function classes without prior knowledge of underlying smoothness or complexity. While adaptation is often achievable at no extra cost in the classical non-private setting, this naturally raises a fundamental question: to what extent is adaptation still possible under privacy constraints?\n  We address this question in the context of density estimation under federated differential privacy (FDP), a framework that encompasses both central and local DP models. We establish sharp results that characterize the cost of adaptation under FDP for both global and pointwise estimation, revealing fundamental differences from the non-private case. We then propose an adaptive FDP estimator that achieves explicit performance guarantees by introducing a new noise mechanism, enabling one-shot adaptation via post-processing. This approach strictly improves upon existing adaptive DP methods. Finally, we develop new lower bound techniques that capture the limits of adaptive inference under privacy and may be of independent interest beyond this problem.\n  Our findings reveal a sharp contrast between private and non-private settings. For global estimation, where adaptation can be achieved for free in the classical non-private setting, we prove that under FDP an intrinsic adaptation cost is unavoidable. For pointwise estimation, where a logarithmic penalty is already known to arise in the non-private setting, we show that FDP introduces an additional logarithmic factor, thereby compounding the cost of adaptation. Taken together, these results provide the first rigorous characterization of the adaptive privacy-accuracy trade-off."}
{"id": "2512.14072", "categories": ["math.PR", "math.DG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14072", "abs": "https://arxiv.org/abs/2512.14072", "authors": ["Zijian Xu"], "title": "Monge solutions and uniqueness in multi-marginal optimal transport with hierarchical jumps", "comment": "23 pages", "summary": "We introduce Hierarchical Jump multi-marginal transport (HJMOT), a generalization of multi-marginal optimal transport where mass can \"jump\" over intermediate spaces via augmented isolated points. Established on Polish spaces, the framework guarantees the existence of Kantorovich solutions and, under sequential differentiability and a twist condition, the existence and uniqueness of Monge solutions. This core theory extends robustly to diverse settings, including smooth Riemannian manifolds, demonstrating its versatility as a unified framework for optimal transport across complex geometries."}
{"id": "2512.13975", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.13975", "abs": "https://arxiv.org/abs/2512.13975", "authors": ["Marc Dambrine", "Helmut Harbrecht"], "title": "An inverse problem for the one-phase Stefan problem with varying melting temperature", "comment": null, "summary": "The present article is dedicated to the forward and backward solution of a transient one-phase Stefan problem. In the forward problem, we compute the evolution of the initial domain for a Stefan problem where the melting temperature varies over time. This occurs in practice, for example, when the pressure in the external space changes in time. In the corresponding backward problem, we then reconstruct the time-dependent melting temperature from the knowledge of the evolving geometry. We develop respective numerical algorithms using a moving mesh finite element method and provide numerical simulations."}
{"id": "2512.14246", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.14246", "abs": "https://arxiv.org/abs/2512.14246", "authors": ["Evgenii Chzhen", "Mohamed Hebiri", "Gayane Taturyan"], "title": "Randomized multi-class classification under system constraints: a unified approach via post-processing", "comment": null, "summary": "We study the problem of multi-class classification under system-level constraints expressible as linear functionals over randomized classifiers. We propose a post-processing approach that adjusts a given base classifier to satisfy general constraints without retraining. Our method formulates the problem as a linearly constrained stochastic program over randomized classifiers, and leverages entropic regularization and dual optimization techniques to construct a feasible solution. We provide finite-sample guarantees for the risk and constraint satisfaction for the final output of our algorithm under minimal assumptions. The framework accommodates a broad class of constraints, including fairness, abstention, and churn requirements."}
{"id": "2512.14473", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.14473", "abs": "https://arxiv.org/abs/2512.14473", "authors": ["Guillaume Lecué", "Zhifan Li", "Zong Shang"], "title": "Sharp convergence rates for Spectral methods via the feature space decomposition method", "comment": null, "summary": "In this paper, we apply the Feature Space Decomposition (FSD) method developed in [LS24, GLS25, ALSS26] to obtain, under fairly general conditions, matching upper and lower bounds for the population excess risk of spectral methods in linear regression under the squared loss, for every covariance and every signal. This result enables us, for a given linear regression problem, to define a partial order on the set of spectral methods according to their convergence rates, thereby characterizing which spectral algorithm is superior for that specific problem. Furthermore, this allows us to generalize the saturation effect proposed in inverse problems and to provide necessary and sufficient conditions for its occurrence. Our method also shows that, under broad conditions, any spectral algorithm lacks a feature learning property, and therefore cannot overcome the barrier of the information exponent in problems such as single-index learning."}
{"id": "2512.14152", "categories": ["math.PR", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.14152", "abs": "https://arxiv.org/abs/2512.14152", "authors": ["Frank Aurzada", "Kilian Raschel"], "title": "Persistence probabilities of MA(1) sequences with Laplace innovations and $q$-deformed zigzag numbers", "comment": "21 pages", "summary": "We study the persistence probabilities of a moving average process of order one with innovations that follow a Laplace distribution. The persistence probabilities can be computed fully explicitly in terms of classical combinatorial quantities like certain $q$-Pochhammer symbols or $q$-deformed analogues of Euler's zigzag numbers, respectively. Similarly, the generating functions of the persistence probabilities can be written in terms of $q$-analogues of the exponential function or the $q$-sine/$q$-cosine functions, respectively."}
{"id": "2512.13993", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.13993", "abs": "https://arxiv.org/abs/2512.13993", "authors": ["Nicholas J. E. Richardson", "Noah Marusenko", "Michael P. Friedlander"], "title": "Multiple Scale Methods For Optimization Of Discretized Continuous Functions", "comment": "25 pages, 8 figures, supplemental materials is 28 pages", "summary": "A multiscale optimization framework for problems over a space of Lipschitz continuous functions is developed. The method solves a coarse-grid discretization followed by linear interpolation to warm-start project gradient descent on progressively finer grids. Greedy and lazy variants are analyzed and convergence guarantees are derived that show the multiscale approach achieves provably tighter error bounds at lower computational cost than single-scale optimization. The analysis extends to any base algorithm with iterate convergence at a fixed rate. Constraint modification techniques preserve feasibility across scales. Numerical experiments on probability density estimation problems, including geological data, demonstrate speedups of an order of magnitude or better."}
{"id": "2512.14387", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.14387", "abs": "https://arxiv.org/abs/2512.14387", "authors": ["Fabio DiFonzo", "Michael Holst", "Morteza Kimiaei", "Vyacheslav Kungurtsev", "Songqiang Qiu"], "title": "Towards Real Time Control of Water Engineering with Nonlinear Hyperbolic Partial Differential Equations", "comment": null, "summary": "This paper examines aspirational requirements for software addressing mixed-integer optimization problems constrained by the nonlinear Shallow Water partial differential equations (PDEs), motivated by applications such as river-flow management in hydropower cascades. Realistic deployment of such software would require the simultaneous treatment of nonlinear and potentially non-smooth PDE dynamics, limited theoretical guarantees on the existence and regularity of control-to-state mappings under varying boundary conditions, and computational performance compatible with operational decision-making. In addition, practical settings motivate consideration of uncertainty arising from forecasts of demand, inflows, and environmental conditions. At present, the theoretical foundations, numerical optimization methods, and large-scale scientific computing tools required to address these challenges in a unified and tractable manner remain the subject of ongoing research across the associated research communities. Rather than proposing a complete solution, this work uses the problem as a case study to identify and organize the mathematical, algorithmic, and computational components that would be necessary for its realization. The resulting framework highlights open challenges and intermediate research directions, and may inform both more circumscribed related problems and the design of future large-scale collaborative efforts aimed at addressing such objectives."}
{"id": "2512.14567", "categories": ["math.ST", "cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.14567", "abs": "https://arxiv.org/abs/2512.14567", "authors": ["Timothy L. H. Wee", "Cheng Mao"], "title": "Cluster expansion of the log-likelihood ratio: Optimal detection of planted matchings", "comment": "81 pages, 9 figures", "summary": "To understand how hidden information can be extracted from statistical networks, planted models in random graphs have been the focus of intensive study in recent years. In this work, we consider the detection of a planted matching, i.e., an independent edge set, hidden in an Erdős-Rényi random graph, which is formulated as a hypothesis testing problem. We identify the critical regime for this testing problem and prove that the log-likelihood ratio is asymptotically normal. Via analyses of computationally efficient edge or wedge count test statistics that attain the optimal limits of detection, our results also reveal the absence of a statistical-to-computational gap. Our main technical tool is the cluster expansion from statistical physics, which allows us to prove a precise, non-asymptotic characterization of the log-likelihood ratio. Our analyses rely on a careful reorganization and cancellation of terms that occur in the difference between monomer-dimer log partition functions on the complete and Erdős-Rényi graphs. This combinatorial and statistical physics approach represents a significant departure from the more established methods such as orthogonal decompositions, and positions the cluster expansion as a viable technique in the study of log-likelihood ratios for planted models in general."}
{"id": "2512.14248", "categories": ["math.PR", "math.FA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14248", "abs": "https://arxiv.org/abs/2512.14248", "authors": ["Michael Hinz", "Jonas M. Tölle", "Lauri Viitasaari"], "title": "On fractal minimizers and potentials of occupation measures", "comment": null, "summary": "We consider four prototypes of variational problems and prove the existence of fractal minimizers through the direct method in the calculus of variations. By design these minimizers are Hölder curves or Hölder parametrizations of hypersurfaces whose images generally have a non-integer Hausdorff dimension. Although their origin is deterministic, their regularity properties are roughly similar to those of typical realizations of stochastic processes. As a key tool, we prove novel continuity and boundedness results for potentials of occupation measures of Gaussian random fields. These results complement well-known results for local times, but hold under much less restrictive assumptions. In an auxiliary section, we generalize earlier results on non-linear compositions of fractional Sobolev functions with $BV$-functions to higher dimensions."}
{"id": "2512.14089", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14089", "abs": "https://arxiv.org/abs/2512.14089", "authors": ["Taylan Demir", "Atakan Koçyiğit"], "title": "Adaptive Wavelet-Galerkin Modelling of Heat Conduction in Heterogeneous Composite Materials", "comment": "12 pages, 3 figures", "summary": "We present an adaptive wavelet Galerkin method for transient heat conduction in heterogeneous composite materials. The approach combines multiresolution wavelet bases with an implicit time discretization to efficiently resolve sharp temperature gradients near material interfaces and boundary layers. Adaptive refinement is driven by wavelet coefficients, significantly reducing the number of degrees of freedom compared to uniform discretizations. Numerical examples demonstrate accurate resolution of layered, inclusion-based, and functionally graded composites with improved computational efficiency."}
{"id": "2512.14468", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.14468", "abs": "https://arxiv.org/abs/2512.14468", "authors": ["Xinhua Shen", "Hongpeng Sun"], "title": "A preconditioned second-order convex splitting algorithm with extrapolation", "comment": null, "summary": "Nonconvex optimization problems are widespread in modern machine learning and data science. We introduce an extrapolation strategy into a class of preconditioned second-order convex splitting algorithms for nonconvex optimization problems. The proposed algorithms combine second-order backward differentiation formulas (BDF2) with an extrapolation method. Meanwhile, the implicit-explicit scheme simplifies the subproblem through a preconditioned process. As a result, our approach solves nonconvex problems efficiently without significant computational overhead. Theoretical analysis establishes global convergence of the algorithms using Kurdyka-Łojasiewicz properties. Numerical experiments include a benchmark problem, the least squares problem with SCAD regularization, and an image segmentation problem. These results demonstrate that our algorithms are highly efficient, as they achieve reduced solution times and competitive performance."}
{"id": "2512.14624", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.14624", "abs": "https://arxiv.org/abs/2512.14624", "authors": ["Rebecca M. Lewis", "Oliver Y. Feng", "Henry W. J. Reeve", "Min Xu", "Richard J. Samworth"], "title": "Learning the score under shape constraints", "comment": "70 pages, 5 figures", "summary": "Score estimation has recently emerged as a key modern statistical challenge, due to its pivotal role in generative modelling via diffusion models. Moreover, it is an essential ingredient in a new approach to linear regression via convex $M$-estimation, where the corresponding error densities are projected onto the log-concave class. Motivated by these applications, we study the minimax risk of score estimation with respect to squared $L^2(P_0)$-loss, where $P_0$ denotes an underlying log-concave distribution on $\\mathbb{R}$. Such distributions have decreasing score functions, but on its own, this shape constraint is insufficient to guarantee a finite minimax risk. We therefore define subclasses of log-concave densities that capture two fundamental aspects of the estimation problem. First, we establish the crucial impact of tail behaviour on score estimation by determining the minimax rate over a class of log-concave densities whose score function exhibits controlled growth relative to the quantile levels. Second, we explore the interplay between smoothness and log-concavity by considering the class of log-concave densities with a scale restriction and a $(β,L)$-Hölder assumption on the log-density for some $β\\in [1,2]$. We show that the minimax risk over this latter class is of order $L^{2/(2β+1)}n^{-β/(2β+1)}$ up to poly-logarithmic factors, where $n$ denotes the sample size. When $β< 2$, this rate is faster than could be obtained under either the shape constraint or the smoothness assumption alone. Our upper bounds are attained by a locally adaptive, multiscale estimator constructed from a uniform confidence band for the score function. This study highlights intriguing differences between the score estimation and density estimation problems over this shape-constrained class."}
{"id": "2512.14264", "categories": ["math.PR", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.14264", "abs": "https://arxiv.org/abs/2512.14264", "authors": ["I. Bailleul"], "title": "Five lectures on regularity structures and SPDEs", "comment": "52 pages", "summary": "This set of five lectures provides an introduction to regularity structures and their use for the study of singular stochastic partial differential equations. Two appendices provide some additional informations that enter in the main text either as some technical results or as some results that deepen the context within which we set these lectures."}
{"id": "2512.14163", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14163", "abs": "https://arxiv.org/abs/2512.14163", "authors": ["Ole Løseth Elvetun", "Bjørn Fredrik Nielsen", "Niranjana Sudheer"], "title": "Weighted Group Lasso for a static EEG problem", "comment": null, "summary": "We investigate the weighted Group Lasso formulation for the static inverse electroencephalography (EEG) problem, aiming at reconstructing the unknown underlying neuronal sources from voltage measurements on the scalp. By modelling the three orthogonal dipole components at each location as a single coherent group, we demonstrate that depth bias and orientation bias can be effectively mitigated through the proposed regularization framework. On the theoretical front, we provide concise recovery guarantees for both single and multiple group sources. Our numerical experiments highlight that while theoretical bounds hold for a broad range of weight definitions, the practical reconstruction quality, for cases not covered by the theory, depends significantly on the specific weighting strategy employed. Specifically, employing a truncated Moore-Penrose pseudoinverse for the involved weighting matrix gives a small Dipole Localization Error (DLE). The proposed method offers a robust approach for inverse EEG problems, enabling improved spatial accuracy and a more physiologically realistic reconstruction of neural activity."}
{"id": "2512.14507", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.14507", "abs": "https://arxiv.org/abs/2512.14507", "authors": ["Nathan Allaire", "Sébastien Le Digabel", "Dominique Orban"], "title": "An Inexact Modified Quasi-Newton Method for Nonsmooth Regularized Optimization", "comment": null, "summary": "We introduce iR2N, a modified proximal quasi-Newton method for minimizing the sum of a smooth function $f$ and a lower semi-continuous prox-bounded function $h$, allowing inexact evaluations of $f$, its gradient, and the associated proximal operators. Both $f$ and $h$ may be nonconvex. iR2N is particularly suited to settings where proximal operators are computed via iterative procedures that can be stopped early, or where the accuracy of $f$ and $\\nabla f$ can be controlled, leading to significant computational savings. At each iteration, the method approximately minimizes the sum of a quadratic model of $f$, a model of $h$, and an adaptive quadratic regularization term ensuring global convergence. Under standard accuracy assumptions, we prove global convergence in the sense that a first-order stationarity measure converges to zero, with worst-case evaluation complexity $O(ε^{-2})$. Numerical experiments with $\\ell_p$ norms, $\\ell_p$ total variation, and the indicator of the nonconvex pseudo $p$-norm ball illustrate the effectiveness and flexibility of the approach, and show how controlled inexactness can substantially reduce computational effort."}
{"id": "2512.14584", "categories": ["math.PR"], "pdf": "https://arxiv.org/pdf/2512.14584", "abs": "https://arxiv.org/abs/2512.14584", "authors": ["David A. Henriquez Bernal", "Peter Nejjar"], "title": "Limit profiles of ASEP", "comment": null, "summary": "We study the asymmetric simple exclusion process (ASEP) on a segment $\\{1,\\ldots,b_N\\}$ and are interested in its total variation distance to equilibrium when started from an initial configuration $ξ^{N}$. We provide a general result which gives the cutoff window and profile whenever a KPZ-type limit theorem is available for an extension of $ξ^{N}$ to $\\mathbb{Z}$. We apply this result to obtain the cutoff window and profile of ASEP on the segment with flat, half-flat and step initial data. Our arguments are entirely probabilistic and make no use of Hecke algebras."}
{"id": "2512.14193", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14193", "abs": "https://arxiv.org/abs/2512.14193", "authors": ["Yasuhiro Matsumoto", "Kei Matsushima"], "title": "Efficient LU factorization exploiting direct-indirect Burton-Miller equation for Helmholtz transmission problems", "comment": null, "summary": "This paper proposes a direct-indirect mixed Burton-Miller boundary integral equation for solving Helmholtz scattering problems with transmissive scatterers. The proposed formulation has three unknowns, one more than the number of unknowns for the ordinary formulation. However, we can construct efficient numerical solvers based on LU factorization by exploiting the sparse alignment of the boundary integral operators of the proposed formulation. Numerical examples demonstrate that the direct solver based on the proposed formulation is approximately 40% faster than the ordinary formulation when the LU-factorization-based solver is used. In addition, the proposed formulation is applied to a fast direct solver employing LU factorization in its algorithm. In the application to the fast direct solver, the proxy method with a weak admissibility low-rank approximation is developed. The speedup achieved using the proposed formulation is also shown to be effective in finding nonlinear eigenvalues, which are related to the uniqueness of the solution, in boundary value problems. Furthermore, the well-posedness of the proposed boundary integral equation is established for scatterers with boundaries of class $C^2$, using the mapping property of boundary integral operators in Hölder space."}
{"id": "2512.14520", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.14520", "abs": "https://arxiv.org/abs/2512.14520", "authors": ["Aihui Liu", "Magnus Jansson"], "title": "The Innovation Null Space of the Kalman Predictor: A Stochastic Perspective for DeePC", "comment": null, "summary": "Willems' fundamental lemma uses a key decision variable $g$ to combine measured input-output data and describe trajectories of a linear time-invariant system. In this paper, we ask: what is a good choice for this vector $g$ when the system is affected by noise? For a linear system with Gaussian noise, we show that there exists an optimal subspace for this decision variable $g$, which is the null space of the innovation Hankel matrix. If the decision vector lies in this null space, the resulting predictor gets closer to the Kalman predictor. To show this, we use a result that we refer to as the Kalman Filter Fundamental Lemma (KFFL), which applies Willems' lemma to the Kalman predictor. This viewpoint also explains several existing data-driven predictive control methods: regularized DeePC schemes act as soft versions of the innovation null-space constraint, instrumental-variable methods enforce it by construction, and ARX-based approaches explicitly estimate this innovation null space."}
{"id": "2512.14567", "categories": ["math.ST", "cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.14567", "abs": "https://arxiv.org/abs/2512.14567", "authors": ["Timothy L. H. Wee", "Cheng Mao"], "title": "Cluster expansion of the log-likelihood ratio: Optimal detection of planted matchings", "comment": "81 pages, 9 figures", "summary": "To understand how hidden information can be extracted from statistical networks, planted models in random graphs have been the focus of intensive study in recent years. In this work, we consider the detection of a planted matching, i.e., an independent edge set, hidden in an Erdős-Rényi random graph, which is formulated as a hypothesis testing problem. We identify the critical regime for this testing problem and prove that the log-likelihood ratio is asymptotically normal. Via analyses of computationally efficient edge or wedge count test statistics that attain the optimal limits of detection, our results also reveal the absence of a statistical-to-computational gap. Our main technical tool is the cluster expansion from statistical physics, which allows us to prove a precise, non-asymptotic characterization of the log-likelihood ratio. Our analyses rely on a careful reorganization and cancellation of terms that occur in the difference between monomer-dimer log partition functions on the complete and Erdős-Rényi graphs. This combinatorial and statistical physics approach represents a significant departure from the more established methods such as orthogonal decompositions, and positions the cluster expansion as a viable technique in the study of log-likelihood ratios for planted models in general."}
{"id": "2512.14219", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14219", "abs": "https://arxiv.org/abs/2512.14219", "authors": ["Weifeng Qiu"], "title": "Analysis of a finite element method for second order uniformly elliptic PDEs in non-divergence form", "comment": null, "summary": "We propose one finite element method for both second order linear uniformly elliptic PDE in non-divergence form and the elliptic Hamilton-Jacobi-Bellman (HJB) equation. For the linear elliptic PDE in non-divergence form, we consider two scenarios of the matrix coefficient matrix $A$. One is $A$ is uniformly continuous. The other is $A$ is discontinuous but $γA$ is dominated by $I_{d}$ where $γ$ is a positive weight function.\n  We prove that optimal convergence in discrete $W^{2,p}$-norm of the numerical approximation to the strong solution for $1<p\\leq 2$ on convex polyhedra in $\\mathbb{R}^{d}$ ($d=2,3$). If the domain is a two dimensional non-convex polygon, $p$ is valid in a neighbourhood of $\\frac{4}{3}$. We also prove the well-posedness of strong solution in $W^{2,p}(Ω)$ for both linear elliptic PDE in non-divergence form and the HJB equation for $1< p \\leq 2$ on convex polyhedra in $\\mathbb{R}^{d}$ ($d=2,3$) and for $p$ in an open interval starting from $1$ and including $\\frac{4}{3}$ on two dimensional non-convex polygon. Furthermore, we relax the assumptions on the continuity of coefficients of the HJB equation, which have been widely used in literature."}
{"id": "2512.14682", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.14682", "abs": "https://arxiv.org/abs/2512.14682", "authors": ["David O. Williams Rogers", "Hang Woon Lee"], "title": "Enhancing Orbital Debris Remediation with Reconfigurable Space-Based Laser Constellations", "comment": "Accepted to the 2026 IEEE Aerospace Conference", "summary": "Orbital debris poses an escalating threat to space missions and the long-term sustainability of Earth's orbital environment. The literature proposes various approaches for orbital debris remediation, including the use of multiple space-based lasers that collaboratively engage debris targets. While the proof of concept for this laser-based approach has been demonstrated, critical questions remain about its scalability and responsiveness as the debris population continues to expand rapidly. This paper introduces constellation reconfiguration as a system-level strategy to address these limitations. Through coordinated orbital maneuvers, laser-equipped satellites can dynamically adapt their positions to respond to evolving debris distributions and time-critical events. We formalize this concept as the Reconfigurable Laser-to-Debris Engagement Scheduling Problem (R-L2D-ESP), an optimization framework that determines the optimal sequence of constellation reconfigurations and laser engagements to maximize debris remediation capacity, which quantifies the constellation's ability to nudge, deorbit, or perform just-in-time collision avoidance maneuvers on debris objects. To manage the complexity of this combinatorial optimization problem, we employ a receding horizon approach. Our experiments reveal that reconfigurable constellations significantly outperform static ones, achieving greater debris remediation capacity and successfully deorbiting substantially more debris objects. Additionally, our sensitivity analyses identify the key parameters that influence remediation performance the most, providing essential insights for future system design. These findings demonstrate that constellation reconfiguration represents a promising advancement for laser-based debris removal systems, offering the adaptability and scalability necessary to enhance this particular approach to orbital debris remediation."}
{"id": "2512.14231", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14231", "abs": "https://arxiv.org/abs/2512.14231", "authors": ["Kevin Dijkstra", "Deepesh Toshniwal"], "title": "Structure-preserving Variational Multiscale Stabilization of the Incompressible Navier-Stokes Equations", "comment": null, "summary": "This paper introduces a Variational Multiscale Stabilization (VMS) formulation of the incompressible Navier--Stokes equations that utilizes the Finite Element Exterior Calculus (FEEC) framework. The FEEC framework preserves the geometric and topological structure of continuous spaces and PDEs in the discrete spaces and model, and helps build stable and convergent discretizations. For the Navier-Stokes equations, this structure is encoded in the de Rham complex. In this work, we consider the vorticity-velocity-pressure formulation discretized within the FEEC framework. We model the effect of the unresolved scales on the finite-dimensional solution by introducing appropriate fine-scale governing equations, which we also discretize using the FEEC approach. This preserves the structure of the continuous problem in both the coarse- and fine-scale solutions; for instance, both the coarse- and fine-scale velocities are pointwise incompressible. We demonstrate that the resulting formulation is residual-based, energetically stable, and optimally convergent. Moreover, our fine-scale model provides an efficient computational approach: by decoupling fine-scale problems across elements, they can be solved in parallel. In fact, the fine-scale equations can be eliminated during matrix assembly, leading to a VMS formulation in which the problem size is governed solely by the coarse-scale discretization. Finally, the proposed formulation applies to both the lowest regularity discretizations of the de Rham complex and high-regularity isogeometric discretizations. We validate our theoretical results through numerical experiments, simulating both steady-, unsteady-, viscous-, and inviscid-flow problems. These tests show that the stabilized solutions are qualitatively better than the unstabilized ones, converge at optimal rates, and, as the mesh is refined, the stabilization is asymptotically turned off."}
{"id": "2512.13993", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.13993", "abs": "https://arxiv.org/abs/2512.13993", "authors": ["Nicholas J. E. Richardson", "Noah Marusenko", "Michael P. Friedlander"], "title": "Multiple Scale Methods For Optimization Of Discretized Continuous Functions", "comment": "25 pages, 8 figures, supplemental materials is 28 pages", "summary": "A multiscale optimization framework for problems over a space of Lipschitz continuous functions is developed. The method solves a coarse-grid discretization followed by linear interpolation to warm-start project gradient descent on progressively finer grids. Greedy and lazy variants are analyzed and convergence guarantees are derived that show the multiscale approach achieves provably tighter error bounds at lower computational cost than single-scale optimization. The analysis extends to any base algorithm with iterate convergence at a fixed rate. Constraint modification techniques preserve feasibility across scales. Numerical experiments on probability density estimation problems, including geological data, demonstrate speedups of an order of magnitude or better."}
{"id": "2512.14258", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14258", "abs": "https://arxiv.org/abs/2512.14258", "authors": ["Marcin Baranek", "Paweł Przybyłowicz"], "title": "SPINNs -- Deep learning framework for approximation of stochastic differential equations", "comment": null, "summary": "In this paper, we introduce the SPINNs (stochastic physics-informed neural networks) in a systematic manner. This provides a mathematical framework for approximating the solution of stochastic differential equations (SDEs) driven by Levy noise using artificial neural networks."}
{"id": "2512.14072", "categories": ["math.PR", "math.DG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14072", "abs": "https://arxiv.org/abs/2512.14072", "authors": ["Zijian Xu"], "title": "Monge solutions and uniqueness in multi-marginal optimal transport with hierarchical jumps", "comment": "23 pages", "summary": "We introduce Hierarchical Jump multi-marginal transport (HJMOT), a generalization of multi-marginal optimal transport where mass can \"jump\" over intermediate spaces via augmented isolated points. Established on Polish spaces, the framework guarantees the existence of Kantorovich solutions and, under sequential differentiability and a twist condition, the existence and uniqueness of Monge solutions. This core theory extends robustly to diverse settings, including smooth Riemannian manifolds, demonstrating its versatility as a unified framework for optimal transport across complex geometries."}
{"id": "2512.14286", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14286", "abs": "https://arxiv.org/abs/2512.14286", "authors": ["Samuel Cruz Alegría", "Bindi Çapriqi", "Shega Likaj", "Ken Trotti", "Rolf Krause"], "title": "An Additively Preconditioned Trust Region Strategy for Machine Learning", "comment": "13 Pages", "summary": "Modern machine learning, especially the training of deep neural networks, depends on solving large-scale, highly nonconvex optimization problems, whose objective function exhibit a rough landscape. Motivated by the success of parallel preconditioners in the context of Krylov methods for large scale linear systems, we introduce a novel nonlinearly preconditioned Trust-Region method that makes use of an additive Schwarz correction at each minimization step, thereby accelerating convergence.\n  More precisely, we propose a variant of the Additively Preconditioned Trust-Region Strategy (APTS), which combines a right-preconditioned additive Schwarz framework with a classical Trust-Region algorithm. By decomposing the parameter space into sub-domains, APTS solves local non-linear sub-problems in parallel and assembles their corrections additively. The resulting method not only shows fast convergence; due to the underlying Trust-Region strategy, it furthermore largely obviates the need for hyperparameter tuning."}
{"id": "2512.14248", "categories": ["math.PR", "math.FA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14248", "abs": "https://arxiv.org/abs/2512.14248", "authors": ["Michael Hinz", "Jonas M. Tölle", "Lauri Viitasaari"], "title": "On fractal minimizers and potentials of occupation measures", "comment": null, "summary": "We consider four prototypes of variational problems and prove the existence of fractal minimizers through the direct method in the calculus of variations. By design these minimizers are Hölder curves or Hölder parametrizations of hypersurfaces whose images generally have a non-integer Hausdorff dimension. Although their origin is deterministic, their regularity properties are roughly similar to those of typical realizations of stochastic processes. As a key tool, we prove novel continuity and boundedness results for potentials of occupation measures of Gaussian random fields. These results complement well-known results for local times, but hold under much less restrictive assumptions. In an auxiliary section, we generalize earlier results on non-linear compositions of fractional Sobolev functions with $BV$-functions to higher dimensions."}
{"id": "2512.14301", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14301", "abs": "https://arxiv.org/abs/2512.14301", "authors": ["Rami Katz", "Dmitry Batenkov", "Giulia Giordano"], "title": "Separation-free exponential fitting with structured noise, with applications to inverse problems in parabolic PDEs", "comment": null, "summary": "We investigate the recovery of exponents and amplitudes of an exponential sum, where the exponents $\\left\\{λ_n \\right\\}_{n=1}^{N_1}$ are the first $N_1$ eigenvalues of a Sturm-Liouville operator, from finitely many measurements subject to measurement noise. This inverse problem is extremely ill-conditioned when the noise is arbitrary and unstructured. Surprisingly, however, the extreme ill-conditioning exhibited by this problem disappears when considering a \\emph{structured} noise term, taken as an exponential sum with exponents given by the subsequent eigenvalues $\\left\\{λ_n \\right\\}_{n=N_1+1}^{N_1+N_2}$ of the Sturm-Liouville operator, multiplied by a noise magnitude parameter $\\varepsilon>0$. In this case, we rigorously show that the exponents and amplitudes can be recovered with super-exponential accuracy: we both prove the theoretical result and show that it can be achieved numerically by a specific algorithm. By leveraging recent results on the mathematical theory of super-resolution, we show in this paper that the classical Prony's method attains the analytic optimal error decay also in the ``separation-free'' regime where $λ_n \\to \\infty$ as $n \\to \\infty$, thereby extending the applicability of Prony's method to new settings. As an application of our theoretical analysis, we show that the approximated eigenvalues obtained by our method can be used to recover an unknown potential in a linear reaction-diffusion equation from discrete solution traces."}
{"id": "2512.14286", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14286", "abs": "https://arxiv.org/abs/2512.14286", "authors": ["Samuel Cruz Alegría", "Bindi Çapriqi", "Shega Likaj", "Ken Trotti", "Rolf Krause"], "title": "An Additively Preconditioned Trust Region Strategy for Machine Learning", "comment": "13 Pages", "summary": "Modern machine learning, especially the training of deep neural networks, depends on solving large-scale, highly nonconvex optimization problems, whose objective function exhibit a rough landscape. Motivated by the success of parallel preconditioners in the context of Krylov methods for large scale linear systems, we introduce a novel nonlinearly preconditioned Trust-Region method that makes use of an additive Schwarz correction at each minimization step, thereby accelerating convergence.\n  More precisely, we propose a variant of the Additively Preconditioned Trust-Region Strategy (APTS), which combines a right-preconditioned additive Schwarz framework with a classical Trust-Region algorithm. By decomposing the parameter space into sub-domains, APTS solves local non-linear sub-problems in parallel and assembles their corrections additively. The resulting method not only shows fast convergence; due to the underlying Trust-Region strategy, it furthermore largely obviates the need for hyperparameter tuning."}
{"id": "2512.14416", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14416", "abs": "https://arxiv.org/abs/2512.14416", "authors": ["Björn Liljegren-Sailer"], "title": "Reducing Training Complexity in Empirical Quadrature-Based Model Reduction via Structured Compression", "comment": null, "summary": "Model order reduction seeks to approximate large-scale dynamical systems by lower-dimensional reduced models. For linear systems, a small reduced dimension directly translates into low computational cost, ensuring online efficiency. This property does not generally hold for nonlinear systems, where an additional approximation of nonlinear terms -- known as complexity reduction -- is required. To achieve online efficiency, empirical quadrature and cell-based empirical cubature are among the most effective complexity reduction techniques. However, existing offline training algorithms can be prohibitively expensive because they operate on raw snapshot data of all nonlinear integrands associated with the reduced model. In this paper, we introduce a preprocessing approach based on a specific structured compression of the training data. Its key feature is that it scales only with the number of collected snapshots, rather than additionally with the reduced model dimension. Overall, this yields roughly an order-of-magnitude reduction in offline computational cost and memory requirements, thereby enabling the application of the complexity reduction methods to larger-scale problems. Accuracy is preserved, as indicated by our error analysis and demonstrated through numerical examples."}
{"id": "2512.14301", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.14301", "abs": "https://arxiv.org/abs/2512.14301", "authors": ["Rami Katz", "Dmitry Batenkov", "Giulia Giordano"], "title": "Separation-free exponential fitting with structured noise, with applications to inverse problems in parabolic PDEs", "comment": null, "summary": "We investigate the recovery of exponents and amplitudes of an exponential sum, where the exponents $\\left\\{λ_n \\right\\}_{n=1}^{N_1}$ are the first $N_1$ eigenvalues of a Sturm-Liouville operator, from finitely many measurements subject to measurement noise. This inverse problem is extremely ill-conditioned when the noise is arbitrary and unstructured. Surprisingly, however, the extreme ill-conditioning exhibited by this problem disappears when considering a \\emph{structured} noise term, taken as an exponential sum with exponents given by the subsequent eigenvalues $\\left\\{λ_n \\right\\}_{n=N_1+1}^{N_1+N_2}$ of the Sturm-Liouville operator, multiplied by a noise magnitude parameter $\\varepsilon>0$. In this case, we rigorously show that the exponents and amplitudes can be recovered with super-exponential accuracy: we both prove the theoretical result and show that it can be achieved numerically by a specific algorithm. By leveraging recent results on the mathematical theory of super-resolution, we show in this paper that the classical Prony's method attains the analytic optimal error decay also in the ``separation-free'' regime where $λ_n \\to \\infty$ as $n \\to \\infty$, thereby extending the applicability of Prony's method to new settings. As an application of our theoretical analysis, we show that the approximated eigenvalues obtained by our method can be used to recover an unknown potential in a linear reaction-diffusion equation from discrete solution traces."}
{"id": "2512.14419", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14419", "abs": "https://arxiv.org/abs/2512.14419", "authors": ["Xiaoqi Ma", "Jin Zhang"], "title": "Semi-robust equal-order hybridized discontinuous methods", "comment": null, "summary": "This paper introduces a unified analysis framework of equal-order hybridized discontinuous finite element (HDG) methods. The general framework covers standard HDG, embedded discontinuous finite element, and embedded-hybridized discontinuous finite element methods."}
{"id": "2512.14467", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14467", "abs": "https://arxiv.org/abs/2512.14467", "authors": ["Neelakantan Padmanabhan"], "title": "Ensemble Parameter Estimation for the LPLSP Framework: A Rapid Approach to Reduced-Order Modeling for Transient Thermal Systems", "comment": null, "summary": "This work introduces an ensemble parameter estimation framework that enables the Lumped Parameter Linear Superposition (LPLSP) method to generate reduced order thermal models from a single transient dataset. Unlike earlier implementations that relied on multiple parametric simulations to excite each heat source independently, the proposed approach simultaneously identifies all model coefficients using fully transient excitations. Two estimation strategies namely rank-reduction and two-stage decomposition are developed to further reduce computational cost and improve scalability for larger systems. The proposed strategies yield ROMs with mean temperature-prediction errors within 5% of CFD simulations while reducing model-development times to O(10^0 s)-O(10^1 s). Once constructed, the ROM evaluates new transient operating conditions in O(10^0 s), enabling rapid thermal analysis and enabling automated generation of digital twins for both simulated and physical systems."}
{"id": "2512.14570", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.14570", "abs": "https://arxiv.org/abs/2512.14570", "authors": ["Zhaonan Dong", "Tanvi Wadhawan"], "title": "On the constants in inverse trace inequalities for polynomials orthogonal to lower-order subspaces", "comment": null, "summary": "We derive sharp, explicit constants in inverse trace inequalities for polynomial functions belonging to $\\mathbb{P}_p(T)$ (polynomial space with total degree $p$) that are orthogonal to the lower-order subspace $\\mathbb{P}_n(T)$, $n\\leq p$, where $T$ denotes a $d$-dimensional simplex. The proofs rely on orthogonal polynomial expansions on reference simplices and on a careful analysis of the eigenvalues of the relevant blocks of the face mass matrices, following the arguments developed in [9]. These results are very useful in the $hp$-analysis of the hybrid Galerkin methods, e.g. hybridizable discontinuous Galerkin methods, hybrid high-order methods, etc."}
{"id": "2512.14590", "categories": ["math.NA", "cs.GR", "math.DG"], "pdf": "https://arxiv.org/pdf/2512.14590", "abs": "https://arxiv.org/abs/2512.14590", "authors": ["Henrik Schumacher", "Jannik Rönsch", "Thorsten Hohage", "Max Wardetzky"], "title": "Inverse obstacle scattering regularized by the tangent-point energy", "comment": "46 pages, 13 figures, 4 tables", "summary": "We employ the so-called tangent-point energy as Tikhonov regularizer for ill-conditioned inverse scattering problems in 3D. The tangent-point energy is a self-avoiding functional on the space of embedded surfaces that also penalizes surface roughness. Moreover, it features nice compactness and continuity properties. These allow us to show the well-posedness of the regularized problems and the convergence of the regularized solutions to the true solution in the limit of vanishing noise level. We also provide a reconstruction algorithm of iteratively regularized Gauss-Newton type. Our numerical experiments demonstrate that our method is numerically feasible and effective in producing reconstructions of unprecedented quality."}
{"id": "2512.14124", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.14124", "abs": "https://arxiv.org/abs/2512.14124", "authors": ["Boris S. Mordukhovich", "Peipei Tang", "Chengjing Wang"], "title": "Complete Characterizations of Well-Posedness in Parametric Composite Optimization", "comment": null, "summary": "This paper provides complete characterization of well-posedness for Karush-Kuhn-Tucker (KKT) systems associated with general problems of perturbed composite optimization. Leveraging the property of parabolic regularity for composite models, we show that the second-order subderivative of the cost function reduces to the novel second-order variational function playing a crucial role in the subsequent analysis. This foundational result implies that the strong second-order sufficient condition (SSOSC) introduced in this work for the general class of composite optimization problems naturally extends the classical second-order sufficient condition in nonlinear programming. Then we obtain several equivalent characterizations of the second-order qualification condition (SOQC) and highlight its equivalence to the constraint nondegeneracy condition under the $\\mathcal{C}^{2}$-cone reducibility assumption. These insights lead us to multiple equivalent conditions for the major Lipschitz-like/Aubin property of KKT systems, including the SOQC combined with the new second-order subdifferential condition and the SOQC combined with tilt stability of local minimizers. Furthermore, under $\\mathcal{C}^{2}$-cone reducibility, we prove that the Lipschitz-like property of the reference KKT system is equivalent to its strong regularity. Finally, we demonstrate that the Lipschitz-like property is equivalent to the nonsingularity of the generalized Jacobian associated with the KKT system under a certain verifiable assumption. These results provide a unified and rigorous framework for analyzing stability and sensitivity of solutions to composite optimization problems, as well as for the design and justification of numerical algorithms."}
{"id": "2512.14468", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.14468", "abs": "https://arxiv.org/abs/2512.14468", "authors": ["Xinhua Shen", "Hongpeng Sun"], "title": "A preconditioned second-order convex splitting algorithm with extrapolation", "comment": null, "summary": "Nonconvex optimization problems are widespread in modern machine learning and data science. We introduce an extrapolation strategy into a class of preconditioned second-order convex splitting algorithms for nonconvex optimization problems. The proposed algorithms combine second-order backward differentiation formulas (BDF2) with an extrapolation method. Meanwhile, the implicit-explicit scheme simplifies the subproblem through a preconditioned process. As a result, our approach solves nonconvex problems efficiently without significant computational overhead. Theoretical analysis establishes global convergence of the algorithms using Kurdyka-Łojasiewicz properties. Numerical experiments include a benchmark problem, the least squares problem with SCAD regularization, and an image segmentation problem. These results demonstrate that our algorithms are highly efficient, as they achieve reduced solution times and competitive performance."}
